1:

 
 
 
Welcome back, Community friends! 
 
Dynatrace Community updatesSeptember's hottest discussionsSeptember's product idea updatesMust-see threadsSeptember's top contributors Additional round of applauseMembers of the MonthThe September challenge overviewEvents and webinars in October - save the date!What's to look forward to?Thanks for being with us! See you in November!
 
 
 Dynatrace Community updates
 
 Our Community went through a large clean-up of the Product Ideas Forum! We reviewed all ideas raised in between 2017-2021 with the status "New," moderated labels and titles if needed, and evaluated each to make a decision on whether to archive or not. You can find the summary here.
 
 Following the trend, we've updated our Community policy on using of AI chatbots in generating answers. To summarize, such content can be used only for reference and must be clearly marked as such. Read more about it here.
 
 We've introduced two new filtering option for our forum: "Followed forums" and "Followed labels", so now you can choose to view only content you're interested in on the main page of the Community 
 
 The new edition of the Developer Newsletter for October 2023 is here ‌‌ Make sure to give it a read!
 
 September's hottest discussions
 




#


Community topics


Views




1.

easyTravel Documentation and Download
1,165



2.

Take the "Taste From the Past" Challenge! ‌
359



3.

Introducing Monaco 2.0 – Dynatrace Configuration as Code
309



4.

HTTP status codes 970-979
296



5.

Dynatrace associate exam preparation
279



6.

Dynatrace technology support roadmap
277



7.

Dynatrace Associate certification mock exam
272



8.

Troubleshoot Kubernetes ErrorImagePullBackOff
267



9.

Product Idea Newsletter for September 2023
260



10.

JVM Heap Metrics on Dynatrace
252



 
 
 September's product idea updates
 
Since the beginning of 2023, product idea updates are published in the dedicated Product Idea News!
 Explore the latest edition 
 
 
 
 
To get notified about next editions of the newsletter, follow the label 
 
 
 
 Must-see threads
 
Content you can't miss:
 
 Are you coming to Dynatrace Innovate 2023 in Barcelona? It may be a chance to catch up with fellow Community members, see this post.
 Got any feedback for the latest Dynatrace? This is your to-go place to do so! 
 
 
Tips and tricks:


 

 PRO TIP - Excluding Monitoring Construct for Alerts
 How to check from browser app if Session Replay is enabled ?



 



 
 Dynatrace Tips & Tricks - Episode #15 - SLO Error Budget Burn Rate Based Alerting 


 
Troubleshooting articles:
 
 Hostgroup is not showing in new (non-classic) Host View
 Service shown as Requests executed in background threads (Microsoft.AspNetCore.Hosting.HttpRequestI...
 Missing Synthetic screenshots. Information and how to troubleshoot
 How do I get logs from a pod that is crashing or in crashloopbackoff ? cloudNativeFullStack/PaaS/Ap...
 How do we change default port settings to 443 from 8443 for the cluster that set up a cluster versi...
 How to generate a HAR file and enable dtHealthCheck.
Heads-up from Dynatrace:
 Dynatrace CVE status (Common Vulnerabilities and Exposures)
 CSI Driver pods with Dynatrace Operator 0.13.0 rejected by admission-webhook in GKE autopilot
 New Service Overview page does not show Throughput values
 Crashes/ segfaults seen on Alpine Linux Edge when OneAgent enabled *Updated 2023/9/20
 Dynatrace Managed backup includes Log Monitoring events even when disabled 
 
Share your feedback:
 
Elasticsearch monitoring extension update - feedback on the new version. It’s on the Hub now. 
 Hyper-V monitoring extension - feedback on the new version. It’s on the Hub now 
 Feedback channel for the enhancements to OpenTelemetry trace-ingest (Unified Services) released w/ ...
 
 September's top contributors
 
 
 
 
We're glad our Community is full of helpful and engaged people! Thank you: 
@Jamz, @radek_jasinski, @Julius_Loman, @Iplinsky, @Kenny_Gillette, @svedula, and @gilles_tabary!
 
 
  Additional round of applause
 
 @Abidyaseen for joining us in the Community Challenge section for the first time! Hope to see more of you there in the future 
 @Julius_Loman and @ChadTurner, our two Community Legends, for keeping a tie in the kudos leaderboard in the Q&A part of our forum, but also big applause to everyone who has offered a helping hand to our newcomers this month! 
 
 @Mohamed_Hamdy, @AntonPineiro and @Mizső for being the most frequently visiting members of the forum this month! Talk about not being able to live without our Community! 






 
 






 Members of the Month
 
 
 
Make sure to read the latest interviews with our extraordinarily engaged Customer/Partner and Dynatracer of the Month! Get to know them better either from a professional or after-hours perspective! 
 
 The September challenge overview
 
Last month Community members were asked to share their favorite tastes from the past, naming nostalgic dishes, snacks, or other types of food bringing forth some kind of memories for them. Find the details of the "Taste From the Past" Challenge below: 
 
 The "Taste From the Past" challenge
 
 Fascinating 36 answers submitted so far!
 Snacks and dishes from around the globe!
 Universal selection of great tastes either from the past or from now!
 
 
Share your food-related memories in the "Taste From the Past" Challenge, it's still on!
 
 Events and webinars in October - save the date!
 




 
 Thursday, October 5, 2023
Dynatrace INNOVATE | EMEA


 
 Thursday, October 5, 2023
 Get to Know Dynatrace Demo




 
 Monday, October 16, 2023
 Gartner Symposium | NA


 
 Tuesday, October 17, 2023
 Office hours for Dynatrace App development




 
 Thursday, October 19, 2023
 Dynatrace and Google Cloud: Intelligent Kubernetes...


 
 Thursday, October 19, 2023
 Get to Know Dynatrace Demo




 
 
 What's to look forward to?
 
  New Community Challenge - October 17, 2023
The last challenge makes our cookbooks bursting with new recipes and our heart - with emotions  We're so happy to be able to share this nostalgic journey with our beloved Community! Make sure to check the touching memories from all over world, meanwhile we at the Community team come up with something exciting for October 
 
 Brand new Community Newsletter layout!
We teased this exciting news last month, the Community Newsletter is under large reconstruction   Stay tuned, the next edition will surely include some "wow" factor!
 
 New and updated Community sub-forums
Following up on feedback we got from you in the survey, we will be moving some content around to ensure it has more visibility. We can't tell more now, but expect some new sub-forums in the upcoming weeks, and some minor changes to the Community navigation 
 
 DynaMight anniversary
 It's this time of year again, when we celebrate our most loyal and helpful warriors and invite new faces to join their ranks. The announcement will follow in the upcoming weeks 
 
Thanks for being with us! See you in November! 
 

----------------
1.1:

Excited but also a bit sad to say goodbye to this shape of the newsletter 

----------------
1.2:

"Next edition will surely include some "wow" factor!" Eager to see the new changes 

----------------
1.3:

I love this monthly newsletter! Sometimes we are away and this is a way to check on the most important things we might have missed...

----------------
2:

I am fairly good with the Dynatrace API V2 and with Data Explorer. However, pulling OpenShift statistics in Dynatrace is still a challenge to me.My question is - Can you pull OpenShift service statistics by Kubernetes namespace?It works fine if I do it by tag and service name.builtin:service.response.time:filter(and(and(in("dt.entity.service",entitySelector("type(service),tag(~"OpenShift Namespace:blah-blah~")")),in("dt.entity.service",entitySelector("type(service),entityName.contains(~"blah-blah-service-1~")"))))):splitBy("dt.entity.service"):avg:sort(value(avg,descending)):limit(20)Any help greatly appreciated.Lou

----------------
2.1:

Am I going down the wrong path for the query key. Rather than querying by Kubernetes namespace, should I stick to tag?Thinking about it, maybe tag is a wiser choice since services can span both cloud and non-cloud applications.

----------------
3:

So yeah, very simple query that I pretty much copied from the Grail Examples in the Dynatrace documentation:
 
 
timeseries usage=avg(dt.host.cpu.usage),
    by:{dt.entity.host},
    filter:{
      dt.entity.host in [
       fetch dt.entity.host
      | fieldsAdd hostGroupName
      | filter hostGroupName == "HOST_GROUP_A"
      | fields id
       ]
    }
 
 
 
That returns back the two hosts in that host group along with their entityId as the names.  However, if I change the
 
 
| fields id
 
 
line to
 
 
| fields entity.name
 
 
 I get no results... 
I changed nothing else other than that line.  Why in the world can I not get the name of the hosts instead? 
If I do a simple query like this:
 
 
fetch dt.entity.host
| filter hostGroupName == "HOST_GROUP_A"
 
 
I get back the two hosts in that group and it shows that each host has two fields, entity.name and id.  So why can't I use entity.name in the fields line?
I even tried doing a fieldsAdd entity.name and that doesn't work either.  I tried putting the fieldsAdd both inside of and outside of the filter block, but nothing works.  I get no results if I don't use id.  But who wants to have id on the charts?  Nobody will know which host is which...



					
						Solved!
					
					Go to Solution.




----------------
3.1:


Uggh, figured it out... For anyone that stumbles across this, it's really weird.Apparently there are two ways of filtering timeseries data in DQL:in and lookup. in has better performance, but you're restricted to use whatever fields are part of the timeseries command output, which are just the metric, the timestamps, and the entityID of whatever you're querying.  No name data or anything like that (which honestly makes it kind of useless... Who wants to display metric data with Entity ID's?  People want readable names...)lookup doesn't perform as well, but, you can add in any fields you want to be fed to the output, so you aren't stuck with just the entity id.  This is what I ended up with (this query returns the average CPU of all hosts in a specific management zone, grouped by the host groups):timeseries usage=avg(dt.host.cpu.usage), by:{dt.entity.host}
| lookup [fetch dt.entity.host
| fieldsAdd hostGroupName, managementZones],lookupField:id , sourceField:dt.entity.host
| filter matchesValue(lookup.managementZones ,"Zone 1")
| summarize AvgCpu = avg(arrayMax(usage)), by:{lookup.hostGroupName}    Now I just need to add some time filters to the query and figure out how to get it to work in an API call and I can finally be done with what should have been an incredibly simple task...

----------------
4:

Anyone having issues with Dynatrace RUM v1.269.140.20230629-182852 & Chrome v117.0.5938.132 or MS Edge v117.0.5938.150
 

----------------
4.1:

Hi,What type of problem do you mean?R.

	Have a nice day!


----------------
5:

I need to run a query with 3 conditions for the ":filter" command, and I am having a hard time with the syntax.This is the base query that I am working off of:
1    builtin:tech.generic.mem.workingSetSize2    :filter(in("dt.entity.process_group_instance",entitySelector("type(process_group_instance),entityName(~"Oracle Database~")")))3    :parents:splitBy("dt.entity.host"):avg:sort(value(avg,descending))4    :filter(in("dt.entity.host", entitySelector("type(~"HOST~"),tag(~"TYPE:Oracle Database Server~")")))
It returns all results without any issues, but I need to add another condition for filtering. I have built the condition separately and I have tried to add the line below, to no avail:
5    :filter(in("dt.entity.host", entitySelector("type(~"HOST~"),tag(~"Capability:Global Money Transfer~")")))
I am assuming that there might be a conflict between the multiple ":filter" instances and the way around would be using the AND operator, but I am struggling so hard with the syntax that I was hoping to get a little guidance from the community.

----------------
5.1:

If you need a host to have both the tags TYPE:Oracle Database Server and Capability:Global Money Transfer, then you can merge your filters in step 4 and 5 with an and as you suggest in the following way::filter(and(in("dt.entity.host", entitySelector("type(~"HOST~"),tag(~"TYPE:Oracle Database Server~")")),in("dt.entity.host", entitySelector("type(~"HOST~"),tag(~"Capability:Global Money Transfer~")"))))If you need hosts that have any of the tags, then you can just do::filter(in("dt.entity.host", entitySelector("type(~"HOST~"),tag(~"TYPE:Oracle Database Server~",~"Capability:Global Money Transfer~")")))Hopefully this helps.

----------------
5.2:

Hey Victor,Thanks for replying. I guess the Victors stay together. LoLI have tried the query with the AND operator, but for some reason, it doesn't return any data. I ended up using Dynamic Filters for the Capability, since the value would be universal for all tiles in the Dashboard, so I don't need the filter in the query themselves.But I appreciate you taking the time to help out.

----------------
6:

Hey,
I am now deciding whether to use metrics API or DQL to query metrics.  But now, I am facing a problem that I can't find some metrics using DQL. (e.g. builtin:host.cpu.load15m)
Is that all metrics that can be queried by metrics selector can also be use DQL to query?
 
Thanks. 



					
						Solved!
					
					Go to Solution.




----------------
6.1:

Hi Stephen - DQL is only used for querying logs and events with Grail: DQL Documentation.
 
For the metric selector, metric queries are handled differently, and do not use DQL. I'd recommend checking out the Data Explorer Advanced Mode to get a better idea of how metric queries are handled.
 
 

----------------
6.2:

I don't think that's true Chris, at least not anymore.  DQL can query metrics via the timeseries command:DQL commands | Dynatrace Docs

----------------
6.3:


Hello @StephenLHChan,With the rollout of the latest Dynatrace, the DQL can also query metrics. Here you can find the documentation article with the list of all metrics supported by Grail:Built-in metrics on Grail 

	If you have any questions about the Community, you can contact me at maciej.neumann@dynatrace.com


----------------
6.4:

Hello @MaciejNeumann A question about calculated metrics.., is there a way to query them? thanks!Jose A

----------------
6.5:

Hello @JAR1 , calculated service metrics (metrics starting with calc:service) are not yet available on Grail.
@StephenLHChan , the Grail metric key is dt.host.cpu.load15m and documentation for querying metrics in DQL can be found here

----------------
6.6:

Do you know when this will be available?  We are looking to do a workflow that has logic like:If calc:service_metric1 + calc:service_metric2 > 20 Then Enable Alerting Profile via api xIf not Disable Alerting Profile via api xIs this possible since these are Calc:service metrics?  If not when is this functionality expected? 

----------------
6.7:

So is there a way to use DQL in API queries?  So far in all the docs, I don't see any mention of using DQL commands and queries in the API, only in the new web console.  Is this coming down the pipe? I ask because I find the Dynatrace API extremely complex and very limiting compared to many other API's I've used for similar tools. However, if we could use DQL queries in our API calls that would pretty much solve all of the issues I have with the Dynatrace API and make it extremely powerful.

----------------
6.8:

Yes there is.It's not that easy to find the documentation for it.Endpoint: /storage/query/v1I use this endpoint to fetch metrics data.

----------------
7:

how do we move licence  from Dynatrace QA environment to Load environment.



					
						Solved!
					
					Go to Solution.




----------------
7.1:


Hi @srpuvvala If you have it within a single DT cluster then you can move license allocations between environments. Otherwise, contact Dynatrace (preferably the licensing department via a ticket in support)Radek

	Have a nice day!


----------------
8:

Hi, we are instrumenting an android app with the dynatrace SDK version: 8.273.1.1003 (https://www.dynatrace.com/support/help/platform-modules/digital-experience/mobile-applications/instr...)Due to technical limitations on networking, we would like to limit the monitor only to the actions set in the code in this way:DTXAction webAction = Dynatrace.enterAction("ACTION NAME");(https://www.dynatrace.com/support/help/platform-modules/digital-experience/mobile-applications/instr...) Unfortunately, we are still seeing actions not set such as this:Loading SmartphoneHomeActivityLoading FAST Pax StagingTouch on LinearLayoutTouch on ImageViewIn this link:https://www.dynatrace.com/support/help/shortlink/oneagent-sdk-for-android#disable-lifecycle-monitori...We have seen that is possible to disable the Automatic monitor of the app but is not working.There are any configurations that we need to set to achieve the result? 

----------------
8.1:

Hey,I assume you instrument your app with the Dynatrace Android Gradle plugin, because user actions like "Touch on ImageView" are only generated when auto-instrumentation (via the plugin) is enabled. You can verify this assumption by looking at the build.gradle files and check if the snippets from this page were added.The linked setting "withActivityMonitoring" only deactivate monitoring for activity lifecycle events. Only the action "Loading SmartphoneHomeActivity" falls into this category. The other actions are generated by the different auto-instrumentation features of the Dynatrace Android Gradle plugin.The Dynatrace Android Gradle plugin allows users to deactivate all auto-instrumentation features via the plugin DSL. When you want to deactivate ALL auto-instrumentation features, then Dynatrace recommends to remove the plugin snippets from your build.gradle files and instead use standalone-manual instrumentation, because the plugin affects the build time of non-incremental builds.When the standalone-manual instrumentation is used, only two monitoring features are enabled by default: crash reporting and activity lifecycle monitoring. You can deactivate both features via the configuration builder (see JavaDoc)

----------------
8.2:

Hi,thank you for your meaningful answer. I double-checked but it does not seem we are using the plugin. We did not see any code snippet that you mentioned...We have simply added this: dependencies {    implementation("com.dynatrace.agent:agent-android:8.273.1.1003") in the build.gradle.kts fileAnd then start the monitoring using this guide:https://www.dynatrace.com/support/help/platform-modules/digital-experience/mobile-applications/instrument-android-app/instrumentation-via-oneagent-sdk/oneagent-sdk-for-android#start-oneagentDo you have any other clue?Thanks a lot,Andrea

----------------
8.3:

User action monitoring is only available with auto-instrumentation or by manually generating "Touch on <component>" user actions. Based on the user actions names, I would assume that these actions are generated by auto-instrumentation. Because of the flexibility of Gradle, there are several other possibilities how the Dynatrace Android Gradle plugin could be added to the Android build.We would have to take a look at the monitoring data or the agent debug logs to determine who generated these user actions. Therefore I recommend to create a support ticket, where you can privately share details about your app and Dynatrace can assist you in troubleshooting this problem.

----------------
9:

Hi! Is it possible to read and write an AppState from the workflow level? As for now, I am receiving an error (code 541). Thank you!

----------------
9.1:

Hi @veranikabarel!From the error you're getting, I suspect that you're utilizing the "Run Javascript" action to read/write AppState. Unfortunately, it won't work, as the State API requires app context (its ID, to be precise) to work, whereas "Run Javascript" is an ad-hoc action with no app context (ID).To make it work, you would need an app function. Also, you can find more details about the State SDK client in the documentation.Please let me know if I can help you further.

Senior Software Engineer @ Dynatrace


----------------
10:

Hello,
As we all know you can turn features within oneAgent on and off,
 
 
But one level deeper, is it possible to find out what methods Dynatrace injects and or is it possible to exclude a specific method?
(I can imagine that above is simply internal)
 
KR Henk



					
						Solved!
					
					Go to Solution.




----------------
10.1:


Hello @henk_stobbe As I know from my experience (I have several cases) it is not possible.If you have Dynatrace features (sensors) (parts of OneAgent) that instruments some endpoint classess/methods you can only switch it OFF or ON.For this cases Support highly recommended use OneAgent SDK and instrument only methods that have value for Customer team. Anyway, if this behavior has changed, I will be happy to see that I am wrong Also, btw, from a research perspective, you can reach the support. They have all the tools to determine what happens during the instrumentation process. Regards, Alex Romanenkov

	DT_NGINX_ALL_WHITELISTED=1


----------------
10.2:

Hi Alex,Maybe in a furure release! Look below at the time, is is a bug or can we time travel (-; Thanks Henk

----------------
10.3:

Looks like my fault, I've changed the message 100500 times.

	DT_NGINX_ALL_WHITELISTED=1


----------------
11:

I'm trying to run a query using Data Explorer that involves 2 separate metrics. The reason for this is because I want the different metrics to have differing thresholds. However, it will only let me run the query for 1 metric at a time, not both in conjunction, even though both are the same, just looking at different applications. Is there a solution or way of being able to run 2 metrics together at the same time using a honeycomb in Data Explorer?

----------------
11.1:

Hi @uzahid,It is not possible.When you have already choosen your metrics and try to change the vizualization you can see an information about if you chose that vizualization there will be limitation eg. only one matric vizualization is possible.Based on the documnetation:"By default, this visualization shows the first metric of a multi-metric query."https://www.dynatrace.com/support/help/shortlink/visualization-honeycomb#change-metric-selection I hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
11.2:

@Mizső is correct, just keep in mind, the older, original out of the box honeycombs take in multiple metrics. For example the honeycomb of host health and service health. That provides all infrastructure level metrics in a Green/Red Fashion honeycomb which you could leverage depending on your metric scope. Anything outside of that metric scope for the out of the box, original honeycomb, you are left with the data explorer result. 

	-Chad


----------------
12:

What happens if a node changes IP number? He has to be installed again>



					
						Solved!
					
					Go to Solution.




----------------
12.1:

Unfortunately, we do not support that currently. In case that happens, you need to reinstall a node so the new network configuration is applied across all cluster nodes. 

	Senior Product Manager, Dynatrace Managed expert


----------------
12.2:


Here are the instructions to 'fix' a node that lives on a box with a change in IP:
 

Change directory to the directory containing the Dynatrace Managed install (i.e., /opt/dynatrace-managed)cd /opt/dynatrace-managed/
Run this command to find all files with the 'old' IP address (replace <OLD_IP_ADDRESS> with the old IP address, like 192.168.137.150)find . -type f -exec grep -H <OLD_IP_ADDRESS> {} \;
You should see an output.
Run this command to replace the old IP with the new (make sure this time it's STATIC) IP address:find ./ -type f -exec sed -i 's/<OLD_IP_ADDRESS>/<NEW_IP_ADDRESS>/' {} \;
For example, if the intentions is to change the node's IP from 192.168.137.150 to 192.168.1.127, the command would look like this:find ./ -type f -exec sed -i s/192.168.137.150/192.168.1.127/' {} \;
Once the command is done executing, verify it was successful by using the original search command with the new IP:find . -type f -exec -H <NEW_IP_ADDRESS> {} \;
Again, replacing <NEW_IP_ADDRESS> with your new IP, e.g., 192.168.1.127
Start the node using the /opt/dynatrace-managed/launcher/dynatrace.sh script


----------------
12.3:

Hey,I will share my experiences with following these steps in case there is somebody out there about to do these changes.While Dynatrace server was functional with the new IP address, I encountered issues with update and installer packages. It seems like the old IP address might be hard coded into the packages, which caused issues with Dynatrace updates.I got the following error after automatic Managed update attempts:Cannot check Elasticsearch indices on Dynatrace cluster nodes. Error: Failed to send GET request to http://<Old IP address>:9200/_all/_settings/index.version.createdI then decided to install another cluster node in the new network alongside the old one as an intended workaround to get the updates working. When running the Managed installer on the new node, I got another timeout caused by a request to the old IP address that was no longer in use, failing the installation.I did not want to go through checking and/or modifying the installer packages in case the IP was hard coded in them. I ended up running the script above again with IP addresses in reverse and moving the original node back to the old network, then opening the required ports between the two nodes that were now in different networks. This restored the functionality of Managed updates and installations.While Managed server itself was functional after the commands, I would still highly recommend doing the network switch the supported way.Br,Lauri

----------------
12.4:

Have you verified it works? There might be also some database changes required.

	Senior Product Manager, Dynatrace Managed expert


----------------
12.5:

Hello @Radoslaw S. and @Kia F.I've just did this, and it worked.Do you think there could be any repercussion?Best regards.

----------------
12.6:

It is worked with me as well. 

----------------
12.7:

Hey,I will share my experiences with following these steps in case there is somebody out there about to do these changes.While Dynatrace server was functional with the new IP address, I encountered issues with update and installer packages. It seems like the old IP address might be hard coded into the packages, which caused issues with Dynatrace updates.I got the following error after automatic Managed update attempts:Cannot check Elasticsearch indices on Dynatrace cluster nodes. Error: Failed to send GET request to http://<Old IP address>:9200/_all/_settings/index.version.createdI then decided to install another cluster node in the new network alongside the old one as an intended workaround to get the updates working. When running the Managed installer on the new node, I got another timeout caused by a request to the old IP address that was no longer in use, failing the installation.I did not want to go through checking and/or modifying the installer packages in case the IP was hard coded in them. I ended up running the script above again with IP addresses in reverse and moving the original node back to the old network, then opening the required ports between the two nodes that were now in different networks. This restored the functionality of Managed updates and installations.While Managed server was functional after running the commands above, I would still highly recommend doing the network switch the supported way to get the latest updates and being able to install more cluster nodes.Br,Lauri

----------------
13:

Via "Analyse Process Connections" we can see which host/process is calling our host and what volumes we are talking about. That's great but it's quite deep dive.For a certain fileserver we want to keep track of the incoming traffic and where it comes from. There are a few metrics for that but none of them have a "calling host" dimension or something like that. See builtin:host.net.nic.trafficIn can be split by host and NIC. But that doesn't tell where the traffic comes from. We know the data is available because we have those details via "Analyse Process Connections".Is this feasible? And how? For this particular service we want it on a dashboard. Maybe even create alerts when certain incoming spikes arise.

----------------
13.1:

Hi @Bert_VanderHeyd ,you can use a more specific entitySelector in your metric query to get the calling PGIs of the PGI (for my example PROCESS_GROUP_INSTANCE-19A05BD896B3AD67) you want to check e.g.: type(process_group_instance),fromRelationships.isNetworkClientOf(entityId(PROCESS_GROUP_INSTANCE-19A05BD896B3AD67))The :parents suffix will as well give you the host where the calling PGIs come form.So your complete query could look like thisbuiltin:tech.generic.network.traffic.trafficIn:filter(and(or(in(
"dt.entity.process_group_instance",
entitySelector("type(process_group_instance),fromRelationships.isNetworkClientOf(entityId(PROCESS_GROUP_INSTANCE-19A05BD896B3AD67))")
)))):splitBy("dt.entity.process_group_instance"):sort(value(auto,descending)):limit(20):parentsHope this helps.BR,Mark 

----------------
14:

Hello,I have the need to determine how many times app pools have been restarted (in 30 days) across our domain in Dynatrace.  I've been poking around, but cannot figure it out.  Is there a Metric I can configure to determine this, or perhaps by filtering through logs?Thank you!

----------------
14.1:

Hi @DStocklandyou can filter through the events for this information. using the API you can determine the timeframe and the entity it happened on"events": [
    {
      "eventId": "6798745626705320663_1696483060541",
      "startTime": 1696483060266,
      "endTime": 1696483064123,
      "eventType": "PROCESS_RESTART",
      "title": "Process restart",
      "entityId": {
        "entityId": {
          "id": "PROCESS_GROUP_INSTANCE-04FB78E5D361DA42",
          "type": "PROCESS_GROUP_INSTANCE"
        },
        "name": "IIS app pool .NET v4.5 Classic"
      },
...For each instance count them up and you have your result.BR,Mark

----------------
15:

After migration `@dynatrace/strato-components-preview` from 0.99 to 0.104 every unit test is failing with the same error:```FAIL src/app/components/BuildsOverTimeContainer.spec.tsx● Test suite failed to runJest encountered an unexpected tokenJest failed to parse a file. This happens e.g. when your code or its dependencies use non-standard JavaScript syntax, or when Jest is not configured to support such syntax.Out of the box Jest supports Babel, which will be used to transform your files into valid JS based on your Babel configuration.By default "node_modules" folder is ignored by transformers.Here's what you can do:• If you are trying to use ECMAScript Modules, see https://jestjs.io/docs/ecmascript-modules for how to enable it.• If you are trying to use TypeScript, see https://jestjs.io/docs/getting-started#using-typescript• To have some of your "node_modules" files transformed, you can specify a custom "transformIgnorePatterns" in your config.• If you need a custom transformation specify a "transform" option in your config.• If you simply want to mock your non-JS modules (e.g. binary assets) you can stub them out with the "moduleNameMapper" config option.You'll find more details and examples of these config options in the docs:https://jestjs.io/docs/configurationFor information about custom transformations, see:https://jestjs.io/docs/code-transformationDetails:/Users/user/code/dynatrace/node_modules/@dynatrace/strato-design-tokens/colors/index.esm.js:15...SyntaxError: Unexpected token 'export'at Runtime.createScriptFromCode (node_modules/jest-runtime/build/index.js:1505:14)at Object.<anonymous> (node_modules/@dynatrace/strato-components-preview/core/index.cjs.js:131:30)```jest.config.ts:```import type { Config } from "@jest/types";import { stratoPreset } from "@dynatrace/strato-components-preview/testing/jest";const config: Config.InitialOptions = {  preset: "ts-jest",  testEnvironment: "jsdom",roots: ["<rootDir>/src"],  setupFiles: ["@dynatrace/strato-components-preview/testing"],  transform: {    ".(css|scss|sass|less)$": "<rootDir>/style-mock.ts",  },  setupFilesAfterEnv: [`<rootDir>/src/jest-setup.ts`],  ...stratoPreset,  moduleNameMapper: {    ...stratoPreset.moduleNameMapper,    "^libs/(.*)": "<rootDir>/src/libs/$1",    "^components/(.*)": "<rootDir>/src/app/components/$1",    "^hooks/(.*)": "<rootDir>/src/app/hooks/$1",    "^contexts/(.*)": "<rootDir>/src/app/contexts/$1",  },};export default config;```



					
						Solved!
					
					Go to Solution.




----------------
15.1:

Hi @beigert ,
Can you add this in your module name resolution config (jest.config.ts):
  moduleNameMapper: {
    "^@dynatrace/strato-design-tokens/(.*)$": "<rootDir>/node_modules/@dynatrace/strato-design-tokens/$1",
    "^@dynatrace/strato-design-tokens$": "<rootDir>/node_modules/@dynatrace/strato-design-tokens",
  },
and check if this fixes your problem?
 
Best,Sini
 

----------------
15.2:


it helps a little bit: tests that don't import anything from `strato-components-preview` works. However rest of them fail with the same error:```FAIL src/app/components/BuildsOverTimeContainer.spec.tsx● Test suite failed to runJest encountered an unexpected tokenJest failed to parse a file. This happens e.g. when your code or its dependencies use non-standard JavaScript syntax, or when Jest is not configured to support such syntax.Out of the box Jest supports Babel, which will be used to transform your files into valid JS based on your Babel configuration.By default "node_modules" folder is ignored by transformers.Here's what you can do:• If you are trying to use ECMAScript Modules, see https://jestjs.io/docs/ecmascript-modules for how to enable it.• If you are trying to use TypeScript, see https://jestjs.io/docs/getting-started#using-typescript• To have some of your "node_modules" files transformed, you can specify a custom "transformIgnorePatterns" in your config.• If you need a custom transformation specify a "transform" option in your config.• If you simply want to mock your non-JS modules (e.g. binary assets) you can stub them out with the "moduleNameMapper" config option.You'll find more details and examples of these config options in the docs:https://jestjs.io/docs/configurationFor information about custom transformations, see:https://jestjs.io/docs/code-transformationDetails:/Users/przemyslawbeigert/code/dynatrace/pipeline-observability-application/node_modules/@dynatrace/strato-components-preview/index.esm.js:2export * from "@dynatrace/strato-components-preview/buttons";^^^^^^SyntaxError: Unexpected token 'export'> 1 | import { Flex, Skeleton } from "@dynatrace/strato-components-preview";| ^2 | import { TimeseriesChart } from "@dynatrace/strato-components-preview/charts";3 | import Colors from "@dynatrace/strato-design-tokens/colors";4 | import { InformationIcon } from "@dynatrace/strato-icons";at Runtime.createScriptFromCode (node_modules/jest-runtime/build/index.js:1505:14)at Object.<anonymous> (src/app/components/BuildsOverTimeContainer.tsx:1:1)at Object.<anonymous> (src/app/components/BuildsOverTimeContainer.spec.tsx:10:1)```

----------------
15.3:


@beigert unfortunately I can't help you further. Please create a support ticket in  https://one.dynatrace.com/hc/en-us/requests with a reference to this thread and the error messages. Our developers need to have a detailed look at it.
Thx,Sini

----------------
15.4:

It works, however after clear the cache by `rm -rf node_modules/.cache`. However pls update docs: https://developer.dynatrace.com/develop/testing/unit-tests/

----------------
15.5:

Just synced with the team about this.
this workaround won't be needed anymore with design system version 0.106.2 and design tokens version 0.19.0

----------------
16:

classic dashboard, simple - builtin:kubernetes.pods:last:filter(eq("pod_phase", "Failed")):splitBy("k8s.namespace.name","dt.entity.kubernetes_cluster"):sum:sort(value(sum,descending))
it shows failed pods, in descending order, works great!  It says last 5 minutes, but those pods never seem to go away from that query. Should they?
Result
Timeframe: 2023-10-04 16:44 - 16:49Auto (1m)4 record(s)
the number of records just keeps going up even though pods are long ago rebuilt.
thanks

----------------
16.1:

Hi @nutsy4sure I guess it depends on. At one of my clients I see a similar situation:My mteric experssion is:builtin:kubernetes.pods:filter(and(eq(pod_phase,Failed))):splitBy("dt.entity.cloud_application"):sort(value(auto,descending)):limit(10)Dashboard filtered for the last 5 minutes (it has not been changed since 9 days becasue nobody cares about the failed pods, they are still there).      I hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
16.2:

Thank you for the reply, but it sounds like you are just confirming my experience. The pods failed and vmware reacted the way it should and spun up a new one. At that point, I dont care about the failed pod. Different circumstances, I might not want it to disappear for investigation purposes, but I want this dashboard to be "real time", and days old failures that vmware long ago recovered from, isnt reflecting the current status. 

----------------
16.3:

Hi @nutsy4sure,It is not VMware, it is kubernetes. And based on the metric expression this is the actual status for the last five minutes: 1 runnning pod and 4 failed pod.You should find another solution. Maybe you could count one of the kubernetes event which refers to the failed pod (with eg. pod name dimension). Then it can be vizualized well. eg. I hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
17:

Hi,I am having trouble configuring my Cisco devices using the extension. The error in the config page takes me to the logs and events where I get this error:
"Query failed err=read udp" followed by a bunch of IPs and timeout args. The status code shows 38. 
What could be the issue for this?

----------------
17.1:

Hi @AmayShah !Are you able to poll the device from the ActiveGate?snmpwalk –v 2c –c yourcommunity yourTargetIP 

	Observability Engineer at Phenisys - Dynatrace Professional


----------------
18:

After enabling the request body using any json key or even * according to the documentation, the APIs stop responding, the parameters do not reach the API.
The error only happens when using Request Body, any other parameter works correctly.
 
Message after enable capture request body:
A non-empty request body is required.
 
Stack:Azure Web Apps with OneAgent Version: 1.269.166.20230715-203547
Dotnet 6.0
Dynatrace Biz Events

----------------
18.1:

Hi @phmonte,I recommend you that if you find an impediment in the configuration of bizevent for .NET, use the Support portal. The agents will help you with more detail, for example asking for images, logs, and any other file that helps to identify and reproduce your problem. Here, the community will help too, but could be answered in hours or maybe days.https://dt-url.net/lb626l9 

	-César S. - LATAM Solutions Architect


----------------
18.2:

Hi @phmonte,What happens when you enable the configuration of bizevent?Your application is not working? Do the captured events contain empty values on the request body variable?Could you share with us a screenshot of the error you refer to?

	-César S. - LATAM Solutions Architect


----------------
18.3:

Thanks for responding @cesarsaravia The oneagent log file does not save any error or action information other than conventionally.I made a drawing to show what is happening. Remembering that the error only happens with the Request Body, the other options are working correctly. 

----------------
18.4:

Hi @phmonte Did you enable the feature flag of capturing .net bizevents? If yes, do you restarted the Asep.Net application?  

	-César S. - LATAM Solutions Architect


----------------
18.5:

Yes, it is enabled and I tried restarting it again.I tested with other apps (another OneAgent/Webapp) and I have the same problem.   

----------------
18.6:

@phmontedid you got any update on this?I am suspecting I am facing the same issue.

	Site Reliability Engineer @ Kyndryl


----------------
18.7:

So far, no updates @dannemca 

----------------
19:

When there are problems logged for a K8s cluster, the filters on the problem page for K8s clusters doesn't find the problems generated from that cluster. Please fix the filter or the metadata to allow the filters to work as expected.

----------------
19.1:

I don think this falls under a RFE. moving it to Q&A @Bill_Demsky can you provide an example of the filter that you are using? I've tested it out on my end and it is functioning as designed. What cluster Version are you on?   

	-Chad


----------------
19.2:

Hi, I do face the similar issue. Can any one has hints to filter out cluster level problems / filter to search problems under cluster . I can get problems if I use at workload levels But I want to see the filter with Cluster level. How many problems under each cluster in problems page.

----------------
19.3:

I'd Suspect that the Cluster Level monitoring isn't completed. Hence why you dont see them in the problems page. You can verify by going to a node and looking to see if the K8 Cluster is listed in the properties. 

	-Chad


----------------
19.4:

Yes. I cloud see the cluster details in a node properties. and I tried with tagging the cluster name as well. But Still i can't see the problems if I filter as Entity : Kubernetes Cluster(KUBERNETER_CLUSTER). It result with 0 problems. 

----------------
19.5:

Make sure that your time frame is wide enough to include a kubernetes problem. What cluster version are you on? In our instance it is working as designed on the most recent cluster version:  If you are at the most recent version of the Cluster then you might want to open up a support case. As a work around for the time being I recommend crating a Auto Tag that provides the value of the K8 Cluster to the related hosts, processes and services. This will then allow you to sort problems by tag being "K8 Cluster:<Value>" 

	-Chad


----------------
20:

Hi.  I'm a new Dynatrace user so please bear with me as I haven't seen the examples.  I am trying to parse a custom application's log within Dynatrace and set alerts based on various fields and keywords within the log file.  The issue is that the custom application produces text files with a *.txt format and separated the fields within the log with a pipe delimiter.  The log is created with a timestamp at the end of the file each hour (ie log file name.YYMMDDHHMM.text).  I haven't tried it yet or seen many examples of this (yet or maybe I'm not looking in the right place).  Do I use the custom log ingestion process to ingest the file and then use the DPL to parse the custom format?  Or, would it be better for me to write a KSH script rename the 'crazy' log file into something that Dynatrace can read and parse more easily (ie make it look like a Windows System log file)?.Any guidance would be appreciated.  Thanks!

----------------
20.1:

Hi,Do you know if your tenant is Grail enabled? Or are you going to use Logs Classic?Best regards

	Consultant


----------------
20.2:

I believe that the team set it up with Logs Classic, but if you tell me that it only works with Grail enabled then I can speak with them about the importance of that feature.

----------------
20.3:

Hi,I would try to ingest logs using Log storage configuration (Logs Classic) And you have Log processing examples (Logs Classic).Best regards

	Consultant


----------------
21:

Hi everyone,Yesterday we found several alerts which appeared in problem console several minutes later than the problem was detected. One of them  didn´t show in the console up to an hour later. Reading this URL from the documentation https://www.dynatrace.com/support/help/platform/davis-ai/problem-and-root-cause/problem-lifecycle  it's read "As the event start analysis timestamp represents the earliest point in time when the violating state was observed, the event end analysis timestamp represents the point in time after all necessary violation samples are collected and the Davis problem is raised. Because each event involved in the problem uses a sliding window, .. ..." I think that the delay in showing the alert in problem console is due to this sliding window and the analysis timestamp. Is it possible to configure this sliding window like we can do for metric events? Can someone explain us why this can happened and how to fix this behaviour?For us this behaviour is very problematic because the final users are detecting the problems before us and we can't give a quick solution to fix the issue.Thanks in advance.Regards,Elena.

----------------
21.1:

Hi @erh_inetum ,What types of problems are you reffering to? For example, anomaly detection for resources have dual thresholds (i.e. Memory usage plus page faults) so a problem won't be raised until both thresholds are met.In case of problems like "failure rate increased", you can make the thresholds more sensitive either globally or for specific services.Regards,E.

----------------
22:

Dear Community, I'm interested in your feedback as well.  The moment latest Dynatrace was released to our tenant I got calls of uncertain excitement from my users.  I told them it was safe to turn it on and it's simple to toggle back and forth incase things don't work out.  This is an early release so look around, let me know how it goes, but improvements are coming.
I received some positive comments regarding the new look and feel. A complaint of the way legacy pages were not converted yet, making for a SolarWinds APM like inconsistent UI feel.
Within 60 minutes though I started getting emails and Teams messages complaining of how difficult it was to access their metrics with the new dashboards and notebooks.  "It looks pretty, but I spent 2 hours unsuccessfully trying to recreate charts I already have in my classic dashboards", "It's too difficult to find metrics in the new structure", "There are not enough examples to guide us", "There should be an in place linter to help fix queries", "Where is the Data Explorer for Grails?", "I am finding it difficult to access my metrics with this code. Where is the visual graph building like Data Explorer".
I've instructed them that it's nice that we are able to experience latest Dynatrace so early, we'll send the feedback to Dynatrace, and lets hope improvements arrive soon.
I would though like to hear how other Community Members are doing. Maybe those Early Adopters could tell us they had similar initial reactions but it got better.
 

	HigherEd




					
						Solved!
					
					Go to Solution.




----------------
22.1:

One of the first problems I noticed was with basic functionality. There is no way that I can find with the new interface to switch between environments. Links to the community from the new interface result in an error. 

----------------
22.2:

It took me a bit to find it but its hidden behind the profile icon on the bottom left of the page.    its that "latest dynatrace" toggle. 

	HigherEd


----------------
22.3:

Sorry I should have been more clear. I did find how to turn off the latest Dynatrace interface. In the new interface there is no way to switch between multiple Dynatrace tenants. Either need to bookmark the urls or switch to the old interface to find all of our tenants. 

----------------
22.4:

As a partner supporting multiple dynatrace customers with sometimes more environments, we are a heavy user of the switch function. So it's often back to the old UI too until Q3 for this function.

	Kind regards, Frans Stekelenburg                 Certified Dynatrace Associate | measure.works, Dynatrace Partner


----------------
22.5:


Hi Mike! The "environment switcher" is planned to be available in the third calendar quarter. Our current concept includes indicating the current environment in the user menu, filtering for all environments users have access to, favoriting of environments to have them show up on top and allowing to switch environments quickly through the search (e.g. CMD/CTRL+K > search for environment > ENTER to open environment)
 
 

----------------
22.6:

Thanks -- this makes sense and I'm glad that it is planned, but it does seem like this is a blocker for some of my organization to easily use the new interface and switch between environments. Will Dynatrace hold off on making this the default interface until this change is made?

----------------
22.7:

While we wait you can create a new notebook and put the links on it:  

	The true delight is in the finding out rather than in the knowing.


----------------
22.8:

Did not find a way to switch between environments 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
22.9:

Amm, yep not straightforward to get use to this latest Dynatrace look and feel 
But just look on this as a menu change from the old vertical menu to a new spread on all over the page menu 
You still able to get to all the "old" entries from the Dynatrace upper left entry  
 
HTH
Yos 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
22.10:

Hi Yos! The general look and feel certainly changes. While that is by design, we're aware that it will take a while to get used to. Just a couple of tips:

The main landing page (accessible through the "Dynatrace" entry) is not actually a menu, but an early version of a fully customizable home screen. Think of it like the desktop on Windows / OSX. It just happens to look like a menu at the moment, because we pre-populated it for everyone accustom to the previously overcrowded left-hand product menu.
The new left-hand menu is the place where the latest Dynatrace already allows for quite some customization. It allows to pin / order your most important apps and will also show all other recently used ones for you to quickly get back to. We pre-populated it with the list of "favorites" from the previous left-hand menu.

PS: Please keep us posted about your early impressions! We'll help to sort out any issues you might face.

----------------
22.11:

Hi @rowinho Since we deal with few SaaS environments, the name of the environment at the top search old UI  is missing in the new UIWithout this search currently we don't know to which environment we are logged to  Old UI: ThanksYos  

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
22.12:

I seem to have to missed the boat on this one, and I can nowhere find an introduction to it (only for the now classic? release). Where can I find the announcement of the new dashboarding and the changes/advantages it entails? Pointer to a release note perhaps?I see the documentation is already updated.Update: OK, so actually interpreting the (Saas) release notes of 1.265, where it is introduced as 'the new Dynatrace'. Dynatrace SaaS release notes version 1.265 | Dynatrace Docs

	Kind regards, Frans Stekelenburg                 Certified Dynatrace Associate | measure.works, Dynatrace Partner


----------------
22.13:

It might take a while until you get your environment(s) converted. 

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
22.14:

Being a "power user" I really find the DQL and "all things grail" extremely powerful, but I have two doubts about adoption:I don't think regular users will be able to use DQL for accessing data without any in-product guidance (wizard helping you build your query) or intensive training. Mainly just for creating a simple dashboard from metrics or logs. FinOps - since you are charged for every DQL query, I find it impossible to plan the licenses even for a short term. Having the license costs under control will be significantly more challenging than before. 

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
22.15:

The FinOps / DQL licensing is a great challenge. I see so many risks, that driving adoption will not be an easy task...

	Antonio Sousa


----------------
22.16:

I completely agree. I understand the concept and vision but keeping costs under control is going to be difficult and will likely hold back adoption in our environment.

----------------
22.17:

A comment on the wizard/guided approach as it relates to the cost comments.

Usage and cost of Grail-related capabilities are shown in the Account Management portal with a drill-down to a prepopulated notebook to provide insights into query usage and the user/app running them. 

 
 
($/usage values are for demo purposes only)

We are also working on features to detect and notify you when higher-than-expected usage is detected on a capability. While this may not directly address the planning aspect of your post, it can help keep costs under control.


----------------
22.18:

Good to know this is at least already addressed at least to some degree. With broader usage more FinOps problems start to appear. @mark_eshelby with Log management / Business events it's clear how the billing works - what about upcoming Metrics on Grail / Traces on Grail?

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
22.19:

I think I saw already somewhere another post, but the Problems and Security counters in the top bar, I miss them too.You can put the Problem app on the sidebar, but we're missing the counter/indicator. RFE: Bring back the live count of problems on the "Problems" app icon in the new Navigation panel - ...

	Kind regards, Frans Stekelenburg                 Certified Dynatrace Associate | measure.works, Dynatrace Partner


----------------
22.20:

I really miss links to API swagger pages, cannot understand why they are gone in latest ui...

	Alanata a.s.


----------------
22.21:

Yeah, I know this new look is still in heavy development, but holy smokes, there is so much that is missing to make this an even close to reasonable replacement for the old look...  Just simple stuff like switching the environment and clicking to the API (as you pointed out) are missing completely...  Not to mention that I really liked having the search box be at the top rather than a clickable link.  Even though it's the same number of clicks, it just felt way better having the search bar at the top of every page...  Not to mention that the results that the old search provided seems far superior to what I'm getting in the new one.

----------------
22.22:

I remember a Dynatrace presentation back in the day 'Dynatrace for AppMon users'.Today was my first experience with the new UI - is there anything like a 'The new Dynatrace UI for Classic UI users' guide available?I predict a big shock for my user base once this eventually gets to us. 

----------------
22.23:

You can now switch between environments :    

	Observability Engineer at Phenisys - Dynatrace Professional


----------------
22.24:

This is helpful, but it would be nice if it included a context menu with the different environments like the old UI has today which is what @rowinho's screenshot above appeared to show. In some cases like this one, the new UI tweaks involve more page loads and clicking around then the old UI which is less than ideal.

----------------
22.25:

Hi community members,I would like to update you on a few topics mentioned in this thread.The Environment switch will be introduced soon and is available for you in CQ4. You can then see your environments if you have access to more than 1 in the user menu and will be on click redirected to the particular one. We will also indicate in which environment a user currently is in.Finding and charting metrics will become much easier with the introduction of our query builder. Accessing data will therefore be much easier for non-power-users and user who are not yet familiar with our DQL. You can expect a first version of this in CQ4 as well.Some were concerned about having the license costs under control. Assigning Dynatrace costs to teams and adding transparency to teams is a key investment area of licensing in upcoming calendar year 2024. This improvements are going to be supported with our newest subscription model “Dynatrace Platform Subscription”.There won’t be a problem indicator integrated into the new UI version anytime soon. However, we’re working on customizable “home” or “launch” pages so that users can set them up individually for their needs. One option for this is to integrate the open problems count and/or system notifications.

----------------
22.26:

We definitely need to have the open problems counter put back the way it was. I'm not sure why that functionality was removed in the first place. It's great to see that no matter where you are in the tenant to keep track of how many open problems we have. 

----------------
22.27:

Has anyone been talking about the new global search feature? I find it doesn't accurately search through all my entities the way the "classic" global search did. It's fairly unusable at this current time. For example, when searching for a simple host by name I will often see the message "no entities found". In the "classic" global search I was able to paste in IP addresses and it would link me to the host it belonged to. It seems the new search feature is not actually searching through the entire tenant the way the "classic" search did, and also doesn't include related links to documentation. Can we at least get the same global searching features that we're used to? 

----------------
22.28:

The new dashboards need to be discussed as well. While it's great to be able to use DQL to drive the tiles, the look and feel of the new tiles is not that great. I would particularly like if they had a more similar look and feel as the old tiles, but driven by DQL instead of Data Explorer. It seems the scaling of the legend in each tile is nonexistent. The legend text appears to stay the same size no matter the size of the tile. We're used to having lots of tiles and data on each dashboard but this limits that capability. We have large screens in our NOC that display our very detailed classic dashboards and our executives are very happy with them. They can easily see all the important metrics around our services/infrastructure at-a-glance. 

----------------
22.29:

One of the things I'm interested in is being able to search directly to particular settings from the search bar. For example, we can go directly to the "request attributes" page in the old tenant by searching for it, but in the new one there is not quite that same level of direct access. 

----------------
22.30:

New left nav panel:  I like the idea of going back to my recent page, however I think this functionality should be reversed. It would work better if, when clicking on the app in the left nav, it did the "relaunch" feature. If I want to go to a recent page, that should be what pops up when I hover over the left nav app. Maybe even store the most recent two or three pages for each app? There also seems to be some apps that don't have a relaunch feature, which has caused me to get stuck in an app before where I had to refresh the entire page to effectively relaunch the app.

----------------
23:

Hello,
Grail and the new UI seem to be not available on Dynatrace SaaS tenants hosted by GCP.Do you know when Grail will be available on GCP ?
 
 
Thank You.Regards

	Observability consultant - Dynatrace Associate/Pro/Services certified




					
						Solved!
					
					Go to Solution.




----------------
23.1:


Hi Aurelien,
and thank you for the question! We have announced the availability of Grail and Dynatrace Platform on Azure in the first quarter of 2024 in a press release today. GCP follows after Azure, however, there is no timeline I can share with you at the moment. 
Thank you,Milan

----------------
23.2:

Thank you @milansteskal for your feedback.Regards.

	Observability consultant - Dynatrace Associate/Pro/Services certified


----------------
24:

Hi Team,
We are using Dynatrace SaaS environment for our POC purpose and want to have the same for Production environment too. Kindly recommend the type for Active Gates to be used for Production setup(Host-based Active Gate or Containerized Active Gate).
And also suggest the limitations of these two types of Active Gates.
 
Thanks,
Gargi Gharat
 

----------------
24.1:

As you posted this in the extensions forum I'll answer from an extensions point of view. Containerized ActiveGates are currently not able to run extensions.

----------------
24.2:

I think this doc page may help you:
https://www.dynatrace.com/support/help/shortlink/ag-container-differences#purposes
 

	Senior Product Manager, Dynatrace Managed expert


----------------
25:

How can I get a json-schema or TypeScript interface (on any other format) to validate workflow definiton locally? 

----------------
25.1:

Hi @beigert,To validate the workflow definition locally in Typescript, you could leverage the Workflow type from the "@dynatrace-sdk/client-automation". We're aware that the typing still isn't perfect, but we're working on it. Please let me know if I can help you further.

Senior Software Engineer @ Dynatrace


----------------
26:

HI Team,I have created workflow  in DT which create Dashboard using JS code. I want to have vey next step in workflow to share Dashboard URL to Dev team by sending Email(preferred formal way to share URL) . Is it possible to do in Workflow task??? Please help me on this.Regards,
Heramb Sawant

----------------
26.1:

Hi Team,Could you please help me on this??Regards,Heramb Sawant

----------------
26.2:

Hi Heramb, 
Yes, we will launch an E-Mail O365 for Workflow action presumably within the next two months, followed by a generic E-Mail Action. I am additionally curious in your use case to create a dashboard with workflows - can you elaborate on this? ThanksAlexander 

----------------
26.3:

Thanks @Alexander_Mohr. On top of a slack message, one of our clients in Israel is also interested in being able to trigger an email via a workflow. Looking forward  

----------------
26.4:

Hi Alexander,We have below 2 use case where we are looking for sending e-mail notification.1. We would like to create workflow that will perform a taske.g. SRG validation. Post this validation I want to send an email to a specific set of people and notify them about SRG results. 2. We have workflow( in future it will be part of jenkins pipeline)  which does some automation task like ingesting events into grail Bizz event and  followed by creating or updating (using document service) existing dashboard tiles with data  fetch from grail. Next step will be sharing this dashboard URL to appropriate audience through email with some custom message. Regards,Heramb sawant  

----------------
27:

Hello! We just published the pre-release information for Dynatrace version 1.276. See what's coming in the next release. 
https://www.dynatrace.com/support/help/shortlink/release-notes-saas-sprint-276
Please note that this an ongoing summary of changes in this release. Check back the same URL at GA for the final version.

----------------
27.1:

I love that you are doing this

	Dynatrace Certified Professional


----------------
27.2:

thanks!!!

	Dynatrace Professional Certified


----------------
27.3:

Thanks for sharing this 

	-Chad


----------------
27.4:

Excellent idea to see what is coming!

	Antonio Sousa


----------------
27.5:

Good to know:) thank you

	Have a nice day!


----------------
27.6:

Very good! thanks much. 

----------------
28:

 Rocket Woman , I guess that's what you can call our Member of the Month for October selected from the customers and partners group. Just reading this article, it’s easy to feel how passionate about work and life overall Marina is.
Passion develops as we learn more about something. We have the power to create motivation in ourselves, and “starting to do” is the first step to achieving it. A strong desire to explore and act is something that @marina_pollehn shows in many areas. Also here, on Community, where she actively helps other Dynatrace users.
I could say more, but I think Marina’s words will speak for themselves best. ________________________________________________________________________________________________________________________________________________
Can you share some details about your past? What is your story, and how it happened that you decided to work in the IT / APM area? When I was about to graduate high school in Hamburg (Germany), I dreamed of becoming a public sector consultant and evaluating policy making – with the big wish to work for the United Nations or the European Union. In between, I had a few impulsive moments where I almost signed up for the exam to become an air traffic controller – I really did not know where this urge suddenly came from. Looking back – as it is also a form of monitoring – it makes sense to me now .
Other than that, I had a big wish to start with IT as a side hobby, but many of my attempts to join a course or to get started with it did not really work out. In high school, the computer science elective was discontinued in my grade, and attending one at another school was too big of a clash with my timetable. So, after graduating, in line with my public sector consulting goal, I started studying economics in Rotterdam in the Netherlands. In my 3rd year of bachelor’s, I signed up for a minor in computer science. I was so passionate about it that I convinced my best friend to sign up for the minor, too. Unfortunately, it was a lottery, and they didn’t have space anymore – so she got in, and I didn’t. I decided to ask her during every break about what they’ve learned, and it only made me more eager to get into IT. At the same time, next to my minor, I joined my university’s ‘Turing Club’ to learn some web development. After finishing my bachelor's, I started with two masters: International Economics and Business Information Management (with a focus on Data Science). At that point, I still saw myself working in economics and saw IT as a cool hobby to have a second master’s in. Well, I was very wrong. After a student job in data engineering at Boskalis (a Dutch maritime engineering company), which only made me more enthusiastic about the field, I started working as a Digital Performance Consultant. Not an air traffic controller – but at least some pilot experience.
Can you tell us a little bit about your professional life? Where do you work, and what do you do in your job? And how does Dynatrace fit into the picture?For the last 3 years, I have been working at Eviden (formerly Atos) – a large IT services and consulting company located in Amstelveen (close to the more famous Amsterdam) in the Netherlands. There I started directly as a Digital Performance Management Consultant. We're a full-service provider, which assists customers with their entire monitoring journey – mostly with Dynatrace. This can include configurations, hosting, and consultancy for almost every type of IT landscape – basically anything you can monitor with Dynatrace. 
My job consists of a mix of operations and project tasks (usually the onboarding of an entire application including all configurations), ranging from creating metrics and configuring extensions to giving Dynatrace trainings and workshops. Two tasks I really enjoy are coaching new colleagues and helping them with their first steps within Dynatrace and the team, as well as giving demos to new potential customers who are often fascinated with the capabilities of the software. 
Another aspect that is especially fun about my job is that I get to speak all three languages (German, Dutch, and English), which I know fluently because I work with different customers from all over the world. I also enjoy how every customer environment and request is different, which gives me the chance to explore as many aspects of Dynatrace as possible. So many that I am now allowed to call myself a certified Dynatrace Professional. LEFT: Bachelor Graduation Day with my sister (who unfortunately lives 500km away from me). / RIGHT: We find celebrating birthdays in the office very important.
What was the biggest challenge Dynatrace helped you to overcome? 
One of the most impressive applications I set up Dynatrace monitoring for was a survey form for uploading COVID test results by the Australian government. The constant global availability of the application was essential to collect COVID data at any time, enable international travel, and avoid user frustration. We tested the availability with multiple synthetic (browser clickpath) monitors at a high frequency and multiple locations. Furthermore, the customer wanted more detailed insights into the bounce rate and drop-off locations. Next to visualizing the expected user journey through the survey with the user action funnel and providing the customer with insights into different failure rate and response time metrics, I also decided to explore the actual user journey further with the Sankey chart. This showed us how and how many users deviated from the expected journey and which application pages they returned to in between. To me, the project was very inspiring due to its social relevance and time criticality. I was impressed with how quickly we could set up the entire Dynatrace monitoring (we had a maximum of two weeks), including everything up to Session Replay, data masking, dashboards, alerting, synthetics, and many more functionalities.
What brought you to our Community? What made you stay? What best advice can you give someone who just started using Community?Initially, I started out as a silent observer in the Community. If I could not find something specific in the Dynatrace documentation, I would just roam around the Community, and quite often, someone else already had the same question answered. After a year, I came back with my own questions. I still remember that the first question I had was related to ignoring specific types of request errors for web applications.
My advice is to ask whatever is on your mind. I sometimes use the Community to get a second opinion on something.  Also, you don’t need to know every little detail about Dynatrace (trust me, that’s technically impossible) to contribute to the Community. Sometimes something might be very best-practice and normal in your way of working and be completely new to someone else, even if they have been working with Dynatrace way longer than you. 
The aspect I love the most is that the Community can be an excellent challenge for yourself. When answering a question, you often need to do some testing on your own or you need to research until you finally find the solution you had hoped for. This keeps me curious and up-to-date.
And – the last piece of advice – make sure you use the product ideas. If I encounter something in Dynatrace which could be done more efficiently I just directly suggest it as a product idea. Dynatrace does a great job at integrating minor improvements very quickly and including other ideas in their long-term strategy, so sharing feedback can really pay off.Tell us something about you that most people don’t know. What is your biggest joy or passion in life? I am a person with too many hobbies and interests. I would say that dancing is my biggest passion. When I was 13, I started with Ballroom and Latin dancing but paused for 5 years after because my friends quit (biggest regret). When I started university, I signed up for dance classes again, and on the ‘blind date’ night, I met my dance partner, who became a very good friend of mine. Together we danced for 5 years and even went to the Dutch and European student tournaments – some cool memories of dancing 12 hours a day with my feet becoming 2 sizes larger afterwards. Since he moved to London, I have tried different dance styles. I have been learning salsa for a year and since last September, you can find me in an aerial dance studio for 2-5 hours a week enjoying the combination of dance and acrobatics. 
 LEFT: Dancing at the Dutch Student Tournament in 2018. / RIGHT: Another dream? Always keeping my passion for technology.
 If I am not dancing, you can find me in my ‘nerd-mode’ reading pen & paper manuals (some of you might only know it as D&D) and of course, also playing it (VTM and Aborea) online with friends once a month. Besides that, I have an addiction to water sports like SUPping and kayaking. Last year I spent a week traveling through one of the Dutch national parks on a stand-up paddle board, paddling from sunrise until sundown with the most contradicting weather conditions. This taught me that you can fit everything you need in life on a surfboard and that a digital detox once per year is quite healthy for the mind.
 LEFT: Relaxing during my family’s yearly Denmark vacation – ‘even uitwaaien’ how the Dutch call it. RIGHT: Stand-up paddling through the Dutch national park ‘Weerribben-Wieden’.
What’s one thing on your bucket list? Your dream?Again, just one big dream or plan would not suit me well – there are simply too many awesome things in life. One big dream, speaking a 3rd language fluently – in my case, Dutch - I made come true over the past 7 years. A lovely next challenge would be learning a Scandinavian language – most likely Danish – as it is my favorite country to travel to.
As a travel goal, Greenland is very high on my list. I would love to plan a kayak trip for multiple weeks, including the Ilulissat Icefjord, and would have high hopes of seeing a musk ox and polar bear in real life – with some healthy distance, preferably. In Canada, I already had the chance to go dog sledding when I was 15. That’s a dream that I would also want to relive in Greenland.________________________________________________________________________________________________________________________________________________Marina, we can only say continue all the great things you do. With your help, Community users are growing, and as you mentioned, it’s a challenge where you also gain valuable knowledge and experience.

----------------
28.1:

Such an inspiring story!  Thanks a lot for sharing, Marina! 
Congratulations on becoming our Community Member of the Month! 
PS. I had a similar dilemma when I was graduating from high school  I was very much into European Union and I love history! But in the end, I decided to take the final exams in mathematics and physics - then chose the Technical University in Gdansk where I graduated from Computer Science 

----------------
28.2:

Super @marina_pollehn ! proud to have you in my team!

----------------
28.3:

Congrats @marina_pollehn  and well deserved! You're a valued team member supporting customers worldwide, spreading the added value of observability powered by Dynatrace. Keep up the good work!

----------------
28.4:

Congrats @marina_pollehn ! Way to go! Awesome story!

----------------
28.5:

Super! Congrats Great story:)

----------------
28.6:

Congrats

----------------
28.7:

Such an inspiring story, I need to give some credit to these amazing pictures - the first one reminds me of my first flight to the Nederlands, that's the exact view that welcomed me right ahead of landing! 

----------------
28.8:

Hi @marina_pollehn,Congrats!!! Thanks for your contribution to the Community.Best regards, Mizső

----------------
28.9:

Thanks everyone for the nice comments  

----------------
28.10:

Well Deserved @marina_pollehn !!!! Thank you for your contribution to the community.

----------------
28.11:

Congratulations Marina!!  

----------------
28.12:

Congrats @marina_pollehn ,"When answering a question, you often need to do some testing on your own or you need to research until you finally find the solution you had hoped for. This keeps me curious and up-to-date." -> This is clearly something I have noticed in your replies, some of them to my own questions  Thanks so much for this posture!BTW, the dancers are back  one more Salsa dancer in the Dynatrace Community...

----------------
28.13:

Congrats @marina_pollehn 

----------------
28.14:

Congrats, @marina_pollehn !!! I knew that you will be here soon or later!!And @AgataWlodarczyk , we should create a book with all those inspiring histories from this "Member of the Month" section.

----------------
28.15:

@marina_pollehn Congrats!!!

----------------
29:

Is there a way to set up a custom alert for slow transactions?For e.g: Send an alert if slow transactions are > certain threshold.



					
						Solved!
					
					Go to Solution.




----------------
29.1:


Yes, is possible.Look this    Documentation pagehttps://www.dynatrace.com/support/help/platform/davis-ai/anomaly-detection/metric-events

	Dynatrace Professional Certified


----------------
30:

If I go to “Technology overview” and filtering by “Dynatrace”, I cannot see any technology: But if I go to a host, I can see Dynatrace processes and process groups.Is that normal? Why Dynatrace technologies are not showed in that section?Best regards

	Consultant




					
						Solved!
					
					Go to Solution.




----------------
30.1:


That's intended, only important and recognized technologies are shown under "Technologies and processes", you will notice all Dynatrace processes and any processes of unknown technology will not show up there and you will need to find them through the host screens.

----------------
31:

I'm a little confused by the documentation below. For 2.0 extensions it states the below. To me this is saying it is needed otherwise the extension will not work, but that is not the case. I've created a JMX extension and added it to a bunch of hosts. I have not added the certificate but we are getting data from the extension. Can someone please clarify this?Each host running your extension, whether OneAgent or ActiveGate, needs to have the root certificate saved in a dedicated directory. This extra step is required to enhance the security of the Extensions 2.0 framework.https://www.dynatrace.com/support/help/extend-dynatrace/extensions20/sign-extension#upload



					
						Solved!
					
					Go to Solution.




----------------
31.1:


JMX is excluded from the certificate requirement, it just needs to exist on the Dynatrace cluster. I'll ask for the documentation to be updated.

----------------
31.2:

@Mike_L  thank you!

----------------
32:

Hi everyone,I've created a 2.0 JMX extension to pull out the kafka status metric for confluent kafka. I am able to see some connector status' but not all of them. In addition to that it seems the status will show as running when in fact it is failed as shown in the kafka console. Any thoughts of where to look at to figure out the issue? Anyone been able to pull in the connector status for confluent kafka? Below is a snippet from the yaml. 



					
						Solved!
					
					Go to Solution.




----------------
32.1:


Seems like the MBean you're capturing is for the connector itself, which can only have the values for running, paused or stopped. If you're expecting to see failed, it might mean you actually want to capture a task's status instead of the connector itself, so maybe something like this is what you're looking for:        - subgroup: Connect.ConnectorMetrics
          query: kafka.connect:type=connector-metrics,connector=*,task=*
          featureSet: connect-metrics
          dimensions:
            - key: connector
              value: property:connector
            - key: task
              value: property:task
            - key: status
              value: attribute:status
          metrics:
            - key: kafka.connector.task.status
              value: const:1
              type: gauge Source: https://docs.confluent.io/platform/current/connect/monitoring.html#connector-metrics

----------------
32.2:

Good catch here! I have added this in but our count is still not matching up with Kafka shows. Do you know if the status metric is 'exposed' only once when the status is changed?Our thought process was that we may have tasks that have been in a failed state for a period time before the extension started collecting the metric. We are trying to do some testing here to get more info.

----------------
32.3:

As per the documentation, it should be the current state, so there's definitely a difference between how the MBean exposed metric is being counted and how your Kafka console is counting it. Difficult to troubleshoot further.

----------------
32.4:

So, I found that the status metric in dynatrace is only updated after I push a newer version of the extension. The change is not relevant, I simply update the version to allow for it to be uploaded. Once I apply the new version to the monitoring configuration I can then see something such as the below in the logs. After a minute or so of 'installing' the newer version then I see that updated status in dynatrace.Ever seen something like this or know what could be causing this? Below is the yaml I have so far.2023-09-27 14:14:02.599 UTC [003b195f] info [java ] [metrics ] Uninstalling monitoring config of JMX extension 'custom:kafka.jmx.misc.metrics' (version 1.0.2)2023-09-27 14:14:03.600 UTC [003b195f] info [java ] [metrics ] Installing monitoring config of JMX extension 'custom:kafka.jmx.misc.metrics' (version 1.0.3) 

----------------
32.5:

The logs are completely normal, it's just telling you it's going to download and use the new version since you updated it. What exactly do you see in Dynatrace, that you feel only gets updated when you upload a new version? Consider that with the above definition, the metric's value is always 1 and only the status attribute changes over time. Also, consider checking the configured frequency, if any, as it might just capture the metric every X minutes and you might not be giving it enough time.

----------------
32.6:

I am fine with a value of 1 always showing, I understand why that is occurring. What I don't understand is why the status of the connector task is only updated when I publish a new version of the extension. A datapoint is logged in data explorer every 1 minute but the status is only ever updated when I update the extension.

----------------
32.7:

I think I understand the issue, when you set the value to const:1, the JMX Datasource is reading the MBean once and then providing a constant value, including the dimensions, even if the value of the dimension changes.Can you try changing the whole thing to something like this:        - subgroup: Connect.ConnectorMetrics
          query: kafka.connect:type=connector-metrics,connector=*,task=*
          featureSet: connect-metrics
          dimensions:
            - key: connector
              value: property:connector
            - key: task
              value: property:task
            - key: status
              value: attribute:status
          metrics:
            - key: kafka.connector.task.status
              value: 
                attribute: status
                accessor: equals("running")
              type: gaugeThis will give the metric a value of 1 if the status is running or 0 otherwise, and should update every time the value of status changes.

----------------
32.8:

Thank you for continuing to look at this! I have made this change and waiting on the app team to change a connector status to see if this gets picked up.Question, is there a way we can have the extension to always report back the current status? Our use case is alert if the status is not running and if the above changes works then we should be good but taking it a step further it would be good to always get the current status rather than logging a 0 if the status is not running, the task status could be any 1 of the below according to https://docs.confluent.io/platform/current/connect/monitoring.html#common-task-metricsAs a note, we originally were looking at the connector status but the app teams has since come back and wanted to alert if the task status is anything but running.unassigned, running, paused, failed, or destroyed

----------------
32.9:

As an update to my post above, I may have spoken too soon. I am seeing other status' showing in dynatrace now so it looks promising so far. Still waiting on our app team to help me validate things.

----------------
32.10:

I was just typing:If you have the dimensions section in your metric inside the yaml file, just like we can see in my example above, then you will get the current status as a dimension, regardless of the value. It is not the most elegant solution, but you can always create a metric event in Dynatrace for a specific value of a dimension in a metric, so in this case you would need to alert when status = unassigned, when status = paused, when status = failed and when status = destroyed, so a total of 4 metric events for this. Or you can alert when the value is 0 and show the value of the status dimension on the description of the metric event.Seems like you figured it out, but still leaving it here for clarification 

----------------
32.11:

Ok here is where I'm at. For 2 different connectors we switched the status from running to paused. It was tracking correctly in Dynatrace. Whenever it was running we would get a datapoint with value of 1, as expected from what you noted above.What is not working correctly (based off previous comments above) is the status dimension will still show the previous status, it does not get updated unless I upload a new version of the extension. The datapoint value is correct, it will drop to a 0 when it isn't running but it will still show a status of paused (we are testing by switching from paused to running then back to paused).The example below is from when a connector was paused. We started it back up and as noted by the '1' it reflects as running (which was correct) but the status never changed, it only changes after updating a new version of the extension. Here is the yaml. The first query is meant to capture the task status because that is what the use case is for, alert if a task hits failed state. The 2nd query is for the connector status which likely can be removed, i just left it in because we were originally looking at the connector status until the use case changed.  

----------------
32.12:

@victor_balbuena i think until we get this dimension status tracking correctly this is not going to work for us. It's great that we have running connectors showing as 1 but we can't alert if below 1 because below 1 could be from the connector being paused or failed, we only care if the connector is failed.Having the status dimension reflect the true status should allow us to alert for what we need.

----------------
32.13:

I undersand your pain but I'm not a support person, I'm just trying to help you because I happen to know about extensions and JMX  I really thought what I mentioned above could work, because I'm as perplexed as you, I've never seen it happen before in any JMX extension in EF2.0. Maybe there is an underlying bug somewhere here...

----------------
32.14:

No worries @victor_balbuena! I appreciate all the time spent here. I think it is an improvement from what we have but still lacking some. I'm hoping our account reps can help us push this along to get more visibility on this, maybe from the extensions team.

----------------
33:

Hi I can see the age column related to pods under kubernetes overview of the node  how can i use it to display in dashboard panel to show the uptime of the pods 

----------------
33.1:

Hello,In order to get that information dashboarded you would have to be able to get a metric to display in data explorer. Please try looking through the kubernetes built in metrics found here, https://www.dynatrace.com/support/help/shortlink/all-metrics#kubernetes.If there is not a metric for "pod uptime" it may have to be a custom metric, or you can post this in the Ideas channel for suggesting the creation of such a metric.

----------------
33.2:

i think that if you use builtin:host.uptime maybe works, but i dont know for sure.You can try create metrics to do this. anyway take a look of this documentation pagehttps://community.dynatrace.com/t5/Container-platforms/Assigning-a-hostgroup-to-an-OpenShift-pod-quo... Feel free to ask if you got any doubts

	Dynatrace Professional Certified


----------------
33.3:

Hi @VENKY1544,AFAIK there is not an OOTB solution. Maybe you can play with Environment APIv2 Monitored entities:GET / entities provide a list of entities with fist seen and last seen attribute, you can filter only for pods by type("CLOUD_APPLICATION_INSTANCE")orGET / entities / {entityId} but in this case you should know the individual entity ids.I hope it helps to start thinking.Best regards,Mizső 

	Certified Dynatrace Professional


----------------
33.4:

hi @VENKY1544 , did any of the comments above help you? You can accept any of them as solutions if they work  

	The only constant is change. Finding ways for great things to happen!


----------------
34:

 The "Taste From the Past" BadgeWelcome to the new Community Challenge. We're thrilled to invite you once again to a nostalgic trip! Food is one of the most crucial fundamentals of our memories -- just one name of a dish or picture can awaken our senses!
 
Let's share our favorite tastes from the past, naming nostalgic dishes, snacks, or other types of food from your old days. Don't hesitate to feature not only names but pictures as well! For every participant, we've prepared a dedicated badge, just like a bonus 100 points! Let's recollect some tastes we used to adore... Or maybe totally the opposite 
 
Let me start once again with the summer speciality from my Grandma, the strawberry soup with croutons 
 Strawberry Soup with Croutons

----------------
34.1:

Growing up in Sweden with roots in the northern parts of the country I always loved the flat bread from that part of the country.
My favorite was a filling with vegetables, sausage, potato and mix of cottage cheese, apple and more. Whenever I go back to Sweden to spend time with the family I always make sure that it is on the menu!
 
 
 
Recipe (In Swedish, but google translate should help): https://ugnstrull.se/recept/gourmetrulle-med-steppsallad/

----------------
34.2:

For me it's Sterz, especially "Heidensterz" (buckwheat) with beans, lightly fried in lots of lard served with sour mushroom soup. Sterz would be in a large p0t in the middle, you'd take a spoon full, dunk it into the soup and eat it. Delicious.Recipe here: https://burgenland.orf.at/v2/radio/stories/2891920/

----------------
34.3:

Being a Ukrainian, there's only one type of food I am legally allowed to talk about /jk
Borshch 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
If I feel particularly homesick, this is the only thing to bring me up  But there's no borshch like the one my mom makes, so every time I come home I ask her to cook it. 
Another thing that always makes me nostalgic is poppy seed rolls 
 
It was always on the table in my grandma's house when I came over 

	The only constant is change. Finding ways for great things to happen!


----------------
34.4:

 In portuguese bife com batata frita or steak with fries, my favorite food of all time. Like a real brazilian, this plate are in almost every table  in the houses from Brasil in the sundays   Recipe here: https://www.tudogostoso.com.br/receita/95741-bife-acebolado-com-batata-frita.html

	Dynatrace Professional Certified


----------------
34.5:

This is a risky post! ...now I can't stop thinking about all of these dishes For me, it is the Mediterranean cuisine and specifically the Libyan couscous which can be served with vegetables, meat, chicken or fish!  The picture showing below is Libyan couscous with meat, chickpeas and onion topping. Served with salad on the side called "sharmola" which is made with tomatoes, cucumbers, onion, jalapeno and a little bit of olive oil and a pinch of salt.  

----------------
34.6:

Hi All,It's a specially different, but I will put here some pictures of what my wife prepare everymorning for kids in the LunchBox.Everything is home made (even the CupCakes).It's a little difficult to eat healthy everyday but we try  

	Sharing Knowledge


----------------
34.7:

WOW what a challenge , as @Mo_Azuz  wrote me also can not stop drool after looking ay your photos  For me any thing that include dough is like a red rag But on top of that every thing need to be hot .... very hot !!!Lately we have found at a neighbor garden an Habanero bush  And now we are practicing at home few dishes     

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
34.8:

These revolting, delicious, revolting concoctions were only available for 1 year but they left a lasting impression and we all miss them!  

	Senior Client Services Analyst


----------------
34.9:

It  looks like really different, i really would like to taste it.

	Dynatrace Certified


----------------
34.10:

They had a flavor profile similar to Boston cream pie or Bavarian cream donut.

	Senior Client Services Analyst


----------------
34.11:

Growing up in Hawaii, I've always had different types of Asian cuisine that you normally can't find anywhere else (nor can it be replicated anywhere else for that matter). One of my favorite dishes growing up (and still is, to this day but I can't find anywhere since I've moved) is Ube Pancakes!  It might look a little too sweet, but the flavor is incredibly balanced, considering the main ingredient is purple yam! So I guess that covers the guilt of it being an 'unhealthy' breakfast option, but it's definitely one for the books if you're ever heading to Hawaii!

----------------
34.12:

Hi,Sure is not best food or healthy food, but talking about nostalgic, 90s...  

	Consultant


----------------
34.13:

Sugar watches!  

	Keep calm and build Community!


----------------
34.14:

"Taste from the past"? Seems like I have to go with our ancestors, and the "pastel de nata":

	Antonio Sousa


----------------
34.15:

Grandmother used to prepare yummy "Idli, vada with sambar and chutney"  

	Dynatrace Certified


----------------
34.16:

Had this a couple of weeks ago, with mint sauce, they were awesome.

----------------
34.17:

One of nostalgic recipes that really makes me to remember my childhood in my entire life, and that i reaaly like its called "Feijoada", basically made of cooked black beans and Assorted Meats. Usually it's served with white rice, sautéed collard greens, and sliced oranges on the side.Feijoada is a hearty and flavorful dish that brings a taste of Brazil to the plate.   

	Dynatrace Certified


----------------
34.18:

My favorite taste from the past, without hesitation, the "breton galette" from my grandma !A Breton galette is a traditional flat cake or pancake from the Brittany region of France. It is made primarily from buckwheat flour and is often served with savory fillings such as eggs, cheese, ham, and vegetables.I ate it every wednesday after the school.  

	Observability consultant - Dynatrace Associate/Pro/Services certified


----------------
34.19:

I love it:) i'm already hungry  

	Have a nice day!


----------------
34.20:

When I was growing up, my grandmother (Nana) was an amazing baker. My wife decided to give those recipes a shot and WOW! She could not have matched the taste any better. The cookies with the jam in the middle she called Scandinavian cookies. The loaf is called Mandelbrot. There are many versions of this but she made it with jam, nuts and raisins.    

----------------
34.21:

Strawberry soup is great. Every summer my mother used to cook this soup for me, but with noodles and mint leaves

	Have a nice day!


----------------
34.22:

I'm the biggest fan of homemade craft pizzas. I could cook and eat them every day, but only if I know that my dish is healthy. I make pizza on spelt dough with lots of vegetables and natural sauces. That's why I don't order pizzas to go. My wife jokes that I put my pizza dough in all the free food containers in our home. One time, I prepared 15 kg of pizza dough and invited all my neighbors for a month of dinners. They still can't look at the pizza  

	Have a nice day!


----------------
34.23:

It wasn't too long ago that I had this, and actually I wouldn't mind some right about now , but its a very old recipe....Haluski - Slovakia  With a cold glass of Kofola! All in a traditional Slovak setting, such a great experience!  Resturaunt: https://www.syrex.s | https://www.syrex.sk/koliba If you find yourself in that part of Slovakia, you might as well also visit Juraj Janosik:            

	-Chad


----------------
34.24:

Well, for me definitively would be the Mate.  I remember drinking it with my grandma seeing her garden and talking a lot.It is a very popular infusion in South America especially Argentina, Uruguay and Paraguay. Famous People Drinking Mate Obama Hetfield (Metallica) Zoe Zaldana Lionel Messi      

	The true delight is in the finding out rather than in the knowing.


----------------
34.25:

You're missing another famous drinking mate (chimarrão) Danne Aguiar 

	Site Reliability Engineer @ Kyndryl


----------------
34.26:

For me the taste I will never forget is the one of chanterelles fried in butter. I used to collect them very early in the morning after every night fishing trip with my uncle. The last time we went on one together was probably about 10 years ago, but it really feels like it was yesterday whenever I have a chance to eat them... 

----------------
34.27:

Something I'll never forget is the "Meet and spinach cannelloni" from my grandma also as Argentinean the "Family Asados"       

----------------
34.28:

For me there's two word 1. Biriyani "Biryani is a mixed rice dish of South Asia. It is made with spices, vegetables, rice, and usually some type of meat (chicken, goat, lamb, beef). In some cases without any meat, and sometimes with eggs and potatoes." In terms of dishes this is my most favorite as every bite is a mouthful of flavor.  2. Fuchka (aka panipuri) These are both highly known south Asian cuisine. "Panipuri is deep-fried breaded sphere filled with potato, onion, or chickpea. It is a common street food in the Indian subcontinent. It is often spiced with tamarind chutney, chili powder, or chaat masala. A variant, fuchka, uses spiced mashed potatoes as the filling." My childhood evening snack is based on this, since this is street food my family would not always appreciate me eating those but I would secretly meet up with friends after school just to have these.

----------------
34.29:

My mother used to make this dessert when I was a child. Here in Brazil we call it "Sorvete americano" (American Ice cream). It is basically make with milk (condensed, cream), eggs and chocolate. When I grew up and moved away from my parents home, I learned how to make it and at least once per month it is part of my children joy after lunch.

	Site Reliability Engineer @ Kyndryl


----------------
34.30:

How much do we have to bribe you so you'll bring some for us, too?

----------------
34.31:

You will be surprised as how easy is to make it!!First layer: 1 can of condensed milk, use the same can with fresh milk, and 3 eggs yolk.Mix all together in the fire until it get creaming consistence.Second layer: 1 can of milk cream, 1 cam of condensed milk, 6 spoons of cocoa powder (or sugar chocolate).Mix all together in the fire until it get creaming consistence.Wait for the first layer to get cold before drop this one over it. You can use some biscuits as an additional layer, so they don't get mixed.Third layer: mix all the remain 3 eggs white until it gets the whipped cream consistence, then add 3 spoons of suggar, mix a bit, then add 1 can of milk cream and mix, until you get a creaming consistence.Add it over the chocolate layer.Let it rest at the freezer and enjoy!!!

	Site Reliability Engineer @ Kyndryl


----------------
34.32:

Growing up on the East Coast of Canada, in Nova Scotia, seafood played a major role in what we ate. There are two things I stuff myself with whenever I get back for a visit. Fried clams, and my mother's seafood chowder.The seafood chowder has several types of fish like salmon, flounder etc., shrimp, lobster, clams, mussels, scallops potatoes, onion, milk, butter and other herbs and it is delicious.   The clams are taken from the shell and dunked in a thick batter, then deep fried. I like them with ketchup:   

----------------
34.33:

For me it's "Hollerröster" (did not find an english translation) which always takes my back too my childhood. It is mainly cooked from elderberry, some vanilla pudding, spices (cloves, cinnamon) and sometimes also some plums or apples. It still is one of my favorite foods, but hard to get somewhere if you don't cook it on your own. Tastes great on its own or also makes a delicious side for "Kaiserschmarrn".Picture is not from me, just for illustration purpose.  

	iOS help: https://www.dynatrace.com/support/help/shortlink/ios-hub


----------------
34.34:

The nostalgic dish for me is "Naporitan". This is a pasta dish seasoned with tomato ketchup that has been eaten in Japan since the 1950s. It is still served at many restaurants, most convenience stores, and is still made at home.It's strange, but even though it's called Naporitan, I think it's a dish unique to Japan. 

	T.Shirai IIM Corp. Osaka Japan


----------------
34.35:

For me as an Egyptian, it will always be "Koshary"    

	Dynatrace Certified Professional - Dynatrace Partner - Yourcompass.ca


----------------
34.36:

Hello,
as a kid I was in love with (and still I'm in love with) so-called Kiachln or Bauernkrapfn. It's kind of a donut made of yeast dough.The basic variant without sugar on top or without marmalade is the best as it's the pure taste.
I remember that my grandma made 40-50 of them for our family 
 

----------------
34.37:

This reply will be a small love letter to my German grandparents :D. I was very lucky as my grandparents live within 15min walking distance of my parents and I spent many afternoons and weekends (I guess when my parents had enough of me and my sister :D) at their place. My grandpa taught me how to make flour with a small hand mill and my grandma always had the most amazing recipes. If we were very lucky, she brought the ice machine upstairs, and we would make ice cream from frozen fruits, whipped cream and sugar. She also taught us how to make 'Königsberger Klopse', an old Prussian recipe. We usually ate them with potatoes which we mashed on the plate so they would absorb the sauce.  Here is an English recipe of the dish: German Meatballs in Gravy (Konigsberger Klopse) Recipe (thespruceeats.com)For some reason, she also made the best mashed potatoes. Even if I use exactly the same measurements of the ingredients mine simply do not taste the same. Also her 'Quarkbällchen' became famous in the entire neighborhood. I am not allowed to share the recipe here so here is an alternative one in English :D. EASY Donut Hole Recipe (Quarkbällchen) - dirndl kitchen  

	A Dynatrace Professional nerd working for Eviden


----------------
34.38:

From my Spanish side, the "roscos de anís" my mom would make every year: 
 
From my Belgian Side: Friet met stoofvlees, which is a traditional Belgian dish consisting of french fries (friet) served with a hearty beef stew (stoofvlees). The beef stew is typically slow-cooked in a rich, flavorful sauce made with beer, onions, and various spices.
 
 

	WHomES


----------------
34.39:

Hi guys have a look at the multicourse Kashmiri dish Wazwan that every Kashmiri loves to eat. Almost all the dishes are meat-based using lamb or chicken with few vegetarian dishes. It is popular throughout the larger Kashmir region. Wazwan is a revered Kashmiri culinary tradition, renowned for its opulent multi-course feasts prepared on special occasions. It features a sumptuous array of dishes, from aromatic gravies to succulent kebabs, each meticulously crafted by skilled chefs known as "wazas." This gastronomic experience embodies the warmth, culture, and hospitality of the Kashmiri people.   

----------------
34.40:

Brazilian hot dog is my favorite snack! 

----------------
34.41:

In Sao Paulo they even put mash potatoes with it: 
 
It is as odd as the pizzas with peas ( the so called "portuguesa")
 
 

	WHomES


----------------
34.42:

This looks amazing!! Do you have a recipe, maybe? I'd like to try it  

	The only constant is change. Finding ways for great things to happen!


----------------
34.43:

 My wife has a mold to make Oreshki 

----------------
34.44:

For me, I like seafood, but the most important thing that I can't live without is Turkish Coffee. 

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
34.45:

What a risky one, indeed!! And although I also very much support @natanael_mendes ' Bife com Batatas Fritas as a taste from my past too (obviously!), the one that really strikes me as nostalgic is the very typical "Bifinhos com Natas e Cogumelos": "Little Steaks with Cream and Mushrooms".Here in Portugal, this dish is present nearly everywhere as it is very simple, cheap and very very yummi It regularly served with a brutal dose of french fries and rice, so you can dip both in the amazing sauce after finishing the meat To me, besides being something that I eat since I was a small child, it has always been the greatest example of comfort food  

	Best regards, Pedro Deodato


----------------
34.46:

look so good!!!

	Dynatrace Professional Certified


----------------
34.47:

We use to live in Germany/Holland many years ago when I was a kid.  Still remember and love a good Tartare sandwich Does anybody still eat there?  People go crazy in US when they here I use to eat this.  

	Dynatrace Certified Professional


----------------
34.48:

I LOVE a good tartare sandwich! With some pickles and a smidge of whole grain mustard 

	The only constant is change. Finding ways for great things to happen!


----------------
34.49:

We upgraded this sandwich in Belgium and it is called Martino: 
 
So apart from the steak tartare, we put: onions, ketchup, mustard(Dijon),tabasco,gerkins,capers, rucula, salad ( last two not for me).

	WHomES


----------------
34.50:

Wow, so many original, amazing dishes, haven't heard before about nearly half of them - kudos! 
For me, the taste from the past (and fortunately, present as well!) is already mentioned before by @Ana_Kuzmenchuk borscht, but in its white version. The difference is, that the main ingredients aren't beets, but mushrooms, which I love! The mandatory addition to it has to be "uszka" - impossible to translate, but they're similar to ravioli 
 
 White borscht with "uszka"
 
This dish is so special for me, because each year for Christmas Eve my grandma cooks it by herself from scratch, forming hundreds of "uszka" to show her love to us. This is something my family eats only once a year to celebrate the fact that despite living away from each other, we manage to gather around and enjoy grandma's fantastic cuisine together!

----------------
35:

Hi everyone,
Is there a way to get the Pub/Sub from GCP like any queue/topic in the Queue Menu ?  It is not practical to have the pubsub topics in the cloud project.
With Apache Kafka I can see my producer/consumer, is that possible to have the full view (via service flow ? Smartscape ?) ?
Is there a way to "follow" an event/message that perform GCP Pub/Sub -> Cloud Function -> pubsub -> Java service (For example)
Thanks for your help

----------------
35.1:

Hi @agonzalez, did, you by chance, find the solution to this on your own? I think our Community would really appreciate it if you published it. If not, let's bring this post back up the activity feed so more people could see it and had a chance to help you out  

	The only constant is change. Finding ways for great things to happen!


----------------
36:

In this episode, Berkan Akbulut and Andreas Grabner @andreas_grabner cover the following latest Dynatrace releases:Release Notes 1.271: https://dynatr.ac/3sj00lv Release Notes 1.272: https://dynatr.ac/3EqdHlH In the talk, we referenced many resources. To get the slide deck with all the links, please navigate to https://dynatr.ac/44kti0n. (Sign in to Dynatrace University. Select "On Demand." Select "Webinar Series" and click on the "Dynatrace Webinars Course." Select this video, and under the "Resources" tab, you'll find the slide deck)
If you have questions or feedback, don’t hesitate to reach out to the Dynatrace ONE team: https://dynatr.ac/3QIFghk 
If you want to give Dynatrace a try, get your own SaaS trial: https://bit.ly/dtsaastrial To watch more tutorials go to https://bit.ly/oneagenttutorials To access documentation: https://dynatr.ac/3QPhgJj To get to the blogs: https://dynatr.ac/3QJI0ek 
Chapter List:00:00 - Introduction03:58 - Product Updates04:22 - Announcements 05:27 - AppSec Updates 07:27 - AppSec Updates Live Demo09:02 - Platform Updates (DQL, ...) 13:34 - Platform Updates (DQL, ...) Live Demo19:22 - Infrastructure Updates22:07 - Infrastructure Live Demo24:00 - Digital Experience Updates24:50 - Digital Experience Live Demo25:00 - Automation Updates 30:08 - Settings Updates31:10 - Settings Updates Live Demo33:38 - Account Experience Updates35:15 - Account Experience Live Demo36:15 - Wrap UpThe recording is available also on the Dynatrace University: LINK- - - Subscribe to our YT channel Stay up-to-date with Dynatrace! Follow us on Facebook, Instagram, LinkedIn, Twitter, Twitch  

 When passion meets people magic and innovation happen. 


----------------
36.1:

As always a super session with the news!

	Have a nice day!


----------------
36.2:

This is fantastic to see embedded in the release notes of the new version. This will make it much easier for teams that leverage the tool to be able to understand all the new features.

----------------
37:

Dears,
We have IIB connected with IBM DB2 which is installed on RHEL server. We could see no host information available for the IBM DB2 server. Also, the database query information is not collected. Even in the traces we don't see the database statements. It is giving statement type as "Default Requests". Any idea how to pull these details?

	Ramanan Raghunathan




					
						Solved!
					
					Go to Solution.




----------------
37.1:


Hi Ram,I have experienced the same phenomen, the support said:The reason there are some database instances are not returning the detailed data is that they are being called by ComputeNodes, which are not a supported node type. If we take a look at the calling service, which is an IBM Integration Bus, and select the code tab we can see the DB call comes directly from that ComputeNode.IIB ComputeNode uses the ESQL, rather than SQL, which we cannot parse.

	Sharing Knowledge


----------------
37.2:

Hi Malaik,Thanks for the clarification. 

	Ramanan Raghunathan


----------------
38:

Hi,
We would like to setup RUM with Office 365, but as O365 is aaS we can't install the agent or inject the javascript.
What additional options do we have?



					
						Solved!
					
					Go to Solution.




----------------
38.1:


Hi,We offer a chrome browser extension which you can roll out to your employees. For some office365 apps like Sharepoint you can add our RUM JavaScript snippet in the page template.Please look at:https://www.dynatrace.com/news/blog/real-user-moni...andhttps://www.dynatrace.com/support/help/user-experi...

----------------
38.2:

Hey,Is there a browser extension or similar for edge or IE?Typically these would be used for Office365 apps.

----------------
38.3:

Official browser is IE and we need also other than sharepoint O365 apps monitored.

----------------
38.4:

According to the document, it seems to support Microsoft Edge in the future releases.Future releases will include browser support for Microsoft Edge and Mozilla Firefox. https://www.dynatrace.com/support/help/user-exper...I can not find about IE...

----------------
38.5:

Hi, Is their an alternative for M365 since te browser plugin is getting out of support? regardsKevin

----------------
39:

Hello community,
i want to enable RUM V2 in my environment, but there are few informations in documentation about it (maybe because it's an early adopter). In screen below there is a switch On/Off:

 
So, i have some questions:
 
1) There is a best practice to enable it? Or just switch On?
2) There is a detailed documentation about it?
3) There is a Process Group Override section, so i can select a specific process group when i enable RUM V2 or i must enable it for whole environment?

4) If i enable RUM V2, i must restart what? Processes, or whole VM?
 
Anyone have some information about it? Thanks so much



					
						Solved!
					
					Go to Solution.




----------------
39.1:


You can go ahead and enable it if you are using java web/app servers for RUM.Documentation is internal and nothing is publicly available. Most of the changes are architectural to solve certain quirks that the older version had and you won't really see any noticeable impact after enabling it Yes you can enable it at the process group levelYou would have to restart the process 

	-Chad


----------------
39.2:

			
				
					
					
						Thank you Chad for your answer
					
				
			
			
				
			
			
				
			
			
			
			
			
			
		
----------------
39.3:


Dear @Chad T.,Dear @Axel V.I have to add to / refute parts of Chads statement!v2 (very bad choice for the name) was maybe initially planned to "improve" or supersede the existing version. However, since v2 is technically different and tries to tackle different cases it should be seen as an alternative approach not an improved version! Hence, if everything works find now and you don't have any class cast exceptions (that's what v2 its build for) then I strongly recommend to stick with the existing version and not enable v2.Heads up here: we will "remove" v2 from the UI in the foreseeable future and only make it available for our support teams to enable it / switch between the approaches if needed. v2 will be an "alternative approach" and therefore a troubleshooting "feature" only. To correctly call it by the name! Pls. let me know if anything is unclearregardsThomasProduct Manager RUM web

----------------
39.4:

Thank you so much Thomas, i appreciate it! 

----------------
39.5:


Dear @Thomas Z., i want to explain my answer. I have an application that run in Webmethods Application server. This Webmethods is officially supported, but RUM injection doesn't work. I opened a ticket to Dynatrace support and they told me that RUM is not supported because this application doesn't use Java Servlet (processes instrumentation is OK). Also, they told me to try ith RUM V2, but there are few chances that it works.So, do you know if RUM V2 might work?Thank you and best regards

----------------
39.6:

Anytime! If I were you, and since "This Webmethods is officially supported" I would push Support to properly troubleshoot this case! If its not because of class cast exception than they have to properly follow it up with development and they have to check whether and how we can fix this. In my humble opinion as simple as that! And please feel free to mention me in the ticket then I can also follow the ticket! thanksThomas

----------------
39.7:

Thank you @Thomas Z.! Support told me that Webmethods are supported for OneAgent instrumentation, but RUM is not supported. This is ad extract from support answer:"First of all there is no official support for RUM for WebMethods Integration Server 0 in other words Dynatrace OneAgent is not able to inject JS library into its HTML pages because these are not Web request services but web services. The documentation only says that OneAngent is able to monitor "Java internals" of this product but not injecting RUM portion.RUM is supported only for "Java servlet-based web applications" and we don't inject RUM into webMethods, as they use something different than servlets and marked as webService which means XML/JSON. Anyway we had once a customer who swiched Java Monitoring to V2 and for WebMethods and it worked well.""if we don't use Servlets than there are small chances RUM V2 will help, sorry ... "So, i don't know if open a new support ticket or try RUM V2...

----------------
39.8:

Dear @Axel V., shortly got in touch with the dev for the Java injection. Yes we don't support auto injection for Webmethods. BUT. what you can do in this case is the following: have an agent on the server capturing the server-side metricshave an application for automatic injection and create an injection exclusion rule to never inject automaticallyinsert manually. make sure the beacons are sent via an Active GateThis way you should be able to monitor that setup full stack! regards ThomasHope that helps. Support should know about this and help you set it up correctly! 

----------------
39.9:

Hello @Thomas Z. and thank you so much! So, i must try to enable manual injection, right?Application settings -> Injection -> "Manual insertion" tab This is correct path for solution? If not, can you tell me the correct path in settings?Thanks for your usefull help, Best regardsAxel

----------------
39.10:

exactly! And don't forget to also add an exclusion rule to not inject automatically for the domain/the whole web site

----------------
39.11:

			
				
					
					
						Perfect, thank you Thomas, i'll update thread if i'll have news. Best regards

----------------
39.12:

Hello,Today we had an issue  with an IBM tool: java.lang.ClassCastException: com.dynatrace.agent.introspection.uem.impl.CacheHookingRequestWrapperSupport advised to turn on: Java Real user monitoring v2 [Opt-In]This fixed the issue. So my question is,Does turning this on, turn off the old stuff (-;?And is your previous (excellent) explanation  now obsolete? KR Henk  

----------------
40:

In a data explorer graph with the process CPU with some filters applied and split by process group instance and host: The 13th of September the CPU dropped a lot (expected behavior). However, even though some processes are still consuming small amounts of CPU, nothing appears in the graph.This is one example:  And this is what the data explorer graph shows:  When the CPU is around 0.15% it doesn't show anything in the graph. Why is this? Is there a way to see this information even though the percentage is small?

----------------
40.1:

Hey @elenaperez ,Seems like you are looking at two different metrics here. The one above is builtin:tech.generic.cpu.usage meanwhile the one below is builtin:process.cpu. If you were to chart in your dashboard the one above, the "small" numbers of that metric would show up in the dashboard as well. The other metric (builtin:process.cpu) has actually stopped being populated, at around the same time that there is the drop of CPU usage in your other metric.So the problem is no longer charting small numbers, because of course the Data Explorer can do that, but why did the second metric (builtin:process.cpu) stop being populated so harshly for so many processes. For this, I don't have an answer, but hopefully someone else does, reads my comments and can add their more professional insights into why it could disappear.Hopefully this helps.

----------------
41:


 



Error

Detail


Test fails


Error category


Notes




400


Bad Request


Yes


HTTP response code


All errors are reported in the same tab




401


Unauthorized


Yes


HTTP response code


gets reported in a same tab since APM-108556




402


Payment Required


Yes


HTTP response code

 



403


Forbidden


Yes


HTTP response code

 



404


Not Found


Yes


HTTP response code

 



405


Method Not Allowed


Yes


HTTP response code

 



406


Not Acceptable


Yes


HTTP response code

 



407


Proxy Authentication Required


Yes


HTTP response code

 



408


Request Timeout


Yes


HTTP response code

 



409


Conflict


Yes


HTTP response code

 



410


Gone


Yes


HTTP response code

 



411


Length Required


Yes


HTTP response code

 



412


Precondition Required


Yes


HTTP response code

 



413


Request Entry Too Large


Yes


HTTP response code

 



414


Request-URI Too Long


Yes


HTTP response code

 



415


Unsupported Media Type


Yes


HTTP response code

 



416


Requested Range Not Satisfiable


Yes


HTTP response code

 



417


Expectation Failed


Yes


HTTP response code

 



418


I am a Teapot


Yes


HTTP response code

 



419


Authentication Timeout


Yes


HTTP response code

 



420


Method failure


Yes


HTTP response code

 



421


Misdirected Request


Yes


HTTP response code

 



422


Unprocessable Entity


Yes


HTTP response code

 



423


Locked


Yes


HTTP response code

 



424


Failed Dependency


Yes


HTTP response code

 



425


Unordered Collection


Yes


HTTP response code

 



426


Upgrade Required


Yes


HTTP response code

 



428


Precondition Required


Yes


HTTP response code

 



429


Too many requests


Yes


HTTP response code

 



431


Request Header fields too large


Yes


HTTP response code

 



440


Login Timeout


Yes


HTTP response code

 



444


No Response


Yes


HTTP response code

 



449


Retry with


Yes


HTTP response code

 



450


Blocked by Windows Parental Controls


Yes


HTTP response code

 



451


Unavailable for Legal Reasons


Yes


HTTP response code

 



456


Unspecified Error


Yes


HTTP response code

 



457


Unspecified Error


Yes


HTTP response code

 



494


Request Header too large


Yes


HTTP response code

 



495


Cert Error


Yes


HTTP response code

 



496


No Cert


Yes


HTTP response code

 



497


Http to Https


Yes


HTTP response code

 



498


Token Expired Invalid


Yes


HTTP response code

 



499


Client Closed Request


Yes


HTTP response code

 



500


Internal Server Error


Yes


HTTP response code

 



501


Not Implemented


Yes


HTTP response code

 



502


Bad Gateway


Yes


HTTP response code

 



503


Service Unavailable


Yes


HTTP response code

 



504


Gateway Timeout


Yes


HTTP response code

 



505


HTTP Version Not Supported


Yes


HTTP response code

 



506


Variant also Negotiates


Yes


HTTP response code

 



507


Insufficient Storage


Yes


HTTP response code

 



508


Loop detected


Yes


HTTP response code

 



509


Bandwidth limit exceeded


Yes


HTTP response code

 



510


Not extended


Yes


HTTP response code

 



511


Network authentication required


Yes


HTTP response code

 



520


Webserver is returning an unknown error


Yes


HTTP response code

 



521


Web Server is down


Yes


HTTP response code

 



522


Connection timed out


Yes


HTTP response code

 



524


A timeout occurred


Yes


HTTP response code

 



598


Network read timeout error


Yes


HTTP response code

 



599


Network connect timeout error


Yes


HTTP response code

 



1001


unsupported script version


Yes


Script error


from recorder and in responsecode.js → moved to errorlist Triggered when the script has no version or the version is neither 1.0 nor 2.0




1002


script syntax error


Yes


Script error


from recorder and in responsecode.js → moved to errorlist It's triggered when parsing the gslScript fails




1301


Hard / Transaction Timeout


Yes


Transaction Timeout


Transaction deadline of 5 min exceeded. Can be set via test configuration but not via the UI (transactionTimeout)




1302


Step Timeout


Yes


Step Timeout


Step deadline of 60s exceeded. Can be set via test configuration but not via the UI (stepTimeout)




1304


Wait for Page Complete Timeout / Time exceeded waiting for page to load completely


Yes


Step Timeout


Error code is thrown if the step deadline is exceeded while waiting for this




1305


Wait Network Timeout / Time exceeded waiting for background network activity to complete


Yes


Step Timeout


Error code is thrown if the step deadline is exceeded while waiting for this




1306


Wait for validate Timeout


Yes


User Script Failure


Error code is thrown if the step deadline is exceeded while waiting for this




1307


Wait timeout was too short for the page to load


Yes


Step Timeout


Error code is thrown when user defined wait timeout was too short for the page to load. This should be fixed within the test. (Increasing the wait timeout or change it to another wait condition; ea. "Wait for page to load completely")




1401


Validate Text Match Failed / One or more validations created for this action have failed


Yes


Content match failed


not generic error message any more, not used as it is but rather a detailed message of which element validation is failed




1501


Clickpath action failure


Yes


User Script Failure


This is also the default error in case we can't find the corresponding error type for an error. Usually, it means there's a bug somewhere in our code.




1502


Locator failure "The html element could not be found to perform action"


Yes


User Script Failure


A special case of 1501 Clickpath action failure where the failure was caused by missing or wrong locators so mainly locator failure. The player couldn't find the element to click on but if the validation before is not set to fail then it won't be a validation timeout error. 1501 will stay the default error in case we don't want to show the details of the error to the user (as it might be an internal error/exception)




1601


JS execution took too long


Yes


JS step errors


JS execution has a shorter limit than a normal step




1602


Exception was thrown


Yes


JS step errors


An exception occurred while the custom script was executing




1603


Test marked as failed by the user


Yes


JS step errors


The user itself marked the test as failed




1701


The specified target window is not found


Yes

 

The target window specified in the script was not found, either it was specified by mistake by the customer or the recorder record it wrongly.




1801


Undefined placeholder was used


Yes


Script placeholders


Placeholder was used but was not defined




2001


playback window was closed


Yes


Recorder error


from recorder




2002


playback window was minimized


Yes


Recorder error


from recorder




2003


Extension is not enabled in incognito


Yes


Recorder error


from recorder (not defined in cluster), the text may change, behind a feature flag




2004


There is another incognito window open that needs to be closed first


Yes


Recorder error


from recorder (not defined in cluster), the text may change, behind a feature flag




10054


Connection Reset


Yes


Chrome net error

 



12000


Default network error


Yes


Chrome net error


This error is thrown when we get an unknown / new chrome network error which does not fit any other error. Since sprint 168 It will be here https://github.com/adobe/chromium/blob/master/net/base/net_error_list.h but not in our list.




12012


Address Unreachable


Yes


Chrome net error

 



12013


DNS Lookup Failure


Yes


Chrome net error

 



12014


Connection Timeout


Yes


Connection error Chrome net error


This error can be caused from 2 places, as an exception to cancel transaction when connectionTimeoutExceeded or as a chrome network error net::ERR_CONNECTION_TIMED_OUT. The first is when it takes so long to receive a response from the server. By default it's a 59 seconds unless specified otherwise in the script.




12015


Unsafe Port


Yes


Chrome net error

 



12016


Connection Refused


Yes


Chrome net error

 



12017


Too many redirects


Yes


Chrome net error


not in recorder This error is handled as netWorkError and it sets a connection error similar to 12014




12018


There is no Internet connection


Yes


Chrome net error


new in case of emulateNetworkConditions true and offline true




12019


Request was blocked by client / Malicious resource detected


Yes


Chrome net error but triggered by us


In case of coin mining url, we block the web request and report the error as it's reported by chrome.




12020


The site unexpectedly closed the connection


Yes


Chrome net error


Since sprint 142, in case a connection is closed from the server / proxy / firewall side.




12026


The site reported ERR_SPDY_INADEQUATE_TRANSPORT_SECURITY


Yes


Chrome net error


Since sprint 162




12027


The site reported ERR_EMPTY_RESPONSE


Yes


Chrome net error


Since sprint 167




12032


The site reported ERR_SSL_VERSION_INTERFERENCE


Yes


Chrome net error


Since sprint 168




12033


The site reported ERR_TIMED_OUT


Yes


Chrome net error


Since sprint 168




20000


Unspecified Event Type Error


Yes


User Script Failure


Internal error when the event we want to simulate is unspecified. Should not happen.




20001


INVALID_USER_AGENT


Yes


User Script Failure


User Agent is Missing RuxitSynthetic part with test id and run id




20002


ABORT_PSR_ERROR


Yes


User Script Failure


Chrome startup error




 
 


----------------
41.1:

@xu_guo,Thanks a lot! I believe these codes should also be in the documentation.BTW, do the 97? codes also appear in synthetics?https://www.dynatrace.com/support/help/how-to-use-dynatrace/real-user-monitoring/setup-and-configura...

----------------
41.2:

Hi @xu_guoDo you have any idea how to get past and fix the error 12020 - The site unexpectedly closed the connection.

----------------
41.3:

There is also an error code 12006 Site Reported Unexpected, if anyone has experience with that. 

----------------
41.4:

12006 Site Reported Unexpected is the Chrome ERR_UNEXPECTED error. This is usually caused by an authentication issue. If you curl to the application from the ActiveGate, do you get a successful response? Often it is the case that a proxy is required to allow the ActiveGate to access the application. Or if you are already using a proxy, possibly you need to bypass it for the affected application. You can see the different scenarios available here

----------------
41.5:

Hello,We're observing "The request failed with error 12100: ABORTED", any idea what exactly this means? and possible causes?Couldn't find any details in the docs. Thanks,Sravanth.

----------------
41.6:

 "The request failed with error 12100: ABORTED" is seen where the request got aborted, and the browser doesn't provide any more details. Do you see the same in DevTools?
 

----------------
41.7:

Hi @HannahM ,No, we observe this error only in waterfall analysis of the synthetic executions and is intermittent with no real trend.

----------------
41.8:

OK, I would open a chat in the WebUI and provide a link to monitor and if possible a Har from when the page was loaded. Thanks

----------------
41.9:

Are these codes in the doc anywhere? What does this one mean?"healthStatusCode": 17,"healthStatus": "CONSTRAINT_VIOLATED_VALUE",

----------------
41.10:

Is that from a Browser Monitor or HTTP Monitor? We mention it here for HTTP Monitors

----------------
41.11:

@HannahM Can you please tell me how to resolve the 403 error of the synthetic monitor?The URL is getting loaded when I try in the browser, but somehow, it is throwing a 403 error in Dynatrace.I have created RUM for this application, but no user actions are getting captured, to troubleshoot this I created the synthetic monitor which is throwing a 403 error.Can you please help me with this?

----------------
41.12:

Hi @Vaishnavi_Ubhe,Is your synthetic running against public Dynatrace robot? Private location?Best regards 

----------------
41.13:

@AntonPineiro Is it running against a private location. 

----------------
41.14:

403 is a forbidden error. Have you added credentials to the monitor to allow it access? If you open the page from the Private location does it have access? Sometimes customers need to explicitly allow certain machines to have access using a proxy or network rules. 

----------------
42:

I have a nextjs app that i have deployed to ECS. The application image has OneAgent installed in it. I'm able to see the app as a Service in Dynatrace. The service ID something along the lines of SERVICE-XXXXXXXXXXXXX
I want to create dashboard templates for future apps that would be deployed via pulumi and I would like to include SERVICE_VERSATILE​ tile types in the dashboard, but they require the service ID.
Is there a way of customising the service ID so that it will be known before an app is deployed for the first time?



					
						Solved!
					
					Go to Solution.




----------------
42.1:


Hi,I think that no but you can tags those entities where you are interested base on rules.Best regards

	Consultant


----------------
42.2:


Correct, it's not possible to customize the identifier itself. Also, service detection rules can override that.If you need ID agnostic dashboard, you need to filter by tags, management zones, or other means as @AntonPineiro mentions. Some built-in widgets for Dashboard Classic such as the service tile won't allow you to do that, in that case - you can either display the data using Data Explorer tile (preferred) or you can configure the IDs in the dashboard JSON based on entity IDs lookup (you need to look up the IDs and update dashboard accordingly).

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
43:

Hi,in the last few days I’ve been exploring Dynatrace for synthetic monitoring.I couldn’t fiund out if the traffic from this automated tests goes to Adobe Analytics reports. I looked for an IP address exclusion or something like that and didn‘ t find any.As so, is this traffic part of the data in AA reports?Thanks

----------------
43.1:

I would say it goes, as the request for the Adobe objects are visible in the waterfall, which I just checked in a synthetic measurement for a client that I know uses Adobe.

	Antonio Sousa


----------------
43.2:

Hi Antonio,first of all, thanks for your support!Do you know how can I filter the Dynatrace traffic in Adobe Analytics?Regards

----------------
43.3:

@mkat,Sorry, but I don't know...

	Antonio Sousa


----------------
43.4:

Hi @mkat Can Adobe Analytics filter out requests according to the user agent?Dynatrace default synthetic user agent is: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/{version} Safari/537.36 RuxitSynthetic/1.0 v0 t0 cfeatureHash=7efgijmoqtvx caes=1 ccux=1 sia=1 smf=1 HTHYos -----With google search found this Adobe Analytics - Bot Filtering using User Agent  so it look like there is a way in  Adobe Analytics to filter out request by user agent. 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
44:

Can not Change Management Zone , When I Change or Write in Box Management zone ,Pop up Alert Error 400 We've hit an error We've run into a technical error, but we're working to resolve it as soon as possible

----------------
44.1:

Hi,I would raise a ticket to Dyntrace support.Best regards

	Consultant


----------------
45:

Our user complains that when they use a custom lasts 9 hours. The unique visitors are higher than the total visitors.  
From the time dropdown, we test with various timelines and is not just the customs having issues.
 
Our Enterprise Web Dashboard shows the followingLast 2 hours (The issue will sometimes occur)Total Visits 310 Unique Visitors 326Yesterday (The issue will always occur - Unique > Total)Total Visits 3315 Unique Visitors 3346Last 72 hours (The issue will always occur - Unique > Total)Total Visits 10083 Unique Visitors 10542
 
Is anyone also facing this issue? Can someone confirm the DEFAULT query for Total Visits and Unique Visitors?
I doubt we modified the query before. Even if we do the same query now wouldn't have caused this strange behavior.

----------------
45.1:

Can you tell us where are you seeing this data? If it is in a Dashboard, you can click on the tile and see the details, where you can see the query for it. 

	Site Reliability Engineer @ Kyndryl


----------------
45.2:

If you can provide a screen capture that would be best. Users commonly confuse Unique users and Session Count which then raise questions like this.  

	-Chad


----------------
45.3:

Enterprise Web DashboardTotal VisitsSELECT count(*) AS "Total Visits" FROM usersessionWHERE userType = "REAL_USER" AND applicationType = "WEB_APPLICATION"Unique VisitorsSELECT count(DISTINCT internalUserId) AS "Unique Visitors" FROM usersessionWHERE userType = "REAL_USER" AND applicationType = "WEB_APPLICATION"

----------------
45.4:

I dont see any issues with the query you are using. I know there can be issues with live sessions vs completed sessions when using the USQL vs nonUSQL as USQL wont look at live sessions, but that isn't the case here. I've tested it in our environment and its working as expected. What cluster version are you on? 

	-Chad


----------------
45.5:

We are on Dynatrace Managed version. 1.272.139I just went in to the dashboard to confirm the query were correct. The issue still happen but intermittence. This time round it occurs for last 7 days.U just need to play around with all the pre-set last xx hours/days to reproduce the issue.  How can I tell if the query are USQL or nonUSQL? Are those the default query?One thing I notice in the view details. Not sure if it matters and if they are the default. Total Visits. Compare with previous timeframe - DISABLEDUnique Vistors. Compare with previous timeframe - ENABLEDDynamic time-frame shift - CHECKED Kindly advice

----------------
45.6:

I cant get the issue to reproduce, but my cluster version is 1.276.181.20231002-204711 - is it possible to upgrade your cluster and see if the issue is still present? 

	-Chad


----------------
45.7:

Dynatrace Managed current latest version release is 1.274.I assume the release for 1.276 would be in a few days time.FYI. This issue was reported few months back when our users discover it.There were trying to use custom time like past 9 hours.At that time we were on Dynatrace Managed version 1.268.Anyway, would keep this thread active and see if others faces the same issue.

----------------
46:

Is there a way to configure globally to force/override service level anomalies to be the same as host group level anomaly settings ? 



					
						Solved!
					
					Go to Solution.




----------------
46.1:


Hi @susmita_ally Yes of course you can set Anomaly Detection at service level for a specific Host Group.The easiest way is to select your Host Group from Deployment Status and go to its settings. In the next step you will be able to set the entire Anomaly Detection configuration for the selected Host Group.    Radek

	Have a nice day!


----------------
46.2:

This may help you: https://www.dynatrace.com/support/help/shortlink/host-groups#how-host-groups-affect-your-monitoring-...

	Have a nice day!


----------------
47:

I need to configure service level alert based on multiple conditions for few key requests. For e.g :
Average response time > baseline + 5 standard deviation
AND 
Average response time >30ms
Can we configure this alert in problem alerting profile ?

----------------
47.1:

Hi @susmita_ally I'm not sure if you can include so many conditions in one Alerting Profile, but it needs to be checked I would first of all start by configuring the Metric Events and secondly add the created metrics to the Alerting profile.https://www.dynatrace.com/support/help/platform/davis-ai/anomaly-detection/metric-eventshttps://www.dynatrace.com/support/help/observe-and-explore/notifications-and-alerting/alerting-profi...Radek

	Have a nice day!


----------------
48:

Hello, As I understand it not all Dynatrace metrics are currently in grail. For the metrics that are not, can you still use dql to query those metrics, for instance on the new dashboard app? Or do you have to create those tiles a different way? Thank you

----------------
48.1:

you can create new metrics for this, and them they will be available on the grail

	Dynatrace Professional Certified


----------------
49:

Hi All, We are trying to capture the time difference between payment request and payment response request. Application is working on .Net technology and asynchronous method is in used for payment request. Now, we need to capture start time for each payment request so that after applying arithmetic logic will get required time difference.

----------------
49.1:

did you see the response time?Look this documentation pagehttps://www.dynatrace.com/support/help/platform-modules/applications-and-microservices/services/anal... The Response time chart illustrates how the response times of the requests triggered by this service were distributed during the selected timeframe 

	Dynatrace Professional Certified


----------------
50:

Hello,Currently when you make a custom metric alert, it can only be based off of one metric. For instance, you can't tell an alert to go off if there is both a cpu threshold of 95% and a memory threshold of 95%. You can only tie one metric to each alert that you make. With using grail / dql, are there any planned changes for this?Thanks

----------------
50.1:

Probably not the answer you are looking for, but you can combine metrics when you create SLOs and then set custom alerts on these SLOs.Unfortunately, SLOs do not support dimensions so you need 1 SLO for each host (and consequently, 1 metric event per host).The below SLO example adds CPU usage and Memory usage of a specific host "hostname" and divides by 2. When the SLO reaches 90% it means both CPU and Memory are at their 90% usage:(builtin:host.cpu.usage:filter(and(or(in("dt.entity.host",entitySelector("type(host),entityName.equals(~"hostname~")"))))):splitBy("dt.entity.host")+builtin:host.mem.usage:filter(and(or(in("dt.entity.host",entitySelector("type(host),entityName.equals(~"hostname~")"))))):splitBy("dt.entity.host"))/2

----------------
51:

Hello,
 
Ar e there any plans to add requests attributes to business events? Or wil they remain always as obsevability data?
 
KR Henk



					
						Solved!
					
					Go to Solution.




----------------
51.1:

This is a good question! I also thought that request attributes and business events seem like they could work well together, and I'm interested to see what co-existence Dynatrace has planned for them. 

----------------
51.2:


Hi Daniel, I think I have the answer,https://community.dynatrace.com/t5/Open-Q-A/Request-attributes-as-source-of-truth/m-p/224497#M28800In simple terms, request attributes  not always captured, and that 's  what is needed for business events,(-; KR Henk

----------------
52:

Hello,
As we all know: Dynatrace tracks all requests, from end to end, and automatically monitors the services that underlie each transaction. 
Does this mean that this information is complete? E.g. no head or tailbased sampling?
 
In shot, how reliable is ths info?
KR Henk
 



					
						Solved!
					
					Go to Solution.




----------------
52.1:


Hello @henk_stobbe,from my point of view, the info should be reliable as long as the technology is fully supported, controlling the number of traces captured per process/minute if needed (check Adaptive traffic management for more details), using request attributes, and if you are using log monitoring, you can use traces log enrichment that will help with more details as well.I hope I have understood you correctly and I hope this helps.

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
52.2:

Hi Mohamed,Great answer, thanks.My concern was basicaly that other observability vendors all implement things like tail based and or head based sampling to limit resource usage. So after reading about adaptive traffic, I conclude that  OneAgent uses head based sampling. (to keep it simple)So the text "all requests, from end to end", should be read as  "all request, that are captured, are captured end to end" But it is possible that not all requests are captured.This means that request attibutes can also be sampled, and that answers my question thx!KR Henk KR Henk  

----------------
52.3:

My experience is - if there is no adaptive traffic management, request attribute values are accurate. For high throughput services (way above the default limit of 1000 captured traces per process group), the counters for request attribute values might not be 100% correct (e.g. you have 2450 instead of 2445 as the counter), but still precise enough for observability - alerting, dashboards, etc.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
53:

Looking at for example "com.dynatrace.filesystem" extension written by Dynatrace.It uses python to check certain things which is very flexible off course. Until now we use the plugin system to create custom python extensions. But extensions2.0 has some advantages.Can't find documentation regarding python based extensions and how to write them ourselves.



					
						Solved!
					
					Go to Solution.




----------------
53.1:

I can confirm to you that, right now, only Dynatrace employees (mostly the extensions team) can use Python in the EF2.0 framework. I don't think anything has been announced as per availability or dates for customers/partners to use the same framework.

----------------
53.2:

Too bad. consider this an RFI then?

----------------
53.3:


We have it on the roadmap and expect to share our plans in the next 60 days.

----------------
54:

Is a workflow able to generate and update a notebook or dashboard and send it as a report on a schedule?

 When passion meets people magic and innovation happen. 




					
						Solved!
					
					Go to Solution.




----------------
54.1:


Automation Workflows can be used to generate and update notebooks or dashboards via document store SDKs and APIs. The links to those can be sent as part of a report.  
Creating status artifacts (e.g. picture or pdf) is currently not supported. 

	Michael


----------------
54.2:

@michaelwinkler Can you send a guide on how to create and update notebooks via API in a workflow? 

----------------
54.3:

Hi,
Using the document SDK in a typescript workflow action is the easiest. 
Would you mind sharing some more information about your use case and what you are trying to achieve?
Thank you,
Michael

	Michael


----------------
54.4:

Sure. We're currently setup with alert profiles and notification profiles through PagerDuty via custom API integration. We'd like to have some workflows with specific problem triggers (probably just for our tier 1 applications) that would run queries against the entity(ies) impacted by the problem, and then generate a notebook with those results (along with some other, possibly templated information). As a final step, we'd like to have the workflow reach out to the PagerDuty API to update the related incident with the link to the notebook. Basically, we want to try to reduce MTTR by having initial queries for problem related data run automatically and a notebook generated to capture it all. This would include custom metric and log data that may not already be included in the Davis AI problem analysis. Having a notebook with queries and data ready to go would provide a great starting point for PlatOps troubleshooting and analysis since they're already running similar queries manually today.

----------------
54.5:

Hi,
It could potentially be more convenient to have a dedicated notebook and/or dashboard for said Davis problems and Tier 1 applications, which is accessed and run on demand (instead of building it every time a problem occurs).
The workflow could look like the following:
- Davis Problem trigger (filtering on specific problems and applications)
- sending a slack/teams message to the corresponding team with the link to the notebook/dashboard
- informing Pagerduty
btw: We just recently released "Pagerduty for Workflows" which includes six different workflow actions to easily integrate with Pagerduty. 

	Michael


----------------
54.6:

That would work, although we want to make sure we preserve the notebook for later use. If we do what you suggested, we'd be overwriting the notebook every time the problem trigger initiated.

----------------
55:

Our SAP Extension is going blank on the live data feed and even showing the wrong custom device name. 
Went into settings, monitored technologies, the SAP Application server, and looked at the endpoint with the wrong endpoint it is disabled. We updated it in case there is a sync issue, however, in Technologes & Processes, it is that endpoint that is shown for Remote extension endpoints.
The correct endpoint is shown OK status and we refreshed but it is not even showing in Technologies & Processes. When I go to Data Explorer and pull up Dialog Response time by custom device, this correct endpoint custom device is not generating any data.
 
For monitoring interruptions what should be done for SAP ABAP extension? How can we check if there is a Dynatrace configuration issue somewhere or if its SAP system issue?
 
What I looked at
https://www.dynatrace.com/support/help/extend-dynatrace/extensions/troubleshooting/troubleshoot-exte...
https://www.dynatrace.com/support/help/setup-and-configuration/dynatrace-oneagent/oneaget-troublesho...
1) Checked Operational status of ActiveGate
Deployment status -> ActiveGates2) Restarted oneagent too
 
Other than check ActiveGate operational status, checking logs, removing ABAP endpoint and readding it (which is next because we disabled and updated it and still no data coming through), what else am i missing?
 
 



					
						Solved!
					
					Go to Solution.




----------------
55.1:


Hi @GP_Stanley , The extension creates log files which can be found on the ActiveGate server : C:\ProgramData\dynatrace\remotepluginmodule\log\remoteplugin\custom.remote.python.sapor/var/lib/dynatrace/remotepluginmodule/log/remoteplugin/custom.remote.python.sapThe logs in that directory should help pinpoint what is going on with the endpoints such as a timeout or another error. 

----------------
55.2:

Hello,I have got same problem with "SAP Application Server (version 1.158)" extension. I configure endpoint, it's seems ok but not data collected.I look into log file on ActiveGate host in C:\ProgramData\dynatrace\remotepluginmodule\log\remoteplugin\custom.remote.python.sap\SAPPluginRemote.log Below is extract 2023-10-03 12:26:58.966 UTC DEBUG [Python][6239264261536217212][SAP_BS7][28772][ThreadPoolExecutor-0_0] - [query] Monitoring WS-HTTP2023-10-03 12:26:58.966 UTC DEBUG [Python][6239264261536217212][SAP_BS7][28772][ThreadPoolExecutor-0_0] - [query] Monitoring ESI2023-10-03 12:26:58.966 UTC DEBUG [Python][6239264261536217212][SAP_BS7][28772][ThreadPoolExecutor-0_0] - [query] Monitoring ALE2023-10-03 12:26:58.966 UTC DEBUG [Python][6239264261536217212][SAP_BS7][28772][ThreadPoolExecutor-0_0] - [query] Monitoring RFC2023-10-03 12:26:58.966 UTC DEBUG [Python][6239264261536217212][SAP_BS7][28772][ThreadPoolExecutor-0_0] - [query] Monitoring CPIC2023-10-03 12:26:58.966 UTC INFO [Python][6239264261536217212][SAP_BS7][28772][ThreadPoolExecutor-0_0] - [query] Skipping execution 1, executing every 5 minutes2023-10-03 12:26:58.966 UTC WARNING [Python][6239264261536217212][SAP_BS7][28772][ThreadPoolExecutor-0_0] - [query] No file found, start process2023-10-03 12:26:58.966 UTC INFO [Python][6239264261536217212][SAP_BS7][28772][ThreadPoolExecutor-0_0] - [runJava] Using java path: ../../../gateway/jre/bin/java.exe2023-10-03 12:26:58.966 UTC INFO [Python][6239264261536217212][SAP_BS7][28772][ThreadPoolExecutor-0_0] - [runJava] ['../../../gateway/jre/bin/java.exe', '-Xmx1536m', '-cp', 'D:\\dynatrace/remotepluginmodule/plugin_deployment/custom.remote.python.sap/SAPRFC.jar;D:/dynatrace/remotepluginmodule/plugin_deployment/custom.remote.python.sap/Jars/sapjco3.jar', 'com.dynatrace.saprfc.Main', 'C:\\Windows\\SERVIC~2\\LOCALS~1\\AppData\\Local\\Temp/10.156.38.2700200/']2023-10-03 12:26:59.454 UTC INFO [Python][6239264261536217212][SAP_BS7][28772][ThreadPoolExecutor-0_0] - [query] [WinError 2] The system cannot find the file specified: 'C:\\Windows\\SERVIC~2\\LOCALS~1\\AppData\\Local\\Temp/10.156.38.2700200/javaRunning.dt.sap.lock'2023-10-03 12:26:59.454 UTC INFO [Python][6239264261536217212][SAP_BS7][28772][ThreadPoolExecutor-0_0] - [query] No previous data found, awaiting next execution I didn't see where is the problem.Could you help me on this, please ? Thanks by advance. 

----------------
55.3:


Please create a support ticket for it.
In 99% of the cases a log such as that means that something went wrong with the "SAP Java Connector configuration" section of the help page: https://www.dynatrace.com/support/help/setup-and-configuration/technology-support/dynatrace-extensio...Either the redistributable isn't installed, or you downloaded a 32 bit version of the sapjco3.jar, or you don't have access to read the sapjco3 file.

----------------
55.4:

 && cd D:/dynatrace/remotepluginmodule/plugin_deployment/custom.remote.python.sap && D:\dynatrace\gateway\jre\bin\java.exe -Xmx1536m -cp SAPRFC.jar;Jars/sapjco3.jar com.dynatrace.saprfc.Main C:\Temp # Exception in thread "main" java.lang.ExceptionInInitializerError: JCo initialization failed with java.lang.UnsatisfiedLinkError: D:\dynatrace\remotepluginmodule\plugin_deployment\custom.remote.python.sap\Jars\sapjco3.dll: Can't load IA 32-bit .dll on a AMD 64-bit platform And i figure out what it is. I installed SAPJco version 32 bits because current default jvm on this server is 32 bitsBut ActiveGate Dynatrace is in 64 bits and you can test loading of SAPJco.jar with it.D:\dynatrace\gateway\jre\bin\java.exe -jar D:\dynatrace\remotepluginmodule\plugin_deployment\custom.remote.python.sap\Jars\sapjco3.jar

----------------
56:

According to documentation
 
Memory usedPercentage of total RAM used by processes. RAM used by system caches and buffers isn't included in this metric. Dynatrace calculates memory usage as:memory_used = total_memory_size - (free_memory + active_memory + inactive_memory + reclaimamble_memory)
 
What does dynatrace consider reclaimable memory?
We are having and instance where the cached memory is considered as memory used where as the actuall process memory is 20%.
Any ideas on correcting / setting changes
 
Thanks
Moses



					
						Solved!
					
					Go to Solution.




----------------
56.1:


Have you seen this blog post ? It explains it pretty well.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
56.2:

Hi Folks,Have you seen such a memory pattern? Do you thnik it is a memory leak in a jvm?I could not recognize any process which is responsible for this pattern. Thanks in advance for your help.Best regards,Mizső

	Certified Dynatrace Professional


----------------
57:

Hi All,Are any of you going to Barcelona on 5 October?With my team planning to stay there for a few days, it's a cool opportunity to get to know each other in person R.

	Have a nice day!


----------------
57.1:

Greetings, @radek_jasinski !Me and @AntonioSousa will be there!See you Thursday! 

	Best regards, Pedro Deodato


----------------
57.2:

Hello @radek_jasinski I will be there till Saturday. see you there 

	Dynatrace Certified Professional - Dynatrace Partner - Yourcompass.ca


----------------
57.3:

Super:) we need to go out for a beer and food together then 

	Have a nice day!


----------------
57.4:

I would say that we gather after the event. I believe there's an "after Innovate", we just have to figure out a place at Intercontinental where we can all meet 

	Antonio Sousa


----------------
58:

Hi,During the last Dynatrace Managed update, I observed an issue with disappearing configuration elements for two of my clients. For example, after the update, one client's Custom Services configuration disappeared, and for another client, the XHR monitoring configuration vanished.I noticed this problem with version 1.274.157. I have reported the issue to support. I'll keep you posted if I learn anything new. Please be cautious.Radek

	Have a nice day!


----------------
58.1:

Hi @radek_jasinski Thanks for sharing this information.Best regards,Mizső

	Certified Dynatrace Professional


----------------
58.2:

Hi @radek_jasinski Did you tried to downgrade the JS agent to the one before latest, in order to check if the new JS agent version is the RC?Yos 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
58.3:

Hi Yos,No, I haven't tried this, but it doesn't matter if the RUM configuration for the XHR was automatically removed during the upgrade.I'm still waiting to hear from support.Radek

	Have a nice day!


----------------
58.4:

Hi Radek,The reason I suggested to try downgrade the JS agent version was, because we had the same issue (losing XHR action) after upgrading to Managed 269. While waiting for support answers, we downgrade the JS version to 263 (latest that support IE7-10) and that solved the issue of missing XHRs. Then we found out with support that there was a use of old Angular that is not support  by JS agent version 265 and on.HTHYos  

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
58.5:

Hi Yosi,This is a different situation. In my case, it looked as if various configuration elements were spontaneously disabled after a cluster update. the XHR was switched off, data collection stopped. After re-enabling the configuration, everything returned to normal.I have never encountered a similar situation in DT.

	Have a nice day!


----------------
58.6:

Understood 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
59:

Is there a way to capture the age of the oldest message in the Solace queue via dynatrace monitoring? I know we have a matrics : Oldest message age for getting this in IBM MQ but coudnt find anything similar for Solace MQ.Any pointers are much appreciated.

----------------
59.1:

Hi @Rinu Have you tried monitoring the Solace MQ using Syslog? Then you can pull metrics from syslog into DT. Another thing is whether you have an API in Solace MQ after which you can pull the relevant metrics and send to Dynatrace?https://docs.solace.com/Monitoring/Monitoring-Events-Using-Syslog.htmRadek

	Have a nice day!


----------------
60:

Regarding the Kubernetes deployment:Is it more recommended to add an additional ActiveGate or to extend the limits of cpu and memory in the yaml file?



					
						Solved!
					
					Go to Solution.




----------------
60.1:

Hi @elenaperez I recommend to use containerized AG (or AGs depends on the size of kubernetes cluster). CPU and Memory modification depends on also the size of the culster (I mean the number of pods). After the install you can follow the AG cpu and memory consumption and modify it if it will be required.To connect the kubernetes cluster api is more simple with containerized AG, than with extrenal AG.I hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
60.2:

And if cpu / memory are under stress how should it be scaled? Vertical or horizontal?

----------------
60.3:


At a first step the vertical scale is sufficient. 

	Certified Dynatrace Professional


----------------
61:

We have hundreds of third party synthetic monitors in our Dynatrace environment. Each third party synthetic monitor is then connected in Dynatrace to an application. However, as we have so many third party synthetic monitors we want to make sure that all are connected to their respective application in our Dynatrace environment. Otherwise we want to check which third party synthetich monitors are not yet connected so that we can connect them. Is there a way to quickly get a list of all third party synthetic monitors in Dynatrace and the application(s) they are connected to?I checked the Dynatrace API, but it seems that for third party synthetics you can only do 'post' and no 'get'...Any help is highly appreciated!

----------------
61.1:

 Hi,Have you tried downloading the list of monitors via GET through the API: https://www.dynatrace.com/support/help/shortlink/api-synthetic-monitors-get-allRadek

	Have a nice day!


----------------
61.2:

@MartijnA Did the hint from Radek help you?

 When passion meets people magic and innovation happen. 


----------------
61.3:

@AgataWlodarczyk , partly. I created a python script that reads out the third party synthetics via the API, but the API does not give back all the results correctly. Sometimes it gives me the monitor(s) per application, but sometimes it states that there is no monitor connected to the application while it actually is. I'm still trying to work out why this is happening.

----------------
61.4:

Interesting. What API endpoints are you using? I can see if I can reproduce it also. Thanks

----------------
62:

Hi,We need to run a json flow only if the Davis problem parameters has particular entity tags like [Kubernetes]version where there are multiple attributes present in entity tags .Can you help in extracting this? below is a sample param object.{"event.id": "111111111","timestamp": "2023-10-01T15:26:08.427000000Z","display_id": "P-113232142","event.kind": "DAVIS_PROBLEM","event.name": "testing","entity_tags": ["[Kubernetes]version:xxxxxxxxxx","[Kubernetes]kube-monkey/identifier:app","[Kubernetes]kube-monkey/enabled:enabled","Market:GROUP","[Kubernetes]version:6346347547547","[Kubernetes]type_manifest:customer"]} 

----------------
62.1:

Below is a screenshot after executing the condition. Though the trigger has required tag, the flow is discarded saying the condition doesnt match. Please help!!  

----------------
63:

I am working to setup a  “Power User” IAM Policy.  I have a feeling this is going to be a huge policy.
 
I found out that you can only have 100 policy statements in an IAM Policy.
Is there a # of IAM Policies that you can attach to a group?
 
Has anybody done a “Power User” policy?
Basically, I am trying to give them access to make changes on hosts, processes, services and settings that make sense like MZs, services naming rules, Application detection, etc.

	Dynatrace Certified Professional


----------------
63.1:

Did you check if out of the box global policies available in account management view cover your needs?There is no limit for number of policies bound to particular group, however there is a limit for number of policy bindings within a level - account or environment - 15 000.

----------------
63.2:

Yes I did and did not see one or two that matched what we trying to do.

	Dynatrace Certified Professional


----------------
63.3:

Is there a max groups that can be created in Dynatrace for SAML SSO?

	Dynatrace Certified Professional


----------------
63.4:

I'm aware of limit of 50k groups for single account

----------------
63.5:

Hello @Kenny_Gillette the following is my power user policy:ALLOW settings:objects:read, settings:objects:write, settings:schemas:read WHERE settings:schemaId IN ("builtin:synthetic.browser.name", "builtin:synthetic.browser.scheduling", "builtin:synthetic.http.name", "builtin:synthetic.http.scheduling", "builtin:synthetic.browser.assigned-applications", "builtin:synthetic.http.performance-thresholds", "builtin:synthetic.browser.kpms", "builtin:synthetic.http.assigned-applications", "builtin:synthetic.http.cookies", "builtin:synthetic.browser.performance-thresholds");
ALLOW settings:objects:read, settings:objects:write, settings:schemas:read WHERE settings:schemaId IN ("builtin:failure-detection.service.http-parameters", "builtin:failure-detection.service.general-parameters", "builtin:anomaly-detection.metric-events", "builtin:metric.metadata", "builtin:settings.calculated-service-metrics", "builtin:tags.auto-tagging", "builtin:tags.manual-tagging", "builtin:alerting.maintenance-window", "builtin:alerting.profile", "builtin:problem.notifications", "builtin:monitoring.slo");
ALLOW settings:objects:read, settings:objects:write, settings:schemas:read WHERE settings:schemaId IN ("builtin:rum.mobile.name", "builtin:rum.mobile.key-performance-metrics", "builtin:rum.mobile.request-errors", "builtin:rum.source-mappings", "builtin:rum.web.name", "builtin:rum.web.request-errors", "builtin:rum.web.custom-errors");
ALLOW settings:objects:read, settings:objects:write, settings:schemas:read WHERE settings:schemaId IN ("builtin:settings.mutedrequests", "builtin:settings.subscriptions.service");

	The true delight is in the finding out rather than in the knowing.


----------------
63.6:

Going to try this.

	Dynatrace Certified Professional


----------------
63.7:

I believe the same set of permissions can be granted by assigning "Settings Writer" policy to the user's group.

----------------
64:

 Destiny… the power that predetermines and orders the course of events. Some things, people, and circumstances come to us even though we defend ourselves against them. In many situations, when we stop opposing them, they can lead us to the places where we should be, surrounded by people who are our best match. And sometimes we don't have to look far for what is written for us.
In the case of Sini, our October Member of the month, he was destined to be in Dynatrace. When you read the article, you'll see that although @sinisa_zubic was running away from fate, he ended up where he was supposed to be and is very happy with this fact. And we’re happy about it, too.  Having Sini as a part of the Community is a big value for the Community users and for the Community Team.________________________________________________________________________________________________________________________________________________
Can you share some details about your past? What is your story, how did it happen that you decided to work in the IT / APM area, and how did you become a Dynatracer?As a child, I had the usual role models in mind:

Firefighter
Astronaut
Excavator driver. 

I always wanted to know how things work and what’s inside. I loved to disassemble old radios or toys. So, from my infant days, I was already attached to technology. Therefore, I went to an IT high school and subsequently did a bachelor's and master’s in business informatics in Linz.
After university, I was looking for a new job in IT. I had never heard about Dynatrace, even though the office was close to the university. A head-hunter got my number and reached out to me a couple of times. Initially, I was reluctant to go to an interview, but then I went to one. As soon as they explained what kind of product they were building, I thought, “WOW, amazing,” and became a part of Dynatrace. LEFT: Recording DQL videos in our studio. / RIGHT: Enjoying the red desert in the Emirates.Can you tell us a little bit about your job? What interesting things you’re working on that you can share? I am part of a team which is called “Platform Enablement Team.” We’re creating content, doing workshops, and answering questions about how to build Dynatrace Apps and DQL. Furthermore, we're also fostering the Dynatrace developer community called Developer Forum. Internally, we have enabled more than 400 colleagues on how to make Dynatrace Apps. Since I have touchpoints with so many different people, it is really interesting for me to see what kind of use cases someone would like to solve with the Dynatrace platform.
What makes you excited about being a part of the Dynatrace?On the one hand, it is our product – a best-in-class solution using cutting-edge technologies. So new technology trends are being quickly adopted. On the other side is the Dynatrace culture – the company has tripled in size since I joined, and I still feel the same spirit. LEFT: Skiing in the mountains. / RIGHT: ATV trip in summer.How is the Community helping you in your job? Why do you think it’s worth joining the Dynatrace Community? What best advice can you give someone who just started using Community?Community is all about exchanging ideas and helping each other. As it is crucial for us as a company to identify our customer needs, one part of my job is giving feedback to the R&D teams. With the launch of the Developer Forum as part of the Community, we're also trying to bring Dynatrace developers with non-Dynatrace developers closer together. So, you can engage with Dynatrace developers – how cool is that?  
For someone who has just started using the Community – don’t hesitate to ask questions. There are no stupid questions.
Tell us something about you that most people don’t know. What is your biggest joy or passion in life?I don’t have one big passion, there are a couple of them. I love to spend weekends outside – be it in the mountains doing sports or traveling.
 LEFT: Hiking to the Traunstein peak with the lake in the background. / RIGHT: Stairway to nowhere on the Dachstein.One time, on accident, I was snorkeling next to a… shark. Some guy on the beach was fishing for some big fish while I was collecting seashells from the ground. I heard people on the shore shouting, “Shark, shark!”, and swam as fast as I could to the beach and noticed that the fisher had a shark on the hook 10m next to me snorkeling. Also, since I am interested in tech, I have quite some gadgets at home like a drone, NAS (network attached storage), 360 action camera, Nintendo Switch, gimbal…
What’s one thing on your bucket list? Your dream?Visiting all continents – there are two still left ________________________________________________________________________________________________________________________________________________
Sini, keep going! We wish your enthusiasm and motivation never to fade and your knowledge and experience constantly expand. And we're happy that the Community helps with that! 

----------------
64.1:

Congrats, Sini!  You're our good soul, always ready to help and support I hope you'll visit the two continents that are still missing the checkmarks on your list 

----------------
64.2:

Congrats @sinisa_zubic ,Besides the Community, huge kudos for your training sessions!

----------------
64.3:

Congrats 

----------------
64.4:

Well deserved, thrilled to see you being honored @sinisa_zubic!

----------------
64.5:

Hi Sini,Congrats!!!  Well done! Keep going on! Thanks for your support! Best regards,Mizső

----------------
64.6:

Congratulations Sini. You're so knowledgeable on so many subjects. I'm glad to have had the opportunity to work with, and learn from, you. Keep doing what you're doing!

----------------
64.7:

Good Work @sinisa_zubic !!! Congratulations

----------------
64.8:

Congratulations Sini!! 

----------------
64.9:

Congrats @sinisa_zubic

----------------
64.10:

Congrats, @sinisa_zubic !! Thanks for the learning! When the "Escape from sharks 101" will be out?

----------------
64.11:

congrats

----------------
65:

Hi All,
 
I recently did a OneAgent deployment to a large volume of Virtual Machines in Azure via PowerShell and noticed that the Dynatrace Documentation doesnt cover how to install the Dynatrace OneAgent VM Extension in Infrastructure Only Mode. (The Documentation uses the depreciated AzureRM Module and doesnt cover the syntax for the settings to enable Infrastructure Only mode on installation). Thought i would drop this here in case anyone runs into the same issue, hopefully it makes someone's life a little easier.
 
This script can be modified to suit any specific situation, in this example you can simply export the VM's from the Virtual Machine blade in Azure into a csv (in this case i targeted windows VM's) and change the column header "Resource Group" to "ResourceGroup". Good for large deployments where you only want to target a single subscription at a time for a rollout. Simply fill in the < >
 
Remember to Import the .Az module and use Get-AzSubscription to find the correct subscription ID and then Set-AzContext -Subscription <Subscription ID Here> to set the context to the desired subscription
 
PowerShell Script:
$Importfile=Import-csv <File Path Here>
Foreach ($Import in $Imports) {
$ResourceGroup=$Import.ResourceGroup
$VMName=$Import.Name
$Location=$Import.Location
 
Set-AzVmExtension -Name Dynatrace.OneAgent -Publisher dynatrace.ruxit -ResourceGroupName $ResourceGroup -Location $Location -VMName $Name -ExtensionType "oneAgentwindows" -TypeHandlerVersion "1.0" -NoWait -Settings @{ "tenantId"="<TenantID Here>"; "token"="<Token Here>"; "enableLogAnalytics"="yes"; “installerArguments”=”--set-infra-only=true --set-host-group=<Host Group Name Here>” } -erroraction continue }

----------------
65.1:

Great Tip @JonathanV 

	-Chad


----------------
65.2:

Nice one Jonathan, do I require admin privileges to the VM to be able to carry out the installation? Also must I log in to the VMs be able to carry out the installation 

----------------
66:

Hello all, I have a question about a combination of Dynatrace and OpenTelemetry. By way of testing I've created a simple Spring application with one endpoint which is instrumented with OpenTelemetry(manually instrumented) and has a Dynatrace OneAgent on the host which also injects into the application.Everything seems to be working and I get all the expected data into Dynatrace.I do have two questions I hope someone can help me with. For all Span Attributes the following message is shown in Dynatrace: "initial value not set" and there is a general message on the purepath as well with "Some attributes have not been set at span start. They cannot be used in Span capturing settings". I tried both custom Attributes and SemanticAttributes set like below and both have the same result.  parentSpan.setAttribute("http.dynaguild.name", name);
parentSpan.setAttribute(SemanticAttributes.ENDUSER_SCOPE, name);   Any idea what I am doing wrong, or what I should set? And the second question is about nesting. I have two spans, a parent span and a child span. I think I set the parenting correctly but in Dynatrace they are not nested. I think all that is required is the following:  Span childSpan = tracer.spanBuilder("child-span").setParent(Context.current().with(parentSpan)).startSpan();    Any ideas? Thanks in advance and kind regards,Erik



					
						Solved!
					
					Go to Solution.




----------------
66.1:


Hi,regarding "initial value not set", this means that the attribute is set after span creation, so the OneAgent does not know of it when he decides based on the "Span capturing" settings if the span should be captured or not. Have you tried directly setting the attribute directly in the tracer.spanBuilder("span").setAttribute(...)..  And regarding setting the parent, try this:void parentOne() {
  Span parentSpan = tracer.spanBuilder("parent").startSpan();
  try {
    childOne(parentSpan);
  } finally {
    parentSpan.end();
  }
}

void childOne(Span parentSpan) {
  Span childSpan = tracer.spanBuilder("child")
        .setParent(Context.current().with(parentSpan))
        .startSpan();
  try {
    // do stuff  } finally {
    childSpan.end();
  }
}Let me know if it worked! Cheers,Josef

----------------
66.2:

Hi @josef_schiessl , Thanks a lot for the reply! Regarding your first point you are totally right, after also setting the Attributes when creating the Span the message dissapears  Regarding your second solution about setting the parent. Unfortunately that seems like what I was already doing and even after copying your code 1 on 1, I get the same results. Do you have any other idea what I can try? Kind regards,Erik

----------------
66.3:

Hi Erik!I just verfied this with the team and you are doing everything correct.This is currently a limitation by the OneAgent, so spans are always reported in a flat hierarchy. But this is currently actively being worked on for all technologies. So this will work in the near future! Cheers,Josef

----------------
66.4:

Hi @josef_schiessl  Thanks again for answering, much appreciated!Any idea when this will be released? I know that the automatic instrumentation is planned for OneAgent 1.237. Will this feature then also be released? Kind regards,Erik

----------------
66.5:

Hi,I cannot give you an ETA - for Java it will not be in 1.237, but as I mentioned, its currently being worked on so it should not be too many versions from that.  Cheers,Josef

----------------
66.6:

Alright thanks! 

----------------
66.7:

No worries 

----------------
66.8:

I'm curious about what progress the Dynatrace team has made on the flat vs. nested hierarchy capability with native tracing tools, such as with the ActivitySource and Activity types in .NET. Is there a setting that needs to be turned on within Dynatrace to change flat span hierarchies into nested relationships, or is this feature still not yet supported in .NET?

----------------
67:

Hi, I have started going through the training videos for creating an application.(https://developer.dynatrace.com/getting-started/tutorial/create-user-interface/).I am stuck on the above step, getting the following error. this is the code I wrote:--------------------------------------------------------- import React from "react";import { SingleValue, Flex } from "@dynatrace/strato-components-preview";interface CardProps {  value: number;  chartLabel: string;  chartSuffix: string;  chartPrecision: number;}export const Card = ({  value,  chartLabel,  chartPrecision,  chartSuffix,}: CardProps) => {  return (    <Flex>      {Number.isFinite(value) && (        <SingleValue          data={value}          label={chartLabel}          formatterOptions={{            type: "customUnit",            unit: chartSuffix,            precision: chartPrecision,          }}        />      )}    </Flex>  );}; ---------------------------------------------------------P.S : Not a React expert 



					
						Solved!
					
					Go to Solution.




----------------
67.1:

After reading through the documentation, found out its being removed: looking forward for the updated videos and documentation.

----------------
67.2:


hi @Sahil2308 
We are aware that the that the FormatterOptions got removed and the tutorial will be soon updated.
Best,Sini

----------------
68:

Hello,
I have an application that is using a Private synthetic location for OnDemand and the Application has SSO enabled, as soon as hit the application URL using a Private location it gives back the Microsoft page for Auth and the private location doesn't have the internet connectivity so wanted to know the best option to tackle this scenario like using some proxies or any other solution where only for Microsoft Auth it will go to proxy and Authenticate otherwise just use no proxy. keep in mind synthetic is not initiating the traffic to Microsoft it comes back from the Application as past of SSO Setup whenever we hit the home page.Thanks for your help.

----------------
68.1:

There are a couple of options:

Set the proxy at the ActiveGate level and add in exceptions for resources that should not use the proxy. https://www.dynatrace.com/support/help/platform-modules/digital-experience/synthetic-monitoring/priv...
Set up a Proxy PAC file with the settings you would like and add this file to the configuration of your Browser Monitors. https://www.dynatrace.com/support/help/platform-modules/digital-experience/synthetic-monitoring/priv...


----------------
69:

Hi everybody. I've had a browse and can't seem to find an answer around synthetics behaviour, so was hoping someone could help.
When setting up synthetics for a user process in a single page application, is Dynatrace able to capture the wait time a user experiences in their browser for a process-heavy JavaScript application?
For example, if a large amount of data is received from a web service that might take 50 seconds to process for a browser in IE compatibility mode, but only 10 seconds in pure Edge mode. Would Dynatrace reflect this in the synthetic performance profile?
I'm also assuming that Synthetics does not actually process the JavaScript that runs in a single-page application for a given browser in order to give a 100% accurate representation of what the user experiences?
Many thanks in advance,
Keith

----------------
69.1:

What's the JS doing? Is it changing somethng on the page? If so, can you make the event wait for that change to complete?
 

----------------
69.2:

@Keith can you provide the details needed so we can close the thread?Thank you. 

 When passion meets people magic and innovation happen. 


----------------
70:

This issue is currently faced in a Managed deployment scenario.
What workarounds should be performed to get it resolved?
 
My solution:I've updated the custom.properties file on the synthetic server and it worked for one of the browser monitors and still facing the same errors for another 2 browser monitors.
 
 
 

----------------
70.1:

Are you trying to use a Private Location for your AG testing an internal app? check with networking to ensure communication is allowed.

	-Chad


----------------
70.2:

@Peter_Youssef Did Chad's answer help you?

 When passion meets people magic and innovation happen. 


----------------
71:

How do I see the current amount of connections to my database?

----------------
71.1:

Hi @Alex7 You need to pull this kind of information with extension for example ms-sql instance-metrics or mysql connections HTHYos 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
71.2:

Is there such an extension for Postgres?

----------------
71.3:

Yes  (Active connections Number of active connections to all databases running under PostgreSQL)https://www.dynatrace.com/support/help/setup-and-configuration/technology-support/dynatrace-extensio...

	Have a nice day!


----------------
71.4:

If looking for that information client side, there are several J2EE implementations that give you the information by connection pools, namely JBoss, Tomcat, Weblogic and WebSphere.

	Antonio Sousa


----------------
72:

Fairly new to log monitoring, we are doing a POC with it. Anyone find it strange you cannot see the EXACT filename unless you actually setup the custom log source configuration rule to have an exact path (aka not using wildcards).Let's say I have any number of directories (the list is never static) within the folder structure below. Within those directories I have a file by the name of <some_name.log> I could do something like /logs/*/*/*.log to capture all of these files but then when I query within logs and events in dynatrace, I see the log.source value as the custom log source rule matcher I setup, in this example '/logs/*/*/*.log'.I thought the whole purpose of a log monitoring tool was to be able see the exact file the issue occurred in but instead with dynatrace I would have to still logon to the host and do my own greps to find the file where the message was logged from. I'll also add that yes you can automate the log source rules via api calls (to create the exact matcher) but are we really expected to have potentially hundreds of matchers and then also have to worry about when a new directory is spun up, adding that new matcher?I could very well be missing something here, looking for feedback here.Example folder structure below. Note, within each directory can be any number of directories which within them, could have any number of log files./logs/sbx/logs/devlogs/test/logs/qa

----------------
72.1:

At the moment, this is "by design" apparently. I also have a customer struggling with this (they're just using the '#' wildcard in their filenames but also would like to know the concrete filename the entry was pulled from).I'd be curious whether anyone else has an idea.

----------------
72.2:

We have encountered similar issues and disappointment with this.  What completely stumps me though is why the documentation for defining custom log sources under Log File Matching states "Custom log sources can contain wildcards..." when using them may very well break your ability to search the data you just defined for ingestion.  If you use a * anywhere in the middle of the path to the log file the UI will provide a link to your newly defined file as expected.  But here's the challenge, you can't search this new log source.  When you try the UI presents the following message: "Unexpected error: Invalid DQL query: [2,10] MATCHES_VALUE: Wildcard '*" in the middle is not supported".  This can be worked around by playing with the advanced search, but I can't imagine explaining this to everyone at the company that wants to search their data.  I suppose another option/workaround might be fully qualifying the path and filename (removing the wildcard altogether) for every log source that's not automatically discovered but yikes!  I'm going to assume this is all just something I've not given enough thought to yet because I know Dynatrace is better than this.  

----------------
72.3:

Hi Alvin,there are two issues present here:1. If you have custom log sources with wildcards, these wildcards are used to match files, but they are not resolved on UI, i.e. log source name still has wildcards. Shortly speaking, this is good for some use cases, and bad for other ones. Having acknowledged these shortcomings, we came up with an idea to allow for decorating log records with an additional attribute carrying the origin file name. This is planned for CQ4'23. The solution is decided so there is a high chance to deliver it as planned.2. You cannot use a '*' character in the middle of a log query. This character is interpreted always as a wildcard (which is not the intention here but would work in most cases) and the wildcard is allowed only at the beginning and at the end of matched value. We have a story to provide a possibility to mask the wildcard character to match it literally which would cover your use case, but unfortunately we do not have capacity to implement it in CQ4'23, at least for now. A workaround is possible in most cases. You can use "'prefix*' and '*suffix'" instead of "`prefix*suffix'" condition. I am aware that is not very elegant.

----------------
73:

What is the recommended version of Python on latest managed release of for Python on AGs?



					
						Solved!
					
					Go to Solution.




----------------
73.1:


ActiveGate extensions in EF1.0 use Python 3.8, however, you don't have to worry about that, as it comes bundled with the ActiveGate regardless of what other versions you have installed on your server.

----------------
74:

Can we get voucher coupon

----------------
74.1:

Hi @gauresh_shinde, The answer is no, You can get the voucher by attending the event hosted on 31 October APEC by amplify powerup Thanks

----------------
75:

Hello, I am trying to set up Dynatrace to monitor resources in AWS. We use Dynatrace Managed which is hosted on our on-prem infrastructure so following this documentation, we have set up an Environment Active gate on EC2 instance.I have completed all the steps listed, created an IAM role and attached to the EC2 instance where my Environment Active gate is deployed. Now while doing the last step which is listed here when I make the connection to AWS from Dynatrace UI, I am getting an error message which says "Active gate unavailable" (screenshot attached). I am not able to understand why? I've checked and my env active gate is up and running.Also how does the flow work? Dynatrace AWS pushes the metrics to Dynatrace or is it Dynatrace which pulls the metrics from AWS?Any help on this is really appreciated.Best Regards,Shashank



					
						Solved!
					
					Go to Solution.




----------------
75.1:

Hey @agrawal_shashan ,Is it possible that the ActiveGate you're set up is not correctly linked to your tenant, as in, there is no communication to it somehow? Does it appear if you search for it under Deployment Status -> ActiveGates? And does it have the AWS module enabled? For your second question, it is the ActiveGate itself that connects to your AWS account, polls the metrics from AWS Cloudwatch and then sends them to the Dynatrace cluster - everything happens in the ActiveGate.

----------------
75.2:

Hi @victor_balbuena Thanks for the response. So right now I have an EC2 instance in a AWS account (XYZ) where I have also deployed Dynatrace Active gate. This EC2 instance has connectivity open to our Dynatrace Managed Cluster.And in Dynatrace UI also I am just trying to connect to this same AWS account (XYZ) for now but it gives me that error which I pasted. Just trying to understand when I click on connect, what happens? Does Dynatrace managed cluster tries to connect to AWS or is it Env Active gate on AWS tries to pull the metrics from the same account?FYI.. AWS module is enabled on the Env Active gate.

----------------
75.3:

Hey @victor_balbuena I was actually connecting from wrong Dynatrace Env but I rectified it and now trying from the correct tenant/env. But now I am getting a different error which says "Invalid Credentials".Also below are the logs from Env Active gate -2023-10-02 09:09:34 UTC INFO    [<XXXXXXX-XXXXXXXX-XXXXXX>] [<vtopology.provider>, RoleCredentialsProvider] Cannot obtain CLIENT short term credentials for arniam::XXXXXXXXXXXX:role/Dynatrace_ActiveGate_role ; AWSCredentialsImpl {identifier: XXXXXXXX, accessKey: null, secretKey: null, tenantUUID: XXXXXXX-XXXXXXXX-XXXXXX, iamRole: Dynatrace_ActiveGate_role, accountId: XXXXXXXXX, externalId: *****, label: Dynatrace Integration, partition: aws, detectedPartition: aws, monitorOnlyTaggedEntities: false, includeTags: [], excludeTags: [], excludedRegions: [], logConfigSQSesEnabled: false, logConfigSQSes: [], version: 2.0, legacyServices: [ebs_builtin, lambda_builtin, ELB_builtin, loadbalancer_builtin, s3_builtin, dynamodb_builtin, ec2_builtin, asg_builtin, rds_builtin], services: []} [Suppressing further identical messages for 10 minutes]
com.amazonaws.SdkClientException: Unable to execute HTTP request: Connect to sts.amazonaws.com:443 [sts.amazonaws.com/209.54.180.124] failed: connect timed out
        at com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleRetryableException(AmazonHttpClient.java:1219)

2023-10-02 09:09:34 UTC WARNING [<XXXXXXX-XXXXXXXX-XXXXXX>] [<vtopology.provider>, AWSFastCheckCallable] Credentials refresh failed: {status: ERROR_BAD_CREDENTIALS, statusInfo: Service failed to assume role provided in credentials, credentials: AWSCredentialsImpl {identifier: XXXXXXXXX, accessKey: null, tenantUUID: XXXXXXX-XXXXXXXX-XXXXXX, iamRole: Dynatrace_ActiveGate_role, accountId: XXXXXXXX, externalId: *****, label: Dynatrace Integration, version: 2.0}, exception: com.amazonaws.SdkClientException: Unable to execute HTTP request: Connect to sts.amazonaws.com:443 [sts.amazonaws.com/209.54.180.124] failed: connect timed out} 

----------------
75.4:


When you click on connect, it's the ActiveGate reaching out to test the connection to AWS, so it acknowledges the connection works before it's set up. Dynatrace Managed is not involved in this step. Once it is set up, the ActiveGate will try to send the data to Dynatrace Managed, but Dynatrace Managed does not reach out to any resource ever.As per the issue, we are falling into AWS teritory now, so it might make more sense if some expert from AWS takes a look or you talk to Dynatrace support directly. Having said that, something you can look into is the outbound security rules of your EC2 instance (where the ActiveGate is running), to allow for requests and data to leave the ActiveGate.

----------------
75.5:

Hi @victor_balbuena Your information has been immensly helpful. Thank you very much.Again looking at this documentation it says "Make sure that your Environment ActiveGate or Managed Cluster has a working connection to AWS. Configure your proxy for Managed or ActiveGate, or allow access to *.amazonaws.com in your firewall settings." And in the logs I can see its trying to make a connection to sts.amazonaws.com:443but failing. Trying to understand if it is the Active gate which tries to make this connection?Best Regards,Shashank

----------------
75.6:

Yes, it is the ActiveGate in this case 

----------------
75.7:

Hi Agrawal,Did you change MonitoringRoleName after upload YAML file from github role_based_access_monitored_account_template.yml in Stack Details? In your screenshot I see in field "IAM role that Dynatrace should use to get monitoring data":Dynatrace_ActiveGate_rolebut in default is:Dynatrace_monitoring_roleBest RegardsPaweł

	"The lion does not ally with the coyote"


----------------
76:

Trying to query an API with a self-signed cert. it seems standard ways of ignoring certificate errors in JS / Node do not work in the serverless runtime. How can I make this work?

----------------
76.1:

Hi @lucas_hocker 
the standard way of ignoring certificate errors does not work yet. In the next month you should be able to use the https node module which which you should be able to skip the certificate check for a reuquest.
Best,Sini

----------------
77:

My Dynatrace Professional certificate just expired, any way i can get it renewed ?Do I need to do the associate and the professional certification process again! I am asking for this, so I can apply for Dynatrace Master Certification 



					
						Solved!
					
					Go to Solution.




----------------
77.1:

Don't let the Professional expire. Somewhere it says that if that happens, you have to start from the Associate again...

	Antonio Sousa


----------------
77.2:


It's in the University:  

	Antonio Sousa


----------------
77.3:

Exactly...I too once missed the renewal date of my PRO certificate and had to go through the whole path again.

	Have a nice day!


----------------
77.4:

@AntonioSousa is correct, unfortunately this means that you'll have to start with associate again, as your initial associate certification is probably older than the professional. Also, if you retake professional (regadless of if its a renewal or if you start from associate again) you will have to do both the written and practical again. So unfortunately this would mean 3 exams before you can be on your way to master 

	A Dynatrace Professional nerd working for Eviden


----------------
77.5:

My humble opinion: there should be a grace period of, say, 6 to 12 months after Professional cert expiry, where you can retake the Professional exams without starting from Associate. If you have successfully passed the Professional cert within the last 3 years, IMO the Associate exam is trivial; basically a formality.

----------------
77.6:

In my way of thinking is easier to get all five AWS certs instead get Dynatrace Master certified.Main reason is that AWS Certs requires no human interaction. It all depends only on you, your knowledge, your skills, your experience, your passion. It is impossible to win the game - where there are no clear rules for victory and defeat.It is better to set real goals and achieve them.Good luck!

	DT_NGINX_ALL_WHITELISTED=1


----------------
78:

Hey there,
I'am just stepping into the depths of Dynatrace and now I got a problem:
How to ingest alphanumerical values into Dynatrace and display them on the dashboard?
1. this works because the value is numerical
/opt/dynatrace/oneagent/agent/tools/dynatrace_ingest "anz_bla.count `ls -ltr /tmp/anz/bla* | wc -l`" 
This script counts files in /tmp/anz/. With this metric (anz.bla.count.gauge) I can use nearly any tile I want.
 
2. that doesn't work, because of the string value
/opt/dynatrace/oneagent/agent/tools/dynatrace_ingest "timestamp_host `date`"
There is no reaction in Dynatrace.
 
Now my questions:
How can I ingest alphanumerical values? date is only an example.
How can I display alphanumerical values in dashboards? Table, Textbox, or something else. Graph, I assume, would not work ;-). The workaround with writing a log file should work, but I cannot test this in my sandbox.
Is there a way to manipulate values when they come in? I.E. Value comes in -> Script changes input "OK" to 1 -> manipulated value is being used by Dynatrace.
Thanks a lot in advance.
Martin



					
						Solved!
					
					Go to Solution.




----------------
78.1:


Hi @freudi,
It sounds like you want to ingest dimensions with your metric. Something like a status code "OK" would make sense here. But a timestamp here would not make sense, as it would increase the number of unique dimension key-value combinations and likely cause you to run into dimensionality limits.
The agent accepts data according to the metric ingest protocol. Adding a status code dimension may look like this:
/opt/dynatrace/oneagent/agent/tools/dynatrace_ingest "my.http.status.metric,status=${status} ${value}"
I hope this helps answer your question.
Take care,Nick

----------------
79:

It seems today when you pull in cloudwatch metrics for things like ebs or efs the detected name that shows is the ID itself rather than the name you provide in AWS (example of ID is below). The name does get pulled in as a tag because the name of the efs or ebs is applied as a tag automatically it seems, if you provide a name.
Rather than show the ID, is there a way to show the name itself so that problems that get created have this name / more friendly human understandable name?
 
 

----------------
79.1:

Hi,If that information is in a tag, you can create a renaming rule adding those tag as name.Best regards

	Consultant


----------------
79.2:

I have not seen anywhere to do this. I'm familiar with how to rename things like process groups but not clear on how to do that for aws services like ebs or efs

----------------
79.3:

Hi,Does that entity appear when you filter it by tag or name in Technology Overview?Best regards

	Consultant


----------------
79.4:

I cannot find it there. I always get to it via the AWS menu then going through the account that has the service, or using data explorer to chart out the metric I care about.

----------------
79.5:

Is this possible with generic entities? 

----------------
79.6:

I'll update this to note that the EFS entity I am referring to is a custom device and not a process group.

----------------
80:

How can I pass response of one task to input of another task?
 



					
						Solved!
					
					Go to Solution.




----------------
80.1:


Hello @Sahil2308,In this documentation article, you can check out the expression reference for result() which will allow you to access the result of a preceeding task within the workflow:Introduction to workflows - Expression reference 

	If you have any questions about the Community, you can contact me at maciej.neumann@dynatrace.com


----------------
80.2:

Thanks @MaciejNeumann  

----------------
81:

Hello Community people! more and more often I'm asked about big enough data extraction from Dynatrace.I usually work with Dynatrace api v2 and Power Query (M) from Microsoft.When I hit the limit for the data extracted I try to segment the api query itself in order to not have the nextPageKey cursor but sometime it is inevitable.So my question is: how do you usally manage to extract data when nextPageKey is showed in your response load?Are you scripting your costum solution in order to continue the extraction automatically? (without everytime re-typing the uri with the nextPageKey cursor?) What other tools do you usually use in order to extract the data with Dynatrace apiv2?Thanks in advance to everybody who will join this conversation and will contribute,Regards



					
						Solved!
					
					Go to Solution.




----------------
81.1:

we just leverage the clearing of the API and provide the key for the next page and so on. Its simple enough but im sure you could automate it with a postman script. 

	-Chad


----------------
81.2:

Same as @ChadTurner , we have done it in Linux shell, python and even MSDOS .bat scripts Have had some problems, but it was in our coding...

	Antonio Sousa


----------------
81.3:

I mostly use Python or cURL to fetch the data. But I'm really interested in how the paging should be used in the Power Query feature of Excel. 

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
81.4:


I usually use the Python API client, that one handles the next page key automatically so I don't have to care about it https://github.com/dynatrace-oss/api-client-pythonTo get all hosts and even handle the too many concurrent request message automatically is as simple as:dt = Dynatrace("environment_url", "api_token", too_many_requests_strategy=TOO_MANY_REQUESTS_WAIT )
for entity in dt.entities.list('type("HOST")', fields="properties.memoryTotal,properties.monitoringMode"):
    print(entity.entity_id, entity.display_name, entity.properties)

----------------
81.5:

Thank you to everybody who answered.I'm taking my time to go trought the process of learning, thinking, practicing. Especially thank you for pointing me to the DT git repo. direction.

----------------
81.6:

I have the same problem and have yet to find a simple solution as well.  Mike_L's link is honestly extremely helpful but I'd rather not rely on it since it doesn't support all API's and it's not logic i can apply elsewhere.  I've tried similar approaches using postman and insomnia REST Clients but they handle nextpages in a way different than DT approaches it. I've coded solutions in Python and PHP but they're clunky and honestly my code is embarassing to get it working. I'm posting in response because the "Next Page" thing is actually a cause sometimes for me to just not want to use the API.  I know I'll only get a partial result set and it's too time consuming to put all the JSON responses together. This is even an issue with PowerBI and Excel reporting because they too can't handle the API's NextPage thing. Is DT considering any solutions for this?  Being that DT is all API First it would be helpful to the clients if the APIs can be a bit more client friendly.  (don't get me start on inconsistent FROM string defaults)

	HigherEd


----------------
81.7:


Hi, I have created a PowerQuery to go through pagination and get the whole list. What you need to do is to create Function and call it recursively.In my case, I need to query all problems from last quarter.So I have created this function named getProblemAPIResult(), and from the code below you can see it is calling itself passing nextPageKey. (api as text, headers as record, parameters as text, nextPageKey as text, currentList as list) => 
let
    apiResult = if nextPageKey = ""
    then Json.Document(Web.Contents(api & parameters, headers))
    else Json.Document(Web.Contents(api & "?nextPageKey=" & nextPageKey, headers)),
    newList = List.Combine({currentList, apiResult[problems]}),
    hasNext = try apiResult[nextPageKey],
    returnList = if hasNext[HasError] 
    then newList
    else getProblemAPIResult(api, headers, parameters, apiResult[nextPageKey], newList)
in
    returnList Then the rest is easy, you call this function passing API, all necessary parameters and keep last 2 parameters empty.Only the function calling matters, the rest are just table transformation.let
    problems = getProblemAPIResult(APIURL & "/v2/problems", [Headers=[Accept="application/json; charset=utf-8", Authorization="Api-Token " & APIToken]], "?pageSize=500&from=" & fromTime & "&to=" & toTime, "", {}),
    #"Converted to Table" = Table.FromList(problems, Splitter.SplitByNothing(), null, null, ExtraValues.Error),
    #"Expanded Column1" = Table.ExpandRecordColumn(#"Converted to Table", "Column1", {"problemId", "displayId", "title", "impactLevel", "severityLevel", "status", "affectedEntities", "impactedEntities", "rootCauseEntity", "managementZones", "entityTags", "problemFilters", "startTime", "endTime"}, {"Column1.problemId", "Column1.displayId", "Column1.title", "Column1.impactLevel", "Column1.severityLevel", "Column1.status", "Column1.affectedEntities", "Column1.impactedEntities", "Column1.rootCauseEntity", "Column1.managementZones", "Column1.entityTags", "Column1.problemFilters", "Column1.startTime", "Column1.endTime"}),
    #"Expanded Column1.managementZones" = Table.ExpandListColumn(#"Expanded Column1", "Column1.managementZones"),
    #"Expanded Column1.managementZones1" = Table.ExpandRecordColumn(#"Expanded Column1.managementZones", "Column1.managementZones", {"name"}, {"Column1.managementZones.name"}),
    #"Invoked Custom Function" = Table.AddColumn(#"Expanded Column1.managementZones1", "problemStart", each EpochToICTDateTime([Column1.startTime])),
    #"Invoked Custom Function1" = Table.AddColumn(#"Invoked Custom Function", "problemEnd", each EpochToICTDateTime([Column1.endTime])),
    #"Added Custom" = Table.AddColumn(#"Invoked Custom Function1", "Duration (min)", each ([Column1.endTime]-[Column1.startTime])/60000)
in
    #"Added Custom" Hope it helps.Regards,Satit

----------------
81.8:

Hi satit_dpm, when I created the function named getProblemAPIResult() and the rest api everything work, but when y try to save i got the error: Expression.Error: A cyclic reference was encountered during evaluation.I think the problem is here, do you know how to fix it?returnList = if hasNext[HasError]then newListelse getProblemAPIResult(api, headers, parameters, apiResult[nextPageKey], newList)

----------------
81.9:

Hi, Unfortunately, I am unable to reproduce your issue This works fine in Excel using the same PowerQuery code I have posted.Could you tried using the code below as-is?(api as text, headers as record, parameters as text, nextPageKey as text, currentList as list) => 
let
    apiResult = if nextPageKey = ""
    then Json.Document(Web.Contents(api & parameters, headers))
    else Json.Document(Web.Contents(api & "?nextPageKey=" & nextPageKey, headers)),
    newList = List.Combine({currentList, apiResult[problems]}),
    hasNext = try apiResult[nextPageKey],
    returnList = if hasNext[HasError] 
    then newList
    else getProblemAPIResult(api, headers, parameters, apiResult[nextPageKey], newList)
in
    returnListRegards,Satit

----------------
81.10:

Hi there!! I'm trying to create a dataflow in power platform. I solved the issue with an "@" where the function is called recursively. (reference).But now, I have a new issue. In power platform, I could create the query but I can't save it. I got this error: "One or more tables references a dynamic data source."In power platform I have this problem:"This query refreshes with no problems in Power BI Desktop. However, when you publish a report that uses this code to PowerBI.com and try to refresh the dataset, you’ll see that refresh fails and returns a rather unhelpful error message:Data source error Unable to refresh the model (id=1264553) because it references an unsupported data source.The problem is that when a published dataset is refreshed, Power BI does some static analysis on the code to determine what the data sources for the dataset are and whether the supplied credentials are correct. Unfortunately in some cases, such as when the definition of a data source depends on the parameters from a custom M function, that static analysis fails and therefore the dataset does not refresh."I change the code as Chris says using RelativePath and Query in web.content, but I couldn't fix it.I tried the "skip connection" and use base_url with xxxx.live.dynatrace.com xxx.live.dynatrace.com/api , xxxx.live.dynatrace.com/api/v2 and none of then work.So this is my code: let
  getMetricsAPIResult = (base_url as text, next_url as text, qty as text, nextPageKey as text, currentList as list) => 
  let
    apiResult = if nextPageKey = ""
    then Json.Document(Web.Contents(base_url,
      [
        RelativePath = next_url,
        Query = 
          [
            pageSize = qty
          ],
          Headers=[Accept="application/json; charset=utf-8", Authorization="Api-Token XXXX"]
      ]
      ))
    else Json.Document(Web.Contents(base_url,
      [
        RelativePath = next_url,
        Query = 
          [
            nextPageKey = nextPageKey
          ],
          Headers=[Accept="application/json; charset=utf-8", Authorization="Api-Token XXXX"]
      ]
      )),
    newList = List.Combine({currentList, apiResult[metrics]}),
    hasNext_tmp = apiResult[nextPageKey], 
    hasNext = if hasNext_tmp is null 
    then try apiResult[nextPageKeyError]
    else try apiResult[nextPageKey],
    returnList = if hasNext[HasError]
    then newList
    else @getMetricsAPIResult(base_url, next_url, qty, apiResult[nextPageKey], newList)
  in
    returnList,

  consulta = getMetricsAPIResult("https://{environmentid}.live.dynatrace.com", "/api/v2/metrics", "500", "", {}),
  #"Converted to table" = Table.FromList(consulta, Splitter.SplitByNothing(), null, null, ExtraValues.Error),
  #"Expanded Column1" = Table.ExpandRecordColumn(#"Converted to table", "Column1", {"metricId", "displayName", "description", "unit"}, {"metricId", "displayName", "description", "unit"}),
  #"Transform columns" = Table.TransformColumnTypes(#"Expanded Column1", {{"metricId", type text}, {"displayName", type text}, {"description", type text}, {"unit", type text}}),
  #"Replace errors" = Table.ReplaceErrorValues(#"Transform columns", {{"metricId", null}, {"displayName", null}, {"description", null}, {"unit", null}})
in
  #"Replace errors" 

----------------
81.11:

Hi,Sorry, I am not able to support on this issue as Power platform is not really my forte Regards,Satit

----------------
81.12:

@satit_dpm wanted to say Thank you.  We were able to successfully implement the solution at our company and it's bringing a entirely new value into focus using PowerBI.  I think we can finally build the Problems dashboard we've been dreaming of all these year.

	HigherEd


----------------
81.13:

Glad to hear this helps you All the best for your dream project

----------------
81.14:

https://github.com/dynatrace-oss/api-client-python how we can pass to and from client to fetch the entities 

----------------
82:

Hi Folks,
What is the problem with my content validation rule? What is worng with my configuration?
 
If I leave blank the last confirguration I always receive: Placeholder values were not defined
If I fill out with the default {windows[0]} the last configuration I always receive: The specified target window "{window[0]}" is not found
 
Thanks in advance.
Best regards,
Mizső

	Certified Dynatrace Professional




					
						Solved!
					
					Go to Solution.




----------------
82.1:


Hi,Is that a label as plain text that appear in the webpage?If yes, I would remove "{" and "}" in specific text field and I will remove "{window[0]}, just blank.Best regards

	Consultant


----------------
82.2:

Hi @AntonPineiro,I have not understand correctly the explanation about the brakets...It works fine based on your guidance.Thanks very much.Best regards,Mizső 

	Certified Dynatrace Professional


----------------
82.3:

Hi,You are welcome.I wanted to say removing placeholders, only specific text. It means "my text" instead of "{my text}".Best regards

	Consultant


----------------
83:

Hello everyone
I am facing a problem of Unexpected low traffic completely every day.When this problem occurs, inspecting the page through the browser and going to the network, I realize that the agent is not in the "ruxitagentjs" frontend. What could it be?
This problem usually stays for 1-2 hours on average and then returns normally. The root cause points to the application itself.
 
 
 

	Dynatrace Certified


----------------
83.1:

@Iplinsky , if a week ago everything is normal, and now the RUM Javascript is gone, it's normal to receive that error. I would try to figure out why the Javascript is gone.

	Antonio Sousa


----------------
83.2:

Exactly. I'm investigating why the agent's javascript isn't in the application, thus generating these Unexpected Traffic errors.

	Dynatrace Certified


----------------
83.3:

The main question is whether the overall level of user actions on the RUM application level is dropping during the problem:

If it's also dropping, then, as Antonio mentioned, we should debug why there is no RUM script in the HTML
If overall user action levels are OK, it might be a geolocation issue, especially if your users are from private networks (192/172/10). The "Unexpected low traffic" alarm is sensitive to situations if the traffic drops in a particular location. If some private client addresses are not assigned to any location, then this alarm does not see traffic from these addresses, and it starts beeping ...

Please let us know which of these situations you're facing.

----------------
83.4:

@Iplinsky an you provide @Adam-Piotrowicz more insights so he can help to solve the issue? 

 When passion meets people magic and innovation happen. 


----------------
83.5:

I completely forgot that I made this post. I was investigating what's going on

	Dynatrace Certified


----------------
83.6:

The traffic drops in everywhere. When i go to network in browser, sometimes i don't see the agent beacon... Creating new sessions in browser, sometimes it's not there. The configs are to monitor 100% of user sessions 

	Dynatrace Certified


----------------
83.7:

 Sometimes, error 405 from different browsers like chrome, edge, opera, networks from different locations with or without vpn. Completely random. Sometimes, just dessapear

	Dynatrace Certified


----------------
83.8:

I've checked waf configs theres no logs, also in Dynatrace too

	Dynatrace Certified


----------------
83.9:

I also get this errors above, like 100k per day. Maybe correlated with this? maybe not? ... 2023-09-28 07:07:23.730;BVLYNHGUIS;Unexpected errror in {Application Name};The controller for path '/rb_bf26736qil' was not found or does not implement IController.;http://{Application URL}.com.br/rb_bf26736qil?type=js3&sn=v_4_srv_1_sn_51344D2F76F8E05FF15451993FC2E3C2_perc_100000_ol_0_mul_1_app-3Aa8a1d4c97d4aae93_1

	Dynatrace Certified


----------------
83.10:

You need to adjust the settingsThe default is too sensitive and will spam you with problem tiles.Since Davice can not handle weekends and public holidays you can use it only for outage monitoring with very low sensitivity.

----------------
83.11:

It's correctly adjusted. The big and real question/probllem is Why the agent javascript isn't in the application, thus generating these Unexpected Traffic errors besause rum is not been monitored.

	Dynatrace Certified


----------------
83.12:

take a look on caching in CDN/LB - it could be that some instances have different content w/o JS snippetThis valid to AEM or similar systems with replication deployment 

----------------
84:

Background: As we move closer and closer to the Holiday season a common issue is suppressing certain alerts that don't reflect a problem. For example, Low User Traffic on a holiday. There have been multiple RFEs to address these type of problems. While we wait for a direct solution from Dynatrace I'd like to offer my Pro Tip on how to handle these unwanted alerts on certain days etc... 
First step: Define what it is that you want to stop alerts on, it could be one thing, or a collection of things. But we need to know what you want to exclude. Lets use this Scenario - Your organization decided to leverage a federal holiday to roll out a bunch of patches. As a result, we fully expect 2 problems. First being 'Unexpected Low user traffic' and Second being 'High CPU Usage'.  
Second Step: Understand how your organization alerts. Some organizations use privatized alerting, meaning that there is an alert profile and an alert integration that shoots out an email to the defined recipients. Other organizations use an event handler, such as Moogsoft, Servicenow etc.. Never the less, you'll need to understand where your alerts go and how they alert to your customers. For this case we will use an event handler as the method can be used for privatized alerting as well. 
Third Step: Now that you know what you want to suppress, and you know what type of notification delivery method your organization uses, we need to validate what alert profiles these 'alerts' you want to suppress apply to. This is easier when you have an event handler because the average organization sends everything to it. So lets go into Dynatrace and look for the low user traffic: 
 
Now we know what alert profiles qualify for this event. And since we are using an event handler in this scenario, I know that the alert profile starting with "N" goes to our event handler. That alert profile is now my target. 
Fourth Step: Lets go into that Alert Profile so we can make the changes needed to suppress the qualification of the alerts. Looking at the Alert Profile we can see al the rules are set to immediately alert, but to remove an alert aspect we want to go into "Add Event Filter"
 
Fifth Step: The key to this is the "Negate" function. We can select a predefined event, basically anything out of the box with Dynatrace. Then we select that out of the box event we want to target. And the final aspect is to set the 'Negate' to ignore issues that fall under Low Traffic. Now our scenario stated that their is going to be high CPU as well, So ill just make two negate rules: 
 
 
Now the system will qualify alerts that pertain to the defined Management Zone, AND any defined severity rule, AND validate that the alert does not contain Unexpected Low Traffic. We can add in another rule to negate the CPU as well.
 
Granted yes this is a manual effort, but if you know the dates and the scopes, you can automate it via the API as well.  
 
I hope this helps everyone this holiday season  
 
 
 

	-Chad


----------------
84.1:

Thanks for the tip Chad, appreciate 

	Dynatrace Professional Certified


----------------
84.2:

This is great information Chad, thank you!

----------------
84.3:

The Pro!

	Dynatrace Certified Professional


----------------
85:

Iam trying to onboard ECS services with Fargate launch type. Followed the Run time injection method as per the documentation. Also, defined  DT_LOGLEVELCON with the value INFO . In the logs, I don't see any specific error related to One agent deployment failure. But the FG Service doesn't  show up on Dynatrace. I have followed the same steps and was able to onboard ECS FG services from one of our cloud accounts, but unable to onboard the services from other accounts now. Attached cloudwatch logs and Task definition created with one agent run time injection method.



					
						Solved!
					
					Go to Solution.




----------------
85.1:

I edited your post because you were publicly sharing your PaaS token.

	The true delight is in the finding out rather than in the knowing.


----------------
85.2:

Hi @ManasaM. Please check if you are using Alpine images because you select in options flavor=musl&include=all

	The true delight is in the finding out rather than in the knowing.


----------------
85.3:

Hi Daniel. Thank you for your response. For the oneagent container image I've provided "alpine:3". Is there anything else that I'm missing?

----------------
85.4:


Assuming that you follow the procedure step by step, try to change this: DT_ONEAGENT_OPTIONS- this is the flavor (valid options are default or musl for Alpine images) and the technology (code module).Syntax for default is flavor=default&include=all.Syntax for musl is flavor=musl&include=all.Have in mind that your install-oneagent is alpine but may be others you are trying to set with OA are not.You have set the musl in Options but maybe the Fargate containers are different. 

	The true delight is in the finding out rather than in the knowing.


----------------
85.5:

Thanks for the suggestion. Initially DT_ONEAGENT_OPTIONS was set to flavor=musl&include=all and that worked without any issues for all services running node image alpine. The other services I was trying to onboard were not running on Debian Linux. And setting the DT_ONEAGENT_OPTIONS to flavor=default&include=all worked. 

----------------
86:

I need to change the displayName of a great number of Services, and of course, was thinking in doing it through the API.To my great surprise, it seems it is not possible.Does someone know how to change the name of an entity through the API, as it can be done by the UI.

	Antonio Sousa


----------------
86.1:

Is Service Naming rules an option for this case?

	Site Reliability Engineer @ Kyndryl


----------------
86.2:

@dannemca,It's not an option. To make an analogy for you, I have to rename things like:/prod/service/03   ->   Loja São Paulo/prod/service/07   ->   Loja Rio de Janeiro/prod/service/23   ->   Loja Salvador Bahia

	Antonio Sousa


----------------
87:

Hi team, want to have the result CS-MONITORING, howfetch dt.entity.host| expand tags| filter contains(tags, "invoiced_team")| summarize str_tags = collectDistinct(tags)
 
 



					
						Solved!
					
					Go to Solution.




----------------
87.1:


Hi @OustiDiousti 
Please check out our documentation about how to query entities in Grail: https://www.dynatrace.com/support/help/platform/grail/querying-monitored-entities#entity-tags
Basically you need to expand the array of tags and parse it
 
fetch dt.entity.host
| expand tag_string=tags
| filter contains(tag_string,"invoiced_team")
| parse tag_string, """(('['LD:tag_context ']' LD:tag_key (!<<'\\' ':') LD:tag_value)| (LD:tag_key (!<<'\\' ':') LD:tag_value)|LD:tag_key)"""
Best,Sini

----------------
88:

Hi Folks,Is there a way to delete all expired maintenance window via API.I gone through few thread on community and suggestion was to filter on expired maintenance window and delete from UI itself.But dilemma is, due to huge number of maintenance window the page is not at all loading hence I'm looking to pull all expired MW via API and delete it.Can someone please suggest.Regards,AK



					
						Solved!
					
					Go to Solution.




----------------
88.1:


You can use the Dynatrace API to automate the process, but you will need to build the logic into whatever script or job you decide to run to delete them.So the steps would be:Get all maintenance windows with the Settings API v2 using the builtin:alerting.maintenance-window schema ID.With the list of IDs, get every maintenace window via the same Settings API v2, different endpoint .For each maintenance window, dive into the body response of the call and check if the scheduleType is ONCE and if the endTime is in the past (we ignore recurring maintenance windows since they are never expired).If the above verifies, save the ID of the object and make one last call to the Settings API v2, delete an object to delete it.It's a bit complicated, but it's the only way as the maintenace window doesn't have an expired field or something else we can check apart from the one mentioned above.

----------------
88.2:

Yep this works. @victor_balbuena thanks for quick help

----------------
89:

I've been updating Postman collections for myself for a while to make it easier to work with the Dynatrace API across multiple clusters, tenants, and environments.
 
I have put the files on github now, maybe someone will find it useful.
 
Setup is very quick, then you can just select the request and environment against which to execute it.
 
Here is a short guide:
  Import collections
Postman is available for free from postman.com.
Import (file -> import) the collection .json files for the APIs you want:

Environment API v1
Environment API v2
Configuration API
Cluster API v1
Cluster API v2

A separate collection for each, including all requests of that API, will be created:

    Create environments
For each of your Dynatrace environments/tenants you want to use, add a postman environment via manage environments -> add:

 
The environment needs two variables (names are case sensitive!):

DT_HOST

URL to the environments

For managed: your-dt-domain.com/e/Environment-ID

example.com/e/b80b158e-ev23-4330-30fcc-c4391bbx6ce2


For SaaS: Env-ID.live.dynatrace.com

abc133769.live.dynatrace.com






DT_TOKEN

An API token for the environment



 
    Request away!
Now you can open any request and easily execute it against different Dynatrace environments by selecting the environment on the top right: 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.1:

This seems very interesting! Going to check it out when I have a little time.

	Antonio Sousa


----------------
89.2:

Thanks @pahofmann for sharing, sure will be useful. I cant find the way to get the json files.  

	Sharing Knowledge


----------------
89.3:

You can get from from the API Explorer. 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.4:

Hi @pahofmann ,How can I download the collection from the github ? 

	Sharing Knowledge


----------------
89.5:

The collections are saved as .json files in the repository. You can either copy them from the specs folder or just download the whole bundle from the releases page.

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.6:

Thanks a lot man Good day  

	Sharing Knowledge


----------------
89.7:

Updated to 220, including cluster APIs.

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.8:

With one of the recent Postman version the UI changed a bit.  The environments can now be found in the left side menue:  

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.9:

Yes, i used this version after my last post Thanks or your update.Very Useful

	Sharing Knowledge


----------------
89.10:

Latest Release updated to Version 1.226 (Cluster API 1.224)

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.11:

It was very much helpful and this acts as a utility to have. It saves a lot of time while working with customers. Thanks for sharing.

	Love more, hate less; Technology for all, together we grow.


----------------
89.12:

Updated to 1.234: Github Link. 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.13:

top nodge, we are currently working on an API v2 version for integration to Splunk , having this so visual in postman really helps. works like a charm.

----------------
89.14:

Update to 1.248: Github Release Link.  Also automated the process so future updates can be more frequent or be done by the user if in a hurry.

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.15:

Updated to 1.250: Github Release Link.  Also there is a Insomnia Version now: Community Thread  -  Github 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.16:

hi @pahofmann the links on your initial page are now not working (404), I guess because of the update? (pahofmann/dynatrace-postman-collections: Summary of postman collections for all dynatrace APIs. (git...

	Kind regards, Frans Stekelenburg                 Certified Dynatrace Associate | measure.works, Dynatrace Partner


----------------
89.17:

Thanks, updated  

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.18:

Thank you x 2 ! 

	Kind regards, Frans Stekelenburg                 Certified Dynatrace Associate | measure.works, Dynatrace Partner


----------------
89.19:

Updated to 1.258 (Environment) and 1.256 (Cluster): Github Release Link 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.20:

Updated Env and Cluster to 260: Github Release Link 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.21:

Thanks for keeping this updated.

	The true delight is in the finding out rather than in the knowing.


----------------
89.22:

@pahofmann  thank you for maintaining this and please keep posting as you make updates. This is a very useful solution you've created here.

	HigherEd


----------------
89.23:

Thanks, always nice to hear. Will do.

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.24:

Update to Environment 1.270 and Cluster 1.268: Github Release 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.25:

Updated to Environment/Cluster 1.274: Github Release. 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.26:

@pahofmann Firstly thanks for this its to truly helpful. Is there a way I can get the metadata / manifest file for the API's. In OCI DI you have to create a REST API task that requires you to add a json or yml manifest file for the API you calling. 

----------------
90:

I'm seeing a lot of errors logged at '/var/lib/dynatrace/remotepluginmodule/log/extensions/datasources/com.dynatrace.extension.sql-server/dynatracesourcesql.jar.log', ones such as the below. We are using the Microsoft SQL Server extension on 4 of our servers but this error is only logged on 3 of them. As far as I am aware we are not missing metrics but I guess because the extension (2.0) maybe is eventually failing over to the 1 server that can make the connection?Has anyone seen this type of error before and know how to fix it?[dca623fa-2197-3c1a-a5a2-c92b51c5202b][-5264616907942138161][1475450][err]SEVERE: Unable to create initial connections of pool.

----------------
90.1:

@sivart_89,Not seen one before like that.The errors you are seeing seem to be on the ActiveGate side. As metrics are flowing in, seems it might not be impacting measurements.Maybe it would be better to open a Support ticket, Dynatrace should be able to dig into your other log lines and find out what the problem might be.

	Antonio Sousa


----------------
90.2:

Definitely would suggest to open a support ticket. We would need more details in addition to this log line. Generating support archive might be very helpful.

----------------
91:

Hi all, please help, is Gemfire cache manager supported by dynatrace ? can we monitor it via a specific JMX extension, if yes what is it ?  Regards



					
						Solved!
					
					Go to Solution.




----------------
91.1:


Direct monitoring via OneAgent is not possible.You can use the built-in JMX extension to extract the required parameters. On the GemFire side, you need to run the JMX support (https://docs.vmware.com/en/VMware-GemFire/10.0/gf/managing-management-jmx_manager_operations.html).Please note that such an operation consumes DDU licences.Radek

	Have a nice day!


----------------
92:

For OTeL implementation, the team needs to install one  agent in their laptops. The aim is to use OTeL sdk and implement trace information in .net and feed to DT. We would  like to test with oneagent and without one agent too. Could you please help and advise on one agent installation on laptops. Also is there an api for agentless trace ingestion?

----------------
92.1:

Hi,There is API/endpoints that accept OTeL You can check them under the link:https://www.dynatrace.com/support/help/extend-dynatrace/opentelemetry/getting-started/otlp-export But I recommend using some collectors to minimize traffic:https://www.dynatrace.com/support/help/extend-dynatrace/opentelemetry/collectorAs of installing OneAgents on personal laptops/workstations - I would highly discourage You from that.The each workstation will be utilizing Licenses, Each will need access to ActiveGates or Dynatrace (network traffic).The best approach would be to test it out on test environments rather than Dev Personal devices.Still technically You can install OneAgents on them if You really want to - using exactly the same procedure as on servers. Hope it answers all questions.

----------------
92.2:

Thank you Michal for your quick feedback and response. Let me go through this solution and will revert back if I need any additional feedback/support.Thank you again for your support

----------------
93:

Hi Everyone, 
When i'm trying to Add a AWS Service, I'm getting the following error message:
 
I have already checked the credentials, and everything is correct.
Has this happened to anyone else? I hope you can help me
thanks in advanceinte
 
 



					
						Solved!
					
					Go to Solution.




----------------
93.1:

Hello,
Would you be able to specify a bit more which service specifically? Are you trying to do the following step of creating an aws policy for dynatrace to be able to ingest cloudwatch metrics directly from aws?
https://www.dynatrace.com/support/help/shortlink/aws-monitoring-guide#aws-policy-and-authentication
Thank you

----------------
93.2:

Hi, I have followed all the steps for the integration of AWS services to Dynatrace. I also already ingested the cloudwatch metrics. However when I want to add another service (e.g. sqs, s3 bucket, etc.) I get error but checking the credentials, policies and yaml file, those services are enabled in the policy.Thank you

----------------
93.3:

I'm having the same issue trying to add additional AWS services. If I don't add any services, AWS saves fine, but when I try to add anything additional, I get that error.We just turned on Grail, I wonder if this has something to do with it.

----------------
93.4:

Having the same issue when I try and update default services by adding s3

----------------
93.5:

I'm having the same issue when trying to connect other AWS services.Is there any solution for this?

----------------
93.6:


Hi All,I used 'Management Account ID' in AWS organization menu as ActiveGate account ID and it works now

----------------
94:

Hi,I am not sure if it is correct channel for this. This is an improvement idea. You can bookmark some threads but you need to be looking for a bookmarked thread one by one until you find your bookmark. Some filtering would be awesome. For example, you know your bookmark is about “easyTravel” and then, you type “easy” and only bookmarks matching those letters appears. It can be applied to only title or body or both.Thank you.Best regards

	Consultant


----------------
94.1:

Hi @AntonPineiro  I agree with you. Searching/filtering in this tab is very hard and you have to look for everything manually. A filter option would be useful. Community Team do you have the option to enable filtering there?

	Have a nice day!


----------------
95:

Hello Community!Is there any efficient way of moving "big" data between APIs using Dynatrace? I tried to do it using Workflows, but I could only fetch a relatively small amount of objects using a single JS node. According to my calculations, I would need to create about 60 JS nodes in a single workflow, that doesn't work for me. Is there any workaround for it? I need the data in my internal API for Dashboards and I somehow need to move it from an external one.

----------------
95.1:

Thanks for this question, I was wondering the same thing too

----------------
95.2:

Hi,Are you talking about configurations as dashboards, alerting profiles... ?If yes, you can use Monaco.Best regards

	Consultant


----------------
95.3:

Hi Anton,I'm basically trying to use Dynatrace on the Community page itself. I want to get the data from our vendor's API to our internal Dynatrace API. However, the access to Khoros API is limited, I can't create any pipeline, I can only send calls to it. In this scenario, is it still worth it to look into Monaco? I just wanted to ask this question before I read all about it.

----------------
95.4:

Hi,Monaco is only to be talking between Dynatrace APIs between environments.I do not know if your use case can be done inside Dynatrace. I would to do it outside Dynatrace using some program language to pull information from Khoros API, parse or extract what you want, and push to Dynatrace API.Best regards

	Consultant


----------------
95.5:

I'm not familiar with the Khoros API myself, but reading about it for 5 minutes, it seems to be able to return data in JSON format for various statistics. If this is what you're trying to get in Dynatrace somehow (hopefully in the form of either metrics or logs) seems like an extension is the way to go. It will read the data from the Khoros API, modify it to the Dynatrace format and ingest it directly.Or as @AntonPineiro suggests, do it outside of Dynatrace.

----------------
96:

Hi all, 
I need to create a dashboard with charts for HU, DEM, and DDU consumption per different applications in a client environment. I have stock charts for Host Units and DDU consumption but it is not able to be shown per application. There is no chart for DEM consumption, but I found a chart for billed user sessions with an option to be shown per application. Help me with that make 3 charts to show HU, DEM, and DDU consumption per application. 



					
						Solved!
					
					Go to Solution.




----------------
96.1:


You can't do this with out-of-the-box functionalities of Dynatrace unfortunately, at least until your tenant gets moved to DPS, where you will have new metrics with a lot more freedom. With current consumption metrics, you need to have an extension or a script that calculates the consumption per application (or usually, management zone) by using these metrics and then ingests the calculated consumption back into Dynatrace.With DPS , new metrics will appear in Dynatrace which you can easily split by Management Zone by default.

----------------
96.2:


For host units, you can use a simple script which will provide you with a host unit metric split by host. Unfortunately, this is not built into the product.For DEMs and DDUs there are metrics already. For DEMs you need some calculations as metrics are session based , not DEM units based.Assuming you have management zones set up (or tags at least) per application, then you can put this data on the dashboard (Dashboard classic) and filter it by Management zone or tag in Data Explorer.  

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
97:

Hello Dynatrace Community, 
Recently, we've noticed a number of replies on the Community created by LLM chatbots, such as ChatGPT or Bing Answers. We’d love to clarify the Dynatrace Community’s stance on using such tools.  
 
We're adding a new rule to the Dynatrace Community Guidelines: 
Mark the AI-generated content 
All the AI-generated content posted in the Dynatrace Community must be clearly marked as such and communicated to other users. AI content can be used only as a reference and not be the only part of the message. If the AI Chatbot you're using provides sources, please include them in the answer. The answers generated by AI must be verified and tested by the author of the question before accepting them as solutions. 
If the post doesn't respect the said rules, it will be deleted. 
 
Dynatrace Community focuses on user-to-user interaction; it’s a place where we can exchange information and learn from each other to become better professionals. While AI tools can be incredibly useful, they currently can’t provide solutions for the more complex questions. The AI-generated answers often lead to confusion instead of a solution and, at the same time, harm the Community itself - lowering the SEO score of the site and preventing us from making the feature Dynatrace AI more knowledgeable, as we can’t feed it content from other AI chatbots.  This is why, while we don’t want to ban the AI content completely, we want to ensure that it is marked and provided with context. 
 
Let us know if you have any questions, and we’ll be happy to answer them. 

	If you have any questions about the Community, you can contact me at maciej.neumann@dynatrace.com


----------------
97.1:

Thanks @MaciejNeumann. Great policy!@MaciejNeumann wrote:Dynatrace Community focuses on user-to-user interaction; it’s a place where we can exchange information and learn from each other to become better professionals. 100% agree with your statement.There is a new tag to identify such content?

	The true delight is in the finding out rather than in the knowing.


----------------
97.2:

Hi @DanielS,At this moment, we won't introduce a special label for AI-generated content, but we'll monitor the situation and introduce one if needed.And, as always, all users can report inappropriate content to us if they notice something breaking the Community rules.

	If you have any questions about the Community, you can contact me at maciej.neumann@dynatrace.com


----------------
98:

I would like to export my graphs contained in a dashboard to create a PDF. I know about the Export to PDF feature, but it doesn't quite meet my needs. The Export feature exports the dashboard as it looks on the screen, so you get a 1-page snapshot. I'd like the graphs to be bigger in the export, so each of the graphs would span the whole page width, ending up with a column view of all my graphs that would span multiple pages.
I understand that this would be difficult, so as an alternative, I was wondering if there is a way to get the graphs through the API, as either a PNG, PDF, or some other graphic format. I can get the data from the API, but don't think I can get the graphic. This would then allow me to combine them into my own document.



					
						Solved!
					
					Go to Solution.




----------------
98.1:

There is no way to get the graph as an image via the API, unfortunately. Since the dashboard export provides always one page, the only solution I can think of your problem is to divide up your dashboard in multiple dashboards, one for each graph maybe, and export each one individually - then merge them. I would suggest a product idea for your use case, but given that dashboards classic is going away for the new grail platform dashboards, I doubt they will allocate any resources on it.

----------------
98.2:


I know it's a workaround, but try the Chrome add-on: GoFullPage - Full Page Screen Capture.I use it often, for reports for my clients.

	Have a nice day!


----------------
99:

Hi guys,Customer got few AGs up and running and every thing was good till they start to drop dead, because of JAVA error but that is not the issue now, the question is how to get alert for dynatrace admin if and when AG is disappearing from the grid.Any suggestions?Thanks in advance for your inputs Yos  

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel




					
						Solved!
					
					Go to Solution.




----------------
99.1:


There's a couple of solutions that come to mind.One way is to install the OneAgent along with the ActiveGate and monitor the ActiveGate process with it. The upside is you have a lof of visibility into the ActiveGate thanks to the OneAgent but the downside is that it will consume licenses. Some people are afraid this is not possible, but it's absolutely compatible to have both on the same machine.Another solution is to use the built-in metrics for self monitoring, like dsfm:active_gate.communication.agent_modules.connected. You can create metric events for this metric for the host.name or dt.active-gate.id dimensions, and alert when data is missing or the value is 0, which could indicate a problem. The upside is it costs no licenses and it's a built-in solution, the downside is you have to create the metric events yourself and make sure they are configured correctly with the host names or active gate IDs you're interested in. You can obviously also use any of the other dsfm:active_gate metrics to monitor your ActiveGates in many different ways (CPU, Memory, network, agent load, etc.).Hope this helps.

----------------
99.2:

Thanks @victor_balbuena But adding OA will cost HU, adding custom metric ,which I was also thinking about, will consume DDU Actually we are looking for something more strait forward  like the OA alerts on system notifications Yos 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
99.3:

The second solution does not consume any licenses, metric events do not consume DDUs, and the metrics I mention above are not custom metrics, they are built-in, so they also do not consume DDUs.

----------------
99.4:

Understood, forgot about the ability to set the alert on missing information.Tried it and its works, thanks !Yos 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
100:

The same way we have the Dynatrace operator source code here: https://github.com/Dynatrace/dynatrace-operator/blob/main/DockerfileDo we have the same for the ActiveGate container image?The objective is to harden that container image.And the only guidance I've found on the documentation suggests pulling the container image and then pushing it to their private repo: https://www.dynatrace.com/support/help/setup-and-configuration/setup-on-container-platforms/kubernet...Thank you in advance!



					
						Solved!
					
					Go to Solution.




----------------
100.1:


Hi @elenaperez,regarding pulling the container image and then pushing it to their private repo, it will be pulled from the environment and it will contain the environment configuration.if you are searching for a reusable image that doesn't contain any configuration related to your environment, I think you might find it in the below linkhttps://www.dynatrace.com/support/help/setup-and-configuration/dynatrace-activegate/activegate-in-co... 

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
101:

I am comparing to bunch of values on one dashboard, so i have two different set of dates, now there seems to be a bug which the date and time defaults back to the first sample data, this bug seems to happen so often, that its really annyoing, does anyone know about this bug?? simply create a bunch of dashboards and compare two different dates and times, and you will see sometimes the time change.really annoying this!!!

----------------
101.1:

Hi @Jamz ,would please provide some details, are you facing this in Managed or SaaS, classic dashboard or new dashboard?is it possible to provide some samples with screenshots?

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
102:

Hi,
Can someone please point me to documentation about what happens if either of these can't send data out to Dynatrace:

OneAgent
ActiveGate

I assume they each have some sort of persistent queue so if communication is lost it will collect the data and then send on reconnection - but is that right?
And what limits are in place as to how long it can accumulate data to send before running out of disk/memory?
I did have a look but I am not used to Dynatrace docs yet so a pointer would be greatly appreciated.
Thanks

----------------
102.1:

Hi @Keith_Harding ,Please note that Dynatrace OneAgent doesn't cache the data to avoid making utilization issues on the monitored server, that's why it's recommended to use the ActiveGate and to be installed closest to OneAgent with fewer/no firewall points between them, as the ActiveGate bundles OneAgent Traffic and is not limited to that, you can find more details here regarding ActiveGate purposes and functionality. and check ActiveGate acts as a secure proxy as wellalso, I think it would be better as well to check and understand the Network Zones Best regards,Mohamed Hamdy

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
102.2:

Dynatrace OneAgent does cache data. I say this from experience, and even yesterday I had one case where I had infrastructure data for several hours, before the agent connectivity was back up. The application modules/subagents seam to have a different behavior, also from empirical observations.I'm not sure if the data that @Keith_Harding references is still valid, because it's some years old, but would love to know more details.

	Antonio Sousa


----------------
102.3:

Thanks Antonio, thats great real world info.It would certainly be a good to see an official answer.  Some of the info I saw was "we don't cache because we don't want to use to much resource on the machine"  which makes sense but as you say in some cases it does cache.I also heard that they may drop metric granularity as the time unable to connect grows - that makes sense.You pont about different behaviour per module makes sense.  Caching some metrics is probably low disk need but caching traces and logs could require a lot of disk evry quickly.Thanks for your thoughts. 

----------------
102.4:

Thanks Mohamed, much appreciated.  For anyone else looking I also found out:If connection is lost data doesn't get dropped immediately. OneAgent has 10 MB buffer, whereas, Activegate has 100MB buffer. Until these are full, data isn't dropped.There is no pushback mechanism from ActiveGate to OneAgent. ActiveGate buffers are larger and compressed.Data can be lost if buffers are full. However, this rarely happens. Summary metrics take up small sub-sections of the buffer and retained to ensure data loss doesn't happen. Granular metrics are more likely to be lost and deprioritise in the event of an inability to connect with clusters.Dynatrace also has automated monitoring and alerting of conditions where large numbers of OneAgents stop sending.And this is a previously similar question:https://community.dynatrace.com/t5/Dynatrace-Managed-Q-A/Does-OneAgent-or-ActiveGates-retain-data-wh... 

----------------
103:

Hi guys, I need to send some metrics to dynatrace with Phyton SDK but I don`t have the dynatrace server, my question is: Is there a dynatrace simulator for local development ? 

----------------
103.1:

You can use the DEMO but i think you will not be able to do what you want https://{environmentid}.apps.dynatrace.com/ui/

	Dynatrace Professional Certified


----------------
103.2:

I wrote my own http server to handle this, I never saw a solution for this. 

----------------
103.3:

Hi @WilliamSca , You can use the trial for this, https://www.dynatrace.com/trial/

	Site Reliability Engineer @ Kyndryl


----------------
103.4:

Do you mean the Python SDK for extensions? If so it comes bundled with oneagent_simulate_plugin.
Or do you mean the Python SDK for tracing Python applications?

----------------
104:

Hello, folks.
I would like to know if there is any way in Dynatrace, whether through metrics, custom alerts, integrations, or the like, to monitor email sending in Office 365.
We have a situation where the user forwards an email containing payment information (PIX) directly to the customer. They receive a QR code and make the payment.
However, some emails are not being forwarded, and the customer needs to contact us directly to request the QR code.
Is there any magical way for Dynatrace to alert us when the sending process fails?

----------------
104.1:

Could the Exchange Server extension help with this?

----------------
104.2:

Nobody for help me?

----------------
104.3:

Do you see anything in the logs when this scenario occurs? If so, perhaps you could use Log Analytics/ Log Monitoring: https://www.dynatrace.com/support/help/observe-and-explore/logs
 

----------------
104.4:

I've searched for similar in the past but Dynatrace does not monitor such things. I'm not sure of the term here but it's what tools like Exoprise do, not Dynatrace.We started to go down the route of MS Graph API and even monitoring the MS Regional Health public monitors.  Neither solution can get you the detailed, real-time metrics you need from a third-party perspective.  In order to do this you will need some direct trigger or event monitor. Some fancy business process rule in Dynatrace that somehow uses Application Monitoring to ensure the QR codes are being picked up at the same rate the emails are going out.  Every time your application sends an email, capture it in Dynatrace as the first leg of your conversion process. Then monitor the number of requests you receive for picking up the QR code. Have Dynatrace monitor the delta between these two numbers and if too large send an alert because it would indirectly indicate the emails are going out but not being received because the QR codes are not being accessed. Outside of the above, we have an internal test that schedules an email to go out every 1 hour to a tool named Healthcheck.io.  If an email is not received every 1 hour the alarms go off.  This isn't the best solution because there are 300,000 Microsoft email servers around the world and our test could cross a healthy server while the critical email crosses an unhealth server. We'll never get alerted.  This is a fundamental issue you can't do anything about by simply monitoring Office365 exchange servers.  You essentially need to turn your email process into a TCP like transmission vs a UDP.

	HigherEd


----------------
105:

There is the option to use security policies to give users direct view or edit access on some specific schema's.ALLOW settings:objects:read, settings:objects:write, settings:schemas:read
WHERE settings:schemaId = "builtin:alerting.maintenance-window"; But how can I create an API token with only that permission? The API-token scopes are not fine grained I presume.

----------------
105.1:

At the moment, tokens use their own scopes so you can't use policies on them, that's correct. I could see the benefit of being able to provide policies for API tokens as well.The only workaround today is personal access tokens which inherit the permissions of the user that created the token, so this means also the policies attached to the customer.

----------------
105.2:

Using personal access tokens is difficult because it would require some kind of technical user which we don't have. It's not the biggest deal off course since we treat tokens as secrets. But if one would leak, it would give access to all settings while it could be restricted.

----------------
106:

Telegraf comes with the Dynatrace Output Plugin that enables you to easily send Telegraf metrics to Dynatrace:
https://www.dynatrace.com/support/help/extend-dynatrace/extend-metrics/ingestion-methods/telegraf
Does someone know if it's possible to configure/restrict the metrics being sent to Dynatrace?

	Antonio Sousa


----------------
106.1:

The GitHub page has some more details and it seems it is not possible through the [[outputs.dynatrace]] configuration section: https://github.com/influxdata/telegraf/tree/master/plugins/outputs/dynatraceAny ideas?

	Antonio Sousa


----------------
106.2:

Looking further at the Telegraf configuration, it seems it can be done with "namepass".Anyone managed to limit data ingestion by this or other way?

	Antonio Sousa


----------------
107:

Hello.
I get `Ingested log data is trimmed` message in Dynatrace Managed CMC events. So I go to the related FAQ : which says : 
 
6. Inspect 1-minute intervals of log events ingest.
- If you see that log events are trimmed to the Maximum ingest of Log Events limit set for this environment, you need to increase it.
- If log ingest was below the limit in subsequent intervals, your log entries will be re-ingested and should be available later, but you could consider increasing the limit to avoid a delay in data processing.
 
But how do I do that ? How do I know in which case I am ? In my Environment Log Viewer, am I supposed to find or not find something related to "dt.ingest.warnings" ? Or is it supposed to be investigated through "Format Table" field named "trimmed" ? In which case what am I supposed to find or not find ? 
Regards.

----------------
107.1:

Hi @gilles_tabary You can check and allocate the maximum ingest of log events per minute in CMC at environment setting.By click on the refresh cluster limit you will have the CLUSTER level overall limit. It can be splitted by the environments. in this example the cluster limit is ~ 168k (based on the memory and cpu capacity). Env1 has 140k / minute, Env2 has 20k Env3 has 8k... With these two metrics you can monitor and alert the incoming or rejected logs:dsfm:server.log_and_events_monitoring.events_incoming_count:splitBy():sum:sort(value(sum,descending))dsfm:server.log_and_events_monitoring.events_rejected_count:splitBy():sum:sort(value(sum,descending))I hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
107.2:

Thanks. I new about that already. Any thing about the actual question ?

----------------
107.3:

You should probably consider increasing the maximum number of log events per minute regardless, as per Mizső's message, but to answer your original question:The message you see about logs being trimmed doesn't always mean that your logs are actually being trimmed. It is a message generated by the DAVIS AI which could be over-reacting by seeing a spike in log ingest and thinking that logs will need to be trimmed, even if there is no data loss. So basically, we need to understand if this is the case, or data is being trimmed for real.The way to do this is to check, as per the first case, if your log events are being trimmed to the maximum set for the environment. If this is the case, you need to increase the maximum to avoid data loss. If logs are not really reaching the maximum set for the environment (or maybe only once or twice in a row), then the case is that DAVIS AI is calculating, because of a spike, that there will be too many logs, even if this is not true. In this last case, there will be a delay in log ingestion (hence why increasing the maximum is still advised), but no data will be lost.Hopefully that helps you understand which one is your case.

----------------
107.4:

Hello.Interesting point about Davis. Thanks.After much chating, here is my understanding. Say trimmed warning in CMC has a timestamp equal to 10:23:12. In the log viewer, set time frame exactly to one hour long from 09:23 to 10:23. Then, watch the graph (i.e. the plot). Don't search or try to filter for a special kind of log line, i.e. log events, especially attribute "dt.ingest.warnings" or table format field named "trimmed"  are not to be used, this is not where to look at or what to search for. On the graph, check how high the bars reach. Each bar shows on a one minute interval the number of log events ingested. This is what could be compared to the "Maximum number of log events per minute" set in the CMC. If bars consistently (many minutes in a row) reach approximately this Maximum (not higher, not lower) it may show there could be a problem indeed. If bars are higher than this Maximum it shows (as stated by @victor_balbuena) that all events got eventually ingested, but with a delay. If bars are lower : no problem.Let me know if this is an acceptable statement (otherwise I'll correct it as to not induce confusion in readers.  )I feel the FAQ doc coud be amended with maybe decorated screen shots, stating explicitly where to look at exactly, what to expect, what not to expect, what could be considered as a confirmation of the problem, or a confirmation there is no problem. Regards.

----------------
108:

 The "Guru" badge
Well, the latest "Gamer Challenge"'s popularity beat all our expectations, and yet the activity in the comments refuses to slow down! But life goes on and... It's time for the brand new Community Challenge! Share the names of people who were important to you on your journey, made a huge impact, or simply inspired you over the years. How did they help? Are they famous, or rather silent, local heroes? Or maybe there's a guru in your own family?
Don't hesitate to feature the names of their books, lectures, etc! For every participant, we've prepared a solid pack of prizes. You'll receive a unique "Guru" badge that you'll see in the Community profile next month, as well as 100 bonus points!
Don't forget to go back to this thread regularly in the upcoming month to update your list of role models and essential sources of knowledge that may be a tipping point for your career... Or beyond !

----------------
108.1:

While there are a lot of people that has helped me both personally and professionally over the years, I'm going with the one person who influenced me the most out of everyone, my mom.My parents separated when I was 3 years old, and while they had split custody of me and my older sister, I was always drawn to stay more with my mom. She worked as a nurse initially, but later took the step to start her own company, traveling all over the world to give lectures about Dementia.She has since retired, but my entrepreneur spirit and drive to help people whenever I can undoubtably comes from her and all that she did for myself and my sister.  

----------------
108.2:

Thanks a lot for sharing this story, Mike  This is a wonderful inspiration.

	Keep calm and build Community!


----------------
108.3:

Years ago a family friend got me into Computers. As a young child we built 4 boxes, it was these afternoon builds afterschool that really sent me into the technology field.  
In terms of Dynatrace, my Wife and @andreas_grabner have inspired, motivated and pushed me to develop unique solutions, use cases and methods inside of Dynatrace. If it wasn't for their support, I don't think I would be so involved with Dynatrace and the Community. I will be forever thankful for their support and the support of all the great Dynatrace Associates and customers I have met over the years as each and every single person has played a role in where I am today. 
In the Dynatrace Community, @Karolina_Linda  was very influential in my community activity. I remember back when I  started in the community at my first Dynatrace Organization. Looking for solutions to unique problems to which at times I couldn't find written solutions. Karolina drove me to not only solve these problems but then formulate documentation on it for the rest of the community. My first 'how to'  in the community was the documentation on how to set up the Dynatrace UFO for customers who were managed. My documentation was the first for Managed Customers which was the spark that propelled me to where I am now in the Community, all thanks to Karolina and her efforts. Over the years she has developed an amazing team of Community Administrators all of which I have interacted in some fashion. 
My Wife, @andreas_grabner and @Karolina_Linda thank you for your inspiration and motivation which has propelled me to where I am today. I will forever be grateful and cherish our friendship! 

	-Chad


----------------
108.4:

Ohhh, thank you Chad for your kind words! 
You've been the Community team's motivation throughout all these years! I'm grateful for having such a helping hand in the times when there was no Community team, always providing feedback, catching issues faster than the lightening, and simply being supportive 
I'm also very grateful for the friendship we've built! 

	Keep calm and build Community!


----------------
108.5:

I am over 30 years old and I really know that I have a long way to go, to learn, know, and trip on. I started my journey in IT at 17/18 years old when I was a student, but the public person who had most influenced me and I learned a lot from his biography was Steve Jobs. I remember his presentations like the first iPhone, after time I viewed the presentation of the first iPod, and it was amazing the form this person share a story, the revolutionary of the industry.Then I learned from his book and videos about his biography and every time I deeping into his history I always learn something new.I think Steve Jobs, Steve Wozniak, and Bill Gates were the top of the IT industry since the 70s/80s and they marked the pathway to a new generation.

	-César S. - LATAM Solutions Architect


----------------
108.6:

As a child I read Leon Uris's Battle Cry , the powerful descriptions of turning young people from different backgrounds into a unit of combat soldiers and continuing "see" them struggling on battlefields, gave me a different perspective on how to overcome obstacles and reaching goals in my life. 10 yeas ago, while I was already a senior systems analyst in information systems department of a large insurance company,  I met, in the elevator, one of our business client, he looked at me and said: "Listen Yosi, you must reinvent yourself" punched me on my shoulder and left the elevator. I was stunned for few moments, but in next few weeks I thought about this sentence again and again. Then I realized that I really have nothing more to contribute in the field of systems analysis .... A year or so after this evaluator conversion, I found myself starting from scratch to learn a different angle of IT, this time it was monitoring ......

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
108.7:

An interesting challenge indeed! Because there have been so many Guru's in my life! And that's the problem: naming one or a few, seems so injust for the remaining!Anyway, probably the one that I cite the most is the President of the Institution,  at the time where I started my first real professional job. He's not amongst us anymore, but he really pushed us/me to some great realizations some 30 years ago! Besides being President of that Institution, he was very good technically. So we were doing remote working in 1995, not only at home but anywhere in the country with GSM. We were also already experimenting with "paperless office" at the time... And we were taking networking to it's limit, and guess what? The main tools that were helping me achieve that, were monitoring/observability tools of the time. No kidding!His name was Fernando Mendes.

	Antonio Sousa


----------------
108.8:

A little controversial these days, but I should remember Mr. Richard Stallman and free software movement started decades back. It has allowed me to think and seeing things from a different angle.Thank you for freedom to learn new things, studying what is happening behind the scenes and sharing knowledge with others.

	Consultant


----------------
108.9:

This is a very good highlight! The open-source movement is really a great inspiration in the last 3 decades!

	Antonio Sousa


----------------
108.10:

Throughout my professional journey, several individuals have inspired me and helped me become who I am today. Even though they might remain anonymous to you, I will mention them as they have been colleagues, mentors, and sometimes even friends to me:Hassan and Clement (managers) taught me not to underestimate myself and to highlight my work.Pascal (CTO) taught me not to let myself be walked over.Guillaume made me dream with his pre-sales vision, his technical expertise, and imparted an effective work methodology to me.I hope to someday contribute as much as I have received.

	Observability consultant - Dynatrace Associate/Pro/Services certified


----------------
108.11:

A great challenge this month. I do not have a reference in capital letters, but throughout my life I have learned many things from a large number of people with whom I have been related, even from those who are not a role model I have learned the value of some things that we take for granted.I am honestly very grateful to the entire Dynatrace community, all the community team, my fellow Dynamights, the Dynatrace team, all the active members of the community. From all of them I learn different things every day and I am not referring to the content but to values such as perseverance, drive to face challenges, team spirit, recognition among many other values. I am very proud to be part of this group of people from whom I acquire new values.On a personal level, I agree that children are a constant source of learning. As well as many values that my parents gave me. I can't imagine that I would be the person I am without their dedication and effort.And of course, I would also like to add, as a fan of reading, all the positive things that books can bring.

	The true delight is in the finding out rather than in the knowing.


----------------
108.12:

 The people who made a big impact on my journey were my family (Mom) and my mentors, bosses. My mother always trusted and believed in every professional decision I made, even if she was afraid that I would get into trouble she always believed in me and gave me all the support I needed, so in my list of people who inspire me she comes number 1, she worked harder than anyone I know. I love you mom and thank you for everythingSecond comes my  3 mentors. When I was 19 years old and entering this market, with little vision, my mentors saw potential in me and gave me all the tools I needed to develop as a professional, they taught me lessons that no college could, a few months ago I got my professional certification, something that seemed so far away when I started, I just have to thank my team and those who bet on me and believed and say that you were rightNOTHING RESISTS HARD WORK.The next step is master and Dynamight certification, and I hope to meet and be inspired by my fellow forum members.and of course inspire many people in the future 

	Dynatrace Professional Certified


----------------
108.13:

I'm a huge believer in every person entering our lives for a reason, so I'm grateful to everyone who's only briefly crossed paths with me, walked along for some time, or keeps me company on my journey to this day 
But if I has to highlight one person who made the biggest impact on my life, I would have to go with my Dad. He taught me to be curious, to question everything, be bold, and brave, and true to myself, to love books and history and know their worth, and to smile even when it seems like it's the end of the world. But most importantly, he taught me what true Humanity is.
The struggle always brings truth about people to the surface, and the war in my country made me reevaluate a lot of relationships, but not the one with my family  It was so easy to just give up and spiral into fear or depression, but instead he chose to focus on helping people. He's volunteering since day one, and us (my sister, my mom and me) were never more proud of him! 
 A "clipping" from the local newspaper about his initiative A "tiny" army of trench stoves (they stopped at 1000!) he and other volunteers made last year.
And on the happier side of things, my dad at his favorite's band concert 
 
He also taught me a thing or two about good music 

	The only constant is change. Finding ways for great things to happen!


----------------
108.14:

Lovely words, congrats to every great Dad!!!

	The true delight is in the finding out rather than in the knowing.


----------------
108.15:

In terms of Dynatrace my former coach @jeroen_peperka1, who answered a lot of my Dynatrace question (especially during the first months),dragged me into the Dynatrace rabbit hole and became a good friend (yea I hope he feels the same :D).Also, @henk_stobbe (our mighty DynaMight) and @michiel_otten (former community member of the month) who almost always know the solution and help out wherever they can within the team - even if its not for their own customer or credits.And lastly, @Mr_Bluethumb, my very first 'coachee' whom I was allowed to teach Dynatrace to from the very first minute onwards (well okay I'll admit we also shook hands before), kept challenging me with questions and who can stand more than perfectly well on his own feet now - and even solves my RegEx problems.

	A Dynatrace Professional nerd working for Eviden


----------------
108.16:

Hi!,
Throughout my life, my mum has been an unwavering source of support, guidance, and inspiration, playing a crucial role in helping me achieve my goals. Her influence can be traced back to my earliest days, as she nurtured my curiosity and encouraged me to explore the world around me. In my formative years, my mum was my first teacher, instilling in me the values of hard work, determination, and resilience. She recognized my strengths and weaknesses, gently pushing me to embrace challenges and learn from setbacks.
 
Nowadays my career is moving on because of my colleague Sebastian Krystosik (@skrystosik) who showed me that every successful person should be constantly developing to achieve goals. He gave me a helping hand when I looking for a job and now he is supporting me to become a better employee and Dynatrace Guru 

	"The lion does not ally with the coyote"


----------------
108.17:

Thx nice words  I missed that post before 

	Regards, Sebastian


----------------
108.18:

Hello Team, The most important and valuable person is Mohamed SAW. But after that a lot of people in my life: my Grand parent. Have a good day.BRs,

	Sharing Knowledge


----------------
108.19:

Before beginning my graduation, I had decided that I would pursue my childhood love, technology. So, every step in my life was aimed at realizing that dream. A few months into my studies, I noticed there were many subdivisions, so I took some time to study and become familiar with some of them that had caught my attention. After this "sabbatical period," I realized what I truly wanted, and then some companie really believed in my abilities and taught me all the necessary steps. They turned me into who I am today, probably one of the youngest certified to achieve professional certification at just 20 years old. This opportunity has taken my career to a new level, and I am deeply passionate about the Dynatrace platform and the community. None of this would have been possible if my mentors didn't believe in me. I am truly thankful for everything, especially @natanael.

	Dynatrace Certified


----------------
108.20:

we made it boy, proud of you

	Dynatrace Professional Certified


----------------
108.21:

Hello All,Lets keep it very short. My Guru, and for me still the king of Appmon (-;  Andreas Grabner!Still creating great online content, in which he always explains everything clear and understandable. I think it is a combination of teaching, story telling and passion. He is always exploring one topic at the time, at a  very precise level so you understand it.  Giving you enough knowledge to  start using it yourself and  explore further.    So for me, if there was a Dynatrace hall of Fame.........KR Henk

----------------
108.22:

My Guru, who introduced me to the incredible platform Dynatrace approximately 6 years ago, illuminated the path not only for me but also for countless others with his inspiring approach and unwavering enthusiasm.I would like to nominate Ibrahim, Mohammed as the "GURU" He is helping everyone to learn, explore our potentials and reach to the new heights. Under his guidance, our team has flourished, amassing nearly a hundred adept Dynatrace consultants from India. Collaborating with him has not only been professionally enriching but has also led many to regard him as their revered "GURU," sought after for invaluable career counsel. 

----------------
108.23:

I don't have any specific Guru in my life... what I have the most are 'anti-gurus', if we could call them like this, lol.I learn with their mistakes, and try to avoid their steps to be successful.I do have lot's of people that inspired me doing the right thing, but I definitely learn lot more with those which failed.Please don't see this as a bad thing (or pessimist). Failures are part of the system, and I think I learn way more with them.I do learn with the people which receive lots of lemons from life.

	Site Reliability Engineer @ Kyndryl


----------------
108.24:

That's definitely a way to learn  cheers to all the anti-gurus out there! I'm a huge fan of being just as honest about your failures, as about your victories. Let people around you learn from yours and make their own!

	The only constant is change. Finding ways for great things to happen!


----------------
108.25:

Hi,From a young age, I was fascinated by maritime transport, perhaps because my father is a sailor. The person who served as a role model for me was Captain Karol Olgierd Borchardt. Captain Borchardt was known for his exemplary leadership and extensive experience in the maritime industry. He not only instilled in me a deep appreciation for the sea but also inspired me to pursue my dreams.Thanks to his influence, I initially set my sights on becoming a seafarer, but the birth of my son prompted a change in my career path. I decided to shift my focus to the world of Information Technology (IT), which had always been my second passion. This transition allowed me to be closer to home and avoid the long periods of absence associated with a maritime career.In the field of IT, one of my guiding lights has been Ivan Alexander Getting. Ivan Getting is renowned for his significant contributions, including the invention of the Global Positioning System (GPS). His groundbreaking work in GPS technology has revolutionized navigation and positioning worldwide, demonstrating the immense impact that one individual can have on technology and society.As for my current role model, I won't reveal their identity, but I've come to understand that sometimes we don't have to look far to find inspiration. This individual holds a special place in my life, reminding me that meaningful role models can be found in those closest to us, guiding us on our journey through life.Radek

	Have a nice day!


----------------
108.26:

My Ideal person whom I call GURU is "Mr.Rakesh" who shaped me during my childhood (My school teacher - Mathematician)."Mrs.Anita (College professor) who understood my capabilities and bring out my stage fear.In profession my Guru is Andreas Grabner whom I admire the most. Still lots of learnings from his content.Cheers!RN

	Dynatrace Certified


----------------
108.27:

For me it would definitely be my parents, for all the hard work and sacrifice they made for me is something I would always be indebted to. They are also both teachers so they are also the one who taught me the basics before I started school as a kid. We had a big combined family with aunts, uncles and grandparents but they set a good example for me how to not only maintain work life but also family. 

----------------
108.28:

Each journey in my life has its own experience and Gurus that I have met, and definitely, my parents and my wife are at the top of the list as they are always the source of support.as for my Dynatrace journey, I would like to thank my colleagues, and community members, and special thanks to my Dynatrace role model @thomas_brandl

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
108.29:

For my personal life, My mother was my guru that pushed me through my educational life and in collage, also supported my hobbies and interest in IT world.In Dynatrace world, i always see @ahmed_el_jafouf as a Dynatrace hero, his support and encouragement since 2015 made me eager to go deeper into Dynatrace world. Also the rocking star @thomas_brandl who doesn't hesitate to provide any help at any time.

	Dynatrace Certified Professional - Dynatrace Partner - Yourcompass.ca


----------------
108.30:

Thanks for the kind words, Islam! Working with you is always inspiring and enjoyable 

----------------
108.31:

Lots of people have come and gone in my life, and many have made a big difference to my journey. Some have even inspired me. I've got to give a shout out to @miro_subasic , who is a great mentor and a top-notch leader when I first started at my current job. And I can't forget the impact of books and talks from folks like Brian Tracy, The Dalai Lama, and Khalil Gibran. I try to read every day, and it's amazing how many different people, from all sorts of backgrounds, can give you a fresh perspective or a bit of inspiration.

	WHomES


----------------
108.32:

Thank you Koen for the kind words. Really happy and glad to have on our team

----------------
108.33:

From a Dynatrace perspective: @andreas_grabner @andreas_grabner  @andreas_grabner He has inspired me and so many in this community.  Starting with his podcasts to all the other videos he does.  He is a great communicator and looks like a natural.  

	Dynatrace Certified Professional


----------------
108.34:

For me is Linus Torvalds   On August 25, 1991, he sent the historical email to comp.os.minix asking the community members about the features they’d like to see implemented in his OS.His vision of collaboration, open source, and community is what makes him a great person and they are some of the things that I admire.> yes Guru god level. Any doubt?

	IT Master | dynatrace Certified professional | SRE Certified | Scrum Certified | Azure Certified | https://www.linkedin.com/in/rodrigocuevas/


----------------
108.35:

Oh my: "it probably never will support anything other than AT-harddisks" 

	Antonio Sousa


----------------
108.36:

There is no doubt everyone around us can be our Guru's. Regardless of what we may think, we don't know everything, and that's why I try to learn from everyone around me. That being said, I can definitely name a few that have been (and some are still) playing an important role model to me.I'll start with my parents. Their ability to put a side all difficulties and enjoy life, insist on moving forward, despite all obstacles, insisting on being independant have thought me not to give up on anything. My father's experience in business management taught me how to be a manager and how to make clear and rational decisions.There was also my first CEO, who taught me how to deal with software products and how to speak to customers and show values. There are many more and some of them you may know, but I would love to take the opportunity and give a big kudos to a friend of mine, a Dynamight himself, who is my guru in his eagerness to learn all the time, in his commitment to customers and yet his commitment to his family, and this is @Yosi_Neuman . So big Kudos to you Yos. When I'll grow up, I want to be like you 

----------------
108.37:

I'm speech less ......  

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
108.38:

Yosi, full respect 

	Have a nice day!


----------------
108.39:

There's definitely a countless amount of individuals who've inspired me along my journey, and no amount of words can express my gratitude to them for how far I've come. With that being said, there are few and far between who have stuck out, the most prominent being my uncle. My Uncle: When I was younger, I had a fairly large interest in fantasy books and technology. My uncle took notice of this and continuously gave me gifts that would help nurture these interests, and continuously encouraged me to follow these goals to create things. Through a combination of imagination and science, he was able to show me that anything was possible - even if it is outside of the realms of what most people believe. We created video games, engineered things out of Legos, and so much more. To this day, much of what he's not only taught me, but been involved in has allowed me to not be afraid of my own creativity, and to embrace different ways of thinking to not only challenge myself, but help others. 

----------------
108.40:

I think its great if you have someone to look up to and there are important people in all of our lives - but I do not want to post some "Guru" here. I think it is far more important to try to be the best version of yourself, as this will help all of us the most.

	iOS help: https://www.dynatrace.com/support/help/shortlink/ios-hub


----------------
109:

Hi Folks,
I have found a Go application in OpenShift (redhat costmanagement-metrics-operator) with inactive deep monitoring because of rule 47.
 
Is there any connection between rule 47 and Go monitoring settings second item?
 
 
Does rule 47 override the Go monitoring settings second item? Or there is not connection between them?
Does anyone have experience about this topic?
Thanks in advance.
Best regards,
Mizső

	Certified Dynatrace Professional




					
						Solved!
					
					Go to Solution.




----------------
109.1:


Hi. Both settings are connected. In order to monitor Go statis processes:In Settings the option "Enable Go static application monitoring" must be enabled.Rule #47 must be disabled.Also there is in Host settings a Go section where you can enable Go statisc monitoring only on individual hosts. Also in this case is needed to disable Rule #47.   

----------------
109.2:

Hi @joseandrescalvo,Thanks very much for your explanation and help.Best regards,Mizső

	Certified Dynatrace Professional


----------------
110:

Is the "Azure Native Dynatrace Service" exposed in this documentation:https://www.dynatrace.com/support/help/shortlink/azure-native-integration what is shown in this quick demo video?Dynatrace for Azure - YouTubeAre there longer videos to see more on the solution? Regards



					
						Solved!
					
					Go to Solution.




----------------
110.1:


Yes, those two refer to the same thing. I don't believe there's any other videos, or better resources for it than what you already linked, just the blog post (which has less information imo).

----------------
110.2:

Hi Victor thank for confirmation - I was a little bit confuse at the beginning.Do you know if after adopting such solution I'll still be able to integrate other kind of monitoring that are not on Azure? (Suppose that I want that kind of agreement but after a while I realize I also need to monitor something legacy in my datacenter)Regards

----------------
110.3:

You mean, monitor other assets outside of Azure in Dynatrace? Absolutely, Dynatrace aims to be a single pane of glass for all your monitoring needs after all 

----------------
110.4:

With that same SAAS environment ID right?(Sorry don't want to give anything for granted)

----------------
110.5:

Yes, within the same SaaS environment ID, you can monitor all your Azure assets with this integration, or any other, and include all your local datacenters as well as any other providers (like AWS or GCP) if needed(No problem, it's the right thing to make sure everything makes sense  )

----------------
111:

I have integrated Dynatrace SDK into our iOS application. When I run our application locally or download it from Testflight, everything works perfectly. I can see our real Apdex rating, web requests, and crashes if any.However, when I release our into production and it is on the Appstore, Dynatrace doesn't show any date.No web requests or crashes. Also, Apdex is 1.0 as a result.
Our cost and traffic control is 1% which shouldn't be an issue because Dynatrace works fine in our Android application. We use the same dashboard for both platforms.
- We have Firebase in our app but we don't use it for Performance Monitoring, I have disabled it just in case but it didn't help.

----------------
111.1:

Hi,for debugging such an issue I would suggest to open a support ticket at https://support.dynatrace.com/But I can give some hints to validate before:1% is a pretty low traffic control value - so if you have more Android users than iOS it might happen that this 1% is mainly filled with Android users as session selection is based on random and not OS familyThere is a webrequest related limitation between Dynatrace and Firebase Performance Monitoring: https://www.dynatrace.com/support/help/platform-modules/digital-experience/mobile-applications/instr...Strange thing is the difference between TestFlight ans AppStore release, as there should not be any difference, as you can use the same build.

	iOS help: https://www.dynatrace.com/support/help/shortlink/ios-hub


----------------
111.2:

I have created a separate dashboard just for our iOS app to see if 1% was the reason. However that didn't solve the issue either.I am using Firebase only for crashlytics but I disabled the performance monitoring just in case. It didn't help.

----------------
111.3:

Please open a support ticket so we can have a closer look.

	iOS help: https://www.dynatrace.com/support/help/shortlink/ios-hub


----------------
111.4:

@enum when your issue is solved maybe you can share a solution with other users? They would be grateful to have some hints if a similar issue will appear. 

 When passion meets people magic and innovation happen. 


----------------
112:

Hello, Can you give an example of how to modify the yaml file to monitor 2 AWS accounts?I found this on docs, but is not clear for me how to set it:https://www.dynatrace.com/support/help/shortlink/aws-managed-deployment#step1

----------------
112.1:

Hi @alejandro_herna ,An example can be found on the GitHub link on how to configure the .yaml file here:https://github.com/dynatrace-oss/cloud-snippets/blob/main/aws/role-based-access/role_based_access_AG...Given that you are attempting to do this with AWS, this should suffice as a starting point.Cheers,Taylor S.

----------------
112.2:

Thanks, but I need an example for multiple accounts

----------------
113:

Hi,
We have got a requirement to integrate Splunk with Dynatrace OneAgent (SaaS).
Could you please guide us with the integration procedure, any different methods to integrate, and any dependencies? If possible please provide any screenshots if available.
Thanks&Regards
Sangeetha
 



					
						Solved!
					
					Go to Solution.




----------------
113.1:

But what do you want to push to splunk from DT? User Sessions? Problems via Webhook? Sebastian 

	Regards, Sebastian


----------------
113.2:


Hi Sangeetha,The easiest way to do this is to set up the Dynatrace App for Splunk and the Dynatrace Add-on for Splunk.The Add-on is responsible for executing the rest API calls and collecting the data from DynatraceThe App provides a collection of dashboards and saved searchesThe Dynatrace Add-on for Splunk contains four distinct input types.Timeseries Metrics: a pre-defined collection of Dynatrace metrics that feed the App's dashboards as well as ITSI’s APM Module (Note: by default the Dynatrace App for Splunk assumes all data is written to a "dynatrace" index)Entity: Selectively choose which entities to collect data for (Applications, Services, Hosts, Processes &/or Process Groups)Problem: Details about problems that Dynatrace detects within a given environmentTimeseries Single Metric: Any single timeseries metric that Dynatrace tracksSee links below for details Dynatrace App for Splunk Dynatrace Add-on for SplunkThanksNJ

----------------
113.3:

Hi, has anyone been able to send the user session data from dynatrace to splunk? using the app and the add-on?

----------------
113.4:

We are currently using the plugin, but I'm really more interested in exporting user session data.  I've been told to point DT to Splunk's endpoint.  Still trying to determine what that is.

	Dynatrace Certified Professional


----------------
113.5:

@sebastian k. @William S.Have you guys been able to figure this out? Like you, I'm trying to push user session data from DT to Splunk but I'm trying to figure out how to set up an endpoint in Splunk. I was able to do this with ElasticSearch easily, but I'm having difficulties with Splunk. 

----------------
113.6:

Hi guys, this may be what you need: https://docs.splunk.com/Documentation/Splunk/latest/Data/UsetheHTTPEventCollector#HEC_functionality_...

----------------
113.7:

It seems the plug-in does not permit to request USQL API but only timeseries ...Any update on this ?

----------------
113.8:

Is this plugin use v1 or v2 api on Dynatrace?

----------------
113.9:

Do we have a solution for importing Splunk logs into Dynatrace?

----------------
113.10:

Hi,You have these options to ingest logs into Dynatrace.Best regards

	Consultant


----------------
113.11:

Thanks) I know these DIY options,I am looking for a DYNATRACE solution like an extension or ready-to-go scrips.

----------------
114:

I can't find an SDK to read the user's IAM roles. Currently, I'm having to do a bunch of error handling and presenting Toast when a user is missing a role. It would be much more preferable to be able to query whether a user has the necessary roles, so the UX can be tailored to what they can do. For example, if they lack a permission for an API call, disable the button that would fire that call.



					
						Solved!
					
					Go to Solution.




----------------
114.1:


Hi Lucas, 
we have an item on our roadmap that will address your issue. We expect to deliver this in CQ3 this year.
Best regards,
Florian

----------------
114.2:

Hi Florian - 
I was wondering if there is an update on this feature,
 
deb

----------------
115:

I am trying to use the user management APIs, as they are shown in this page: https://api.dynatrace.com/spec/#/User%20Management/UsersController_getUsers when i click authorize at the top right it ask for a bearer, http, what is that? should i enter a PAT, an API token or what exactly? i also went to th eaccount management APIs section and generated client ID and secret, but as per your documentation, i am having issues to generate the Token from there, you have this snippet in there, is this snippet correct? does not look correct to me, why there is this strange string at the end on the parameters list: %3Adtaccount% ? POST /sso/oauth2/token HTTP/1.1Host: sso.dynatrace.comContent-Type: application/x-www-form-urlencodedgrant_type=client_credentials&client_id={your client id}&client_secret={your client secret}&scope=account-idm-read+account-idm-write&resource=urn%3Adtaccount%{your account UID}  



					
						Solved!
					
					Go to Solution.




----------------
115.1:


Hi davide_piras, The resource parameter is simply to let dynatrace SSO know that the token will be scoped to a particular account as users can be on multiple accounts.  What you see is URL encoded.  It will look something like this:  urn:dtaccount:00000000000-0000-0000-000000-0000000000000 where the "0"'s would be replaced with our account UUID.  Once you make the request you will get a JSON payload payload with a field called "access_token".  You can copy this and paste it into the the swagger and run the request. Thanks,Ryan

----------------
115.2:

Thanks Ryan, the documentation page doesn't only have that error, also the scope to be used is not:scope=account-idm-read+account-idm-writebut the correct value is:scope=account-idm-read account-idm-writewithout a plus, I got help from the consultant in the in-product chat, i understand url is encoded but as it is not clickable anyway and values should be replaced, that page would be more helpful if explaining clearly in details which value in each parameter for instance with a screenshot from Postman, SoapUI or whatever other http client... anyway all worked now for me and i could successfully retrieve that token. Thanks,Davide

----------------
115.3:

Hi Davide, I really appreciate the feedback.  I'll take this back to the team and see if we can come up with some simpler explanation. Cheers!Ryan

----------------
115.4:

Hi, I have the same problem, is not working for mehttps://www.dynatrace.com/support/help/shortlink/account-api-authentication#request-a-token  

----------------
116:

hello, can we do something like this? In the clickpath section of the synthetic browser Can we dynamically query the PNR number when doing online check-in? For example, we want to take the PNR numbers from file and add them to the field as in the figure.  I hope I was able to explain. Can I pull the data from a file in the Clickpath section and do this with a script? Thanks. 



					
						Solved!
					
					Go to Solution.




----------------
116.1:

Hi,I would say yes if you that file is reachable. It means, if you can make a JavaScript code to reach content in that file, and paste it in that field.Best regards

	Consultant


----------------
116.2:

Do you have a sample of the Java Script code I can test?Regards,Mustafa.

----------------
116.3:

How is the file getting updated? Is it another monitor that is creating the booking reference and this one does something with it? If that's the case, you might be better using the Credential Vault. So the first monitor could create the PNR and use the Credential Vault API to update an existing credential, and then the 2nd monitor can just reference it. 

----------------
116.4:

Do you have an example?Regards,Mustafa.

----------------
116.5:


In the first script, store the PNR value in a Credential Vault entry. CREDENTIALS_VAULT-xxx is the credential vault entry where you are storing the PNR, CREDENTIALS_VAULT-yyy is the token needed to update the crdential vault entry. 
api.startAsyncSyntheticEvent();
var PNR = yourPNRvalue;
url = 'https://yourTenant.live.dynatrace.com/api/v2/credentials/CREDENTIALS_VAULT-xxx';
pdata = '{  "name": "YourCredentialName",  "type": "TOKEN",  "token": "' + PNR + '"}';
api.info(pdata);
fetch(url, {
        method: 'put',
        body: pdata,
        headers: {
            'accept': 'application/json; charset=utf-8',
            'Content-Type': 'application/json; charset=utf-8',
            'Authorization': 'Api-Token ' + api.getCredential("CREDENTIALS_VAULT-yyy", "token")
        }
    }).then(function(res) {
        ResponseCode = res.status;
        api.info("responseCode = " + ResponseCode);
        return res.text();
    })
    .then(function(data) {

        if (ResponseCode == 204) {
            api.finish();

        } else {
            api.fail('Update failed: ' + ResponseCode);
        }
    })
    .catch(e => api.fail(e));
Then in the  second script you can retrieve the PNR and set a variable with it to be used elsewhere in the script
var PNR = api.getCredential("CREDENTIALS_VAULT-xxx", "token");

api.setValue("PNR", PNR);

----------------
116.6:

@Mustafa_ERZURUM did it help you?

 When passion meets people magic and innovation happen. 


----------------
117:

We migrated to Grail and discovered that Synthetic and RUM metrics are still not available there, DQL can't be used to work with these.
Various posts in May / June indicated that some metrics were already in testing for the version 269 preview, but we are on version 274 already, and I don't see these being available - neither in the documentation nor in the release notes.
So what is the current roadmap for Synthetic (browser and HTTP monitors) and RUM metrics migration into Grail?
 
 

----------------
117.1:

Looking forward to the next steps. Integrating metrics will be a vital aspect of the transition from the Old Dashboard to the New Dashboard. It will be intriguing to observe how DQL functions in conjunction with the 'Split by' feature, especially when utilizing TAG values. In our current dashboards, creating panels is incredibly user-friendly and doesn't require any coding. I'm eager to see how this process will evolve.

----------------
117.2:

Hi @alter I have good news preview, synthetic metrics are already available in Grail as a preview. Interested in trying it? please, reach out to your CSM and ask him about contacting me regarding that topic. I'll be happy to have a call with you, to run quick demo and discuss your needs
 
Best Regards,
 
Jacek
 

----------------
117.3:

Hello @Jacek_Janowicz , is there an update on when RUM and Synthetic metrics will be available in production?

----------------
117.4:

Hi @heybeckerj 
Most likely synthetic metrics in Grail will be released as GA with new Synthetic Monitoring application. As mentioned above subset of those metrics is available as a preview. Are you interested in call to discuss enabling it for you ? Best Regards,
Jacek

----------------
117.5:

Hello @Jacek_Janowicz , yes please. I would appreciate that

----------------
118:

Hi! I have an issue trying to use the MultiMeterBarChart - there is an error 'Module '"@dynatrace/strato-components-preview/charts"' has no exported member 'MultiMeterBarChart'. And actually, there is no such member in index.d.ts (../charts). Can you help me with that? 



					
						Solved!
					
					Go to Solution.




----------------
118.1:


Hi @veranikabarel ,
which version of the @dynatrace/strato-components-preview package do you use?
I just tested it with the latest version 0.104.1 in a CodeSandbox, and there it works: https://codesandbox.io/s/vhj56f

----------------
118.2:


"0.99.3", I will upgrade the version and try to import, thanks!

----------------
119:

What is and How to generate a HAR File?How to enable dtHealthCheck.What is and How to generate a HAR File?  A HAR (HTTP Archive) file is a log of all network requests made by a web page in your web browser. It includes details about each request, such as the URL, response headers, request headers, and timings. Generating a HAR file is a useful troubleshooting tool because it provides a comprehensive snapshot of a web page's network activity, allowing for precise issue identification. How to generate a HAR file: This tutorial covers Google Chrome, Microsoft Edge, and Mozilla Firefox. (For webview, see this tutorial.)Step 1: Open the Developer Tools.Open the Browser.Press F12 on your keyboard to open Developer Tools.Alternatively, right-click anywhere on the page and select "Inspect" or "Inspect Element."For Chrome, you can also use the three-dot menu in the top-right corner of the browser > More tools > Developer tools.Step 2: Go to the "Network" Tab and check the Preserve log checkbox.In the Developer Tools, you should see a set of tabs at the top. Click on the "Network" tab. Make sure the "Preserve log" checkbox is checked. This option keeps the network log intact even after a page refresh or navigation.Optionally, you can clear the network log by clicking the "Clear" button. ∅  Chrome and Edge:  Firefox:  Step 3: Reload the Page or Trigger the Actions.To capture all network activity on the webpage, you'll need to reload the page or perform the specific actions that trigger the network requests you're interested in (e.g., submitting a form, clicking a link, etc.).Step 4: Stop Recording.Once you've captured the network activity you need, return to the "Network" tab in Developer Tools. You should see a list of network requests made by the webpage.Click the red "Stop" button (square icon) in the top-left corner of the "Network" tab to stop recording network activity. - Chrome and Edge:   - Firefox: | | Step 5: Export the HAR File.Right-click anywhere in the list of network requests.Select "Save as HAR with content" (Chrome and Edge). "Save All As HAR" (Firefox). Choose a location on your computer to save the HAR file, give it a descriptive name, and click "Save."How to enable dtHealthCheck. dtHealthCheck is a feature enabled by adding the User-Agent header value dtHealthCheck. Responses to any requests made with this header contain additional headers and sometimes an HTML marker in the body. If injection problems occur, these headers provide diagnostic details, which may help us to identify the issue. (It only works for Google Chrome and Microsoft Edge). Step 1: Open Chrome or Edge Developer Tools.Open the Browser.Press F12 on your keyboard to open Developer Tools.Alternatively, right-click anywhere on the page and select "Inspect" or "Inspect Element."For Chrome, you can also use the three-dot menu in the top-right corner of the browser > More tools > Developer tools.Step 2: Access Network Conditions. There are two ways of opening Network Conditions. 1 - In the Developer Tools, you should see a set of tabs at the top. Click on the "Network" tab. In the additional settings bar, click the "More network conditions..." icon (the one with a yellow square), and the Network conditions will open.2 - In the Developer Tools pane, locate and click the three vertical dots (Options) in the top-right corner of the pane. Choose "Network conditions" from the dropdown menu. Step 3: Untick "Use browser default" and Customize User-Agent to "dtHealthCheck".In the "Network conditions" settings, you'll find an option called "User agent." Untick the box that says "Use browser default" to enable manual User-Agent configuration.After unticking "Use browser default," a dropdown menu will appear. Select "Custom..."A text field will appear where you can enter a custom User-Agent string. Enter "dtHealthCheck" into this field. Step 4: Open the webpage.As soon as you set the User-Agent to "dtHealthCheck" in the "Network Conditions" settings, it should take effect for the currently open tab, and you can proceed to open or reload the webpage and create the session. (Do close the tab or browser. Once it's closed, the option will reset to default).Step 5: Export the HAR File.Right-click anywhere in the list of network requests.Select "Save as HAR with content" (Chrome and Edge).Choose a location on your computer to save the HAR file, give it a descriptive name, and click "Save."Note: The dtHealthCheck will only show results if the OneAgent is working on the web server. Keep in mind that it doesn't work for Agentless injection. 

----------------
119.1:

Great write up. Really helpful info. Thanks Patrick. 

----------------
120:

I have JVM dashboard and I want to get rid of an extra GC process that shows in the dashboard, 
I've created a filter using the DQL but I get a warning
 
 
Does anyone know what this is? "dimension Key has been referenced, but the metric has no such key



					
						Solved!
					
					Go to Solution.




----------------
120.1:


I think you're confusing terms here, what you're using in your screenshot is a metric selector, which doesn't use DQL. Inside that metric selector, you're using a filter which follows the syntax <dimension, value> where dimension is the metric dimension to filter by and value if the value used to filter that dimension. The value seems to look fine, as it's an entity selector that selects some specific process group instances. However, the dimension is wrong as the metric builtin:tech.jvm.memory.gc.suspensionTime does not have a dimension with value builtin:tech.jvm.memory.gc.suspensionTime. Instead, your filter should look like: filter(and(or(in("dt.entity.process_group_instance",<value>), since dt.entity.process_group_instance is an actual dimension of the metric.

----------------
121:

Is it possible to know when a synthetic event started happening? We do have the start and end time for the whole "transaction", but it seems to not have the timing for when each event happened. Before submitting a Product Idea, does someone have an idea if it's possible to get this information?

	Antonio Sousa




					
						Solved!
					
					Go to Solution.




----------------
121.1:


I am unsure if this is what you're looking for and if you want to refer to the timestamp of each event in terms of a metric, but if you select Synthetic sessions in the top of a browser monitor, this will show all recorded synthetic sessions like this.   If you select one, you get the timing of each synthetic event. Is this what you are looking for?

	A Dynatrace Professional nerd working for Eviden


----------------
121.2:

@marina_pollehn,Yes, thanks! Was concentrating on the screen that has the events / screenshots, and totally forgot about the session data!Going to put in a Product Idea so that for each measurement there can be a link to the session.Edited: Product Idea here: https://community.dynatrace.com/t5/Product-ideas/Link-from-a-Synthetic-measurement-to-the-correspond...

	Antonio Sousa


----------------
122:

I'm seeking a DQL query that provides detailed insights into log ingest. Currently, without Grail, we can observe log volume based on the number of log lines. However, Grail measures logs by size. Although the default Grail UI displays the previous log lines count, I'm interested in a DQL query that offers log ingest information based on size. Additionally, I'd like the query to break down the data by log.source and dt.process.name so that I can gain a comprehensive understanding of my sources in relation to their respective sizes.
In my opinion, I believe that since Grail now considers the size of logs, enhancing the UI to display both volume/lines and size would be a valuable improvement.

----------------
122.1:

@GregOReilly Your last paragraph sounds like a great RFE. I am still quite new to Grail but maybe our other community members that have more experience in Grail can lend you a hand with formulating the query 

	-Chad


----------------
122.2:

I tried to figure out any way to get log size distribution, but there are no good options. You can get the events count, but not the size - there is no direct correlation between the number of events and total size as the sources differ.The only way to actually see the size is to check the small info button: But using this method, to get a distribution of log sizes by log source, we will have to query the data for a large period for a particular log source, and write it down. Then query the next log source, and write it down, etc. This is nuts! It won't show anomalies in sizes over some days, and if we need to split even further (by pod/container/etc/error level) - again run 1 query at a time and write it down.  There isn't a single command or function that would actually return the size. It seems like it is intentionally hidden, as obviously the size is known (see above) + there is a parameter limiting the amount of data to fetch: Anyone got any ideas how to gather the stats? It is important for license management and keeping the sizes in check

----------------
123:

The new UI is horrible. I don't know how else to describe the functionality removed by the new search. I cannot search for anything without knowing exactly what it is. In the past using this to find groups of things quickly or candidates for troubleshooting sequences or threshold adjusting. At this point if I know the name of the host I can put the name in search and get no results.  I can't type host:hostname as per instructions in documentation and nothing. I have to type:'>' then type "host" THEN type the 'hostname' to find a single host.  how does this add anything to my experience?  Why wouldn't I just go to hosts then find the host, there?Please fix.  I really used the ability to open search text in the entire tenant. I find the inability to use it a very strong negative in recommending this product. Thanks,

----------------
123.1:

This is a very spot-on description of the new search.If you know exactly where to find something and what it is called - then you might 'find' it - but then - why even bother to search? Some stuff is still not searchable and you are better off just clicking by guessing than using the search.You really need to work on this - a lot.If it ain't broke don't fix it. 

----------------
123.2:

Hi Nathan, thanks for your feedback! We're aware about the need to "simply search for hosts" or similarly prominent artifacts. We're do plan to improve the current search experience for entities in Grail and we'll provide further details, once an update is available.

----------------
123.3:

For many people at my company, we used the old search quite religiously for learning - finding things in Dynatrace we never knew existed there before. Maybe we know a service name (or part of one). Maybe we know the prefix to a host name, but nothing more. The old search was like one-click to Universal Searching Awesomeness.I have lots of folks that are avoiding switching to the new GUI simply because they miss/love the old search.

----------------
123.4:

Hi all. Thanks for the feedback. We're aware of the limitations you're facing, and are working on improving the experience. It seems like most of the feedback is about searching across multiple entity types simultaneously. In the meantime, while we're working on improvements, I recommend typing ">" followed by "Entities" to search across a selection of common entities. We have similar 'umbrella' categories for "Kubernetes" and "Applications". If there is a need for additional 'umbrella' categories – please provide feedback on those that would be most useful to you.
 
@uhh you mention that "Some stuff is still not searchable" – can you please provide some details on which categories/sources are missing, and I can confirm if these are on the roadmap. 
 
@nathan_tennant you're right, the docs were outdated. They should be fixed now. 

----------------
124:

Hi friends
I want a Dashboard where I can see the list of processes under the host, please help me
thanks



					
						Solved!
					
					Go to Solution.




----------------
124.1:


Hi,You can use the Table tile on the dashboard and, once you have selected the correct measure, split it by host name or host group:  

	Have a nice day!


----------------
124.2:

Thank you so much, man. Very lucky and happy to see you again.  

----------------
124.3:

You're welcome 

	Have a nice day!


----------------
124.4:


Here is another way looking for process that starts with admin:builtin:tech.generic.mem.usage:filter(and(or(in("dt.entity.process_group_instance",entitySelector("type(process_group_instance),entityName.startsWith(~"admin~")"))))) :parents:splitBy("dt.entity.process_group_instance","dt.entity.host"):sort(value(auto,descending)):limit(100)   

	Dynatrace Certified Professional


----------------
124.5:

Hi, friend.This is really good.

----------------
125:

I'm studying a little about Notebooks, SRG and Workflow. I'm using EasyTravel as a test.
I would like to know if it is possible to extract the number of errors 400 and errors 500. And if it is possible to have information on how many of these errors were at checkout.

----------------
125.1:

Hey WellPP,Maybe someone else has a solution but I cannot find one at the moment with DQL. Metrics on Grail is not quite GA so there are a lot of missing metrics. For a full list of available ones, you can find that here: Built-in metrics on Grail | Dynatrace DocsUsing the classic metric selector, to do what you're looking for I'd make the request associated with checking out a key request which would allow you to graph the errors using the following metric keys.builtin:service.keyRequest.errors.fourxx.countbuiltin:service.keyRequest.errors.fourxx.ratebuiltin:service.keyRequest.errors.fivexx.countbuiltin:service.keyRequest.errors.fivexx.rateAlso regarding SRG, it supports SLOs which support the classic metric selector.Hope this helps!

----------------
126:

Hello,I saw on the databricks monitoring configuration that it gave 2 examples for what you could put into the Dynatrace url.https://{environmentid}.apps.dynatrace.comWould that mean that the correct Dynatrace URL would be https://{environmentid}.apps.dynatrace.com? Thanks for the assistance

----------------
126.1:

Hi @danielD I can see these two examples. Fist is the Saas, the second is the Managed format.https://{your-environment-id}.live.dynatrace.com or https://{your-domain}/e/{your-environment-id}I think the first could be https://{your-environment-id}.apps.dynatrace.com in case of SaaS with the new look.Best regards,Mizső

	Certified Dynatrace Professional


----------------
127:

@everyone
Do you want a playground or want to look at the new UI?  Dynatrace has created a tenant for everyone to access so you can see all the new features of Grail/UI.  Hope all enjoy.
Link: https://wkf10640.apps.dynatrace.com/ui/
 
This was introduced in below.
What's New in Dynatrace - August 2023 (v271, v272)
https://www.youtube.com/watch?v=UMEI_MO_1Eo

	Dynatrace Certified Professional


----------------
127.1:

Thanks for sharing @Kenny_Gillette 

	The true delight is in the finding out rather than in the knowing.


----------------
127.2:

Thanks Kenny! This is good info to have on hand. 

----------------
128:

useful tip for using Dynatrace effectively to monitor and troubleshoot your applications:**Tip: Set Up Custom Alerts for Critical Business Transactions**While Dynatrace provides automatic anomaly detection and alerting for various metrics, it's essential to create custom alerts for your critical business transactions. These are the transactions that directly impact your business's success, such as user registration, checkout processes, or specific API calls.Here's how to set up custom alerts for critical business transactions:1. **Identify Critical Transactions:** Determine which transactions are vital for your business. These might be revenue-generating transactions, user engagement actions, or any other key performance indicators.2. **Define Custom Thresholds:** Custom thresholds allow you to set specific performance criteria for each critical transaction. For example, you might set a threshold for response time, error rate, or throughput.3. **Configure Alerting:** In the Dynatrace dashboard, go to the "Alerting" section and create custom alerts for your critical transactions. Set up alerts based on your defined thresholds. You can configure notifications via email, Slack, or other channels.4. **Include Contextual Information:** When creating alerts, consider adding contextual information, such as the affected application, service, or user impact. This helps your team understand the urgency and context of the alert.5. **Test and Refine:** After setting up alerts, perform testing to ensure they trigger when expected. Tweak the thresholds if necessary to strike a balance between avoiding false alarms and catching critical issues.6. **Collaborate and Automate:** Ensure that relevant team members are notified when critical alerts are triggered. Consider integrating alert notifications with your incident management and collaboration tools for seamless incident response.By setting up custom alerts for your critical business transactions, you can proactively identify and address performance issues before they impact your users and business operations. This helps you maintain a high level of application reliability and user satisfaction.

	Dynatrace Professional Certified


----------------
128.1:

Thank you!

	Have a nice day!


----------------
128.2:

These are some good tips, cheers. 

----------------
129:

JMeter integration consume DDU?

	Dynatrace Professional Certified




					
						Solved!
					
					Go to Solution.




----------------
129.1:


Hi @natanael_mendes I think if you push back events or metrics about the tests via DT API endpoints the answer is yes. Dynatrace and load testing tools integration | Dynatrace DocsOtherwise if you use only request attributes for analyse the tests I thnik the answer is no, becasue there is not any external data ingestion to DT.Dynatrace and JMeter integration | Dynatrace DocsI hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
130:

I want to know is there any feature in Dynatrace that allows to apply threshold settings for CPU consumption for a  Process. 



					
						Solved!
					
					Go to Solution.




----------------
130.1:

You can do this on the host level Take a look on the documentation pagehttps://www.dynatrace.com/support/help/platform-modules/infrastructure-monitoring/hosts/configuratio... go to host>settings>anomaly detection

	Dynatrace Professional Certified


----------------
130.2:


If you are looking to impose an alert criteria on a process that runs on a host and alert on the process consumption outside of the host overall consumption, it can be done via Custom Metric Events:  go to settings>anomaly detection>Metric Events - and add one in  

	-Chad


----------------
130.3:

hi Chad, i have setup'd Custom Metric Events, to generate alerts for generic.cpu.totalTime , but i'm observing the alerts are raised for the The Process total CPU time value of 0 µs.i have applied Static threshold of 14Mins, still the alert are raised for The Process total CPU time value of 0 µs was above your custom threshold of 14 min.Can you advise, what settings or attributes can be configured to alert only when the CPU time cross the threshold 

----------------
130.4:

Can you share a screen shot of the metric event you created? It should look something like this:   

	-Chad


----------------
130.5:

please see the snaps attached

----------------
130.6:

Sorry for the delay, been pretty busy today. The reason why you are being alerted even at the 0 Upsidedow "h"s is because you have selected to be alerted on missing data. I suspect that there is occasionally a delay in the metrics being passed for example its looking for data every 1 min, 8:00 data arrives, 8:01 no data, 8:02 no data - At this point an alert is triggered, 8:03 current data and missing data from 8:01 and 8:02 shows up, giving you the illusion there was no gap in data but there was. Turn off the alert on missing data and see if your problems go away. 

	-Chad


----------------
131:

Team,Has anybody else seen that Dynatrace started monitoring UNC shares and alerting on it?  I looked through release notes and have not found anything (could have missed).  Our Product Specialist noticed this also started for another customer he is supporting at same time as it did for me.  Started around mid June.  I know how to filter out Unc shares by disk: \\* but just curious why Dynatrace started doing this.  This hurting other people? From DT Chat: now that you have mentioned it, one of my other customers had the same thing happening too. 

	Dynatrace Certified Professional




					
						Solved!
					
					Go to Solution.




----------------
131.1:


From support:Based on feedback from our lab, this was the timeline of changes, and indeed some changes would have affected your cluster version: Before OA 1.267, network drives were not monitored on Windows.In OA 1.267, Windows network disk monitoring has been introduced. That's why the network share metrics are showing up.As soon as that version was rolled out to our customers, we discovered that the implementation was causing multiple problems, so we decided to disable it again with a debug flag temporarily.We made multiple improvements, and the whole feature will be reenabled in OA 1.277. We hope this helps explain the situation. Going forward, if you do not want to have network drives monitoring, we can disable it by setting a debug flag. Alternatively, you can update OneAgent to a newer 1.267/1.271/1.273/1.275 version that just sets it by default. Please let us know which route you'd prefer to take, and if there are any questions.

	Dynatrace Certified Professional


----------------
132:

Hi all, I have a simple question, but it seems to be complicated at the same timeI am simply looking to show the status UP or down for my process or process group but not baised on availability % a simple tile, not a pourcentage Regards 

----------------
132.1:

Question for clarification here on this - what exactly do you mean by up or down? There are a couple of visualizations that are available OOB from the classic dashboards. If you can describe what visualization you're looking for, we could look for a solution from there.  In terms of if a status is UP or DOWN, that could also depend on what you categorize as up or down for your specific environment (percentage of availability that classifies it as such).  For now, linking this here to look into: https://www.dynatrace.com/support/help/shortlink/available-tiles#visualization-types

----------------
133:

Endlich ist es soweit:
Nach langem Warten und Homeofficezeiten hosten wir das 1. deutschsprachige Usergroup-Treffen. Ich würde mich freuen, wenn viele von Euch kommen könnten, damit wir die Themen, die uns alle bewegen einmal diskutieren und uns Gedanken machen, wie wir in Zukunft Usergroup-Treffen organisieren und veranstalten.
Anbei der offizielle Einladungstext:
 
Dynatrace User Group Donnerstag, 12. Oktober 2023 | 10:00 - 19:00 Uhr Atruvia Campus, Karlsruhe
 
Folgende Themen erwarten Sie:• Vorstellung der Usergroup, gemeinsames Kennenlernen• Impulsvortrag: Was bringt uns Grail für die Datenanalyse und -management?• Impulsvortrag: Aktueller Stand Application Security• Impulsvortrag: Wie können wir die ACE-Services von Dynatrace nutzen?• Austausch in kleinen Gruppen zu dynamisch gewählten Themen
Unser Usergrouptreffen soll Ihnen die Gelegenheit bieten, wertvolle Kontakte zu knüpfen, Ihr Wissen zu erweitern und insbesondere Ideen mit Usern anderen Unternehmen auszutauschen. Und selbstverständlich stehen Ihnen auch unsere Experten für Fragen zur Verfügung.
Das Networking steht hier stets im Fokus.
Nach den Impulsvorträgen haben Sie bei einer Leitstandführung die Möglichkeit hinter die Kulissen der Atruvia schauen zu können.
Und mit einem gemütlichen Get-Together runden wir die Veranstaltung ab.
Die Platzzahl ist beschränkt, sichern Sie sich also schnell Ihren Platz, und melden Sie sich hier an.
Hier anmelden

----------------
133.1:

Hi,Leider kann ich dieses Mal nicht teilnehmen. Ich komme die Nacht vor dem Treffen aus dem Urlaub zurück und 6 Stunden Fahrt sind dann nicht mehr drin :(. Wird so ein Treffen öfters stattfinden? Eventuell auch in der Norddeutschen oder Westdeutschen Region? Ich finde das Treffen wirklich eine tolle Initiative. 

	A Dynatrace Professional nerd working for Eviden


----------------
133.2:

Hi,
wir werden uns bei dem ersten Treffen die Karten legen, wie wir weitere Usergroup-Treffen organisieren. Mal schauen, was der 12.10. an weiteren Ideen und Vorschlägen mit sich bringt. Gern informiere ich Dich danach bilateral über das Ergebnis und das weitere Vorgehen.

----------------
134:

Hi ,I have installed the EasyTravel Application in Linux AWS VM and the application is running fine. I have started the application from UI and it's generating the backend Traffic(APM) but Frontend Traffic (RUM) is not generating. In  easyTravelConfig.properties for config.apacheWebServerHost & config.apacheWebServerB2bHost values have been updated with my PublicIP address also tried with localhost. Also monitoring for com.dynatrace.easytravel.weblauncher.jar easytravel-*-x* has been disabled.  
In Business2Business Frontend (.NET) it shows the value as N/A.  How can we fix this issue? 



					
						Solved!
					
					Go to Solution.




----------------
134.1:


Hi @MSK Its look like your esayTravel is not connected to your tenant as it shows dynatrace  At least with windows installation, If it is connected it should show your environment version  I would recheck the settings in easyTravelConfig.properties to ensure the connection  HTHYos 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
134.2:

@Yosi_Neuman , Thanks for your response. I have updated the config files as suggested do we need to add the token as well? config.apmTenantToken?If yes what capabilities this token should have.  
config.apmServerProtocol=https://{environmentid}=live.dynatrace.comconfig.apmServerWebPort=443config.apmServerPort=443config.apmServerWebURL=https://{environmentid}/live.dynatrace.com config.apmTenant=<abc1234>config.apmTenantToken=?

----------------
134.3:

HI @MSK You do not need to set the APM part, just the dynaTrace one.This is how  easyTravelConfig.properties looks at my installation  HTHYos 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
134.4:

Hi @Yosi_Neuman , I have updated the dynatrace configuration as below .. still the real user traffic is not getting generated.    

----------------
134.5:

Ammmm, @MSK do you see any errors on the log file of weblauncher.sh ?  

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
135:

Hi,  We have installed many extensions 2.0 on Dynatrace console and on the AG server and we want to know how we will be able to maintain the life cycle of these extension automatically without any manual action. Does extensions are updated in their new version during the update of the AG or does it need other action for that? (like download the new zip on Dynatrace console and on the server also manually). 

----------------
135.1:

If, as your post mentions, this is just about extensions 2.0 in Dynatrace, you just need to update the extension and its related activations in the Dynatrace UI, the new version is downloaded from the cluster automatically by the ActiveGate or OneAgent and you don't need to worry about that part of the process. These two buttons on the UI are enough, which you can also trigger via the API for further automation. 

----------------
136:

I have an application (sadly it is a thick java client in Citrix) that talks to a UniVerse data store - does anyone know if Dynatrace can monitor this?  

----------------
136.1:

i think yes, cause dynatrace can monitor all dependencies across your environment. but if no, you can create a custom service or a custom extension. Take a look on these documentation pages https://www.dynatrace.com/support/help/platform-modules/applications-and-microservices/services/serv... https://www.dynatrace.com/support/help/extend-dynatrace/extensions

	Dynatrace Professional Certified


----------------
137:

Hello, Is there any way to compare my knowledge about Dynatrace before giving the actual exam?If you have link for MOCK test, could you please share the link for me to test my knowledge before actual exam.Do you have the DOC for Q/A for Dynatrace ex 

----------------
137.1:

You can find a test exam and training materials in the Preparation tab of the Associate Certification in Dynatrace University: From my own experience, practice is your best ally. If you have access to a Dynatrace environment where to try things out, just try out all of the settings in Dynatrace and understand how they work. Also, just take some time to read through the Dynatrace Help pages to see everything that is doable with the product. 

----------------
137.2:

I totally agree with @victor_balbuena .If you have time and any demo \ Free trial environment the best option to deploy simple application with classic tiers ( web - app - db) and have Hands-On.Your own experience and practice will immediately remove any complexity from 75% of the questions.The exam itself is very simple if you have worked enough with the product.Good luck on the exam!Alex Romanenkov

	DT_NGINX_ALL_WHITELISTED=1


----------------
137.3:

Hello,i don't have full access for Dynatrace Demo trial Community/university please let me know, how can i get full access , please suggest or help me to get it 

----------------
137.4:

Ideally, you should set up a ticket used the Univesity request type and describe your problem. https://support.dynatrace.com/

	Have a nice day!


----------------
137.5:

You should be able to get a Dynatrace SaaS environment trial through dynatrace.com, if you haven't used it up already: If you have access to demo, it's still worth checking all the settings and see what they do, even if you can't create/modify them. 

----------------
137.6:

Hello, I have created and using but I am unable to change and modify them, please help me,Please check screen attached

----------------
137.7:

You probably need to give yourself permissions, then. Which is a good first thing to learn towards the Associate exam On the bottom left of your screen, go to Account Management, choose your Dynatrace account, and on the top bar, choose Identity Access and Management -> People. On this new section, click on the triple dot on the right for your user, and choose to Edit user. Make sure to select all the groups needed, but Monitoring Admin should be enough: Save, give it a couple of minutes, and see if that solves the issue. More about user permissions here: https://www.dynatrace.com/support/help/managed-cluster/users-and-groups-setup/user-groups-and-permis...

----------------
137.8:

Hello,I am unable to find settings, please help me. please refer attached snap.  

----------------
138:

Hi. Iḿ trying to install easytravel app on Ubuntu 20.04 VM and It is not starting. I got some errors: 
 
vagrant@ubuntu:~/easytravel/easytravel-2.0.0-x64/weblauncher$ ./weblauncher.shFeb 02, 2022 6:54:55 PM com.dynatrace.diagnostics.uemload.utils.RentalCarsGenerator generateUserFileINFO: Creating files with Rental Cars.Feb 02, 2022 6:54:55 PM com.dynatrace.easytravel.spring.PluginNotificationConfigFileGenerator generateConfigFileINFO: Creating pluginNotificationConfig.json file.2022-02-02 18:54:55 WebLaunche INFO [Init] -----------------------------------------------------------------------------2022-02-02 18:54:55 WebLaunche INFO [Init] easyTravel Demo Application - Copyright (C) 2010-2022 dynaTrace software GmbH2022-02-02 18:54:55 WebLaunche INFO [Init] -----------------------------------------------------------------------------2022-02-02 18:54:55 WebLaunche INFO [Init] Procedure: WebLauncher2022-02-02 18:54:55 WebLaunche INFO [Init] Version: 2.0.0.33732022-02-02 18:54:55 WebLaunche INFO [Init] Build Date: Fri Jan 21 09:38:55 BRT 20222022-02-02 18:54:55 WebLaunche INFO [Init] Platform: Linux 5.4.0-96-generic, amd642022-02-02 18:54:55 WebLaunche WARN [PluginFinder] Specified classpath directory 'C:\Program Files\IBM\WebSphere MQ\java\lib' not found or is not a directory.WARNING: An illegal reflective access operation has occurredWARNING: Illegal reflective access by org.apache.catalina.loader.WebappClassLoaderBase$1 (file:/home/vagrant/easytravel/easytravel-2.0.0-x64/lib/catalina.jar) to method java.lang.ClassLoader.registerAsParallelCapable()WARNING: Please consider reporting this to the maintainers of org.apache.catalina.loader.WebappClassLoaderBase$1WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operationsWARNING: All illegal access operations will be denied in a future release2022-02-02 18:54:57 WebLaunche WARN [DocumentStarter] Exception occurred while opening URL: http://localhost:8094/ . Exception: Cannot run program "firefox": error=2, No such file or directory^CStopping HTTP Service Thread and Engine because scenario is not executing any more or a shutdown request was received.Checking Linux headless processes are not left in memorylooking for[/home/vagrant/easytravel/easytravel-2.0.0-x64/weblauncher/../chrome/chromium-browser]or [/home/vagrant/easytravel/easytravel-2.0.0-x64/chrome/chromium-browser]]or [/home/vagrant/easytravel/easytravel-2.0.0-x64/weblauncher/../chrome/driver/chromedriver_linux64]]or [/home/vagrant/easytravel/easytravel-2.0.0-x64/chrome/driver/chromedriver_linux64]Linux Process check completeKilling Chrome processes finished
 
 
Why Linux app is mapping paths from Windows like this one: 
022-02-02 18:54:55 WebLaunche WARN [PluginFinder] Specified classpath directory 'C:\Program Files\IBM\WebSphere MQ\java\lib' not found or is not a directory.
 
I installed java 11. It is not well explained what dependencies it needs. Can someone installed it on Ubuntu 20.04? 



					
						Solved!
					
					Go to Solution.




----------------
138.1:

Why I got this error:  2022-02-02 19:06:29 WebLaunche WARN [DocumentStarter] Exception occurred while opening URL: http://localhost:8094/. Exception: Cannot run program "firefox": error=2, No such file or directory

----------------
138.2:

Hi EveryoneI had the same error: "WebLaunche WARN [DocumentStarter] Exception occurred while opening URL: http://localhost:8094/. Exception: Cannot run program "firefox": error=2, No such file or directory"My Fix:I figured that firefox was not install on my VM. I ran "yum install firefox" (as root) then relaunched my weblauncher "./weblauncher.sh" and the error stopped popping up. Hope that helps

----------------
138.3:

Hello,I have installed the Easy travel app in windows 10 but i can't find the link for Dynatrace .exe file for download and install, could you please share link for me to download and use. 

----------------
138.4:


It worked. 

----------------
138.5:

May you explain how you did it? im having the same issues: sudo ./weblauncher.sh[sudo] senha para mardata:fev 11, 2022 10:55:45 DA MANHÃ com.dynatrace.diagnostics.uemload.utils.RentalCarsGenerator generateUserFileINFO: Creating files with Rental Cars.fev 11, 2022 10:55:45 DA MANHÃ com.dynatrace.easytravel.spring.PluginNotificationConfigFileGenerator generateConfigFileINFO: Creating pluginNotificationConfig.json file.2022-02-11 10:55:46 WebLaunche INFO [Init] -----------------------------------------------------------------------------2022-02-11 10:55:46 WebLaunche INFO [Init] easyTravel Demo Application - Copyright (C) 2010-2022 dynaTrace software GmbH2022-02-11 10:55:46 WebLaunche INFO [Init] -----------------------------------------------------------------------------2022-02-11 10:55:46 WebLaunche INFO [Init] Procedure: WebLauncher2022-02-11 10:55:46 WebLaunche INFO [Init] Version: 2.0.0.33732022-02-11 10:55:46 WebLaunche INFO [Init] Build Date: Fri Jan 21 09:38:55 WAT 20222022-02-11 10:55:46 WebLaunche INFO [Init] Platform: Linux 5.13.0-28-generic, amd642022-02-11 10:55:47 WebLaunche WARN [PluginFinder] Specified classpath directory 'C:\Program Files\IBM\WebSphere MQ\java\lib' not found or is not a directory.WARNING: An illegal reflective access operation has occurredWARNING: Illegal reflective access by org.apache.catalina.loader.WebappClassLoaderBase$1 (file:/home/mardata/easytravel-2.0.0-x64/lib/catalina.jar) to method java.lang.ClassLoader.registerAsParallelCapable()WARNING: Please consider reporting this to the maintainers of org.apache.catalina.loader.WebappClassLoaderBase$1WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operationsWARNING: All illegal access operations will be denied in a future release     ^CStopping HTTP Service Thread and Engine because scenario is not executing any more or a shutdown request was received.Checking Linux headless processes are not left in memorylooking for[/home/mardata/easytravel-2.0.0-x64/weblauncher/../chrome/chromium-browser]or [/home/mardata/easytravel-2.0.0-x64/chrome/chromium-browser]]or [/home/mardata/easytravel-2.0.0-x64/weblauncher/../chrome/driver/chromedriver_linux64]]or [/home/mardata/easytravel-2.0.0-x64/chrome/driver/chromedriver_linux64]Linux Process check completeKilling Chrome processes finished

----------------
138.6:


Try to remove extracted folder and repeat installation again. I am getting problem on "credit card C app whatever" complaining about one lost log. I removed app folder and extracted again and it works.   

----------------
138.7:

I removed extracted folder and repeat installation, and same problem: ./runEasyTravel.shstarting easyTravel===================OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.2022-02-11 16:09:33 Launcher INFO [Init] -----------------------------------------------------------------------------2022-02-11 16:09:33 Launcher INFO [Init] easyTravel Demo Application - Copyright (C) 2010-2022 dynaTrace software GmbH2022-02-11 16:09:33 Launcher INFO [Init] -----------------------------------------------------------------------------2022-02-11 16:09:33 Launcher INFO [Init] Procedure: Launcher2022-02-11 16:09:33 Launcher INFO [Init] Version: 2.0.0.33732022-02-11 16:09:33 Launcher INFO [Init] Build Date: Fri Jan 21 09:38:55 WAT 20222022-02-11 16:09:33 Launcher INFO [Init] Platform: Linux 5.13.0-28-generic, amd64Unable to init server: impossível ligar: Ligação recusadaException in thread "main" org.eclipse.swt.SWTError: No more handles [gtk_init_check() failed]at org.eclipse.swt.SWT.error(SWT.java:4725)at org.eclipse.swt.widgets.Display.createDisplay(Display.java:1040)at org.eclipse.swt.widgets.Display.create(Display.java:1020)at org.eclipse.swt.graphics.Device.<init>(Device.java:175)at org.eclipse.swt.widgets.Display.<init>(Display.java:586)at org.eclipse.swt.widgets.Display.<init>(Display.java:577)at com.dynatrace.easytravel.launcher.LauncherUI.init(LauncherUI.java:74)at com.dynatrace.easytravel.launcher.Launcher.run(Launcher.java:194)at com.dynatrace.easytravel.launcher.Launcher.main(Launcher.java:159)Stopping Engine because shutdown request was received.Checking Linux headless processes are not left in memorylooking for[/home/mardata/easytravel-2.0.0-x64/chrome/chromium-browser]or [/home/mardata/easytravel-2.0.0-x64/chrome/chromium-browser]]or [/home/mardata/easytravel-2.0.0-x64/chrome/driver/chromedriver_linux64]]or [/home/mardata/easytravel-2.0.0-x64/chrome/driver/chromedriver_linux64]Linux Process check completeKilling Chrome processes finished

----------------
138.8:


you must run linux app using sudo ./weblauncher.sh.Locate this script in webapp folder.  chmod a+x sudo weblauncher.shsudo ./weblauncher.sh

----------------
138.9:

Hi Sir ,I run sudo ./weblauncher.shand still run into the same issue .First of all why does it look for Websphere in my local (C:\Program Files\IBM\WebSphere MQ\java\lib) . Please see the exception below . (Note :I have installed the EasyTravel on Ubuntu 20 linux ). Appreciate your help. Thanks 2023-02-17 18:51:02 WebLaunche WARN [PluginFinder] Specified classpath directory 'C:\Program Files\IBM\WebSphere MQ\java\lib' not found or is not a directory.WARNING: An illegal reflective access operation has occurredWARNING: Illegal reflective access by org.apache.catalina.loader.WebappClassLoaderBase$1 (file:/home/ubuntu/easyTravel/easytravel-2.0.0-x64/lib/catalina.jar) to method java.lang.ClassLoader.registerAsParallelCapable()WARNING: Please consider reporting this to the maintainers of org.apache.catalina.loader.WebappClassLoaderBase$1WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operationsWARNING: All illegal access operations will be denied in a future release2023-02-17 18:51:05 WebLaunche WARN [DocumentStarter] Exception occurred while opening URL: http://localhost:8094/. Exception: Cannot run program "firefox": error=2, No such file or directory  

----------------
139:

I tried to work the easytravel app in the VM of Azure (ubuntu 20.04), but after installation, the below status appeared and it does not work the function of credit auth.  So, I checked the logs, it is the error message in the console log below  



					
						Solved!
					
					Go to Solution.




----------------
139.1:

Hello,You need to check the permissions on the VM, seems that the web launcher can't execute the creditcardauthorize process. Thanks,Islam

	Dynatrace Certified Professional - Dynatrace Partner - Yourcompass.ca


----------------
139.2:

Thanks! I tried to install it as root, executed successfully.

----------------
139.3:

Great 

	Have a nice day!


----------------
139.4:


I recommend using ET with root rights (then you will avoid such situations) - unfortunately this software is quite unreliable and generates a large number of problems.

	Have a nice day!


----------------
139.5:

Thanks! I tried as you suggested and was able to successfully run ET.

----------------
139.6:


Hi DXC_Yoshi,
Is the same user (azureuser) is used to install and run easyTravel? easyTravel should not be installed & run as root.
It may help if you send a listing from the easyTravel installation directory (/home/azureuser/app/easytravel/easytravel-2.0.0-x64) containing file owners and permissions.

----------------
139.7:

Thanks to your answer, my problem is solved.

----------------
140:

Is it possible for two OneAgents to coexist on one host?We have a customer that has Tenant A and a Tenant B was created for them.The customer requires that the servers that are viewed on Tenant A, be viewed on Tenant B.Is it possible to install a second agent on those servers, or is there an alternative to migrate all that data to the other tenant?Thanks in advance



					
						Solved!
					
					Go to Solution.




----------------
140.1:


Two OneAgents on one host is not possible.

	Antonio Sousa


----------------
140.2:

I (and @MartijnA) wonder: on Linux (where suchs things are possible), what will happen if you install a second agent in another path. My hypothesis (not tested) is, that the 2nd install does not spot the 1st install nor its configuration, and will come a long way. It's the things like service (start) name configuration and watchdog part where things will become complicated.Bottom line, kids do no try this at home 

	Kind regards, Frans Stekelenburg                 Certified Dynatrace Associate | measure.works, Dynatrace Partner


----------------
140.3:

Hi @soportetr,it's not possible to install two OneAgents on the same host, however, you can use oneagentctl and in your case, you will be using OneAgent communication settingsthe following is an example:Linux or AIX:./oneagentctl --set-server=https://my-server.com:443 --set-tenant=abc123456 --set-tenant-token=abcdefg123456790 --set-network-zone=<network-zone> --set-host-group=<host-group> --restart-serviceWindows:.\oneagentctl.exe --set-server=https://my-server.com:443 --set-tenant=abc123456 --set-tenant-token=abcdefg123456790 --set-network-zone=<network-zone> --set-host-group=<host-group> --restart-servicenote: you need to restart the monitored processes and based on a case that I have faced, I think it will be recommended to restart the server.

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
140.4:

Hi,I agree with @Mohamed_Hamdy last comment of restart of server. I too faced this; and recommend restarting the server. note: you need to restart the monitored processes and based on a case that I have faced, I think it will be recommended to restart the server.

----------------
141:

Hi Everyone, Will there be a possibility that Dynatrace can automate the reboot of a server remotely using workflow? If possible, could you show me some didactic materials to be able to learn it? Thanks in advance



					
						Solved!
					
					Go to Solution.




----------------
141.1:


This will be possible, but you will need to integrate Dynatrace with some other automation tool like Jenkins. Basically, the workflow will be triggered by any of the available tirggers, like CPU usage passing a specific threshold, and it will send a request to a Jenkins endpoint that will trigger the restart of the server - Dynatrace will not be able to restart the sever itself.You can learn more about workflows here:https://www.dynatrace.com/support/help/platform-modules/cloud-automation/workflowshttps://developer.dynatrace.com/develop/workflows/

----------------
142:

I am trying to get the one agent host configuration via GET API call. but I am getting below error."Token is missing required scope. Use one of: ReadConfig (Read configuration), Davis (Dynatrace module integration - DaHow to get the required scope. please suggest steps.



					
						Solved!
					
					Go to Solution.




----------------
142.1:


Hi @PrateekGupta I hope it helps: Best regards,Mizső

	Certified Dynatrace Professional


----------------
143:

Hi All, can someone suggest this query to me.
 
We are doing Kubernetes installation for that we have done port opening from application pods to our cloud based Azure and GCP AG and post when we try to install the activegate-pods is trying to connect to our cluster node which are on-prem server through port 443 but gets fail to connect.
 
We had done Port opening from AG to Cluster node on 9998 port unidirectional. But we haven't done any port opening from the cluster node to our AG.
 
So questions are here do we need to port the opening from the Cluster node to AG on 443 port ?

----------------
143.1:

Sorry need to upgrade small mistake we had done Port opening from AG to Cluster node on 443 not for 9998 wrongly posted.

----------------
143.2:

Hi @Siddhesh9,is it possible to provide us with the error or the logs, if this is not possible, I do recommend opening a support ticket and the logs and other details related to the issue.https://support.dynatrace.com/

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
144:

I am trying to join two tables. dt.entity.service and "Davis problem events". I believe the syntax is correct, and I am not seeing any errors. However, the following DQL shows that there are no matching services. Which sounds incorrect. Am I missing something?fetch events, from:now()-24h, to:now()
| filter event.kind == "DAVIS_PROBLEM"
| fields event.start, event.end, display_id, event.category, event.name, affected_entity_ids, root_cause_entity_id, event.status, resolved_problem_duration
| sort event.start desc
| lookup [fetch dt.entity.service],sourceField:affected_entity_ids,lookupField:id
| summarize count=count(), by:{lookup.entity.name}   



					
						Solved!
					
					Go to Solution.




----------------
144.1:


The issue is coming from different data types: the source field "affected_entity_ids" is an array, while the lookup field "id" is a string. The quickest fix here would be to use "expand" to break down the array, e.g: 
fetch events, from:now()-24h, to:now()
| filter event.kind == "DAVIS_PROBLEM"
| fields event.start, event.end, display_id, event.category, event.name, affected_entity_ids, root_cause_entity_id, event.status, resolved_problem_duration
| expand affected_entity_ids
| lookup [fetch dt.entity.service], sourceField:affected_entity_ids, lookupField: id

	I had a life once. Then I bought my first computer ...


----------------
145:

Dynatrace discontinues support for the Chrome and MS Edge browser extension by January 2024 as remotely hosted code will no longer be allowed for those browsers.
 
The SaaS vendor RUM browser extension will soon no longer be hosted in the Chrome store as remotely hosted code is being disallowed by Google. As a result, the JS Agent will no longer pass the Chrome store review process. By January 2024, browser extensions cannot be used and will be deleted from the Chrome store. However, Dynatrace has solutions available for customers on a case-by-case basis. 
Read more:1. Overview2. What it means to our customers 3. Timeline 4. Alternative Solutions 
- - -1. Overview 
One of the consequences of the rollout of Manifest Version 3 for Chrome and Microsoft Edge  extensions is that remotely hosted code will no longer be allowed. An extension will only be able to execute JavaScript that is included within its own package. Because we inject the JS Agent into the customer’s page, and it’s not bundled with the browser extension, we will not pass the Chrome store review process beyond June 2023. Even if we were to bundle the JS Agent within the extension, it would most likely not be approved because we are using some functions that will not be allowed. - - -2. What it means to our customers 
This means that we will have to discontinue support for the extension and the customers who use our browser extension to inject data will not be able to do so any longer; the full sunset is in January 2024.   
- - -3. Timeline 
As of the first release of MV3 from Google in January 2023, Dynatrace can no longer update the extension. However, it will still function in the stable versions of Chrome but might be rejected in dev/beta/canary versions.   
In June 2023, the extension might also be rejected in stable Chrome versions, but the customers can disable the rejections for both of these scenarios with an Enterprise policy.  
Finally, in January 2024, the extension will no longer be usable even with an Enterprise policy, and all V2 extensions will be deleted from the Chrome store. 
 
- - -4. Alternative Solutions  
Depending on the type of customer application (e.g. Salesforce, Office 365 etc.), there might be other options such as Agentless monitoring with manual injection. We are aware that this solution might not work for all customers, and we’d have to look at applications on a case-by-case basis to see if there are other alternatives. For example, for Salesforce, we also have the option of using the Salesforce Streaming API. 
 

 When passion meets people magic and innovation happen. 


----------------
145.1:

Thank you @AgataWlodarczyk for this Notice

	-Chad


----------------
145.2:

If there's one thing you can count on, it's google discontinuing something 

----------------
145.3:

can we put this link in the documentation as well.

----------------
145.4:

It's a sad news as we just enabled RUM browser extension monitoring. The timeline section  motioned about Google Chrome only.  Will it apply to MS Edge as well? is Edge a better choice from now on to Jan., 2024? Will MS Edge continue to support RUM extension?

----------------
145.5:

The announcement is for both Chrome and Edge.

----------------
145.6:

This is a big ouch, as we're left with just two options, OneAgent and Agentless 

----------------
145.7:

Sad news, Thank you @AgataWlodarczyk  for this Notice. We are missing one easy way of agentless injunction.

----------------
145.8:

January 2024, will it still be useable or a Hard cutoff? Completely done by Jan 2024? Is it based on a particular version? Old versions that would still have extensions - an old version might still work? Asking for one of my clients that uses SAP C4C. Thanks.

----------------
145.9:

thanks @AgataWlodarczyk for this notice

	Dynatrace Professional Certified


----------------
146:

I noticed there is a Dynatrace add-on within Azure Log Analytics for Managed, but not for SaaS. How do you integrate Azure Log Analytics into Dynatrace SaaS? This is for Azure App Service on Linux. Within the App Service/Monitoring/Diagnostics section, I added diagnostics and connected it to a blobstorage and to log analytics. I would like to use the rsyslog/API import function to get logs from Azure and import them into Dynatrace.

	Dynatrace Certified Professional




					
						Solved!
					
					Go to Solution.




----------------
146.1:


Dynatrace has just announced this feature for all Azure and AWS services. This will roll out in Q2 of this year 

	-Chad


----------------
146.2:

Hi @Chad T.  Do you have any other information on this?  We actually have a slightly different request.  We are using Dynatrace for log monitoring and we previously had Logz.io which had the capability to export our logs to cold storage like AWS S3 so that we could keep them for our 1 year data retention period.  Is this possible?

----------------
146.3:

hey @Michael P. - currently it is not possible in Dynatrace. We have this on mid term RoadMap - unfortunately this will not be delivered in next 6 months.

----------------
146.4:


@bill_scheuernst you can now forward logs from Azure to Dynatrace on SaaS, put them in context, do analytics and set metrics and alerts. Give it a try and let me know what is your feedback. Starting point is here: https://www.dynatrace.com/support/help/technology-support/cloud-platforms/microsoft-azure-services/s...
 

----------------
146.5:

WE have integrated this but the logs are are not connected to the Azure app service traces as in https://www.youtube.com/watch?v=Ac5_aPBx2f0

----------------
147:

Our Infrastructure teams are looking for a way to list all Hosts (later all entities) that are currently in maintenance mode. According to this documentation it would be where Availability = Maintenance.
 
https://www.dynatrace.com/support/help/how-to-use-dynatrace/hosts/monitoring/host-availability#maint... 
 
I'm unable to find any API call that would return such a result. Even worse, I see no UI page that would list the same.
 
Does anyone have any suggestions?

	HigherEd


----------------
147.1:

Currently there isn't an ability for that other then grabbing the API data for All the Defined windows. This would be a great RFE.

	-Chad


----------------
147.2:

@ct_27,Have you been able to solve this, or created a Product idea?

	Antonio Sousa


----------------
147.3:

I never got what I really wanted because DT makes it too difficult. Seriously, they need to over hall their Maintenance module because what they have now apparently is not flexible enough to provide customers the basic capabilities we're asking for and thus every day it's holding Dynatrace back more and more. BUT we built something that's good enough....our own in-house solution (using NodeRed) that sends a daily report at 3:00pm every day with a list of...- Problems OPEN TODAY && are CURRENTLY OPEN- Problems OPEN BEFORE TODAY && are CURRENTLY OPEN- Problems OPEN BEFORE TODAY && CURRENTLY OPEN && have NO ALERTING PROFILE assigned- All other Problems OPEN TODAY && CURRENTLY CLOSED- A list of HOSTS, ExternalSynthetics, Synthetics, HTTPChecks, and HYPERVISOR actively in Maintenance mode.----Where entity has tag with key MM_ON (this is how we manually put things in maintenance mode) This report has been a game changer for us because we visually see repeat bad behaviors.  What I thought Dynatrace AI was supposed to do for us but hasn't.  So we've been able to adjust maintenance windows to improve our Availability, we've noticed systems with errors that repeat on unusual patterns, we've seen related systems report unrelated problems that actually helped us catch unusual issues.  TODO: I have started development of a NodeRed UI to allow for realtime reporting of hosts in maintenance but I took a detour to try and do it the DQL in the Gen3 Dashboard.  Bad idea......I just got myself wrapped around the axel and walked away. Never completing the work. Need to get back to the NodeRed solution.

	HigherEd


----------------
148:

I always had troubles getting this documentation page right:
Back up and restore a cluster | Dynatrace Docs
 
It starts explaining about Metrics and configuration storage with no clue about its underlying technology Cassandra.
Then it starts taking about ElasticSearch technology with no clue what its purpose is about and what kind of data it holds. We can only read it is uncompressed binary format.
 
Then it moves on talking about Transactional storage but it neither explains the technology nor the type of data in it. We can only read there is no back up for Transactional storage.
 
I found this thread was asking many of the questions I have but questions remained unanswered even though it says Solved for some reason.
Solved: Transaction storage on Dynatrace Managed - Dynatrace Community
 
My understanding so far is that:
 
Cassandra holds metrics data and it is backed up daily on each cluster node with 80% data compression.
ElasticSearch search holds session data, distributed traces, problems and configuration data with incremental backup every 2 hours.
 
What is Transactional storage about and what is the database technology involved?
What else am I missing?
 
Kindly refer to the community thread above and comment there.
Please also update the doc page.

	Digital Performance Optimizer


----------------
148.1:

 MartinWhat is transaction storage was explained in that thread. https://community.dynatrace.com/t5/Dynatrace-Managed-Q-A/Transaction-storage-on-Dynatrace-Managed/m-...It's stored as flat file, not any database. 

----------------
149:

Has anyone created any DPS Licensing dashboard yet?In demo we have a really cool Licensing Dashboard that I loved to use in my previous account. But now, I am running a DPS account, so the metrics are different.I was about to create a new dashboard, since found none created in demo, but facing hard time to understand the new metrics. So, has anyone already created one so I can borrow it? 

	Site Reliability Engineer @ Kyndryl


----------------
149.1:

@dannemca I've worked with customers across all types if Dynatrace License models. We have a DPS licensing dashboard, this dashboard is very in-depth and covers all environments with the ability to click into a specific environment and get even more granular with the consumption.   

	-Chad


----------------
149.2:

@dannemca is it enough for you?  

 When passion meets people magic and innovation happen. 


----------------
149.3:

It does helps, but I am not satisfied yet. Let's see if someone else has others examples to share.

	Site Reliability Engineer @ Kyndryl


----------------
150:

 
 

	Dynatrace Certified




					
						Solved!
					
					Go to Solution.




----------------
150.1:

Hello @lplinsky,It appears there was an error when trying to invite a new user to your account.  In order to triage this, we would need more information:1) The account you were working in,2) When you tried to complete the invite3) The user email you were trying to invite4) The user account you were logged in with

----------------
150.2:


It was some bug on tenant. Dynatrace solved it

	Dynatrace Certified


----------------
151:

So, I can turn OneAgent on or off on a particular host with a POST call to /api/v2/settings/objects as follows:   [
  {
    "schemaId": "builtin:host.monitoring",
    "value": {
                "enabled": true,
                "fullStack": false,
                "autoInjection": true
            },
    "schemaVersion": "1.2.0",
    "scope": "HOST-29200A0CBEF971B4"
  }
]   But, if I try a GET to confirm my change went through, via:/api/v2/settings/objects?schemaIds=builtin:host.monitoring&scope=HOST-29200A0CBEF971B4I get an array with 24 items:  {
    "items": [
        {
            "objectId": "vu9U3hXa3q0AAAABABdidWlsdGluOmhvc3QubW9uaXRvcmluZwAESE9TVAAQMDgyNzAwQTIxMzNCRTNGQwAkOTUxYjNiYjUtMmM3ZS0zZDYwLTk5NjEtM2IxY2ExOGJhN2Njvu9U3hXa3q0",
            "value": {
                "enabled": false,
                "autoInjection": true
            }
        },
        {
            "objectId": "vu9U3hXa3q0AAAABABdidWlsdGluOmhvc3QubW9uaXRvcmluZwAESE9TVAAQMDg5QjE1OTVFQzkwOEQzNAAkZDhhMTEyOWUtYmEzZC0zZGVkLWFjMmYtYTlhMzc5NDA1NGU1vu9U3hXa3q0",
            "value": {
                "enabled": false,
                "autoInjection": true
            }
        },
        {
            "objectId": "vu9U3hXa3q0AAAABABdidWlsdGluOmhvc3QubW9uaXRvcmluZwAESE9TVAAQMTZCRjBDNzIwRUZDMjQ0MQAkNGNiZTc4NDAtMDBmZi0zMDM2LTk2MjctNTRhMjQ0ODRkZWM1vu9U3hXa3q0",
            "value": {
                "enabled": false,
                "autoInjection": true
            }
        },
        {
            "objectId": "vu9U3hXa3q0AAAABABdidWlsdGluOmhvc3QubW9uaXRvcmluZwAESE9TVAAQMjkyMDBBMENCRUY5NzFCNAAkYzEwMTM3YzEtNDgxNS0zZTE1LTgwZDEtNDIyYzQyNTE4NTllvu9U3hXa3q0",
            "value": {
                "enabled": true,
                "autoInjection": true
            }
        },
        {
            "objectId": "vu9U3hXa3q0AAAABABdidWlsdGluOmhvc3QubW9uaXRvcmluZwAESE9TVAAQMzMwNkM1MDQ2RkEwOTVERAAkMmFmYmE2NGYtNDY0Ni0zODdjLWJkOTktMmZiMjRlNGFhOWVhvu9U3hXa3q0",
            "value": {
                "enabled": false,
                "autoInjection": true
            }
        },
        {
            "objectId": "vu9U3hXa3q0AAAABABdidWlsdGluOmhvc3QubW9uaXRvcmluZwAESE9TVAAQNDEwNUVCQzUyMERCNkU3OAAkZmY0YjA4ZmEtYTgzZS0zNDIyLThkNmYtY2NkYzJmYjdlMGE4vu9U3hXa3q0",
            "value": {
                "enabled": false,
                "autoInjection": true
            }
        },
        {
            "objectId": "vu9U3hXa3q0AAAABABdidWlsdGluOmhvc3QubW9uaXRvcmluZwAESE9TVAAQNEMzQUE4RTJBMkFDMDg4MAAkOWY0YWJjN2MtNjNmMy0zYzFmLWI5OWItM2UxYzIxOWVmZDhivu9U3hXa3q0",
            "value": {
                "enabled": false,
                "autoInjection": true
            }
        },
        {
            "objectId": "vu9U3hXa3q0AAAABABdidWlsdGluOmhvc3QubW9uaXRvcmluZwAESE9TVAAQNUUyNDc5Q0E4OTg2NUE1NgAkY2UwY2VjMjYtNGJiNi0zNDg0LTkwYjYtZjc4OWYyYmY2MjU5vu9U3hXa3q0",
            "value": {
                "enabled": false,
                "autoInjection": true
            }
        },
        {
            "objectId": "vu9U3hXa3q0AAAABABdidWlsdGluOmhvc3QubW9uaXRvcmluZwAESE9TVAAQNjFGQUE5Q0NCNjk4QkY5QgAkY2RjODg3NzMtNDFmYi0zYjZmLWFjYjUtYzJiMDVjODk1NjUwvu9U3hXa3q0",
            "value": {
                "enabled": false,
                "autoInjection": true
            }
        },
        {
            "objectId": "vu9U3hXa3q0AAAABABdidWlsdGluOmhvc3QubW9uaXRvcmluZwAESE9TVAAQNzREQzU2Qzc5QjhFNzA2RAAkNWViNDg5YmItZDM0OC0zY2JlLWFkOGEtMzU1Y2UxZDI0ZjE0vu9U3hXa3q0",
            "value": {
                "enabled": false,
                "autoInjection": true
            }
        },
        {
            "objectId": "vu9U3hXa3q0AAAABABdidWlsdGluOmhvc3QubW9uaXRvcmluZwAESE9TVAAQN0I3MkMyQjVGRENBNzQ1MAAkZGNlY2E5NTItNGJjYi0zYTNmLThmMWUtYzZmYjM3N2JkNmYzvu9U3hXa3q0",
            "value": {
                "enabled": false,
                "autoInjection": true
            }
        },
        {
            "objectId": "vu9U3hXa3q0AAAABABdidWlsdGluOmhvc3QubW9uaXRvcmluZwAESE9TVAAQN0QxOTZFMTg3NjQ2MkFBNQAkMDU1ODZhMWYtYzIwZi0zZTNmLWFlZTctMTllMTVmNGQ3OGE5vu9U3hXa3q0",
            "value": {
                "enabled": false,
                "autoInjection": true
            }
        },
        {
            "objectId": "vu9U3hXa3q0AAAABABdidWlsdGluOmhvc3QubW9uaXRvcmluZwAESE9TVAAQOERFRjg2MjgxMDBGNDlERgAkNmE2MWNkNDItYTdjYS0zMTQwLWEzM2UtZjg0MjI2NmY1MjZlvu9U3hXa3q0",
            "value": {
                "enabled": false,
                "autoInjection": true
            }
        },
        {
            "objectId": "vu9U3hXa3q0AAAABABdidWlsdGluOmhvc3QubW9uaXRvcmluZwAESE9TVAAQOTQ2QzQ5Qzc0ODcwM0M1MgAkMjJlNGQzNzEtOTY4Ni0zMGQ5LTg2MWYtZGZlZjVmZWYyNWJhvu9U3hXa3q0",
            "value": {
                "enabled": false,
                "autoInjection": true
            }
        },
        {
            "objectId": "vu9U3hXa3q0AAAABABdidWlsdGluOmhvc3QubW9uaXRvcmluZwAESE9TVAAQQTAzRUUzQjJGMjQ4QjRCRQAkNzIyNDFlNGEtMjdkNS0zMzlkLTg2ODktZTUwZWYyOGZhN2Q0vu9U3hXa3q0",
            "value": {
                "enabled": false,
                "autoInjection": true
            }
        },
        {
            "objectId": "vu9U3hXa3q0AAAABABdidWlsdGluOmhvc3QubW9uaXRvcmluZwAESE9TVAAQQUNBRkIwOUU4OUMyNTFCMQAkZjJlZGJiODctOTk3NC0zNGEzLWExMjMtMzZmMThlZTMxNWZkvu9U3hXa3q0",
            "value": {
                "enabled": false,
                "autoInjection": true
            }
        },
        {
            "objectId": "vu9U3hXa3q0AAAABABdidWlsdGluOmhvc3QubW9uaXRvcmluZwAESE9TVAAQQUUwRTU2OUU1NjM3NTFEMAAkZWMxNWM4NjItNDU2Ny0zZTdiLWE1NmItNTUzMmQ0MzJmMTE3vu9U3hXa3q0",
            "value": {
                "enabled": false,
                "autoInjection": true
            }
        },
        {
            "objectId": "vu9U3hXa3q0AAAABABdidWlsdGluOmhvc3QubW9uaXRvcmluZwAESE9TVAAQQUU3ODI0QTZGREJGODY0QgAkMzFlOGE2M2ItNWU0MC0zMzFmLThjNmQtMThkNjA3OGMzOWE0vu9U3hXa3q0",
            "value": {
                "enabled": false,
                "autoInjection": true
            }
        },
        {
            "objectId": "vu9U3hXa3q0AAAABABdidWlsdGluOmhvc3QubW9uaXRvcmluZwAESE9TVAAQREEwMDJCODFDNkMxRkQ2QgAkMzg1ZDQyNzMtOTAyMi0zMmU0LTlhYWQtMWVmNDNiZjU5MWFhvu9U3hXa3q0",
            "value": {
                "enabled": false,
                "autoInjection": true
            }
        },
        {
            "objectId": "vu9U3hXa3q0AAAABABdidWlsdGluOmhvc3QubW9uaXRvcmluZwAESE9TVAAQREFDNkU1RjcxNUE3QUI2MgAkYzI0NmZjODEtY2U2Zi0zMzRjLTg5OWMtOGY4NzUzZmI4MmU4vu9U3hXa3q0",
            "value": {
                "enabled": false,
                "autoInjection": true
            }
        },
        {
            "objectId": "vu9U3hXa3q0AAAABABdidWlsdGluOmhvc3QubW9uaXRvcmluZwAESE9TVAAQRTEzMjBDNEY5RTE3MEI5NgAkNjFhYzY1NTQtY2U4OS0zODAxLWFiOWItODUwMzYwNDg2YWVmvu9U3hXa3q0",
            "value": {
                "enabled": false,
                "autoInjection": true
            }
        },
        {
            "objectId": "vu9U3hXa3q0AAAABABdidWlsdGluOmhvc3QubW9uaXRvcmluZwAESE9TVAAQRTMwRjM1OEEzOEI0MjZEQwAkZWRkNDMyMTMtNjU4Mi0zOWZlLWFiNTAtZjZhMjI3OWM1ODE1vu9U3hXa3q0",
            "value": {
                "enabled": false,
                "autoInjection": true
            }
        },
        {
            "objectId": "vu9U3hXa3q0AAAABABdidWlsdGluOmhvc3QubW9uaXRvcmluZwAESE9TVAAQRjY2RUZFOUI4MkZDODgwOAAkOGM3ZjRhNGUtZGIyYi0zMzY1LTg2NzktMTA2NGM4MDQ4YTQ5vu9U3hXa3q0",
            "value": {
                "enabled": true,
                "autoInjection": true
            }
        },
        {
            "objectId": "vu9U3hXa3q0AAAABABdidWlsdGluOmhvc3QubW9uaXRvcmluZwAESE9TVAAQRjg2MjVEOUNCMDQ3MDk1NwAkMGRlMDY5ZmUtMDU4Yy0zZDA0LTgwYTMtYjdjNjVhY2I4MWE2vu9U3hXa3q0",
            "value": {
                "enabled": false,
                "autoInjection": true
            }
        }
    ],
    "totalCount": 24,
    "pageSize": 100
}  How can a POST to a hostid and scope correctly target the host I want when a GET from the same host and scope returns 24 hits?How do I query the OneAgent status to confirm enabled/disabled?      



					
						Solved!
					
					Go to Solution.




----------------
151.1:


@DuaneRoelands, seems like a typo in your scopes param, try this:/api/v2/settings/objects?schemaIds=builtin:host.monitoring&scopes=HOST-29200A0CBEF971B4

	Site Reliability Engineer @ Kyndryl


----------------
151.2:

Sometimes the answers are simple.  Thank you!

----------------
152:

We are using tag values from Dynatrace to direct ServiceNow to automatically route incidents (problems) to teams, and we would like to leverage a custom AWS tag to do this. Is there a way to get the value from a custom AWS tag into ServiceNow? 



					
						Solved!
					
					Go to Solution.




----------------
152.1:

If you are ingesting your Tags from AWS then you should be able to transmit them via problems into your Service Now Integration as well. 

	-Chad


----------------
152.2:

AWS tags that are associated with problems automatically go into ServiceNow?  Perhaps we aren't seeing any yet because we haven't had any problems in our new AWS environment yet. If that's the case, we will try setting up ServiceNow rules based on our AWS custom tag.

----------------
152.3:

If you are ingesting the AWS tags into Dynatrace - You must have them show up in the Dynatrace Tags section first.  Then you can set your Service Now Integration to include tags:   

	-Chad


----------------
152.4:

My AWS tags do show up in Dynatrace, so that part is good. Do I have to add {Tags} to the ServiceNow Description field in the box above for them to be sent over, or is that automatic?

----------------
152.5:


You will need to add it. Whatever is in the Description is what you will pass into ServiceNow. Remove any of those placeholders, and you will not pass along that data Such as {State} - removing that will remove the "Open" or "Resolved" in the description of the alert in ServiceNow.   

	-Chad


----------------
152.6:

Got it.  I'll give that a try and see what we get when we start seeing problem cards for cloud resources.  Thanks!

----------------
152.7:

Sounds good  

	-Chad


----------------
152.8:

@ChadTurner I came across this post while searching for something similar. We have built integration Between AWS and Dynatrace using oneagent and also tested integration with ServiceNow. As per your post, the tags are showing up in ServiceNow, so all good here. But in order to make proper CI binding in ServiceNow, we will need to also push AWS account ID associated with the resource as a tag/value pair to ServiceNow. I was wondering if there is any options available to add AWS account ID as custom tag either while ingesting data from AWS to ServiceNow (may be through custom processing rule in Settings-> Log monitoring -> processing) or while pushing data to ServiceNow. Please let me know if such a thing is possible.    

----------------
152.9:

I would recommend setting the tag at the AWS level and then ingesting it into Dynatrace. Then as alerts fire via your SN integration the tags will show. Much like its been described in the other comments on this thread. 

	-Chad


----------------
152.10:

Hi @ChadTurner , thank you for getting back on this. This is precisely what was recommended but challenge is that this being an existing environment with 150+ accounts and 10s of applications/teams it would not be possible to get everything on AWS tagged with AWS account ID tag. While we are putting conscious effort to get the tags updated on AWS resources, it will take considerable time/.effort to do that. Even then, there will always be resources which would not be properly tagged.  Thus I was thinking if there is any approach to add tag on the resources in Dynatrace or into the notifications pushed into ServiceNow based on the account associated with the resource which is generating notification.

----------------
152.11:

AWS doesn't have an auto tag feature? Unfortunately even if you were to set a tag in Dynatrace, i dont think its going to be a dynamic value. Meaning if you found the ID in the properties, you might not be able to set it as a value for the tag like you can for say IP Address. AWS side might be the best way if they have an auto tag feature or if you associate an application ID to the entities for your SN CI linkage

	-Chad


----------------
152.12:

There is no such option in AWS to set a default tag.As mentioned in my first post above, I tried setting up a custom rule under Settings-> Log monitoring -> processing to add AWS account ID as an attribute. This way every time a log is ingested from AWS Account account ID is captured as an additional attribute. But I am not sure if there is any way to push this account ID as an additional tag/value on associated resources.USING(INOUT aws.account.id:STRING, content)| FIELDS_ADD(AWSAccount_ID: IF(aws.account.id <> '',aws.account.id))I am trying to see if we can enrich the tags on the resources before they are ingested into Dynatrace 

----------------
153:

Hi, is it possible to show distributed traces through AWS Step Functions? If not, does Dynatrace have any plans to support it?
We already pull the Step Function Cloudwatch metrics which is nice but we are looking for tracing like what Datadog and AWS X-Ray provide. 
 



					
						Solved!
					
					Go to Solution.




----------------
153.1:


as you mentioned you are already pulling the step functions via the extension: https://www.dynatrace.com/support/help/setup-and-configuration/setup-on-cloud-platforms/amazon-web-s... If you are looking to get more like tracing I recommend putting in a RFE for extension enhancement. 

	-Chad


----------------
153.2:

We have the same usecase, We are very much waiting for support of Dynatrace supporting AWS step function ,already we are ingesting metrics but seeing end-to-end trace is our top priority.

----------------
154:

I want to find items where a specific field is not existing. How can I do that with DQL? Something like fetch events| filter myItem.nonexisting == null 

----------------
154.1:

A colleague pointed out the isNull function to me. The syntax isfetch events| filter isNull(myItem.nonexisting) And this also works when the field does not exist.

----------------
155:

Hello,
I assume that these kind of extensions are only for Dynatrace,  or else where is the documentation (-;
 
KR Henk 



					
						Solved!
					
					Go to Solution.




----------------
155.1:


Hey Henk,
That's correct, at least for now they are only for Dynatrace. This as we require the extensions to be signed with the Dynatrace certificate due to security concerns of auto distributing python code which didn't go through an extensive security pipeline. If/when that changes we'll announce it with a blog post.
Mike

----------------
155.2:

Any updates on this? We have scripts we would like to deploy. We are kind of back against the wall at this point.

	HigherEd


----------------
155.3:

It is still planned, but we don’t have a timeline that we can communicate yet. The blog post is currently planned for the next quarter.

----------------
155.4:

Do we currently know what the timeline/perspective is to use the Python SDK for Extensions 2.0.?This topic was brought up by a customer of mine during a meeting today. Thanks in advance!

----------------
155.5:

More information will be shared in the next few months.

----------------
155.6:

I would also like this feature!

----------------
155.7:

Hi @Mike_L ! Any updates on this? Also, wouldnt the security be kept by using the signing process which is used on the other Extension 2.0 plugins?

----------------
155.8:

The messaging should go out in the next few weeks.
From a security point of view there is quite a large difference between using the Dynatrace infrastructure to distribute configuration, and using it to distribute any code.
FYI @michal_nalezin 

----------------
156:

 
IBM MQ ActiveGate Extension - Troubleshooting Steps in case of uninitialized or error 13. 
Dynatrace provides both Oneagent and ActiveGate extension (aka: remote monitoring). 
 
This article is specific to ActiveGate extension as mentioned here:
https://www.dynatrace.com/support/help/shortlink/ibm-mq-extensions#activegate
Possible error messages:
Status Uninitialized or Error 13: 
Can't access to "/opt/dynatrace/remotepluginmodule/plugin_deployment/custom.remote.python.ibmmq_java/plugin.json" (filesystem error: status: Permission denied [/opt/dynatrace/remotepluginmodule/plugin_deployment/custom.remote.python.ibmmq_java/plugin.json])
[Errno 13] Permission denied: '/opt/dynatrace/remotepluginmodule/plugindeployment/custom.remote.python.ibmmq_java/psutil/init.py'
 
Troubleshooting steps:
1. Make sure you have an Environment ActiveGate installed with all its default modules running. It is not allowed to have only extension 1.0 and 2.0 enabled while rest of the modules are switched off through custom.properties file. If this is the case please uninstall the ActiveGate (including all its files and folders) and reinstall it. 
2. If step (1) did not work, check the file permissions on /opt/dynatrace/remotepluginmodule/plugin_deployment/custom.remote.python.ibmmq_javaand change the file ownership and permission as follows:
Change the ownership of the directory to dtuserag:dtuserag and modify the permissions to 744: 
chown -R dtuserag:dtuserag /opt/dynatrace/remotepluginmodule/plugin_deployment/custom.remote.python.ibmmq_java
chmod -R 744 /opt/dynatrace/remotepluginmodule/plugin_deployment/custom.remote.python.ibmmq_java
 
After changing the file ownership and permissions, please restart the remotepluginmodule service
systemctl restart remotepluginmodule
 
If the steps mentioned still did not work, please reach out the the product/tech support at Dynatrace. 
Thanks!
 
 
 

----------------
156.1:

  

----------------
156.2:

I am having the same issues.The MQ plugin stars as OK, and is fetching data, then it suddenly becomes uninitialized.Any suggestions?

----------------
156.3:

When is the Extension 2.0 MQ monitoring due?

----------------
157:

Dear Dynatrace Warriors.Hope you guys are doing well. 
Is it possible to Configure JVM Heap space memory monitoring and splitting by host/server? Instead of monitoring the overall server process, how can I focus on the JVM heap space only for a specific server? I would like to get the details of this and showcase this on the Dashboard so that my team can monitor and review this. 
Look forward to your guys' response on this. Thank you so much for helping out guys. 
Appreciate it as always. Thanks, 
Regards, Afrezal Karim
 
 
 



					
						Solved!
					
					Go to Solution.




----------------
157.1:


Hi,I am not sure if I understand you but can you execute this in data explorer?builtin:tech.jvm.memory.pool.used:splitBy("dt.entity.process_group_instance"):sort(value(auto,descending)):parentsIf you choose table visualization for example, you should see 3 columns:Hostname.Process.JVM heap memory pool used bytes.Best regards

	Consultant


----------------
157.2:

Hi @AntonPineiro ,Thank you so much for your response on this.  I've tried to execute the query in the Data Explorer and it works like a charm!. Thanks for helping out. I appreciate it!. By the way any idea how do i filter by hostname?.  was trying to use the :filter and eq("dt.entity.host","HOST-001") still not able to get the specific host to be filter. 

----------------
157.3:

Hi @Afrezal_Karim Here is an example for filter host. In this case you should also use parents transformation and filter together.builtin:tech.jvm.memory.pool.used:parents:filter(and(or(in("dt.entity.host",entitySelector("type(host),entityName(~"YOUR HOST NAME ~")"))))):splitBy("dt.entity.process_group_instance","dt.entity.host"):sort(value(auto,descending))Or you can use the dynamic filter on the dashboard as I mentioned before. I hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
157.4:


Hi @Afrezal_Karim @AntonPineiro  answer is perfect. If you would like to provide more extra, useful information about the jvm behaviour to the IT operation guys I reccomend these metrics: suspension time and garbage collection total time. You can also collect some extra jmx metrics at different types of jvms (jboss, tomcat, weblogic etc...) which ones could be useful for IT ops.Eg. at weblogic: hogging thread, pending requests or connection pool metrics waiting threads and failed db connects...   And it could be useful if you use the dynamic filter on dashboards:eg. I hope it helps to provide better service to your teams.Best regards,Mizső

	Certified Dynatrace Professional


----------------
157.5:

Hey @Mizső ,Thats a pretty cool Dashboard you've created. Looks awesome. Do you mind sharing the details of the builtin query keyword that i can use similar like yours ?.  Still learning and trying to understand which one is good to be put in the Dashboard.Again thanks for sharing and and also helping on this. Appreciate it. 

----------------
157.6:

Hi @Afrezal_Karim,These are the metric expressions: In bulilt basic metric:builtin:tech.jvm.memory.gc.suspensionTime:splitBy("dt.entity.process_group_instance"):max:sort(value(max,descending))builtin:tech.jvm.memory.gc.collectionTime:splitBy("dt.entity.process_group_instance"):max:sort(value(max,descending)) WL specific in built:builtin:tech.weblogic.connectionPool.WaitingForConnectionCurrentCount:splitBy("dt.entity.process_group_instance"):sum:sort(value(sum,descending))builtin:tech.weblogic.connectionPool.FailedReserveRequestCount:splitBy("dt.entity.process_group_instance"):sum:sort(value(sum,descending)) WL extra jmx metrics:ext:custom.jmx.HoggingThreadCount.metric_HoggingThreadCount_1601572768674:splitBy("dt.entity.process_group_instance"):max:sort(value(max,descending))ext:custom.jmx.PendingRequestCount_JMX.metric_PendingRequestCount_1601790848493:splitBy("dt.entity.process_group_instance"):max:sort(value(max,descending)) Oracle extension metric:builtin:tech.oracleDb.cd.sessions.active:splitBy("dt.entity.custom_device"):sum:sort(value(sum,descending)) I hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
158:

Hello,Sikerül majd megrendezni ezt az eseményt jövőhéten? (Csak, hogy nem utazzak fölöslegesen Debrecenből Budapestre :))Üdv,Zoli

----------------
158.1:

Szia Zoli!Igen. Várunk szeretettel. A helyszín változott, mindjárt lekövetem itt is: Helyszínváltozás: Paulaner Sörház H-1123 Budapest, Alkotás u. 53. (MOM Park I. em.) Web: paulanersorhaz.huÜdv:Mizső

	Certified Dynatrace Professional


----------------
158.2:

Ha valakinek megvan a csoportkép, én kíváncsi lennék majd rá. 

----------------
159:

Hi guys, Customer asks to monitor OPEN APIC with synthetic so we create http checks with token saved in the vault.The issue here is that the tokens got only 10 hours lifetime and we need to generate a new token with rest api every hour.Our intension now is to call the rest api that generate the token on OPEN APIC and with value from the response body to set a value (with api.setValue(key, value)) for the next step which will send dynatrace vault rest api to change the value of the token to the new one.  We need your help here with how to extract values from response body in the post execution step with response.getResponseBody() , how can we extract a value after token=" till the next " from the response body?Thanks in advanceYos 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel




					
						Solved!
					
					Go to Solution.




----------------
159.1:

Hello I think it's possible using Request Attributes More details here Request Attributes 

	Sharing Knowledge


----------------
159.2:

Hi @Malaik Question is about post-execution script in http monitor.How can we implement RA in http monitor?Yos  

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
159.3:


Hi Yosi, As the response body is a string, I'd say using a regex match would do the trick, with a capture group somewhat like this (adapt it to the format of your token of course):api.setValue("token", responseBody.match(new RegExp("token=\"([A-z0-9]+)\""))[1]) Regards,Álvaro

----------------
159.4:

Hi @alvaro_sanchez  Great , will give it a try next week at customer site and will update !Thanks a lotYos  

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
159.5:

Hi @Yosi_Neuman!
 
I'm curious how this issue has ended eventually, were you able to find a desired solution as promised last year? 
 
Best regards!

----------------
159.6:

Hi @Michal_Gebacki As far as I remember it works OK.I have accepted @alvaro_sanchez  answer as a solution  and sorry for the "slight" delay in doing that Yos 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
159.7:

I can confirm that you can use regex in the post-execution synthetic script. Here is who I did it for our application.   

----------------
159.8:

Hi,I'm trying to capture a specific value from the response of a HTTP (API) request.I have tried the approaches suggested by @alvaro_sanchez and @jkinner above, but with no success.I've attached an example of the response from the API request.I specifically need to capture the value returned for "policyNo" into a new variable, "policyNumber".Does anyone have any suggestions on how I can get this working?jmodeorain14

----------------
159.9:

I was able to extract the value of policyNo from the response body.In case anyone is interested or has a similar challenge in future, here is the post-execution script I used: jmodeorain14

----------------
159.10:

HiAnd where you put this code?

	Sharing Knowledge


----------------
160:

We are seeing almost 100% failure rate for request https://localhost:9999/mbeacon coming from service Dynatrace ActiveGate on port 9999. Does anyone know what this request represents? Should I be concerned with it being this high? One of our ActiveGates has <1% but 2 others are at almost 100%.Looking at the failure details I see all were from java.io.FileNotFoundException but I don't really know how to dig deeper into how to fix this.  

----------------
160.1:

Looks like an incorrectly custom app with openkit. Most likely it's an extension reporting to the ActiveGate (and trying to send data locally). What extensions is the ActiveGate running?

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
160.2:

Your comment led me down the path of looking at our custom applications. I found that the app ID in the relative URL of the trace (see below), refers to a custom app for endpoints associated with AG extension SAP Application Server (ID: custom.remote.python.sap).I did find some custom apps associated with these endpoints configured to our internal vip that hits our ActiveGates, I changed the settings of each app to use the cluster AG. I believe the failures that are occurring now are associated with endpoints that have a custom app ID setup (in the endpoint settings) but no associated custom app actually created with that ID. Still doing some clean up. It is very likely that we removed some custom apps that have not had traffic in say 1 year, but did not remove the endpoint in the extension.   

----------------
161:

I want to create a summary table that has 2 columns - the first column would be the name of the data, and the second would be the value. These values would be the min / max / average of various metrics over a given time period. Or, if this can't be done, maybe 4 columns - the first column to be the name of the metric, - the second to be min, - the third average, - fourth max. Whenever I try to do this I get a separate column for each calculation, which leads to a table with a lot of blanks in it. Any way to do this?

----------------
161.1:

Hi @kostellod,Can you share the wrong result table? and the mentioned calculations?Best regards,Mizső

	Certified Dynatrace Professional


----------------
161.2:

This would be an example. I want 1 line, left column as "CPU %", 2nd as "Min", 3rd as "Avg", 4th as "Max". I'd like this for a couple of different metrics in the same table. 

----------------
161.3:

Since you are using the same metric, you should include all the tags in the filter for the same query. Example:builtin:host.cpu.usage:filter(and(or(in("dt.entity.host",entitySelector("type(host),tag(~"YOUR_FIRST_TAG:HERE~")")),in("dt.entity.host",entitySelector("type(host),tag(~"YOUR_SECOND_TAG:HERE~")")),in("dt.entity.host",entitySelector("type(host),tag(~"YOUR_TIRDH_TAG:HERE~")"))))):splitBy("dt.entity.host"):sort(value(auto,descending)):limit(100)EDIT:In your case, you should create the following queries, using the same formula, just replacing the aggregation you need. EDIT 2:I see the problem now. With no 'split by' condition, you still get the one line per query... So I think this can be an Idea candidate...

	Site Reliability Engineer @ Kyndryl


----------------
162:

I am creating a table that is displaying data which is split by one of the dimensions whose values range from 0-19. When I add a sort, it's sorting the values alphabetically, so I get 0, 1, 10, 11, ... instead of 0, 1, 2, ...   How can I make my sort numeric instead of alphabetic?



					
						Solved!
					
					Go to Solution.




----------------
162.1:

you got this option to sort Sort byBy default, results are sorted in descending order based on the aggregation chosen.To set the sort orderIf Sort by is not already displayed in the query editor, select  and then select Sort by from the list.Set Sort by to the dimension by which you want to sort.Select the sort order: ASC (ascending) or DESC (descending). Documentation page https://www.dynatrace.com/support/help/observe-and-explore/explorer 

	Dynatrace Professional Certified


----------------
162.2:

I've got a sort added, but it's not working as I'd like. It's doing an alphabetic sort - I need numerical.

----------------
162.3:

Hello,Can you send a screenshot of your configurations? Thanks,Islam

	Dynatrace Certified Professional - Dynatrace Partner - Yourcompass.ca


----------------
162.4:


If it's a dimension, you cannot sort it numerically. Dimension is a string, not a number and is sorted lexicographically as stated here. The only way I can think of is to replace the data at the source and pad it with zeroes( 0 -> 00, 1 -> 01, 2 -> 02).

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
162.5:

Unfortunate. It would be nice to be able to do a transformation on data before it gets sent to the chart.

----------------
162.6:

yes, unfortunate. This probably won't happen with the classic data explorer and will be possible only with Grail.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
163:

In this session, Dynatrace security researcher Mario Kahlhofer @mario_kahlhofer demonstrates security use cases from both the attacker and defender side using the open-source application Unguard.
Mario shows how an attacker:
Conducts target reconnaissance using open source fuzzers wfuzz and commixGains access to the insecure Unguard application into the Kubernetes clusterGains persistence using a reverse shellMaps the cluster, finding an insecure Redis serverCompletes the compromise by dumping information in RedisMario then demonstrates how a Defender can:
Use Dynatrace to see the distributed trace information for indicators of compromiseUse Dynatrace to efficiently categorize where to look for compromisesUse Dynatrace and Falco to see, in realtime, how an attack took place and what commands the attacker executedUse Dynatrace for post-incident forensic review – to understand the attack timelineLinks discussed in this webinar:Unguard: https://github.com/dynatrace-oss/unguard Falco: https://falco.org/ MITRE Att*ck: https://attack.mitre.org/ 
The recording is also available on the Dynatrace University: LINK
- - - Subscribe to our YT channel Stay up-to-date with Dynatrace! Follow us on Facebook, Instagram, LinkedIn, Twitter, Twitch  

 When passion meets people magic and innovation happen. 


----------------
163.1:

this is awesome!!!

	Dynatrace Professional Certified


----------------
164:

Hey all,
Wondering if anyone comes across trying to export response time distribution under a custom action for a single user session.For example, I would like to have the info of CPU time & database sequential read time (highlighted in yellow) from the session and also the database call value (highlighted in green)Refer to the screenshot below:
 
Basically what we trying to achieve here is having the t-code (Session Manager ....), CPU time (125ms), database sequential read time (24ms) and database calls (231) to be displayed in the dashboard or exported somewhere for our performance analysis purpose. 
Looking forward to the reply .Thanks in advance.
 

----------------
164.1:

Hi @yuesong_teh ,As far as I know, waterfall analysis is not exportable.Reported Values have a trick to read/query them but it doesn't work on Custom Applications (like SAP ABAP) unfortunately 

----------------
165:

Hi All,I feel this is probably something very simple but im having some issues working out how to do it and i've not seen any answers that help.In our app we have a number of user actions we track with actions,   for example screens being viewed,  buttons being clicked etc.Example of screen view tracking.val action = Dynatrace.enterAction("Screen view : <app.error_screen>")action.leaveAction() I need to be able to view these screen views over a time period similar to this graph,  for example when Error screens are being shown,  so I can see a graph of the last x days and see when problems have occurred.  Any help is much appreciated. ThanksKev



					
						Solved!
					
					Go to Solution.




----------------
165.1:

Hi @KevThompson,Please double check it, but it will not meet your requirements exactly, because it gives back the all action count numbers from the affected sessions:SELECT DATETIME(startTime, 'HH:mm', '5m'), SUM (userActionCount) FROM usersession WHERE useraction.application='your appliacation name' AND useraction.name="your individual user action name" GROUP BY DATETIME(startTime, 'HH:mm', '5m')So it would be closer, because it gives back the session id count where the specific user action can be found. This is not deal with those cases where the specific action can be found more than one.SELECT DATETIME(startTime, 'HH:mm', '5m'), COUNT (userSessionId) FROM usersession WHERE useraction.application='your application name'AND useraction.name="your individual user action name" GROUP BY DATETIME(startTime, 'HH:mm', '5m')I hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
165.2:

Hi Mizső, Thanks for the feedback,  I've tried to use this one but I get the following error,  any ideas?   SELECT DATETIME(startTime, '2023-09-01 00:00', '5m'), COUNT (userSessionId) FROM usersession WHERE useraction.application='My3 App ' AND useraction.name="Screen change : app.dashboard" GROUP BY DATETIME(startTime, '2023-09-20 00:00', '5m')  ThanksKev

----------------
165.3:


Hi @KevThompson,Try this one, you should cahnge only the app and the user action name. In this case you will have graph and it can pin to dashboard:SELECT DATETIME(startTime, ''HH:mm', '5m'), COUNT (userSessionId) FROM usersession WHERE useraction.application='My3 App ' AND useraction.name="Screen change : app.dashboard" GROUP BY DATETIME(startTime, ''HH:mm', '5m').I have not tried it but check to create custom metric (for alerting) and change to graph to single value (maybe it would be better on dashboard with time filter). Best regards,Mizső

	Certified Dynatrace Professional


----------------
165.4:

Excellent thank you Mizső,  its working now,   the confusion point was I thought you had to put the required date ranges into the DateTime in the query, where as that comes form the timeframe selector.We have recently moved from another provider which also had its own QL so a few confusing cross over points.ThanksKev

----------------
165.5:

Your welcome! 

	Certified Dynatrace Professional


----------------
166:

Hi All,Can i integrate Dynatrace with ivanti itsm?

----------------
166.1:

Hi,You can send notifications via Webhooks.Best regards

	Consultant


----------------
166.2:

Hi,Is by webhooks will open a ticket automatically, and please provide me how to integrate.

----------------
166.3:

Hi,Dynatrace will send a payload to Ivanti. Do you have some API in Ivanti to receive information?Best regards

	Consultant


----------------
166.4:

Hello,You can use the webhook integration as @AntonPineiro mentioned. in case you need a tailored way for the integration, you can check Zigiwave integrations. they provide a connector between Dynatrace and Ivanti.https://zigiwave.com/dynatrace-integrations/ Thanks,Islam

	Dynatrace Certified Professional - Dynatrace Partner - Yourcompass.ca


----------------
167:

Hi,I've got a little bit of a doubt; this is the situation: on Friday 100 hosts were gracefully shutdown and, since I set Dynatrace to open a problem even for this kind of event, I got 100 problems opened.Today (Monday) I noticed that all the problems were closed after 12h from the shutdown event on Friday even tought the hosts are still down.Is this normal? Does Dynatrace close problems for gracefull shutdown after a certain amount of time even if the hosts are still down?Can I change this behavior somewhere in the setting?Thank you
 



					
						Solved!
					
					Go to Solution.




----------------
167.1:

Perhaps dynatrace decided that this was planned behaviour. In general if shutdown was gracefull, better idea is configuring maintenance window to prevent falls positive alerting. Sebastian 

	Regards, Sebastian


----------------
167.2:

I needed that list of opened problems to remember the 100 hosts that I shutted down on Friday.Sure I could have done a Maintenance window but I didn't in order to pick every single problem tile today and start rebooting all hosts listed there.Can I avoid this automagic problem management system so I can keep my problem open even after 12h of shutted down hosts?

----------------
167.3:

No, but there is no issue with it. When you go to host list and pick filter that will list your offline hosts (by tags, by name etc) with timeframe 72 hours you will see all of them. Offline and online ones. In such case you see which of them still needs restarts or agent installation.Sebastian 

	Regards, Sebastian


----------------
167.4:

Thank you for your time Sebastian

----------------
167.5:


Yes that's by design, as documented here:https://www.dynatrace.com/support/help/shortlink/event-types-availabilityIn previous versions we kept the problems open for 7days but many customers were annoyed by the open problems and demanded a shorter timeout period of 12hours for closing the host unavailable problems. Alerts are sent out anyway, so it does not make much sense to keep those problems open forever if the host is not coming up again. Best greetings,Wolfgang

----------------
167.6:

As Ben also started, this is a big Process problem for us with ServiceNow Integration.  The PRoblem is closing the ServiceNow Incidents after 12 hours even if the server is still down.  This is unacceptable from our customers perspective who uses ServiceNow to rack the status and availability of their servers from ServiceNow. We need the ability to either change the configuration to a much longer time, like 7 days ;-), or never to close the Alert to ServiceNow unless the problem is corrected.

----------------
167.7:

Hi,It would be nice if this was configurable. In some scenarios it is nice that the problems time out and disappear, but in other scenarios that can be an issue

----------------
167.8:

One scenario where automatic closure after twelve hours causes problems is with the ServiceNow integration. The host going offline creates an incident in ServiceNow that is then closed after 12 hours. This in some cases prevents teams returning from the weekend from investigating these issues and hosts are then left in a offline state. 

----------------
167.9:

Sorry to revive this old thread, but today we also noticed issues with the hard 12 hour timeout. When a server goes down just after the end of a workday, the timeout prevents us from seeing the issue on our dashboards the following morning. It would be nice to have these timeouts be configurable.

----------------
167.10:

HI @RikvanEngelen At the moment, it is not possible to configure such a timeout. You can set up a Product Idea and describe your need in detail. 

	Have a nice day!


----------------
167.11:

It is correctly summarized that on the back end Dynatrace will close the problems after 12 hours, by designed, as asked for by a number of customers some time ago.  I think that may be fitting for some, but clearly not all. ANSWER (tactical) - You can request support to increase that time to several days as needed for your environment.ANSWER (strategic) - I did submit an enhancement idea for this configuration that Dynatrace Support has access to to be made available to us. 

----------------
167.12:

I've made a product idea for this functionality.Manually set timout for dynatrace problems - Dynatrace Community

----------------
168:

 
 
 
 
 
Welcome back, Community friends! 
 
Dynatrace Community updatesAugust's hottest discussionsAugust's product idea updatesMust-see threadsAugust's top contributors Additional round of applauseMembers of the MonthThe August challenge overviewEvents and webinars in September - save the date!What's to look forward to?Thanks for being with us! Stay safe in September!
 
 
 Dynatrace Community updates
 
‌‌ As some of you have probably already noticed, Dynatrace Community Redesign 2.0 went live! We've changed how a few crucial forum widgets and spaces look, as well as introduced some new functionality. Make sure you're up-to-date with the latest UX&UI changes we've prepared together with our Community Interns 
 
 We went through all the valuable feedback you shared in the the Community Survey 2023, and prepared a summary article showing the main areas of improvement to our forum we've recognised. Check it our and share your thoughts in the comments 
 
 Our new dedicated forum for Dynatrace Managed has been filled with a lot of interesting content in August. We highly recommend to dive deeply into this space!
 
 New month has come, so as the new edition of the Developer Newsletter ‌‌ Grab a cup of your favorite beverage and check it out!
 
 August's hottest discussions
 




#


Community topics


Views




1.

easyTravel Documentation and Download
1,251



2.

Dynatrace associate exam preparation
652



3.

Dynatrace Associate certification mock exam
456



4.

Introducing Monaco 2.0 – Dynatrace Configuration as Code
384



5.

HTTP status codes 970-979
339



6.

 Product Idea Newsletter for August 2023
318



7.

Take the Gamer Challenge! ‌‌
257



8.

No module named 'cx_Oracle'
252



9.

Introducing new Kubernetes metrics for improved user experience (and deprec...
250



10.

Take the Guru Challenge!‌‌ ‌
244



 
 
 August's product idea updates
 
Since May 2023, product idea updates have been published in the dedicated Product Idea News! At the beginning of every month, expect a new summary published in the Feedback Channel forum. Explore the latest edition 
 
 
 
To get notified about next editions of the newsletter, follow the label 
 
 
 
 Must-see threads
 
Content you can't miss:
 
 How to coach Dynatrace to a new junior colleague (Plan for the first 3 months) 
 Disrupt or be disrupted, the story behind the Dynatrace reinvention
 New Dynatrace playground tenant with Grail/New UI
 
 
Tips and tricks:


 

Entity Selector host custom metadata 
Services Delivery Certification - CloudOps Tips
Automation to get CSV file with links to all available packages and updates
PRO TIP - Dynatrace Account Management API Postman Collection
IAM Policy - Read and write permissions on extensions configurations
 Services Delivery Certification - Observability learning materials



 



 
 Dynatrace Tips & Tricks - Episode #12 on JavaScript in Dynatrace Best Practices with Arijan Zenuni
 Dynatrace Tips & Tricks - Episode #13 - Automatic Infrastructure Rightsizing with Dynatrace Workflo...
 Dynatrace Tips & Tricks - Episode #14 - Argo Rollout with Dynatrace
 Dynatrace Tips & Tricks - Episode #15 - SLO Error Budget Burn Rate Based Alerting
 Dynatrace Tips & Tricks - Episode #16 - Dynatrace Tenant Review


 
Troubleshooting articles:
 
 How to interact with trusted events in a Browser Clickpath Monitor
 How to create Browser Monitor that does not ignore certificate errors
 How can I find which ActiveGate my Browser Monitor execution ran on?
 HTTP Monitors: How to sign a request for AWS Signature Version 4
Heads-up from Dynatrace:
 Memory leak in Node.js OneAgent 1.269
 Browser Monitors run on public locations failed for a period of time on 3rd/ 4th July 2023 (Resolved...
 Dynatrace CVE status (Common Vulnerabilities and Exposures)
 
Share your feedback:
 
 Kubernetes log - feedback channel
 Make K8s metadata (labels, annotations, ...) a first-class citizen
 
 August's top contributors
 
 
 
 
We're glad our Community is full of helpful and engaged people! Thank you: 
@natanael_mendes, @marina_pollehn, @islam_zidan, @Iplinsky, @vpatre, @asant257, and @SOBE!
 
Additional shout-out to those whose names we see on this list for the first time!
 
  Additional round of applause
 
 @Pawel_Zalewski, our Community challenge first-timer! As well as @Iplinsky, @Malaik, @islam_zidan and @Mohamed_Hamdy and other sharing with the Community their candidates for Gurus and making us all a little better with touching and inspiring stories 
 @AntonPineiro and @marina_pollehn, for being the most active lurkers on our forum (right after the Community team )






 
 






 Members of the Month
 
 
 
Make sure to read the latest interviews with our extraordinarily engaged Community member and Dynatracer of the Month! Get to know them better either from a professional or after-hours perspective! 
 
 The August challenge overview
 
In August we've asked Community users to share the names of people who were important to you on your journey, made a huge impact, or simply inspired you over the years. Let's explore the main details of the Guru Challenge.
 
 The "Guru" badge
 
 Impressive 21 answers submitted so far!
 Personal and worldwide known role models!
 A lot of touching stories from users!
 
 
Share your role models in the Guru Challenge, it's not over yet!
 
 Events and webinars in September - save the date!
 




 
 Thursday, September 7, 2023
 Get to Know Dynatrace Demo


 
 Tuesday, September 12, 2023
 Office hours for Dynatrace App development




 
 Tuesday, September 12, 2023
 Drive Innovation, Speed, and Agility by Upgrading to...


 
 Wednesday, September 20, 2023
 Dynatrace INNOVATE | APAC




 
 Wednesday, September 20, 2023
 Observable Lightning Talks September 2023


 
 Thursday, September 28, 2023
 Progressive Delivery with Feature Flags




 
 
 What's to look forward to?
 
  New Community Challenge - September 18, 2023
Engagement in the latest Community Challenges is utterly amazing! We're not slowing down with this format, preparing something exciting in the second half of September. Stay tuned for more informations!
 
 Community Newsletter layout refresh
Community Redesign 2.0 is only a bus stop in the further, exciting trip. In September we're preparing a general update of the Community Newsletter concept, implementing some more unique, innovative, and even more user-friendly features. Expect some "wow" effect very soon 
 
 
Thanks for being with us! Stay safe in September! 
 

----------------
168.1:

Love this!

----------------
168.2:

Cool!!!

----------------
168.3:

great monthly update  

----------------
168.4:

Thank you 

----------------
169:

ive created a dashbaord with like 10 things that we regards as KPI metrics for a stress test, 
CPU
Memory
HTTP errors
GC errors
GC Cycles
availability
database calls
 
This is agreat dashboard because it gives you all the info in a single glass pane view, now the problem is each of the tiles is tiny and you cannot even make out the X or Y axis labels, can we please have a click button on any tile that will simply expand the tile into a large view {pop up} at the moment i have to click and go to explorer which is still ok but its a different view, why can we not just have the same view on a larger screen

----------------
169.1:

Hi,Unfortunately this is not possible. You can only click on a particular tile on the dashboard and see the details on a separate tab (for eg. Data Explorer).Radek

	Have a nice day!


----------------
169.2:

Hi @Jamz,Surely an interesting idea, some dashboarding tools offer that indeed. I would suggest this to Dynatrace via the product ideas so that they can review it. GRAIL brings a lot more dashboarding options so maybe it would only be integrated there.   

	A Dynatrace Professional nerd working for Eviden


----------------
169.3:

thanks for this Marina i will do this now

----------------
169.4:

Product idea is here.

	Consultant


----------------
170:

Hi all,We're looking at the next phase of our DynaTrace deployment and how we can automatically act on certain problems (automatically execute scripts, restart services, etc.).  Can anyone advise which tools have been used and integrated into DynaTrace to perform the orchestration of these remediation tasks.  I have no preference, so any recommendation would be gratefully received!Thanks,Richard



					
						Solved!
					
					Go to Solution.




----------------
170.1:


Ansible / Ansible Tower is one that comes to mind. We have an integration with it that's discussed here:https://www.ansible.com/blog/enable-self-healing-applications-with-ansible-and-dynatrace https://www.dynatrace.com/news/blog/connect-dynatrace-with-ansible-tower-to-trigger-your-it-automati... https://www.dynatrace.com/news/blog/set-up-ansible-tower-with-dynatrace-to-enable-your-self-healing-... You can use it to kick of defined 'playbooks' in response to certain problems.

----------------
170.2:


James is Exactly right, Ansible tower can be used for auto remediation as well as deployments and can be very useful. I would recommend looking into leveraging the product. 

	-Chad


----------------
170.3:

Do we have a similar one for Terraform in AWS? 

----------------
170.4:

Hi @kvsudheerbabu,Could you please check these links:Docs overview | dynatrace-oss/dynatrace | Terraform | Terraform RegistryGitHub - dynatrace-oss/terraform-provider-dynatraceI hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
170.5:

Thanks for your quick response. How can we use these terraform modules to restart a specific process or host that were reported as part of metric event problem?  ThanksSudheer

----------------
170.6:

Hi @kvsudheerbabu,I have shared those links becasue you can find inofrmation about the DT and Terrafrom integration. I have never used Terrafroam.As in the previous answers in most cases I have met with Ansible Tower job template solution for autoremediation.This is an Azure example: Best regards,Mizső  

	Certified Dynatrace Professional


----------------
171:

Hi all,is it possible to delete an app that have been deployed on dynatrace?We have made a typo an the ID and after deploying the correct one the previuos one is still present, so there is a duplicate in the app-hub..



					
						Solved!
					
					Go to Solution.




----------------
171.1:

Yes, is totatlly possible. Go to settings>monitoring> aplications and you will see the flag to delete this app   

	Dynatrace Professional Certified


----------------
171.2:

Sorry, but I was talking of a custom APPLICATION developoped and deployed in dyanatrace like this:npm run deploy You can see the duplication here.Thanks,Andrea

----------------
171.3:


oh, ok. I looked at the documentation page and found thisuninstallApp​appEngineRegistryAppsClient.uninstallApp(config): Promise<void>Uninstall an app.Required scope: app-engine:apps:delete Documentation Page:https://developer.dynatrace.com/reference/sdks/client-app-engine-registry/

	Dynatrace Professional Certified


----------------
171.4:


Hi @andreaCaria,
the simplest approach to uninstall an app is via Hub app. You can find the documentation at https://www.dynatrace.com/support/help/manage/hub#uninstall

----------------
172:

Hello, theres an way to do a dashboard with all the ips that made an especific request?

	Dynatrace Professional Certified




					
						Solved!
					
					Go to Solution.




----------------
172.1:


@natanael_mendes,I didn't try this before, but you can create a Request Attribute for client IPs. You could then eventually create a metric with that count, and IP as a dimension. You could then be able to dashboard it. But this approximation has a caveat: it would probably consume a lot of DDUs...

	Antonio Sousa


----------------
172.2:

yeah, i saw this. but i was trying to do without create any metric

	Dynatrace Professional Certified


----------------
172.3:


Check this out, and see if it helps: https://community.dynatrace.com/t5/Dashboarding/Multiple-access-attempts-from-one-IP/m-p/216668/high...

	Site Reliability Engineer @ Kyndryl


----------------
172.4:

So nice to see someone has done it 

	Antonio Sousa


----------------
173:

Hi，
Does anyone know the proper way (gracefully) of shutting down a server?
Overview:

AIX server was shut down for maintenance purposes.
one agent is not running after restarting the server, later it was due to endpoint corruption which has been claimed was due to the server being shut down ungracefully.

Problems:

It was likely due to shutting down the server ungracefully. Hence I wanted to ask what's the way of shutting down the server gracefully.
As per documentation (https://www.dynatrace.com/support/help/platform-modules/infrastructure-monitoring/hosts/monitoring/h...), shutting down properly would return as shutdown (in grey) NOT offline (in red). 
I have tried a few methods to shut down the server, however, all returned as OFFLINE (in red) which implies an ungracefully shutdown.

Below are the shutdown methods I have tried:
-Shutdown via virtual manager-Command shutdown-Command sudo shutdown-Command poweroff-Command init0-Command shutdown -P +1
Conclusion:

I wish to understand the proper way of shutting down the server which will return as SHUTDOWN not OFFLINE.
And also how Dynatrace classifies graceful and ungrateful shutdowns although we are using the correct shutdown events as per above.




					
						Solved!
					
					Go to Solution.




----------------
173.1:

This is really good question. I too want to understand this. Appreciate is someone from Dynatrace product team can pick this up. 

----------------
173.2:

Hello @kwangxi,Can you share details about the endpoints corruption?We have similar issues since few months after the restart or some servers and the corruption of files like deployment.conf.Thanks for your help.

----------------
173.3:

Hello,
One thing you'd want to make sure you rule out is the part in the documentation shared about "alerting on graceful shutdown" and making sure that setting is turned off. 
 
 

----------------
173.4:


What I got from Doc on this: https://www.dynatrace.com/support/help/platform/davis-ai/anomaly-detection/adjust-sensitivity-anomal....By default, Dynatrace alerts only about unexpected outages.During a graceful shutdown, the host outage is expected and the operating system has sent a shutdown signal notifying OneAgent that an operator is intentionally shutting down the host.If OneAgent receives no shutdown signal, the shutdown is classified as unexpected.You can opt-in to receive notifications about graceful shutdowns as well.

	Dynatrace Certified Professional


----------------
174:

Hi,Does the Services Delivery Certification have to be renewed every 2 years like the professional one?



					
						Solved!
					
					Go to Solution.




----------------
174.1:


Yes, it expires after two years.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
174.2:

Yes, after two years.Take a look  

	Dynatrace Professional Certified


----------------
175:

Hi,After we have changed our deployment to bg-deploy, the key requests that were defined in our Dynatrace environment have stopped functioning, because they depend on the service Id, which changes every deployment.Therefore, we request that the key requests will be based on the service name instead of the Id.Kindly assistThanks,Boaz



					
						Solved!
					
					Go to Solution.




----------------
175.1:


I moved this to the Dynatrace Open Q&A because service detection is not related to or handled by extensions.Key requests have to be associated with a single service and service names are not guaranteed to be unique, so grouping them by a service name is not an option. You may need to look at some of the service detection options that are available to find a way of ensuring that new services are not detected in such scenarios where you would prefer to keep them the same.https://www.dynatrace.com/support/help/platform-modules/applications-and-microservices/services/serv... 

----------------
175.2:

Hi James,We have a service naming rule, which aggregates all the blue-green services to a single service. Hence, we were expecting that the key request feature will work, because the service name is unique. The filtering is important for us, because we need to opt-out irrelevant customer-related info.

----------------
176:

Problem statement:I noticed that Dynatrace captured and counted periodical network activities like embedded chats as part of the loading duration. This creates false timings e.g. 100 sec instead of 10 sec for finishing functional XHRs. Or worse it leads to a timeout 180 sec. That's indeed not what is expected from the measurement of action duration.
As per support, there is no possibility to exclude requests from waterfall analysis.What are the capabilities of managing wich resources/xhr will be included in the duration and what is the best practice for adjusting measurements?

----------------
176.1:

Hello,https://www.dynatrace.com/support/help/shortlink/user-action-metricsThis page details the different metrics around performance that are considered for various user actions. One possibility is looking at the metrics for the XHR action that appears to be taking longer than expected, and see if one of the other metrics seems to be a more accurate indicator of what you're looking for. For example, try looking at the "HTML Downloaded" or "Response End" metric.

----------------
176.2:

I know this, using other metrics is not an option. Need to know the root cause of the problem and fix it.Then use the required metrics with confidence as a source of truth.How are You supposed to make automated quality gates if metrics are broken? Workaround is not an option for high-quality products like Dynatrace.

----------------
177:

Hi there,I need help querying SSL certificates with exp_days == 30 and set that as warning and exp_days == 10 critical    

----------------
177.1:

Hi @Maelam,It is not a Notebook but you can try it and use the created metric information on your Notebook.SSL Certificate Monitor | Dynatrace HubExample: Created metric with lot of dimension for splitting the cert information: You can check you this or other extensions health (eg. errors) with this:Extensions Health | Dynatrace HubI hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
177.2:

Hi @Maelam 
you can query it with such query
fetch `dt.entity.python:certificate_monitor_certificate`
| fieldsAdd lifetime, status = if(lifetime[end] -10d < now(), "", else:if(lifetime[end] -30d< now(), "🟡"))
and this would be the result
 
 
 
 
Best,Sini

----------------
178:

Hi guys,Customers are asking how dynatrace decide if service calls are sync one or async?Didn't find any documentation on that Anyone can elaborate on this please?Yos

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
178.1:

Thread id

----------------
178.2:

hi , could you explain more, please?I see in one transaction, calls are marked as asynchronous, but the thread ID and trace ID are the same for all these calls. As per my understanding, for an async call, a new thread is created. 

----------------
178.3:

I believe - it is by traces, you should see polling requests after the initial.if you have polling indeed.If this fire-and-forget async not sure.

----------------
179:

Hello, is there any material, taste of the test or something that helped you guys preparation in this journey to get the ACE certification?

	Dynatrace Professional Certified




					
						Solved!
					
					Go to Solution.




----------------
179.1:

Ace certification?  Dynatrace Associate Certification?

	Dynatrace Certified Professional


----------------
179.2:

Service Delivery Certification

	Dynatrace Professional Certified


----------------
179.3:

ok, normally they have a practice test when you go to preparation but not sure on that cert as I don't have access to it.  You must be a partner.

	Dynatrace Certified Professional


----------------
179.4:

im a partner but the only material that i have are videos

	Dynatrace Professional Certified


----------------
179.5:

@natanael_mendes it's just the course - the videos + the mindmap (attached to the course). Be sure to check this existing thread.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
179.6:

Are you referring to the ACE Services Partner or Autonomous Cloud? 

----------------
179.7:

Services Delivery Certification

	Dynatrace Professional Certified


----------------
179.8:

Hi @natanael_mendes I passed this certificate. It is entirely sufficient for you to pass by carefully studying the videos you will find on University.Radek

	Have a nice day!


----------------
179.9:

@radek_jasinski Hi Radek, do you got any tips for the exam? where focus more or what its most important?

	Dynatrace Professional Certified


----------------
179.10:


What you should pay attention to is the best practice mentioned in the videos. There have been many questions where they have just asked about such details. They also asked what Dynatrace modules (One, Community, Support etc.) could be found on the Dynatrace website and in the DT console. There were certainly questions about the mind map.In general, if you watch the videos 2-3 times with understanding and take notes, you should pass without a problem:)Radek

	Have a nice day!


----------------
179.11:

thank you @radek_jasinski , you got linkedin?

	Dynatrace Professional Certified


----------------
179.12:

Yes I have Linkedin, but switched to private mode because I had terrible spam from recruiters . If you want to catch me directly it's best on FB or Instagram. You can find me as Radek Jasiński (city: Warsaw) 

	Have a nice day!


----------------
179.13:

i wasnt able to reach you, can you send some link or connect with me in linkedinhttps://www.linkedin.com/in/natanael-mendes-517111189/

	Dynatrace Professional Certified


----------------
180:

Hi Community,We're monitoring process availability of few processes via declarative process grouping, if we intend to turn off monitoring for a specific process against specific OS, would be feasible to do so?In my case, process command and executable path is common for Linux and AIX, requirement is to disable alerting only for AIX.Many thanks

----------------
180.1:

You can create Maintenance Window for this  Take a look on this documentation pagehttps://www.dynatrace.com/support/help/observe-and-explore/notifications-and-alerting/maintenance-wi... settings>preferences>maintenenace window. Any doubts feel free to ask 

	Dynatrace Professional Certified


----------------
180.2:

Thanks much. I've done this way.1. Tag process group instance for which alert suppression required via auto tagging2. Filter this created tag in the maintenance window.

----------------
180.3:

Hi @ssamraj ,If you are looking to turn off monitoring you can do so a couple of different ways. One of the ways is to explicitly state which group you want to monitor by turning it off environment-wide here: Another way, since you mentioned that you have declarative process grouping is to specify custom process monitoring rules here:https://www.dynatrace.com/support/help/shortlink/process-group-monitoring#rulesHope this helps!  

----------------
180.4:

@Taylor-Sanchez wrote:Hi @ssamraj ,If you are looking to turn off monitoring you can do so a couple of different ways. One of the ways is to explicitly state which group you want to monitor by turning it off environment-wide here: Another way, since you mentioned that you have declarative process grouping is to specify custom process monitoring rules here:https://www.dynatrace.com/support/help/shortlink/process-group-monitoring#rulesHope this helps!  Thanks for your response. My requirement is to turn of this specific process monitoring only for AIX systems and it should stay intact with Linux. Please note that exe name and path are same for both OS.

----------------
180.5:

This is where robust tagging comes into play. As you stated, you want to disable the monitoring for a given process name where the underlying OS is AIX. If you create an auto tag rule for the OS value, it can be populated from the host level and down into the PGs, PGIs, and Services. Once that is completed you can then create the Maintenance window to say suppress alert notifications for <PGName> where the tag is OS:AIX. 

	-Chad


----------------
180.6:

Thanks for the response.. Almost, I did the same.. Please see my reply to nataneal_mendes.

----------------
181:

Hi,Is there a metric we have that we can use to show the number of Problems being reported to Servicenow?Maybe somehow we can retrieve the Integration that was called for a Problem? Would that help?I need to display this as a Dashboard in DT (preferably with the new Dashboards).or should I be running a custom extension to query servicenow and push the data to DT as a custom metric?Let me know if there is another solution for the same. Thanks,Vishnu

----------------
181.1:

You should be able to use this metric dsfm:server.notifications.problem_notifications. And then filter by alerting profile and select the one for SNOW. Let me know if that's what you were looking for  

	A Dynatrace Professional nerd working for Eviden


----------------
181.2:

Hi,So this i was able to pin the metric to Classic dashboards.How do i do the same for the new Dashboards? using Grails, i dont see these metrics in the docs.fetch events| filter dsfmlike that, doesnt work...

----------------
182:

Hi there my plugin.json file reporting VALIDATION_ERROR_ILLEGAL_PROPERTY_CHANGE error when uploading plugin to Dynatrace when using type "Password" in the schema file.
When changed type to "String" plugin is uploaded but issue is password is visible in the endpoint configuration. plugin_sdk verify_plugin does not report errorStarting oneagent_verify_pluginChecking plugin metadata: /opt/dynatrace/remotepluginmodule/plugin_deployment/custom.remote.python.mobilitysendgrid/plugin.jsonValidating plugin.json against schemaPlugin custom.remote.python.mobilitysendgrid is validplugin_sdk version: plugin_sdk 1.273.138.20230829.095340Anyone had this issue?Thanks



					
						Solved!
					
					Go to Solution.




----------------
182.1:


You cannot change the property type without removing and readding the extension (which means you need to recreate all endpoints).
You can solve it by renaming the property in the plugin.json and the python code at the same time as changing the property type. That will just require you to re-add the password into the endpoints.

----------------
182.2:

Thanks for your reply Mike_L. Will try this and keep you posted.

----------------
182.3:

Thanks @Mike_L after removing the existing plugin and executed the plugin upload command, no errors encountered.Marked your reply as the solution. Thanks again!

----------------
183:

Hi,This page describes OneAgent features for Perl process monitoring:https://www.dynatrace.com/technologies/perl-monito...I'm not seeing any detailed metrics for my Perl processes, like descibed in the pic "Hard(ware) facts". Of course that is since deep monitoring for the process is disabled. And I can't enable it, since it's not even listed under the Supported Technologies settings. So far it seems like there is no actual support for additional metrics regarding Perl, it's just like any "unsupported" technology. The only visible difference is that Perl processes have a different logo compared to the processes labeled in the category "Other". The actual data is just the basic process metrics like Worker Processes, Responsiveness, etc. - but that's it. Am I missing something?



					
						Solved!
					
					Go to Solution.




----------------
183.1:


Hello,https://www.dynatrace.com/support/help/deploy-dyna...Perl isn't supported technology for deep monitoring by default. You can always use Dynatrace ADK to instrument it to see services and transactions. It is possible, I've done such things before. About additional perl metrics you need to prepare plugin for dynatrace  to see them. Sebastian 

	Regards, Sebastian


----------------
183.2:

Thanks, that's what I suspected. I was thrown off by Perl having its own page like that. To me it doesn't make sense to highlight a technology that's unsupported, it's a bit misleading to be honest.

----------------
183.3:

As you compare Perls page to others, generaly there is true. You see those processes with some bunch of basic metrics. But I understand with you that sometimes those pages are hard to understand. Sometimes clients tell me that he saw something there and I have to clarify his point of understanding. Sebastian 

	Regards, Sebastian


----------------
183.4:

Hi DynaMight Guru,Thank you for your Input.Which you have shared the link is not Working, throwing 404 Error msg. Could you please re share the Link where you can see as Perl isn't supported technology for deep monitoring .Thanks,Ameena.

----------------
183.5:

Hi @pb388 Check Extend AI-based root cause analysis with OneAgent SDK blog There you will see the follows explanation on how you can get code-level visibility also for Perl HTHYos  

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
184:

It would be useful to have TTFB available as an option for USQL. All other Core Web Vitals are available but not this one.

----------------
184.1:

@chris_palmer,In a user action you have multiple TTFB, one for each request.There is a variable serverTime that gives you that information though.

	Antonio Sousa


----------------
184.2:

Thank you for the reply. I'm looking to run a query like this only with TTFB rather than LCP: I spoke to customer support regarding this and they suggested Response Time as an alternative but we didn't feel this was an accurate reflection of TTFB. They also suggested asking regarding TTFB here.

----------------
184.3:

select serverTime from useractionwill get you what you want. Just adapt it to your query.

	Antonio Sousa


----------------
184.4:

Thank you @AntonioSousa.

----------------
185:

Is there any ETA as to when all Dynatrace Metrics will be migrated to GRAIL?  I'm trying to see if I can calculate Visually Complete Times (VCT) excluding Synthetic & Robot users.  As well as a few other users that Dynatrace sees as "REAL USERS" but they are actually service accounts that are being used by other tools in our monitoring tool set.
 
The difference in results via USQL and the Data Explorer is huge.
 
 
 

----------------
185.1:

@apasoquen1 metrics in Grail won't help you to solve this case. But this is already possible by defining your own calculated metric for the web application. Just use apdex as the metric, and add filters (user type, action type, ... ). Dynatrace will create a new metric and will only calculate the metric for the actions passing the filter.  

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
185.2:

I was thinking about doing this.  However, we have other synthetic monitoring tools running tests, that Dynatrace picks up as 'REAL USERS'.

----------------
185.3:

You can add Web crawler header to user agent for tests - they will be marked as ROBOTS

----------------
185.4:

Check your filters and compare results max 30 days (USQL limit).Use the same filters for USQL and Data ExplorerAlso, check if USQL is not limited by samplingResults should be similar.I don't recommend Apdex for low-level KPI (to abstract for developers)

----------------
185.5:

I don't think we have a "master plan" for all metrics yet. But we are actively working on moving them. For instance, I know about...: Application observability solution and the k8s teams are working on k8s metricsInfrastructure metrics are actively worked on but in your case the most relevant ones areDigital Experience and service metrics are also moved but the main missing piece is the possibility of having percentiles in Grail which is a bigger investment that is planned but not finished yet. @fcourbon, our metrics PM, can provide you with more details there. regardsThomas

----------------
186:

We are trying to capture a property of an object that is one of the items in a ValueTuple that is returned by a method of a DotNet classobject.Do we have a chance or will that never be possible? 

----------------
186.1:

You can use deep object access if the method does not return a primitive. If there is no good way to access the value, you can add a simple getter to your application that returns the value you want, than instrument that with dynatrace.

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
186.2:

Hello PA, unfortunately we only have the return value available. Dynatrace does not allow deep object access for that option.

----------------
187:

An error occurred: HTTP Error 431: Request Header Fields Too LargeQuery (on a 30m timer):fetch logs, from:now() - 30m| filter matchesPhrase(content, "[LATEFILE]") and status == "WARN"| fields latefile, {host.name, alias: hostname} The DQL Query doesn't seem to be expensive yet seems to fail randomly throughout the day. I have set the retry to 10x15sec and yet it will still fail all 10. 



					
						Solved!
					
					Go to Solution.




----------------
187.1:


Hi @CameronFW 
 
The reason why you're seeing this problem is, that the selection of too many permissions in the authorization settings of workflows can trigger such error. The short term workaround is to only select the permissions really needed ( Workflows > settings > authorization settings). The team is already working on a long-term solution. Unfortunately I can't provide you an ETA yet.
Best,Sini

----------------
188:

Hello Team,
On one of my production platforms pod autoscaler has stopped after installing Dynatrace.
Please suggest a solution, as it is critical for us to autoscale up and down pods automatically to save cost nd tp serve traffic effectively.

----------------
188.1:

Hi @shubham1413,Which pod autoscaler do you use? I would check it at my clients in order to share with you the experience.Best regards,Mizső

	Certified Dynatrace Professional


----------------
189:

Hi guys, im getting this error The controller for path '/rb_bf2****qil' was not found or does not implement IControllerSomeone has seen before?

	Dynatrace Professional Certified


----------------
189.1:

Hi @natanael_mendes ,This seems to be a general area in terms of the .NET space, meaning there could be a variety of reasons as to why you're getting this error. Doing a little bit of research here, I found this StackOverflow post that might be beneficial in your debugging process. https://stackoverflow.com/questions/16444981/the-controller-for-path-home-was-not-found-or-does-not-...In addition, since this could potentially be a .NET issue, you could have problems with the MVC framework. I suggest reviewing the code that you currently have with the exception errors to resolve the issue. Cheers,Taylor S. 

----------------
190:

How can i see a view statement in dynatrace?

	Dynatrace Professional Certified


----------------
190.1:

Hi,I am not sure if you are asking about this, but you have top database statements in Dynatrace.Best regards

	Consultant


----------------
190.2:

but i cant see the "view" statement there

	Dynatrace Professional Certified


----------------
190.3:

Please review:https://www.dynatrace.com/support/help/shortlink/release-notes-saas-sprint-275#bind-variable-setting...Bind variable settings for DPS and Adaptive traffic management Version 3Application Observability | Distributed tracesBind variable capturing can be enabled by all accounts using a Dynatrace platform subscription and tenants that are using Adaptive Traffic Management V3. No additional support request is needed. 

	Dynatrace Certified Professional


----------------
190.4:

Hi @natanael_mendes ,What exactly do you mean by the 'view' statement, or what specific data are you trying to look for? As @AntonPineiro mentioned, most of the information that you're going to want to be able to analyze is going to be in the top database statements.Since Dynatrace captures the DB information from the perspective of the application, you'll be able to see specific queries and modifications as well in the 'Database' section of Dynatrace as well.   Drilling down into this might give you further insight into what you're trying to look for.Cheers,Taylor S.

----------------
191:

Hello Everyone
I hope this message finds you well. I'm currently working on configuring custom alerts in Dynatrace for our AWS resources, and I could use some guidance and advice from those who have experience with this tool. If you have expertise in Dynatrace or have faced similar challenges, your input would be greatly appreciated.
Here's a bit more context about my situation:
Objective: I want to set up custom alerts in Dynatrace to monitor specific AWS resources and trigger notifications when certain conditions are met. This will help us proactively address issues and optimize our AWS environment.
Challenges:


Understanding Metrics: I'm struggling with identifying the relevant metrics and thresholds to create effective alerts. Which AWS metrics should I be monitoring, and how do I determine the right thresholds?


Alert Configuration: Once I have identified the metrics, I'm not entirely sure how to configure the alerts within Dynatrace. What are the best practices for alert configuration?


Notification Integration: We use multiple communication channels for alerts, including email, Slack, and SMS. How can I ensure that Dynatrace integrates smoothly with these platforms for timely notifications?


False Positives: I want to avoid being flooded with false positives. Any tips on fine-tuning alert conditions to minimize unnecessary alerts would be incredibly helpful.


If you've successfully set up custom alerts in Dynatrace for AWS resources or have insights into any of the challenges I mentioned, please share your knowledge. Your experience will undoubtedly help not only me but also others in the community who might be facing similar issues.
Thank you in advance



					
						Solved!
					
					Go to Solution.




----------------
191.1:


Hey Devinmarco,This is a very open ended request and I would highly recommend first narrowing it down.1. Without knowing what is important to you/your team this is difficult to answer. One team might care about network metrics, another about hardware, another about users. Also with over 100s of metrics to pick from relating to many different services (like 80+ supported) there is a lot. However, to get an idea of things that are important, Dynatrace has OOTB alerting available. This is only for a very small few services and metrics but it is there and can give you ideas. You can also look at other alerting options under the same settings to get an idea. Also, to see what metrics are available you can head over to the docs here: Amazon Web Services | Dynatrace Docs2. Try and focus on what someone would consider a problem. There are many different options, different conditions, models, etc so determining the best way to create alerts is very subjective. One alert may require completely different configurations to another. Also I would recommend starting small, ensuring what you have created works, makes sense, doesn't over alert, and then expand.3. Dynatrace supports Slack and Email notifications just fine. For SMS notifications it supports other services that can send via SMS or if your carrier supports it, there are options for sending custom messages to an API or email which can be configured to send via SMS.4. While setting up custom alerts you can see the last 7 days and whether or not those custom alerts would have alerted. This is incredibly helpful as well for setting up alerts just after a problem has occurred because you can tune the alert to not fire except during that problem scenario since you can visualize it right there in the UI. I would really recommend focusing on mission critical services and then expanding the alerts. Try not to look too far out just yet. Find something like Lambdas, or EC2 or something else and focus on just one service first.Hopefully this helps to move things in the right direction. If you have any specific questions follow up and hopefully people can help out!

----------------
192:

Hi Team,I am creating a workflow in the new Dynatrace; this workflow has a DQL query as 1st task, and then in 2nd task(js code)  I want to add this DQL result to the dashboard. Here I want to update the dashboard by DQL results.How to do that? Somebody, please provide some examples.I read somewhere using document service, we can create a notebook, similarly, I want to create a dashboard using js code.Regards,HerambRegards,Heramb Sawant



					
						Solved!
					
					Go to Solution.




----------------
192.1:


Hey Heramb,
You can use the new platform API for this. To get there you would go to https://Your.Tenant.Address.com/platform/swagger-ui/index.html?urls.primaryName=Document%20Service#/. Currently this is documented in our developer docs here https://developer.dynatrace.com/platform-services/#swagger-ui
Then from there you could follow the following steps to see how the document creation and editing process works as well as the format for requests:

GET /documents to find the ID of an example dashboard or notebook you want to use as a template.
GET /documents/{id}/content to get the layout that you would need to mimic.
POST /documents to then post an example document.

Once you have a template setup you would then in your script just do POST /documents to create a new document with your desired DQL OR do PUT /documents/{id}/content to update an already existing document with your DQL query.
Hope this helps!

----------------
192.2:

Hey thanks Fin for your help. This will definitely help to move forward.Regards,Heramb

----------------
192.3:

Hey ,I m trying to update my own dashboard( having id f3592b6d-XXXXXXXX411ae35) using  "updateDocumentContent" method but getting below exception Uncaught (in promise) 409: Share of type 'environment' with access 'read' already exists for document 'f3592b6d-XXXXXXXX411ae35'. errorRef: 282afd6c-2125-435b-8af5-f92fd10d670aWhat needs to be changed?? and What should be the value of optimisticLockingVersion???Regards,Heramb

----------------
192.4:

Hey ,Somebody please help me on this.Regards,Heramb

----------------
192.5:

Hey Heramb,Hopefully you've already come across the solution. I was unable to find anything regarding that exact error or reproduce it but as for the optimisticLockingVersion field, if you first GET the document you'll get a version returned. This is NOT the version in the document JSON but in it's metadata. The optimisticLockingVersion field needs to be this latest version. Every time a document is updated, this version will update and to update it through the API you'll need this latest version every time.   

----------------
193:

SNMP traps are available as LOGs in Dynatrace. Searching SNMP traps seems to be an issue, as searching in content doesn't match a lot of strings I'm seeing in OIDs.How have you been able to search for specific content inside SNMP traps? BTW, this is in Managed, a non Grail environment.

	Antonio Sousa




					
						Solved!
					
					Go to Solution.




----------------
193.1:


Hi @AntonioSousa ! Here are my tips for the "Log monitoring classic" that works with Managed :First you can rename your field if it contains "::" : Then you can to add your field in a custom log attribute :  https://www.dynatrace.com/support/help/observe-and-explore/logs/log-monitoring/analyze-log-data/log-...Finally you can search into it :  Hope it helps.  

	Observability Engineer at Phenisys - Dynatrace Professional


----------------
193.2:

@jegron,This is an exceptional tip!I hadn't had the time to try it out, but worked flawlessly!I believe you should post it in the Tips & Tricks zone, so other Community users might benefit.BTW, I was intrigued about the first step: it might be because "::" are not permitted as keys, or even caps letters being present. Do you have a confirmation why it is needed? Because if it is, I believe it is structural, and not even a Product Idea would be applicable here.

	Antonio Sousa


----------------
194:

I'm currently testing out the Microsoft IIS Extension that's available in the Dynatrace Hub and I'm running into issues.  I have two configurations.  One that is based on Environment and the other targeting a MZ that only has IIS I can see data on displayed on the IIS Overview Dashboard However, looking at the configs I'm running into errors with both configs.  Any tips on troubleshooting this?

----------------
194.1:

i had the same problem. Take a look if the hosts that you selected have IIS on it

	Dynatrace Professional Certified


----------------
194.2:

That is what my second config has.  I have it based on a MZ that contains hosts with IIS installed.

----------------
194.3:

Open one of this logs and share with us please

	Dynatrace Professional Certified


----------------
194.4:

Here is a screenshot that chat support provided from the OneAgent Diagnostics that I've taken.

----------------
194.5:

To me seems like the IIS is not showing up on this host, can you certify that de IIS technology is on this host?

	Dynatrace Professional Certified


----------------
195:

Hello:We have a series of web pages that simply download PDF's.I contacted support today to ask why they did not show up under the pages or page groups defined for the website/application.I was told that "pages and page grouping will only appear if the RUM JavaScript agent is present, as those require a user action or page change to be attached to the events. These are just PDF files, so the browser simply loads the file with no HTML provided by the server." and that "if you wanted to monitor this you would have to wrap the loading of the PDF files in your own HTML to include the RUM JS Agent inside of it," Is there any other way to gain basic statistics on these types of pages?What we are really looking for is "how many times was the page accessed/viewed" This seems pretty basic. How can it be done in Dynatrace Thanks,Chris  

----------------
195.1:

what you can do is observe the action that directly you to this pdf pages, you can create a key user action to observe better like "If i click button A the pdf page will open for me"You can observe how many people clicked on this button. you can try create an request attribute to know with page was created.  Take a look on these documentation pageshttps://www.dynatrace.com/support/help/platform-modules/digital-experience/web-applications/addition...https://www.dynatrace.com/support/help/platform-modules/applications-and-microservices/services/requ... If you got any doubts feel free to ask 

	Dynatrace Professional Certified


----------------
196:

How to stop automatic update of OneAgent on multiple host  via cli  ?



					
						Solved!
					
					Go to Solution.




----------------
196.1:


Hi @PrateekGupta,I would use API calls.First: Environment APIv2 Monitored entities:GET / entities provide a list of entities, you can filter only for hosts by type("HOST")Second:Configuration API  OneAgent on a host.POST  / hosts/{id}/autoupdate.Here is an example for disable with curl: I hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
197:

i have a process suppose abcd and this process was down in number of hosts between like sept 1 - sept 3 how can i get the list of hosts where it was down    

----------------
197.1:

The best way is to create an Automatic TAG and assign it to a process and mark it so that it also covers hostshttps://www.dynatrace.com/support/help/manage/tags-and-metadata/setup/how-to-define-tags 

	Have a nice day!


----------------
198:

Hi,in our custom app, we would like to reindex the user into a classic dynatrace app in the same tenant by passing some parameters in the URL.In particular, we would like to land on the APP: dynatrace.classic.query.user.sessions and change the get parameter:gtf and query in such a way the user see immediately the result of the query.On the documentation we have found this approach:https://developer.dynatrace.com/reference/design-system/preview/navigation/AppLink/The implemented code is this:  <AppLink appId="dynatrace.classic.query.user.sessions">
    Link to user session
 </AppLink>   But it seems does not allow us to pass the parameter and the app is loaded with the default ones...Is there any way to achieve what we are looking to do?



					
						Solved!
					
					Go to Solution.




----------------
198.1:


Hi @andreaCaria,
the AppLink component does not work for this case since the app dynatrace.classic.query.user.sessions does not support any intents.
For this particular page, you can use the ExternalLink like following:




import { getEnvironmentUrl } from '@dynatrace-sdk/app-environment';...<ExternalLink href={`${getEnvironmentUrl()}/ui/apps/dynatrace.classic.query.user.sessions/ui/user-sessions/query?gtf=-2h&gf=all&sessionquery=SELECT+*+FROM+usersession`}>A link to User Sessions</ExternalLink>


Please let me know if this works for you!



----------------
198.2:

It worked perfectly,thank you 

----------------
199:

How to use davis copilot? Is available?

	Dynatrace Professional Certified


----------------
199.1:

I agree with you that documentation should be made available. For the moment, information about Copilot is only on the blog.

	Have a nice day!


----------------
200:

The chart showing the data found that there was data loss



					
						Solved!
					
					Go to Solution.




----------------
200.1:

Hey @Lwl can you give us more details about?

	Dynatrace Professional Certified


----------------
200.2:

 That's it. Don't know what to do

----------------
200.3:

Hi @Lwl ,How's it going? Previously, was the data collection correct?Have you tried doing a restart of OA or AG? R.

	Have a nice day!


----------------
200.4:

Hi @radek_jasinskiIt's good to see you againNo attempt has been made to restart AG or OA 

----------------
200.5:

There seems to have been this situation before, but it has not been solved, and now I want to solve it.

----------------
200.6:

I had a similar situation when mcafee antivirus was running on the system. Have you checked the log entries?

	Have a nice day!


----------------
200.7:

Checked the logs, and there's not much difference between them and normal host nodes

----------------
200.8:


I believe you should report the case to support. You may have many variables as to why this data is not being collected correctly.

	Have a nice day!


----------------
200.9:

Yes, I will do that

----------------
201:

Hello,
 
Datacenters names are not auto-detected correctly on Smartscape for all my Vmware clusters. I know that we could configure it manually through "Settings -> Web and Mobile Monitoring -> Geo Locations".
But do you have an idea about the VMWARE parameters, configuration or properties which are used by Dynatrace to autodiscover the datacenter name ?
 
The goal is to adapt the Vmware deployment procedure to be persistent on Dynatrace.
Thank you.
Regards Aurélien.
 

	Observability consultant - Dynatrace Associate/Pro/Services certified




					
						Solved!
					
					Go to Solution.




----------------
201.1:


FYI,After my investiguation, the VmWare property "datacenter" is automatically collected by Dynatrace when VmWare monitoring is enabled :  I don't know yet why this property is sometimes not available for some Vmware clusters because it seems to be a mandatory property (version ? permissions ?...).If none applies, then there is the fallback to trying to resolve the IP address of the sender of the OsiInfo message to a geolocation (cf support). The workaround is to map IP to location manually on "Settings -> Web and Mobile Monitoring -> Geo Locations". Regards, Aurélien.    

	Observability consultant - Dynatrace Associate/Pro/Services certified


----------------
201.2:

Hello Aurelien,did you find a solution to deactivate this DC autoaffectation of a vsphere label  ?did you find a proper way to manage Datacenter in Dynatrace ? without "Geo Locations" method feature more dedicated of the customers api access  Thanks for your time

----------------
202:

Hi, 
Currently, i have notice an unusual amount of android 10 sessions. These sessions are usually web application sessions opened on a mobile using a chrome browser. 
After further read ups, i am aware that for web applications, Dynatrace uses the user agent string sent by the browser to distinguish user sessions of real users from synthetic and robots. It also leverages this string to identify operating systems and device types like desktop, tablet, or mobile.  
I also came across this article about Chrome's user‑agent reduction. In the article it states that "Starting in Chrome 110 (February 2023) we are gradually introducing a fixed value for Android version and device model—the default value will always be Android 10 on a model K". 
This leads to my suspicion that chrome's user-agent reduction might be the reason for unusual number of android 10 sessions. 
Does anyone else experience the same issue and if there is ways to counter it. Else would it be part of dynatrace's roadmap to fix this such that we get an accurate operation system. 
Thanks in advance!
 

----------------
202.1:

i never heard about this but i dont think the Chrome agent is the cause. Dynatrace can identify real users and bot users. You can investigate de IP of this users. Tell me if i can help you in some way

	Dynatrace Professional Certified


----------------
202.2:

Hi @natanael_mendes, I see, however our user sessions are indeed real users and not bot users. It is just surprising to see so many android 10 users using chrome mobile, since android 10 is considered an old version and the last security patch was feb 2023. Hence we were not expecting to see much android 10. On the contrasting note, Chrome mentioned in the article that " Starting in Chrome 110 we are gradually introducing a fixed value for Android version and device model. Instead of seeing something like Android 13 on Pixel 7 the default value will always be Android 10 on a model K. " seems to match better with my suspicion because chrome 110 is a relevantly new version that rolled out this year.  

----------------
202.3:

Maybe some user start the session multiple times and this is causing the number of the android 10 sessions. Hope this help you. If you got any doubts feel free to ask

	Dynatrace Professional Certified


----------------
202.4:

Managed to do more analysis on the data, they seems to be different users. From my finding i realised that:This issue only affect users with browserFamily = Chrome browser.For browserMajorVersion before Chrome Mobile 110, i am about to capture the different osVersion e.g. Android 10, 11, 12, 13.However for browserMajorVersion from Chrome Mobile 110 onwards, osVersion are recorded mostly as Android 10. Though there are some outliers e.g, browserMajorVersion = Chrome Mobile 114 and osVersion = Android 11, however the ratio is like 1:100. As for device column they are null, maybe Dynatrace only capture device for mobile application. hence i am not able to verify if model K is being captured. Thanks.  

----------------
203:

I am starting to grab more container-level statistics within Kubernetes/OpenShift. Someone mentioned to me about the importance of measuring CPU throttling. What is the best metric in DT for measuring CPU throttling?
I am already grabbing container CPU, millicores, millicores and maximum. Is there an actual statistic for the percentage or degree of throttling?
Any help would be appreciated.
Thanks,
Lou



					
						Solved!
					
					Go to Solution.




----------------
203.1:


Yes exist, the metric is literally CPU throttling haha"The CPU throttling metric tells you how long the application was throttled, so you can determine where more CPU time would have been needed for processing. This usually happens when the containers don't have enough CPU resources (limits) in the workload definition. This might affect the performance of the processes and applications running inside the containers." Take a look on this documentation pagehttps://www.dynatrace.com/support/help/platform-modules/infrastructure-monitoring/container-platform...You can also see the number of running pods versus desired pods for every cloud application.

	Dynatrace Professional Certified


----------------
203.2:


Hi @crabbylou,I usually use these ones at clinets:(  builtin:containers.cpu.throttledMilliCores:avg:parents:parents:splitBy("dt.entity.cloud_application_instance","dt.entity.cloud_application"):sum    / builtin:containers.cpu.usageMilliCores:avg:parents:parents:splitBy("dt.entity.cloud_application_instance","dt.entity.cloud_application"):sum    * 100):splitBy("dt.entity.cloud_application_instance","dt.entity.cloud_application"):setUnit(Percent):sort(value(avg,descending)):limit(5)  or builtin:containers.cpu.throttledMilliCores:filter(series(avg,gt,10)):parents:parents:splitBy("dt.entity.cloud_application_instance","dt.entity.cloud_application"):avg:auto:sort(value(avg,descending)):limit(5)  I hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
204:

 
Issue Solution Tasks Alternative(s)



How do we change the default port settings to 443 from 8443 for the cluster that set up a cluster version earlier than 1.166?
Changes in the required file.
The mentioned steps need to be followed.
NA



 

Environments preserve port settings from the previous versions.
Cluster version later than 1.166 exposes port 443 for incoming access from OneAgent as default.
There is no API or automated way of configuring the port setting for new nodes that get added to the cluster, i.e. They need to be manually configured from the CMC page as shown in the below screenshot.

 
 
 
Steps must be followed to change default port settings to 443 from 8443 for the cluster that set up a cluster version earlier than 1.166.:

The port value is taken from “security-Gateway/config.config.properties” from the seed node, which happens during the node installation.
To fix the issue, replace “port-override=8443” with “port-override=443” in the above file.
The configuration changes need to be made on all the nodes.
After this fix, the next newly installed node should use the 443 port.
If the warning message below appears, you can proceed with the configuration changes as this is an exception case.

 

You do not need “custom.properties” file to be changed and the configuration can be applied to the above-mentioned file.
There is no requirement to restart the server applications after implementing the changes as when a new node is installed, the installer asks the seed server for the ActiveGate configuration file, which is taken by the seed server directly from the disk.


----------------
204.1:

Thanks for the tip @Akki 

----------------
205:

Hello:I am trying to make sure I am reading a trace correctly. I had to redact some information for security purposes, but the stricture is the same in the trace. Please look at the images provided.We have an agent on both the database and the application server.In the first image we see that the database lists "Failed Requests" (not failed connection)1- Does this mean that the database server saw the request? Or is that information being populated from what Dynatrace gathered from the Application server (and then inserted it into the DB page/overview) In the second image I dive into one of the failed requests "Failed Request" traces from the image above.At the outermost layer is the Microservice.1 action.I then see Microservice.2 action (indented 1 level) make several successful requests from Database AFollowing that I see Database B attempt to be accessed. (and create an error)That last action in indented 1 level less than the Database A actions.So, does this mean it is part of Microservice.1 's actions?If so, is it showing that Microservice.1 waited to access Database 2 until Microservice.2 was completed? The last image is what shows up under the error message for trying to access Database B.It says it is a SqlClient Exception, but was it generated from the database itself? Or from the Microservice attempting to access it?  Thank you all so much for any clarifications.If you have any good suggestions for sources that delve into reading these traces with examples please share! Kindest regards,Chris     



					
						Solved!
					
					Go to Solution.




----------------
205.1:


I believe the error is in the database, giving a timeout to process the request. Since the exception is in the database.The oneagent in the database is only for infra-only monitoring.The quality metrics are taken from the services that communicate with it. But if you look at the exception you can see that the request hit the database but took time to process 

	Dynatrace Professional Certified


----------------
205.2:

Thank you Natanael. So when you say "The exception is in the database" Are you saying that the exception listed was created from the SQL server and not the application server making the request? When I see the icon/image of the MS SQL database next to the entry [UserAssociations].[User_find] is this telling me that the data is from the SQL server? (And not from the application server?)In the case of a timeout, I guess it makes a difference as to who is reporting it. If the SQL server is the one reporting it, then we can safely say the message arrived. However, if the message is from the calling application server, then something may have happened on the way to the SQL server.  Knowing which server is providing that information helps immensely. Let me know which it is if you could and thanks! 

----------------
205.3:

Yes, I think the problem is in the sql server, with all the evidence you provide I come to that conclusion. You could try service backtrace or distributed trace to see if the component is taking longer to run. Feel free to ask if you got any doubts

	Dynatrace Professional Certified


----------------
206:

 
Hi Team, 
we have Nginx running on Google Container-Optimized OS version 105 LTS that we need to monitor via DT. 
Is the version supported? 
 



					
						Solved!
					
					Go to Solution.




----------------
206.1:


Hi,You can see here all technologies supported and versions.Best regards

	Consultant


----------------
206.2:

Hi Anton , Thanks for your answer. according to the documentation ONLY version 89 is supported , Is there a plan to add more versions soon ?

----------------
207:

Does anyone know how to get a list of entities that have problems "only"? What endpoint to be used with parameters? if it is possible please show me example, Thanks



					
						Solved!
					
					Go to Solution.




----------------
207.1:


Do you mean the only entities that have open problems? If so: you could you the normal problem api. These APIs give information about impacted entities / root causes etcetera. Using a small script you can easily get a result that provides exactly what you'll need.https://www.dynatrace.com/support/help/dynatrace-api/environment-api/problems-v2/problems/get-proble... Kind regards,Michiel 

	#Performance matter!


----------------
207.2:

Hello. I am trying similar thing: I want to list all open problems but only with some fields. I want problem title and hostname. Unfortunately I can't get the hostname into the resulting JSON. I tried name, hostname, but it doesn't put it there and I get result completely without hostnames or with hostnames but also with many other information which I don't want. The best thing would be to be able to get a CSV format result, but I guess this is not possible?

----------------
207.3:

Hi there, So basically the API gives you a LOT of field. You can't reduce this according to the documentation:A list of additional problem properties you can add to the response.The following properties are available (all other properties are always included and you can't remove them from the responseevidenceDetails: The details of the root cause.impactAnalysis: The impact analysis of the problem on other entities/users.recentComments: A list of the most recent comments to the problem.To add properties, specify them as a comma-separated list (for example, evidenceDetails,impactAnalysis).Second part is the question about HOST. What do you want to know exactly? The root cause?In the JSON response there will be something like this:rootCauseEntity": {        "entityId": {          "id": "PROCESS_GROUP-511F9ECC59F68DD4",          "type": "PROCESS_GROUP"
        },
        "name": "Oracle Database"
      } In case this is a HOST, you will have the host ID there.  If you want to customize something to XML, you'll probably need to write a simple custom script. by the way: adding field evidenceDetails can give you more infomation about the host. 

	#Performance matter!


----------------
208:

Just curious if anyone is using MIRTH Connect, or has in any way managed to integrate it into Dynatrace? We are in the process of evaluating developing an extension for this interface engine, but would like to know if anyone has done something with it?

	Antonio Sousa


----------------
208.1:

@AntonioSousa do you have any updates or insight on this integration that you can share with the community? 

	-Chad


----------------
208.2:

Yes, we have been developing an extension integration with Mirth. Are you a Mirth user?

	Antonio Sousa


----------------
208.3:

That is great news! Not that I am aware of.

	-Chad


----------------
208.4:

Hi, I am  working on project where mirth technology is implemented. Is the the solution to monitor mirth using DT available now?

----------------
208.5:

@SeemaP,Mirth data is available through an extension we have developed. It is not available in the Hub though. Please reach out directly with me if needed. 

	Antonio Sousa


----------------
208.6:

Hi @AntonioSousa , how is this project going? I would like to take a look on this extension you've created!!

	Site Reliability Engineer @ Kyndryl


----------------
209:

Is there a way to connect Power BI to Dynatrace?



					
						Solved!
					
					Go to Solution.




----------------
209.1:


Hi,indeed, this is possible. See the following video: https://www.youtube.com/watch?v=LpH8IlUeBSU&list=P...Thorsten

----------------
209.2:

Thank you 

----------------
209.3:

The video is not available. could you please reupload the video?

----------------
209.4:

Hi @dynamic Try Dynatrace and PowerBI - Taming IT Change Risks through Automation

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
209.5:

Thank you for the informative webinar.  I think I have a better idea as to how to connect Dynatrace with Power BI.  I would like to know how to export/import user sessions from Dynatrace into Power BI.  We use both Power BI and Splunk here and I know our data analytics team and business teams would benefit greatly with at least the user session export into Power BI.

	Dynatrace Certified Professional


----------------
209.6:

Talk with your Dynatrace support team, we got a sample BI report/integration for problem reporting from our support team that really accelerated the process for us. 

----------------
209.7:

You can also take a look at this post.I've added a detailed description and guidelines.

----------------
210:

I have a specific use case, but I think the answer can be more generic. I would like to get a list of extensions and return them in a table, the problem is I get an 'Extension crashed' error when just trying to query the api:import { extensions_2_0Client } from "@dynatrace-sdk/client-classic-environment-v2";

export default async function() {

  const data = await extensions_2_0Client.listExtensions();
  return "test";
}This is the example code from the documentation: Classic Environment V2 | Dynatrace DeveloperI can't even move forward from here, I was expecting that I would get a list of extensions that I can loop through. 

----------------
210.1:

Hello, I see you said that you are getting an "extension crashed" error. Did you make sure that you had the correct permissions from the following list? Required scope: environment-api:extensions:read Required permission: environment:roles:manage-settings Thanks

----------------
210.2:

That is definitely the initial problem as I was able to capture the error, but I have added them to one of my group policies and it is still happening, so presumably I have not done that correctly.I have double checked my effective permissions and I have both of the required scope and permissions, so now I'm stuck.

----------------
210.3:

I verified everything was setup correctly, and contacted support. They had the same issue with the 'listExtensions' call that I did so they are escalating to the product team.I was able to do what I wanted using the Problems API, so I have working code now, just not with the API I want.I will report back here when there is a solution.

----------------
211:

Does anybody have experience/suggestion how to route certificate alarms coming from cert extension (SSL Certificate Monitor | Dynatrace Hub)
I'm trying test and implement this extension which, after some applied fixes by Dynatrace, does what it should do. However I'm experiencing one big gap which support can't solve and suggesting an RFE which I can't imagine someone didn't solve it already.
The extension is detecting certificates on eg host and creates a custom device for each certificate. The extension is generating alarms once certificates are (going to be) expired. The problem is that I can't send these alarms to the right teams. I can't autotag these items eg based on the host they're detected on or the domain the certificate applies for.
Does anyone have experience with this and/or even solved this issue? I would have expected that via a entity selector rule using the relation or regex auto tag should be possible. Once autotagged the correct alarmprofile can be applied and alarms will be sent out to the right to solve the issue.
Looking forward seeing the responses,
Kind regards,
Daan

----------------
211.1:

You can select all certificates related to a host with an entity selector like:type("python:certificate_monitor_certificate"),fromRelationships.runsOn(type(HOST), entityId(HOST-xxxxxx))Apply this entity selector to an automatic tagging rule, you can get results like: Would that solve your use-case? 

----------------
212:

I am trying do up my skills with the new dashboards, does there any place that i can get some ideas how to do it?

	Dynatrace Certified


----------------
212.1:

Hi @Iplinsky ,Aside from the documentation, which you can find in the following link, a good starting point would be to get familiar with DQL. This provides the most customization when it comes to creating these dashboards, considering you can import these data visualizations directly from the Notebook itself. There's an interactive tutorial that was recently created, I would suggest starting from there to get familiar with the functionality as you translate those skills to the newer dashboard capabilities. Dashboards: https://www.dynatrace.com/support/help/observe-and-explore/dashboards-newLearn DQL: https://www.dynatrace.com/hub/detail/learn-dql/Cheers,Taylor S.

----------------
212.2:

Hello
We are currently working on providing a solution to share workflow ideas with new users.
In the meantime, I recommend taking a look at the Observability Clinics or other video materials - they often feature templates for dashboards and notebooks which can be downloaded from Github:

Getting started: GitHub - dynatrace-perfclinics/dynatrace-getting-started: This repository contains supporting materi...
Open Observability: GitHub - dynatrace-perfclinics/OpenObservability-clinic

Christian

----------------
212.3:

I wonder if the BizOps Configurator will (can?) eventually contain new dashboards as well.https://dynatrace.github.io/BizOpsConfigurator 

	Kind regards, Frans Stekelenburg                 Certified Dynatrace Associate | measure.works, Dynatrace Partner


----------------
213:

Hi,
Is there a way to change chart background color based on specific thresholds/metric values?For example I would like specific chart to turn Red if the value on the chart drops below given value.
Thank you,Martin

	Digital Performance Optimizer




					
						Solved!
					
					Go to Solution.




----------------
213.1:


@Martin K. This is currently not available in the product. Id recommend tossing in a RFE if your organization will need this functionality. Request a RFE:https://answers.dynatrace.com/questions/ask.html?space=482

	-Chad


----------------
213.2:

Are you a thrill seeker who thrives by being on the cutting edge and love using Chrome to access your Dynatrace dashboards?If you answered yes to both questions, I would suggest trying out this Chrome Plugin.https://chrome.google.com/webstore/detail/dynatrace-dashboard-power/dmpgdhbpdodhddciokonbahhbpaalmco

----------------
213.3:

Holy cow that is awesome, first time seen it. This is awesome. The math and Sankey is awesome!

----------------
213.4:

Yes, I just learned about in the last week or so, and had a great internal session about it this week at our virtual services conference.  The Sankey is really awesome, math is great, coloring based on thresholds...all very cool stuff.

----------------
213.5:


Something like this is now possible, see https://www.dynatrace.com/support/help/observe-and-explore/dashboards-classic/charts-and-tiles/visua... .

----------------
213.6:


Hi all,If you will use Single value or Table views you will find a switch called link background to thresholds that will answer @mkulov old request.  Just wonder why its shown up in different sections in each of this 2 options   HTHYos   

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
214:

 
Dynatrace Community is built around customers’ needs. Why? Because the best product created is the one “co-created” with its users. This forum is a space for giving feedback, sharing ideas, and creating opportunities for learning. But not only for customers but also for Dynatrace employees who can have contact with direct users of the product.
Our Employee Member of the Month, Stefanie Pachner is one of the people who sees a lot of value in the cooperation between these two sides and that’s why she is involved by the heart by helping Community users.
How does she do it and what is the purpose behind it? We invite you to read more about the @stefanie_pachne ________________________________________________________________________________________________________________________________________________
Can you share some details about your past? What is your story, how it happened that you decided to work in the IT / APM area, and how did you become a Dynatracer?
When I was a girl, no one talked about cybercrime or IT security – that’s why I initially didn’t know how to fulfill my dream of working as a technical engineer in the area of law and order. I grew up in Upper Austria and liked the idea of programming and designing software so I attended the Higher Technical School in Perg and the University of Applied Sciences in Hagenberg. Early in my career, I came to Technical Support as it combines Engineering and Communication in a broad technical field. I joined Dynatrace Tech Support in 2015 and currently focusing on security topics after finishing my master’s in Information Security to make my dream come true. 
Can you tell us a little bit about your job? What exciting things you’re working on that you can share?
I love my job, also thanks to the flexibility, trust, and guidance given by Dynatrace, my manager Klaus Prückl, and the collaboration within the Global Technical Support team and with other teams like Product Security and Privacy. Recently, we worked on the Global CVE DB which has been publicly made available at cve-status.dynatrace.com. Generally, I am promoting the idea of customer self-service in different projects like proactively sharing knowledge with customers in the Heads-up from Dynatrace forum.What makes you excited about being a part of the Dynatrace?
In a nutshell - especially the vision of the product – we're revolutionizing the APM market with constant innovation.
 LEFT: Coming back after maternity & education leave to the Hagenberg Office. / RIGHT: Dynatrace party on the MS Digital Mile in the Linz harbor.
How is the Community helping you in your job? Why do you think it’s worth being a part of the Dynatrace Community? What best advice can you give someone who just started using Community?
The Community allows customer self-service and reduces our Support afford.  
If you’re new to the Community, I suggest checking the User Guide and exploring the Troubleshooting and Ideas forums.
Tell us something about you that most people don’t know. What is your biggest joy or passion in life? 
My biggest passion is beach volleyball. I love to play with the Hagenberger beach volleyball team or Dynatracers. And in winter, I enjoy skiing with family and friends. I also played soccer for a long time, and I am now focusing on teaching it to the U6 team (kids from 3-5 years). LEFT: Dynatrace playing beach volleyball tournament at Business Cup Perg. / RIGHT: Austrian Winter Wonderland, where I love to ski in winter.
What’s one thing on your bucket list? Your dream?
Continue traveling the world once kids are ready to, snorkeling again on the Maldives in awesome coral fields or with whale sharks. And before that, hold time still when kids have a cute moment  - with best greetings, especially to all working parents of “crazy” little kids out there. ________________________________________________________________________________________________________________________________________________Stefanie, thank you for everything you do. We see that Community is a strong element you consider helpful in becoming the best engineer in the area of law and order. 

----------------
214.1:

Well deserved accolade! You have great vision and collaboration skills. Great work!

----------------
214.2:

Congrats @stefanie_pachne 

----------------
214.3:

Parent of “crazy” little kids here. Congrats, @stefanie_pachne !!Being a beach volleyball player, I bet you have heard of some Brazilian players in that area, right?

----------------
214.4:

Congratulations @stefanie_pachne. Beautiful Ski Center

----------------
214.5:

Congrats @stefanie_pachne . Very good work on thinking, creating, organizing and maintaining the Global CVE database. We use this database quite often and is of great value to to us and to our customers. 

----------------
214.6:

Congrats, @stefanie_pachne !!

----------------
214.7:

Hi @stefanie_pachne,First of all Congratulation!!!  cve-status.dynatrace.com is a very useful information source for me when I have to talk with clients IT sec teams. Keep going on!!!Best regards,Mizső

----------------
214.8:

Congratulations @stefanie_pachne.

----------------
215:

Hi,I want to give access to a few specific users to monitor their applications in a "soft way".The idea would be to hide the "problems" view from and other menus/dashboards to avoid being contacted by these users while we work on resolving the current issues.Have you been faced with this kind of situation? any idea on how to manage it?Thank you,Moh.



					
						Solved!
					
					Go to Solution.




----------------
215.1:


Regarding the Persmissions, You cannot specify which menu to hide or which page to access...At this time its very light. You can open a RFE for this. Have a good day.

	Sharing Knowledge


----------------
215.2:

Hi,Maybe creating a specific management zone for them where those entities are not included.I do not see a way to hide problem's menu.Best regards

	Consultant


----------------
215.3:

Hi AntonPineiro,Thank you for your suggestion, I already thought about it, but I am looking for a kind of matrix that manages both rights and the partitioning of data by "application/MZ"

----------------
216:

Dynatrace 1.261 introduced new API /api/v2/monitoringstate  for querying status of monitoring for process group instances. At first sight this looks as a replacement for legacy process group API v1.It seems this API is not yet in the documentation , @jaroslaw_orlows can you give a look?
I'd like to ask folks using the API already how can you use it on a larger scale?
I ran into two issues severly limiting usage of this API:

API does not support pagination and the response is limited to 500 entities. How do you use it? Querying entities indivudually is not really an effective way of API usage.
API does not seem to support filtering for monitoring state itself - typically I need to query processes where there an issue (like severity equals warning). There is just the healthState(UNHEALTHY) - which does not reflect the monitoring state.


	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
216.1:

im right there with you on this @Julius_Loman. Have you made any headway with this?

	-Chad


----------------
216.2:

@ChadTurner no, there is no progress I'm aware of. In the current state is not useful for us, we are still using the legacy v1 smartscape API for process groups (mostly detecting processes requiring restarts).

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
216.3:

Yeah I tend to fall back on the Legacy methods even when they are "Deprecated" lol 

	-Chad


----------------
216.4:

Looks like some of my wishes sometimes make it to the product In 1.275 there is finally pagination supported as described in release notes. Still waiting for filtering on the monitoring states 

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
217:

Hi Team,I am trying to run  DQL in notebook to  fetch metric & timeseries data  but getting the below error,1. Command - timeseries avg(dt.host.cpu.usage)   Error - Unknown command: timeseries!
2. Command -  
     fetch metrics
     | filter startsWith(metric.key, "dt.process.jvm.threads.count")   Error - Unknown record type: metrics.Please help me on this.Regards,Heramb Sawant

----------------
217.1:

Hi Heramb,
Unfortunately, none of the two commands is currently available for you. But the team is currently in the progress of deploying it. You can expect the command to be available within the next couple of days.
Best,
Sini

----------------
217.2:

Hi Sinisa,Any update on deployment. Those 2 commands ( fetch metric & timeseries) are still not available  and this is the  huddle for us to implement SRG for metric evaluation.Regards,Heramb Sawant

----------------
217.3:

Hi,Any update on this??Regards,Heramb Sawant

----------------
217.4:

Hi Heramb,
I'll email you so we can share and discuss more details around your specific tenant.
Take care,
Nick

----------------
217.5:

HI NIck,Even I am also searching for same thing. Please let me know once it is available. 

----------------
217.6:

Hi @ShyamPradhan,
This turned out to be a permissions issue. The required permission policy is called "Storage Default Monitoring Read". This should be added to the desired user groups in the account management page.
To do this, follow these steps:

Log in to your Dynatrace account as an account admin (https://account.dynatrace.com/my/accounts) and select your environment.
Go to "Identity Management" and select "Group Management."
Choose the user group that should have access to Grail monitoring data.
Scroll down to "Environment permissions" and click the expand button for the environment.
Change to the "Policies" tab and bind the "Storage Default Monitoring Read" policy.

The image below provides a visual representation of this process.
 
I hope this helps!
Take care,Nick

----------------
218:

Hi,
I have an azure with multiple web app service which I need to monitor them via Dynatrace (SaaS).
I have a local AG as well.
now to monitor them via oneAgent extension is easy,but if I like to send the traffic to AG and then to Dynatrace, do I only need to put the URL of the AG(and how to get the URL of AG)in this case I believe the AG needs to be publicly accessible as well, correct?
Regards,

----------------
218.1:

Hi @ahmadjamali ,How are you currently monitoring the Azure applications (if you have them set up already)?If you're wondering about how to integrate the monitoring with the ActiveGates, you can do so via the documentation here:https://www.dynatrace.com/support/help/shortlink/azure-monitoring-guide#capable-activegateIn addition, I'm not sure what you mean by the URL of the AG, but you will need the AG to be accessible on the ports listed here(note that this is for a Linux server, but the idea generally remains uniform). By publicly accessible, it will need to accept incoming connections on port 9999 and make outgoing connections to port 443. Adjusting the necessary firewall configurations should allow these configurations to work as expected.https://www.dynatrace.com/support/help/shortlink/sgw-install-linux#allow-connections-through-firewal...Cheers,Taylor S.

----------------
218.2:

Hi Taylor,Thank you for your reply.Currently No azure monitoring is in the picture.I would like to only monitor azure app service (web app) and not the whole azure, which is mentioned in below article:Integrate on Azure App Service for Windows | Dynatrace DocsI am just wondering about the integration with the AG, as in azure it does ask for environment URL or AG URL,so simply typing the AG URL is enough (if the AG is publicly accessible on 9999) to route the traffic to AG or extra action needs to be taken as well. Please let me know if we can change the URL and port (AG URL and 9999) to our custom URL and port.Regards, 

----------------
219:

Has anyone had success in working with Genesys to get some monitoring points within the Genesys IVR and Pindrop auth framework? 
Seems like a huge gap for Dynatrace to not have a plugin. 

----------------
219.1:

I don’t think so. Please go with a product idea. 

----------------
219.2:

hi, we have GTSL - Genesys PS product and it integrates in our environment with an API layer with PinDrop API. We use Dynatrace to monitor GTSL hosts and the API interfaces. 

----------------
220:

Does Dynatrace support Oracle HTTP Server on Solaris SPARC 11, and if it does, could someone provide assistance with the configuration process?



					
						Solved!
					
					Go to Solution.




----------------
220.1:


Yes, it is supported. Please see also this thread. For installation follow the documentation for Solaris. Since Solaris does have only the PaaS OneAgent version, you have to include the preloading of the OneAgent in the execution context as described here. Most likely you need to include it in the startup script, or in the Apache envvars file (not sure if OHS is using it) and also it seems OHS has also its own variable definition methods.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
221:

Hello Guys im having a problem with this regex i want to bring only CARLOS ALBERTO CAINO And i did this cleanup rule  but the e-CPF and the numbers still showing up. How can i do this?

	Dynatrace Professional Certified


----------------
221.1:

Hi @natanael_mendes ,I'm not too sure if you know of this website, but you can use it to test various cases of RegEx alongside Python if you're familiar with that as well. https://regex101.com/In addition, inputting your test case into the RegEx generator on that site, I was able to generate this. Hopefully it serves as a starting point:   Best Regards,Taylor Sanchez

----------------
221.2:

Also adding that you can use that RegEx generator to test out your specific String. I've noticed that the appending values are blotted out, so if it's sensitive information and the RegEx provided doesn't work, you can adjust as needed for your use case. 

----------------
222:

 
hello,I have a question about how I can correct this server.sh service, after I have updated my operating system from red hat 7.9 to 8.6, after the restart it is not loading the server.sh.I get these details.
 
Redirecting to /bin/systemctl status dynatrace-server.service● dynatrace-server.service - Dynatrace ServerLoaded: loaded (/etc/systemd/system/dynatrace-server.service; enabled; vendor preset: disabled)Active: failed (Result: exit-code) since Fri 2023-09-15 13:44:51 -05; 7min agoProcess: 171705 ExecStart=/opt/dynatrace-managed/server/services/server.sh start (code=exited, status=2)Tasks: 2 (limit: 32768)Memory: 341.7MCGroup: /system.slice/dynatrace-server.service└─7664 /opt/dynatrace-managed/server/dynatraceserver -config /opt/dynatrace-managed/server/conf/dynatraceserver.ini -bg
Sep 15 13:44:51 dynaservamt3.vuce.gob.pe systemd[1]: This usually indicates unclean termination of a previous run, or service implementation deficiencies.Sep 15 13:44:51 dynaservamt3.vuce.gob.pe systemd[1]: Starting Dynatrace Server...Sep 15 13:44:51 dynaservamt3.vuce.gob.pe server.sh[171705]: Starting Server ...Sep 15 13:44:51 dynaservamt3.vuce.gob.pe server.sh[171705]: Launcher PID: 7664, main PID: , NOT listening on ports: 8021Sep 15 13:44:51 dynaservamt3.vuce.gob.pe server.sh[171705]: Starting Server ... the launcher is running, it should restart main process soonSep 15 13:44:51 dynaservamt3.vuce.gob.pe systemd[1]: dynatrace-server.service: Control process exited, code=exited status=2Sep 15 13:44:51 dynaservamt3.vuce.gob.pe systemd[1]: dynatrace-server.service: Failed with result 'exit-code'.Sep 15 13:44:51 dynaservamt3.vuce.gob.pe systemd[1]: Failed to start Dynatrace Server.Redirecting to /bin/systemctl status dynatrace-security-gateway.service● dynatrace-security-gateway.service - Dynatrace Active GateLoaded: loaded (/etc/systemd/system/dynatrace-security-gateway.service; enabled; vendor preset: disabled)Active: inactive (dead) since Fri 2023-09-15 13:04:03 -05; 48min agoProcess: 160363 ExecStop=/opt/dynatrace-managed/security-Gateway/services/security-gateway.sh stop (code=exited, status=0/SUCCESS)Process: 32886 ExecStart=/opt/dynatrace-managed/security-Gateway/services/security-gateway.sh start (code=exited, status=0/SUCCESS)Main PID: 34668 (code=exited, status=143)



					
						Solved!
					
					Go to Solution.




----------------
222.1:

The error message you're seeing in the systemctl status output indicates that the Dynatrace Server service failed to start. Here are some steps you can follow to diagnose and potentially correct the issue:1. Check the logs: Look into the logs generated by Dynatrace Server for more detailed error messages. You can find these logs in the Dynatrace Server's log directory, which is typically located at `/var/log/dynatrace/`. Look for any specific error messages or stack traces that might help you pinpoint the issue.2. Review the systemd service unit file: Make sure that the systemd service unit file `/etc/systemd/system/dynatrace-server.service` is correctly configured for your Dynatrace Server installation. Check that the `ExecStart` line points to the correct `server.sh` script and that all required environment variables or configurations are set. You might need to update this file if paths or configurations have changed after your OS upgrade.3. Permissions and Ownership: Ensure that the `server.sh` script and all related files and directories have the correct permissions and ownership. The user account running the service should have appropriate access to all necessary files.4. Check for missing dependencies: After upgrading your operating system, some dependencies or libraries required by Dynatrace Server may have been updated or removed. Check if there are any new dependencies needed by Dynatrace Server, and make sure they are installed on your system.5. Systemd Service Reload: After making any changes to the systemd service unit file or other configurations, reload the systemd manager with the following command to ensure it recognizes the changes:```bashsudo systemctl daemon-reload```6. Try starting the service manually: You can attempt to start the Dynatrace Server manually to see if it provides more detailed error messages. Use the following command:```bashsudo /opt/dynatrace-managed/server/services/server.sh start```This might give you more immediate feedback on what's causing the issue.7. Check for resource constraints: Ensure that there are no resource constraints like low memory or disk space that might be preventing Dynatrace Server from starting properly.8. Check for configuration changes: Review any configuration files that Dynatrace Server relies on (e.g., `dynatraceserver.ini`) to ensure they are still valid and compatible with the upgraded OS.9. Check for SELinux or AppArmor: If you're using SELinux or AppArmor, ensure that the policies are correctly configured to allow Dynatrace Server to run.10. Contact Dynatrace Support: If you continue to face issues, consider reaching out to Dynatrace support for assistance. They may have specific troubleshooting steps or patches for compatibility with Red Hat 8.6.Remember to make backups of any configuration files or settings before making changes, and proceed with caution when troubleshooting system services.

	Dynatrace Professional Certified


----------------
222.2:


Hi @Vuceti ,I think this question could best be answered by the Dynatrace Support team by adding some additional files from the logs that are collected by Dyntrace to troubleshoot the issue. Link: https://support.dynatrace.com/In addition, this would allow for you to give context to Support Engineers by providing the Log Output. The most relevant logs in the Dynatrace files would be: Server Launcher LogsServer.0.0.loglaunc-logging.logYou can also download the SupportArchives as a Zip file and append it as a whole. 

----------------
223:

Does anyone know if there is template dashboard presets available for Istio\Istio service mesh KPIs available?  If so where can they be found?



					
						Solved!
					
					Go to Solution.




----------------
223.1:


Hi @DAVID_JAUREGUI1 Have you already checked this?Istio Service Mesh | Dynatrace HubI hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
224:

Hello, i need help to make a regex \n \n <strong>e-CPF:</strong> LUIZ CLAUDIO GOMES DA SILVA - 279\n \nTo output only LUIZ CLAUDIO GOMES DA SILVA

	Dynatrace Professional Certified




					
						Solved!
					
					Go to Solution.




----------------
224.1:

Hi @natanael_mendes, assuming that name is a placeholder. You can use:/[[:upper:]]+[[:blank:]]+/gm 

	The true delight is in the finding out rather than in the knowing.


----------------
224.2:

 Im getting this

	Dynatrace Professional Certified


----------------
224.3:

Hi @natanael_mendes,you can also use the following for user tagging regex cleanup rule  

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
224.4:

i tried this too

	Dynatrace Professional Certified


----------------
224.5:

The sample that i have is this  \n \n <strong>e-CPF:</strong> LUIZ CLAUDIO GOMES DA SILVA - 27\n \n

	Dynatrace Professional Certified


----------------
224.6:


Hi @natanael_mendes,I've tested it and it works with the sample you've provided, you need to add "space" after ">"> (.*?)-    

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
224.7:

i used your code to do what i wanted, was not the solution for real but was very very helpful. thanks alot

	Dynatrace Professional Certified


----------------
224.8:

@DanielS thanks for providing the regex to complete this ask. @natanael_mendes - https://regex101.com/ is a great site to build and test your regex. I highly recommend it. using it, I was able to validate Daniels Solution:   

	-Chad


----------------
224.9:

I tried but the Dynatrace Regex is different from others

	Dynatrace Professional Certified


----------------
225:

i am trying to install a Nagios activegate extension and one of the requirements is a license. Problem is I am not sure which license they require; dynatrace, nagios or if the extension has a license of its own. Kindly assist



					
						Solved!
					
					Go to Solution.




----------------
225.1:


@sbundi are you trying to install the Nagios integration extension? This one is a separately licensed extension developer by Alanata (Dynatrace Partner). Please reach out to dynatrace_integration@alanata.sk for a trial license if you are interested.You can find more about the extension here: https://alanata.atlassian.net/wiki/spaces/DTNAGIOS/overview

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
225.2:

Question out of curiosity... What does Nagios offer that would not be same as just placing the Dynatrace OneAgent on the hosts? Thanks!

----------------
225.3:

@larry_roberts Reasons for the extension vary, however typically customers do have some investment in their Nagios installation and want to use that data - such as custom integrations or hardware monitoring. It's also not uncommon for customers to have limited Dynatrace licenses (budget) and cannot cover the whole environment with OneAgents.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
225.4:

Makes sense. Thanks!!!!

----------------
226:

While right now we don't have mechanism to do automatic alerting based on key-transaction and key-user action, is it possible to add at least a red-color-dotted line in custom chart?
This way, I can still at least ask NOC team or L1-support team to look at their TV screen and do ticket escalation manually, and eventually answer the client's ultimtate question of "we can do alerting based on business transaction in AppMon, I want to get something similar or analogous to that in Dyna Managed"
 



					
						Solved!
					
					Go to Solution.




----------------
226.1:


Why don't you subscribe a service method and set a threshold or adapt the baseline for that subscribed key request?

----------------
226.2:


There is no way to add threshold lines to charts in dynatrace yet.But automatic alerting based on key user action and key requests is possible. You can modify the baseline behavior or set static threholds for those.

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
226.3:

Wolfgang was a minute faster  The same is possible for key user actions and should do what you want.

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
226.4:

I have this same question. It makes sense to add this feature to the custom charting. This way while we look at the dashboards we would come to know if anything is crossing the thresholds. Plus one more point to make this request a requirement is the X & Y axes of the charts are not static, it is dynamic. Hence when we have a lot to monitor on a dashboard it becomes too hard to identify if the spike is really a spike or a normal transaction within the threshold. This becomes clear only when we look at the chart closely to understand what is the x/y axes of the chart pointing at.Alerts come under the problem tile and if there is a very sensitive application where there will be constant alerting, this gets missed out or it becomes over alerting.Please, this is a very needed requirement. Please do not ignore this feature request and provide workarounds. Kindly consider this. I hope you understand the concern.

----------------
226.5:

This is possible now, see https://www.dynatrace.com/support/help/shortlink/visualization-graph#thresholds .

----------------
227:

Hello Guys,
 
Is there a way to pin output from either seasonal baseline or auto-adaptive threshold to a dashboard because I'd like to add such tile as a way to have an insight whether an alert might pop up?
 
 
Regards,Vasil



					
						Solved!
					
					Go to Solution.




----------------
227.1:


Hi @Vasil_Penev,I think this is not available, however, you can create a graph tile on the dashboard and select the last 7 days for instance then apply a baseline to the Graph tilealso, you can check Prediction-based anomaly detection that might help using the parameter predict=true to Dynatrace Metrics API v1 request, for more details check the following URLhttps://www.dynatrace.com/support/help/shortlink/anomaly-detection-prediction#application-load-predi...note that the prediction will be calculated for the next 30mins only as I remember.

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
227.2:

This is true, but you can't currently display the baseline on a dashboard - it's only visible in Data Explorer.

----------------
227.3:


Hi @Vasil_Penev There is a product idea for that which is currently under review, you can share your use case there for better reach.https://community.dynatrace.com/t5/Product-ideas/Option-to-apply-Seasonal-baseline-intelligence-to-A... BR,Islam

	Dynatrace Certified Professional - Dynatrace Partner - Yourcompass.ca


----------------
228:

Please help us with the solutions for the status codes this issue is appeared on Extensions for Hp Proliant and Hp Chasis. 
Dyntrace error Failed to assign monitoring configuration to ActiveGate. Reason: INVALID_CONFIG_ERROR:Invalid configuration: Duplicated Host address / port (ip: 0.0.0.0, port: 161); [status code=32];
 
Failed to assign monitoring configuration to ActiveGate. Reason: DEVICE_CONNECTION_ERROR:Status DEVICE_CONNECTION_ERROR (38) returned from 1 agents (10.********: Agent(10.********): GetBulk timout args: 1.3.6.***** : request timeout (after 3 retries) [status code=38])

----------------
228.1:

Hi,Is it the same configuration log ? It seems you have a wrong entry in your configuration :Duplicated Host address / port (ip: 0.0.0.0, port: 161)Could you fix it ?

	Observability Engineer at Phenisys - Dynatrace Professional


----------------
228.2:

No Duplicate entry for device.  And no configuration gaps. 

----------------
228.3:

Hmm.Did you configure it through API or GUI ? Could you share your configuration payload (with anonymized IP of course) ?   

	Observability Engineer at Phenisys - Dynatrace Professional


----------------
228.4:

Using GUI for configuring the devices.  

----------------
228.5:

Regarding duplicate issue you should create a configuration with 1 host, then add gradually others to identify why it failed.Regarding timeout issue :Try to run snmpwalk from the AGIf it works well you can adapt SNMP settings in your configuration:Increase timeout if the device is far away from AG and you have lots of OiD to pollReduce Max repetitions to 50 if you have an MTU issue (reducing response payload)    

	Observability Engineer at Phenisys - Dynatrace Professional


----------------
228.6:

Could you please provide the right snmpwalk command to check connection establishment. We ran the below snmpwalk command from AG server but we received the timeout error.snmpwalk -v2 -c  public <IP Address>

----------------
229:

Hello All, Currently I'm testing Dynatrace on my dev environment.I want to temporary disable the oneagent monitoring for it so it will not consume license.Is there any way to disable monitoring on node of kubernetes cluster instead of manually disable it one by one? Thank you in advance.



					
						Solved!
					
					Go to Solution.




----------------
229.1:


Hi @agylpradipta,I thnik you should try the combination of Monitored entities and Settings objects API. Enable/Disable by settings objects API: I hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
230:

I'm new to Dynatrace so bare with my dumb questions here 
What I need is to make Dynatrace to watch a very simple log file in text format , check for a specific value and raise an alert if found.
So far I was able to specify a custom log source under a process that produces my logs but it seems Dynatrace does not want to monitor it. Why is that?
 
Also , I stumbled across log processing rules and I 'm struggling to create my own to simply find a word sequence there. All examples seems related to known logs from web servers like nginx /haproxy and includes some pretty complex data manipulation. Plus, It seems that logs should be in JSON format? At least that what's required for Rule Testing section..
I have a feeling that I've missing something obvious here - can you point me to the right direction how can I:
- add a text log file to Dynatrace
- add a rule to simply check for words "exit code XXX"
- raise an alert
 
 
 



					
						Solved!
					
					Go to Solution.




----------------
230.1:

Hey, you can use some rules to do this.Check this documentation if you use classic v2https://www.dynatrace.com/support/help/observe-and-explore/logs/log-monitoring/log-processing Check this documentation if you use Grailhttps://www.dynatrace.com/support/help/observe-and-explore/logs/log-management-and-analytics/lma-use... 

	Dynatrace Professional Certified


----------------
230.2:


Hi @olegus,Could you please check my pervious posts about log monitoring.Solved: List log files for a metric - Dynatrace CommunitySolved: Application Log monitoring - Dynatrace CommunityAs a first step is to set the log collection:1. At cutom log source configuration you add it manually the test file log  and then2. At log source configuration if DT recognized your text file log after ponit 1. It will be also usefull from other members: Solved: Logs Classic - Log storage configuration vs Custom log source - Dynatrace CommunityMaybe you can use them.I hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
230.3:

Thanks, Mizso,That looks promising, a question regarding switching to Log Monitoring v2 - what will we lose when we switch to v2? We dont monitor any logs yet , but if we do, would we need to redo all log metrics ?

----------------
230.4:

Hi @olegus,I think the answer yes. You will have to redo the log metrics. I was lucky because I switched to v2 quite early I did not have to much v1 configuration. You should do it as soon as possible because as you may read v1 support will end by 01.2024.Regarding the v1 vs v2. No questions, v2 has much more possibilities than v1. I perfer it.Best regards,Mizső

	Certified Dynatrace Professional


----------------
230.5:

Not  sure how this forum works, but the first post that was "accepted as a solution" (not by me btw) did not answer my questions   - it just contains links to general DT docs, which I already read before asking those questions.  I will re-read them and try solutions provided by Mizsco and report back.

----------------
230.6:

Hi @olegus,You can accept my answer also. Thanks in advance.Best regards,Mizső

	Certified Dynatrace Professional


----------------
230.7:

Mizso, 1. So far I created Custom Log Source configuration and I also created Log Storage configuration for the same log file - now i see my log in Logs&Events.2. I've added DQL rule to filter my log data to show only "exit code XXX" lines3. Looks like I'm good to go to create a Log event. 

----------------
231:

We are using Dynatrace SaaS platform and could see a Log monitoring on grail activation pop up in Logs page, but how could i confirm if we are using log monitoring v1 or v2 ?



					
						Solved!
					
					Go to Solution.




----------------
231.1:

If you can see the grail pop up activation you are using log v2

	Dynatrace Professional Certified


----------------
231.2:


You can detect if you have v1 in Settings, but even if you don't have Settings, go to the Classic host page, on the bottom right you should see:  Click on one of them, and if you see something like the following, especially the "Download log files" button, you have the oldest Log  monitoring version...  

	Antonio Sousa


----------------
231.3:

Thanks for the response AntonioSousa, But, i actually don't see logs on hosts page (o logs) , logs are not directly ingested from the hosts but were forwarded using dynatrace-aws-s3-log-forwarder

----------------
231.4:

So, you should have v2 then v1 is only available in older tenants that didn't switch to v2, so they should be pretty rare these days...

	Antonio Sousa


----------------
232:

We are looking to add some request attribute rules for an application and we are wondering if there is a way to filter on the contents of the request attribute value where it either contains or starts with certain values?We are currently using Dynatrace Managed however I would curious to also know if this functionality may exists with Grail.

----------------
232.1:

Yes, its totally possible. Take a look on this documentation pagehttps://www.dynatrace.com/support/help/platform-modules/applications-and-microservices/services/requ... In this screen you can set your filter based on request attribute and put there what you want like if i want a ip that begin with 192 the will retrieve if this value are on the filter  https://www.dynatrace.com/support/help/platform-modules/applications-and-microservices/services/requ...

	Dynatrace Professional Certified


----------------
232.2:

I read the documentation and I understand that we can filter requests using a complete Request Attribute value such as the provided example of "Booking = checkcreditcard" however I could not find where it mentions being able to filter using operators such as "contains" or "starts with" so that we can create a filter like "Booking contains credit".  

----------------
232.3:

You dont need use Contains, if you put Booking= creckThe querie will retrieve checkcreditcard, creckx and crecky

	Dynatrace Professional Certified


----------------
232.4:

I have walked through the example again and there is no way to modify the filter in the Multidimensional Analysis view, it simply uses whatever Request Attribute value that was selected in the Service details page.We are on Dynatrace Managed, could this ability to modify filters as you described be available on SaaS only?

----------------
232.5:

Can you send me a print screen?

	Dynatrace Professional Certified


----------------
232.6:

Sorry for my last post, it was wrong. im searching something that will help you

	Dynatrace Professional Certified


----------------
232.7:

The only way that you can do this is putting the whole IP for search. and insert more filtes based on the request attribute

	Dynatrace Professional Certified


----------------
232.8:

Could you elaborate as to how more filters could be applied?  Let's stay with the IP example where there is a Request Attribute called "SrcIP".  If we wanted to find all requests which contained "192" in "SrcIP" how would that be accomplished?

----------------
232.9:

this is what i was saying, i think thats not possible 

	Dynatrace Professional Certified


----------------
233:

I have around 100 hosts and one of them seems to go offline randomly but then it comes backonline, i dont have access t the OS, how can i find out why it does that? im not sure what is causing this, but can i check with the console to find out what it is, i do have the oneagent logging turned on for the host but cannot find what is causing this not sure i am looking in the right place?  any ideas what else i can do or what to check?



					
						Solved!
					
					Go to Solution.




----------------
233.1:

Hello @Jamz You might have a license quota (host units) issue. Can you verify the license?Regards,Babar

----------------
233.2:


Another option may be to extract a support archive from the OneAgent and review the logs to see there are clues as to why the agents/hosts may be going offline.  The logs may show things like connectivity issues between the agent and the cluster or agent shutdowns, etc.https://www.dynatrace.com/support/help/setup-and-configuration/dynatrace-oneagent/oneagent-troublesh...

----------------
234:

Hello,
I am currently using Couchbase 7.x as my database, and it exposes metrics through the Prometheus Node Exporter on the /metrics endpoint, the database is deployed on a virtual machine hosted in the cloud.
I have been searching for materials or extensions that explain how to retrieve these metrics using Dynatrace, but I have been unsuccessful in finding any.
Additionally, I wanted to inquire if there is a way to simplify the process of importing these metrics into Dynatrace. Is there a method similar to the RabbitMQ extension where manual coding of each metric is not required?
Thank you for your assistance.

----------------
234.1:

You can ingest metrics into Dynatrace, here is a link on how to do it  https://www.dynatrace.com/support/help/dynatrace-api/environment-api/metric-v2/post-ingest-metrics 

	-Chad


----------------
234.2:

Hello glorywe have the prometheus dataSource for Extensions V2.0 that allows you to integrate those metrics directly.https://www.dynatrace.com/support/help/extend-dynatrace/extensions20/data-sources/prometheus-extensi...https://www.dynatrace.com/support/help/extend-dynatrace/extensions20/data-sources/prometheus-extensi...

----------------
235:

I found the way to do it via the v1 API (and it's extremely straightforward...), but as that will one day be deprecated, I'd prefer to write my query to use a v2 method (assuming it exists) so that I don't have to come back to the script years later and have to update it.
v1 method:
Web application configuration API - GET key user actions | Dynatrace Docs
I can query via the Monitored Entities v2 API and get a list of all User Actions for an application, but there's no way I can tell to determine if that action is marked as a Key User Action or not... 
I've tried poking around the Settings v2 API, and the closest thing I found there is a list of Apdex settings for an Application, but those appear to only be the fallback settings for the entire application (i.e. for user actions that aren't marked as Key).  I'm guessing Key User Actions will show up in that same section if we've customized an Apdex threshold for them, but that's kind of the whole point of this script, so we haven't yet.
So is the functionality to get a list of just the Key User Actions for a specific Application not present in the v2 API yet, or am I missing something?
 
Extra Context:
In case it isn't clear, I'm writing a script that we can feed a list of Application names.  It will then loop through those and, for each application, get a list of all the Key User Actions.  Then, for each Key User Action, determine what the average VCT was over a certain timeframe (like last 7 or 14 days or whatever), then calculate what the standard deviation was for that time period.  We can then use that to set Apdex thresholds for each Key Action where the Tolerating threshold is maybe 2 standard deviations above average and the Frustrated is 3 or 4 standard deviations above (it's kind of crazy that Dynatrace doesn't do this for us automatically....  Are we really expected to manually determine the thresholds for each Key User Action for all of our Applications?).

----------------
235.1:

Hello @xtraspecialj under the Configuration API you have:  

	The true delight is in the finding out rather than in the knowing.


----------------
235.2:

Yeah, that's the API I mentioned in my original post, which is v1 API.   Based on your other post it sounds like you are saying there isn't an equivalent v2 API way to reach this?

----------------
235.3:

Right, as I add below, the future roadmap of APIv1 in particular and API in general is unclear, but in the latest Dynatrace there is at least a classic APIv1 and v2 environment.  

	The true delight is in the finding out rather than in the knowing.


----------------
235.4:

The future of the current API is not clear, even within V2 I have seen many modifications over time. I haven't seen end of life for API v1 yet. Your approach is valid, but today not everything has an equivalence. I think you have exhausted all the possibilities correctly.The only change that is likely to be implemented is to obtain Bearer tokens through an Oauth application.

	The true delight is in the finding out rather than in the knowing.


----------------
235.5:

You need to use the Monitoring entities API (Environment v2 API) and look for the APPLICATION_METHOD entities.Use the entitySelector with relation for looking up the key user actions for a particular application, for example:type(APPLICATION_METHOD),fromRelationships.isApplicationMethodOf(entityId(APPLICATION-C45712444213D6A1)) This will return the list of key user actions present in the searched timeframe. Then you can fetch the metrics using Metrics API for such actions. There is no schema in Settings API at this time which will allow you to configure or retrieve key user actions for an application.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
235.6:

No, as I stated in my original post, the Monitored Entities API will get you a list of all User Actions for an application.  There's no property that denotes whether any of those properties are Key User Actions.  At least not any that I could find.  I'm just using the v1 Configuration API for now.

----------------
235.7:

No, APPLICATION_METHOD is a key user action. You won't see non-key user actions in Monitored entities, only key user actions. Just be sure you are looking at the correct user action and application since key user actions can have the same name across different applications.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
235.8:

You can use terraform, which powered by v2 API https://registry.terraform.io/providers/dynatrace-oss/dynatrace/latest/docs/resources/web_applicatio...if TERRAFORM_EXPORT:    terraform_export = subprocess.Popen(        args=[os.environ['DYNATRACE_TERRAFORM_BIN'], "-export", "-id", MODULE],        cwd=PROJECT_FOLDER)    terraform_export.communicate()module "web_application" {  source = "./configuration/modules/web_application"}  

----------------
236:

Hi, Does enabling the event function of k8s consume the resources of cluster nodes? Is there a best practice configuration requirement

----------------
236.1:

Hi @Lwl ,To answer the best practice configuration, you can find additional information in our documentation here to configure Dynatrace with Kubernetes. Overall, there are different deployment options depending on what fits best for your observability purposes.https://www.dynatrace.com/support/help/shortlink/installation-k8s 

----------------
236.2:

Hi @Lwl ,You can connect to the public API or internal API endponit of Kubernetes. Kubernetes API Monitoring | Dynatrace DocsEvent monitoring configuration:Monitor Kubernetes/OpenShift events | Dynatrace DocsIn case of Internal API end point connection you need a containerized AG (FullStack) instrumentation. In case of AppOnly instrumentation you can also create a containerized AG as a StatefulSet set.Instrumentation types:Deployment options on Kubernetes/OpenShift | Dynatrace Docs Create manual containerized AG in case of AppOnly injection:Manually deploy ActiveGate as a StatefulSet | Dynatrace Docs For event configuration I always use this without filters (I prefer it, pvc consumes lot of DDU):  Then you can able to create nice dashboards and alerts (there are some perdefined in Settings / Anomaly detection): I hope it helps.Best regards,János

	Certified Dynatrace Professional


----------------
237:

Hello.
I am on managed 1.274.157.20230908-165051 + OneAgent v1.267.155.20230629-142023+. We moved to log Classic kinda recently.
I have a process group with Dynatrace UI showing auto-detected log files : 
 
 
...
/myFSLocation/var/log/tomcat/abcd2/abcd2-daily.log
/myFSLocation/var/log/tomcat/abcd2/abcd#-daily.log (File is not included in log monitoring, some log records may be missing)
...
 
 
 

I double checked /myFSLocation/var/log/tomcat/abcd2/abcd2-daily.log does comply with dynatrace monitorability prerequisit, including being appended at least each minute. 
FYI: we have some other logs for which uploading does work. Like for /myFSLocation/var/log/tomcat/abcde/abcde-daily.log (note : no number in log file name).
FYI : the "Maximum ingest of log events per minute" is high enough.
Though, we don't get any content being uploaded for this abcd2-daily.log log. I mean zero content, zero lines in.

Could we be exposed to an issue with log rotation detection (https://www.dynatrace.com/support/help/shortlink/log-rotation-patterns) ? Any one experienced this ? Any idea ?
Regards.
--
(My private internal refs: dynt request: 217427 - jira: DEVOPS-14282)

----------------
237.1:

I observe, when I add an extra rule in "Custom log source configuration" to tell Dynatrace /myFSLocation/var/log/tomcat/abcd2/abcd2-daily.log is a log, then it at last get's uploaded.But not associated to its PG nor itS PGI. Which is strange, because when I watch through the PG, the tabs "Logs" shows the log file alright. If I add a PG context in the "Custom log source configuration" rule then it's contextualised all-right with PG and PGI.Yet all this requires per log / per PGI définitions : quite some qork ! Ans not durable : if a PG-ID changes : all gone ! Any ideas.Regards.

----------------
238:

Working with logs within Azure, we had some issues with Log Management and Scale. We would find ourselves hours behind real time. There was no real documentation on how to scale based on GB/hour. Then we noticed this link that provided some information (much to what we kind of sized and presumed anyway):
Azure Logs | Dynatrace Docs
However,  as we use this now for guidance, there are NO updates for Grail that seem to be dated and we think that our previous sizing templates may not be big enough/sized right for Grail. ie, we have been selective in the past, but now considering pushing more and retaining more.
I'd like to know your experiences if possible. There are no significant documentation updates, so presume the figures still stand. 
 
 

----------------
238.1:

Hi @GregOReilly 
Current Azure log throughput characteristics are described in the documentation page mentioned by you in the section scaling guide . We have a backlog item to improve Azure throughput further. What would be the expected throughput in your environment?

----------------
238.2:

Hi. 
Just wanted to update this topic with information about the improvement to the throughput of Azure forwarder. It's now up to 138GB/h ​(3,3TB/day). Refer to the documentation for details and scaling guides: https://www.dynatrace.com/support/help/setup-and-configuration/setup-on-cloud-platforms/microsoft-az...

----------------
239:

Hello ,Can we pull data from Dynatrace documents up to date (web scraping)?Is this type of operation allowed? Does it create any problems? I'm thinking of analyzing the information found in the document page in json format. It can be done by writing a simple code along with things like Python web scraping, but I was wondering if this information is available in a json format etc.? Is there an easier way to get this data?https://www.dynatrace.com/support/helpKind regardsKadirhan Cekmez

----------------
239.1:

@kadirhan,Have you checked the Dynatrace APIs? They should have the information you need...

	Antonio Sousa


----------------
239.2:

Hello ,Thanks for your answer , But I know that we can pull our own environment data using Api . Also, is there an API where we can pull the Dynatrace document page?I'm talking about the data on the Dynatrace Document page, not our own environment data.https://www.dynatrace.com/support/help/get-startedIs there a different way to pull the data from the Document page?Thanks.

----------------
239.3:

@kadirhan,OK, I get the idea If it's not for something like academia, you don't have to reinvent the wheel. Use Bing (quick example below):  

	Antonio Sousa


----------------
239.4:

Hi @kadirhan ,As @AntonioSousa mentioned, you are able to get information about your environment via the Dynatrace API as linked here:https://www.dynatrace.com/support/help/dynatrace-apiThe information that is returned is in JSON format as you mentioned.However, in terms of your question, I've noticed that you specify the Dynatrace documents. Do you mean the documentation page or the data collected in your environment? 

----------------
239.5:

Hello ,Thanks for your answer , But I know that we can pull our own environment data using Api . Also, is there an API where we can pull the Dynatrace document page?I'm talking about the data on the Dynatrace Document page, not our own environment data.https://www.dynatrace.com/support/help/get-startedIs there a different way to pull the data from the Document page?Thanks. 

----------------
239.6:

Hello Kadirhan, this is not possible. At least, not that I know of.
As far as I understood, please correct me if I am mistaken, you have a chat bot (a GPT-like) and you want to feed it our Dynatrace documentation so that it can answer you.
So, you are looking for an API to hand-deliver you our documentation in an easy format for the chat-bot to understand, unfortunately, we do not have this. So as previously mentioned, please raise a new feature request in Product ideas - Dynatrace Community.
The currently available solution for you is to scrap our documentation, in terms of staying up to date, you have feed.xml as previously provided.
Hope this helps.

----------------
239.7:

Hello Kadirhan,Can you please provide more details on what you want to achieve? And example JSON format that you are looking for? Is it that you want our HTML tags to be in JSON format?In terms of scrapping, you might want to just simply use https://www.dynatrace.com/support/help/feed.xml to only scrap for whats new, considering that this is in XML format, but it shouldn't be difficult to convert it to JSON on your end. If you want us to support JSON Feed, I'd suggest you to please raise a new feature request in Product ideas - Dynatrace Community.Hope this helps.Regards,Adham

----------------
239.8:

Hello ,Thanks for your answer, the link https://www.dynatrace.com/support/help/feed.xml seems to be enough for me. Is it possible to shoot all the contents of the titles in the document via this link?There is a project I want to do, I want to develop a chatbot with the help of a chatgpt using Dynatrace document data. For this, I need a structure to keep up-to-date document data and to classify all of these data as title - content.Thanks for support .

----------------
239.9:

Hello ,I see only a few titles and content from the RSS feed, I want to get all the content from the documentr page. is there an easier and different way to do this?Thanks

----------------
239.10:

No, you will have to scrap the documentation then rely on feed for whats new.

----------------
240:

Hi,We have some perl process to monitor those in dynatrace we have configured declarative process group detection rules.After creating a rules, Dynatrace is detecting perl processes. Bootstrap perl process is detecting by Dynatrace  but it's not operating state it is only running for 2 min while restarting the process after that it's going to shutdown. We are using Kshell script for this bootstrap process under this some components are running and some of these components are detecting by Dynatrace.(PFA-2)Please help us to understand why this process showing as Shutdown and How can we fix this? 

----------------
240.1:

Hi @pb388 Can you verify the agent log and see if there is a problem related to this process? There could be many causes, but let's check the agent log to start with.Radek

	Have a nice day!


----------------
240.2:

Hi Jasinski,Thanks for your response!We have checked the one-agent logs, but we didn't find any problem related to this process in the logs. could you please explain how this Perl bootstrap process will work in Dynatrace? Ameena 

----------------
240.3:

I can't answer you how this is implemented technically for Perl. I suggest you set up a ticket in support - you will get the most detailed answer there.

	Have a nice day!


----------------
241:

How to create a maintenance window for OS service for a specific host? our OS services will be same name in all hosts so can't create unique tag for each OS service.Hope our requirement will be fixed if there is any we can bring host name as tag on OS services.We are facing this since OS services are separated as custom devices and don't see any soliton yet for Dynatrace.

----------------
241.1:

I would create a tag based off the entity selector and then supply the host name to the OS Service, which is a custom device and then use your Maintenance window to define out a set of tags for the entities you want to suppress.  The only down side is, I don't thin that the entity selector can do dynamic placeholders, but its worth a shot. I have an RFE out for added functionality on tags, please give it a like: https://community.dynatrace.com/t5/Product-ideas/Dynamic-Automatic-Tagging-Expansion/idi-p/210349https://community.dynatrace.com/t5/Product-ideas/Expand-Dynamic-Auto-Tag-constructs-for-Kubernetes/i...  

	-Chad


----------------
241.2:

We have thousands of hosts\custom devices. Hope not possible to create auto tag for each host and moreover not sure what is max limit for auto tags.I already created few tags on custom devices with referring the tag from Host, but those tags are keep missing and working intermediately. Already a case is open for this with Dynatrace. The ultimate solution is they need to include host name in the placeholders for custom devices or they need to revert back OS services are part of Host. This change is really irritating and impacting our business and not sure the reason behind this idea about separating OS services as custom devices from Host. How will OS services run without a HOST?We have a plan to decom Dynatrace and move to different monitoring tool if no solution from them as this change has been made in 1.265 and we are running 1.273 but still don't see any solution from them.

----------------
242:

Hello,Can you tell me how to download the Cluster ActiveGate SSL certificate?thanks for your help. 

----------------
242.1:

Hi @Candy ,The documentation for configuring the Cluster ActiveGate SSL certificate can be found in this documentation:https://www.dynatrace.com/support/help/managed-cluster/installation/install-your-own-ssl-certificate...Cheers,Taylor S.

----------------
243:

Hello Dynatrace Community!
Last month, we asked you to help us by sharing your valuable feedback in the Community Survey. We didn't expect it to get as much response as it did, and we can't put into words how grateful we're. But we'll try!
Thank you, everyone, from the bottom of our huge cube-shaped hearts 
 
 
Below, we'd like to share the main areas of improvements we identified based on the feedback you provided, our ideas and plans to address them.
 



AREAS
IDEAS
PLANNED
COMMENT


User Groups
For partners

 


Spanish

 


Hebrew

 


Polish

 


Southern hemisphere, English speaking

 


More activity in user groups

Activity in user groups lays outside the responsibility of the Community team. We provide the space for users to connect, but it's on owners and members to keep the group alive. We will pass the feedback to owners of user groups, and will be happy to help with advise anytime!


More visibility of the area

We will investigate ways of making this area more visible to our Community.


Events and Webinars
Lots of feedback on this area that gave us the confirmation that full review and re-invention of this area is due.

It's on our roadmap!


Forum features and bugs
Community chat

Our Community by design doesn't have a chat feature turned on for all users, as we'd like to keep all knowledge and conversations between users public, so more people could use that exchange.


See questions with no reply/solution


You can see all questions with no reply by using the "Without reply" filter on the main feed:
 
On separate sub-forums, you can use "Unanswered questions" for the same, and "Without solution" to see threads with no comment accepted as a Solution.
 
It's available from the level of a sub-forum only, unfortunately, for the moment.



Built-in dark mode


Unfortunately, there's no possibility to introduce a dark mode built-in feature as of now. If our platform provider ever introduces such functionality, we will definitely adopt it, too 
Follow the Product idea to get updates.
For now, you can use a workaround solution described in this post.



Filtering by date

You can filter by date by using either "Most recent" (for lastly commented on posts) or "New topics" filters on each level of our forum: 


Pro Tips to be allowed to be marked as Solution

No such functionality, unfortunately, but for all authors of the Pro Tips in Dynatrace Tips space we have a special prize in shape of additional bonus points  


Zoom links in webinars in Outlook not working/are missing


We created a ticket for our platform provider to investigate this issue and fix it.
As a workaround, add the event your calendar, and on the day of the event follow the link to the Community you have in the invite - we always make sure the Zoom link is available in the description.



Option to "Outdate" content

The topic of outdated content is on our roadmap, but in the meantime you can simply let the Community team know that a post needs to be archived. We do our best to do it proactively, but any help is appreciated.


Option to "Close" the topic


Same as with outdated content, we will investigate what can be a solution for such a use case.
In the meantime you can ask the Community team to archive or simply close comments on your posts.



Improve readability of huge threads


As for now, we cannot provide a solution beside two filtering options available under each thread - Newest to oldest, and Oldest to newest.
We raised a product idea on the forum of our platform provider, so hopefully one day 



Option to "feature" posts instead of publishing the link in the comments


Unfortunately, there's no functionality that can support this use case.
And on the other hand, we would like authors of posts to be able to accept all additional resources (documentation links, other posts on the Community, video, etc.) as Solutions, and it won't be possible with the "feature" function.



Option to filter product ideas based on status


You can see all ideas with a particular status by clicking on the status name:
 
 
Unfortunately, there's no way to see the list of ideas with all statuses except for one.



Personalized main page with an option to view only new content in followed sub-forums/labels


Personalization of content is already on our roadmap  Follow this product idea for updates.
DONE: read here.



Missing content
More video content focused on the upcoming features

Not in the hands of the Community team, but we have passed the feedback to people creating this type of content.


More video content focused on tips and tricks

Not in the hands of the Community team, but we have passed the feedback to people creating this type of content.


Use cases and best practices

Creating more content around use cases and best practices is on the roadmap.


Best practices with detailed explanations/configuration examples


It lays outside the responsibility of the Community team, as authors of content are choosing to provide examples and explanations.
What we can do from our side - investigate ways of making such content more valuable for the Community and share those tips  



Demos from different domains

Not in the hands of the Community team, but we have passed the feedback to people creating this type of content.


More content on Cloud best practices

Not in the hands of the Community team, but we have passed the feedback to people creating this type of content.


Weekly digest of the hottest content

We're working on making our newsletters content more valuable   You can expect some changes in the upcoming months!


Product ideas and Feedback area
More feedback channels (related to major product areas)

While we can't promise there will be a Feedback thread on every new feature of Dynatrace, we continuously work with our Product Managers to expand this sub-forum 


All channels to be up-to-date and well-maintened

The Community team at least once a year runs an extensive clean up of Feedback channels, and archives those that are left unattended. We are working on making the collaboration between PMs and the Community even smoother in the future 


More engagement from Dynatrace employees

This is not something that can be done at once as a project, but the Community team is working on involving more Dynatrace experts in the knowledge-sharing on the Community.


New spaces
Latest Dynatrace


It won't be a separate sub-forum, but you can find content specific to new Dynatrace under the label "latest Dynatrace", or under other specific labels.
More in the article.



DQL


Our survey took place before the change went live, but DQL sub-forum is now a place! 
Check it out here.



Workflows and automations


Spoiler alert: it's already in the works! You can expect the announcement soon.
In the meantime, check out helpful materials we've gathered for you 



Notebook


There's no plan to make a separate space for this content.
Notebooks are a part of Dashboarding, and it's a default place for all questions related to that topic. 



App engine

Developers forum is the place to go to learn about creating apps on the Dynatrace Platform 


Grail

There's no plan to make a separate space for this content.


Monaco

There's no plan to make a separate space for this content.


General feedback
Recognition and appreciation for active users

As we did in the past a few times, we will plan some prizes for future Community challenges, for example SWAG store vouchers!


Vouchers for the Dynatrace certification

We will investigate if it's possible. Lets keep it a surprise 


Extra points for Pro Tips

Every author of an article on the Dynatrace Tips and Tricks sub-forum already gets extra bonus points  


Identify partners and customers on the forum (as it is with Dynatracers)


There's no plan to provide any kind of identification for prospects, customers and partners on our forum. 
A workaround is to provide this information in "Bibliography" section of your profile:
 
 




 
We'd like to also thank everyone for the ocean of compliments you showered our forum with, and all the kudos given to the team. Nothing makes us happier than seeing our work make a difference 
 
If you have any questions or further suggestions for our Community, you can leave them in the comments 
 

----------------
243.1:

Thank you for this awesome summary, @Ana_Kuzmenchuk!! 

----------------
243.2:

Great news, and very well documented.

----------------
243.3:

Thank you, @DanielS and @AntonPineiro, for your kind words, but also for giving us your feedback in the first place 

----------------
243.4:

thank you so much, i've been looking for this for a while

----------------
243.5:

The first step of introducing the personalized feed in the Community! 
We now have two additional sorting options that you can use to see only the content you're subscribed to.
Read more here.

----------------
243.6:

very exciting! 

----------------
244:

Hi All,Please can some one help me to understnad best approach to monitor AWS Fargates out of three approaches mentioned in DT docs , fargates running on ECS service.Currently we are using runtime injection, just want to understand Bulidtime injection has any advantages over runtime.https://www.dynatrace.com/support/help/shortlink/aws-fargate



					
						Solved!
					
					Go to Solution.




----------------
244.1:


Hi @gurugogi ,Thank you for your question. The best approach really depends on your circumstances and what works for you, since each environment is different. Build time injection would simply be done once and less at deployment time, while the runtime injection involves automated download of agent files. In addition, build time injection is a less overhead intensive way to build the image, but the trade-off is the increase in size for application image and build time. The main two differences between the two are installation and set up related.

----------------
244.2:

Thanks @Taylor-Sanchez .what I understood is for "runtime injection" will have two containers, one is application container and another one is Oneagent container, oneAgent container will have required code modules based on the technology and inject it on to application container, injection will happen only time when these containers are run for first time, so oneagent container will run for onetime and inject code modules onto application container and then it will be in stopped status.Please let me know what I understood is correct or not.This is the path on oneAgent container which is available on volume mount where OneAgent code modules are stored ?Scroll to Environment, and in Environment variable, define LD_PRELOAD with the value /opt/dynatrace/oneagent/agent/lib64/liboneagentproc.so

----------------
244.3:

This is a very interesting topic. I've seen issues with monitoring Fargate. The main issue is that the Fargate node will not have access to download the Oneagent and do auto injection. Which then causes a gap in the monitoring stack. This is just one of the issues I've run into with Fargate. All the other K8 connections I've seen and work with were pretty seamless, Fargate is the one that gave us the most problems. 

	-Chad


----------------
245:

Any ideas how to figure out Dynatrace tenant version in SaaS environment? (Not in Dynatrace managed).Oneagent version available from the tenant can be seen by navigating to Settings->Preferences->Oneagent updates or when deploying new agent, but I can't see the tenant version anywhere. 

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner




					
						Solved!
					
					Go to Solution.




----------------
245.1:


Hi, what do you mean by tenant version? Tenant is just an environment for agents that are versioned.

	Senior Product Manager, Dynatrace Managed expert


----------------
245.2:

By tenant I mean the version of my dynatrace environment - what version is running at my https://xxxx.live.dynatrace.com . 	I was about to try the Golang support, but I can't see the option in my environment. Blog post says it is from the cluster version 127. How can I see if my environment is at this level?Briefly looking at the HTML source code - it should be 127, since some URLs include this numbering, but I don't see the Golang support in our environment.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
245.3:

OK. I see. So in SaaS all clusters are already on 1.127. You can not bother that at all if you are SaaS user. We perform all cluster updates in time.It seems that this feature was not enabled yet for your tenant. Please give us some time, and we'll enable that shortly.

	Senior Product Manager, Dynatrace Managed expert


----------------
245.4:

Hey Julius, I've just received a confirmation this is going to be available on Friday. Thanks for your interest in willing to test that. Let us know your impressions and insights you discovered with that new functionality! 

	Senior Product Manager, Dynatrace Managed expert


----------------
245.5:


With recent sprints (probably from 146) the tenant version is visible in the bottom of the user menu. No need to look at the source code anymore.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
245.6:

I still cant see the SaaS version in the UI? Can you please help with the right navigation to see the same

----------------
245.7:


 SaaS Version

----------------
245.8:

Great, thank you

----------------
245.9:

Where we can see it with the new Dynatrace view?

----------------
245.10:

@Duran_Narbona it's not (yet) in the new platform UI but it will be available shortly in the next releases with additional improvements. You can switch to the old UI to get the version.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
245.11:


You can see the tenant version if you go to the Hub> Manage > any Classic App, e.g Data Explorer
 
 
 

----------------
246:

 
 
Welcome to the #3 edition  of your developer's newsletter. This is where you'll find all the highlights of our favorite new releases, to keep you updated alongside monthly news and announcements.
 
What can you expect to see in this post:
Announcements and events New learning App releasedRelease highlights for App developersUseful resources 
 
 Announcements and events
 
As mentioned in our previous newsletter, we’ve got a new event in store for you this month. We’re kicking off our new Dynatrace App office hours event series on September 12. This office hours session will be available for any developer with a question regarding app development. In this session, you can expect news, learn more about Dynatrace Apps, and get your burning answers to your questions.
 
To attend, you'll need to register for the event; visit the Community Events page.
 
 
 
 New learning App released
 
More often than not, developing a Dynatrace App involves using our new Dynatrace Query Language (DQL) for querying data stored in Grail. To make it even easier to get started learning DQL, we’ve now released a new hands-on on App with interactive tutorials. It’s never been this easy to learn DQL!
Try it for yourself, or install the App today on your own environment. Want to learn even more about DQL? Join our DQL community or have a closer look at the DQL language reference. 
 
 Release highlights for App developers
 
React Hooks [0.1.0] 
 
To make it easier to add React Hooks functionality to your apps, we've released a new package to cover some of your basic needs, such as interacting with Grail, Documents, or the App State.
To learn more about adding React Hooks to your app, visit the React Hooks documentation.
 
App utils [0.3.1] 
 
With the latest release we've introduced a breaking change in this package. The 2nd parameter in functions.call was changed. For a full overview of the interface including the changed parameter, visit the App utils documentation. 
 
Design System [0.101] 
 
With the latest release we've introduced some breaking changes in the TextInput component. TextInput now uses compound components for Prefix and Suffix and the forwarded ref now uses an imperative handle (of type InputRef) to allow access to the wrapper element and the input element. A migration is provided for using the prefix and suffix icons and renaming the inputRef prop to the new ref prop. The migration also changes simple usages of the old ref type, but for more complex scenarios it might still be necessary to migrate manually.For information on how to easily migrate, see the design system changelog.To learn more about the TextInput component, visit the TextInput documentation.
 
Design System [0.102]
 
In this package version we've introduced a new MeterBarChart component, that allows you to display a horizontal bar that fills according to the percentage value of a measure.To learn more about the MeterBarChart component, visit the MeterBarChart documentation. Another new component we’ve released as part of this version is the FeatureHighlight component. This component supports the onboarding of new users, as well as the introduction of new features to existing users.To learn more about the FeatureHighlight component, visit the FeatureHighlight documentation.
 
 
 Useful resources
 




 
️ Build an app in 5 mins via our Quick Start video
 Take a deep dive and follow our beginners tutorial
 Read our documentation in Dynatrace Developer
 




 
 

----------------
246.1:

Awesome

----------------
247:

We have a public API and no control of the casing that clients use when using the API. The problem that we see is the '/api/project' and '/api/Project' are treated as different requests. We've used request naming rules as a workaround for this but that feels like a very clunky solution as we have to do them individually for each request that we care about.
 
Is there a way to turn off case sensitivity for detected web request names for a service?



					
						Solved!
					
					Go to Solution.




----------------
247.1:

Hi Brian,With request naming rules you should be able to go service by service (using the UI) instead of request by request. You can create a cleanup rule that extracts the request name as is and converts it to lower case. Go to your Service > Edit > Web request naming rules > add Cleanup rule:If you have a need for this for more than a couple of services, the API is the alternative for creating these rules at a global level..../api/config/v1/service/requestNamingI hope this helps.Best regards,Radu

----------------
247.2:


Radu, this is not solution. It doesn`t work.  It transfer all URL to "/" - I have requested "/pDp/2222/dRd" and "/ppp/2222/ddd"   It can be done  by rule with additional placeholder:  Result:      Regards,Alexander 

----------------
247.3:

This is great, but by doing this it removes the clean up rule `Remove UUIDs, IP addresses and IBANs from URLs`Do you have a way how we can fix this ?

----------------
247.4:

You can apply the placeholder on the request name rather than the URL path to preserve [uuid] and similar replacements that Dynatrace already performed.In case of non-URL request names, I use a broader match of regex:  (\S+?)$

----------------
247.5:

I have this same issue and would really appreciate a global way to turn off case sensitivity on all requests. It has to be at least by service and I'd appreciate it if it was simply a check box at the global or service level. It's very much a pain to try and do this at a request or service level now.

----------------
248:

I am unable to install an extension for an Azure App Service running on Linux. Per the Dynatrace documentation, there isn't an extension for this. How do you use Dynatrace for this type of App Service?
 

	Dynatrace Certified Professional




					
						Solved!
					
					Go to Solution.




----------------
248.1:

Is there not going to be an answer to this?  We're finding ourselves in the same position where we are unable to monitor these PaaS apps because we chose to deploy them to Linux.

----------------
248.2:

			
				
					
					
						Is Dynatrace going to find the solution for this or we have to tell our customers to use the Native tool instead of Dynatrace?
					
				
			
			
				
			
			
				
			
			
			
			
			
			
		
----------------
248.3:

https://www.dynatrace.com/support/help/technology-support/cloud-platforms/microsoft-azure/azure-serv...As I understand, you don't see available extension mentioned here for linux instances? Sebastian 

	Regards, Sebastian


----------------
248.4:

No, the extensions option is grayed out.  You also can't add extensions through Kudu.

----------------
248.5:

Extensions in general are not supported for App Services on Linux.  However, there is a workaround which isn't supported by Dynatrace.  It is based on the runtime OA script for Kubernetes and Docker.  The Azure App Service on Linux is essentially a Docker container.  The Java image used is a "musl" type.  I've created a basic script which will deploy OA under /home; this must be done in this directory as any changes outside of it will be lost when the container restarts.

	Dynatrace Certified Professional


----------------
248.6:

I tried doing something like this, more as a test, but it couldn't get access rights to the .Net dll so it wouldn't report on the process itself just the container.

----------------
248.7:

Is your app Java or .NET?  We are using Java in ours and was able to deploy OA successfully to our PROD and TEST environments.Also, In your application environment, you have to add "LD_PRELOAD=<*/agent/lib64/liboneagentproc.so> pathAnd then restart your application.Let me know if you need/want to talk about this offline.

	Dynatrace Certified Professional


----------------
248.8:

Our app is an ASP.NET Core app.  Thank you for your assistance thus far.  I'll continue to toy around with it and see if I can make any progress and if not I might just take you up on your offer.Again, thank you!

----------------
248.9:

Hi Josh - I have same requirement for ASP.NET Core app on Linux. Did yours work out?

----------------
248.10:

Hi Bill, it is possible to talk about Azure Linux WebApp OA deploy? We are facing with some issues with deploys, so I would be happy for some tips.Thanks!Ondrej

----------------
248.11:

Hello Bill,Can you share with me the script you deploy?Kofi

----------------
248.12:


This is what has been provided by Dynatrace support. I tried a few times and it works quite well. You would need to do the following steps: -) Set 3 environment variables via the Azure Portal -) Download and execute a script from us -) Set 1 environment variable via the Azure Portal -) Restart the WebAppFor this approach Dynatrace prepared a script which is comparable to our buildpacks: https://github.com/DTMad/azure_webapp_linux/blob/master/dynatrace_installer.sh In this script do the following steps:Download the agentInstall the agentSet the standalone.conf fileSteps to doThe customer needs to set the following environment variables through the Azure Portal:DT_TENANT - only the tenant ID (skj22538), not the entire URL (skj22538.live.dynatrace.com)DT_API_TOKEN – It needs to be a PaaS TokenDT_API_URL – needs to be the tenant URL followed by /api (ie skj22538.live.dynatrace.com/api) Then the customer needs to ssh to his container and execute the following command: wget https://raw.githubusercontent.com/DTMad/azure_webapp_linux/master/dynatrace_installer.sh && bash dynatrace_installer.shThis downloads the script mentioned above and runs it. After the agent installation is finished the customer then needs to set another environment variable via Azure Portal: 'LD_PRELOAD'The value for variable 'LD_PRELOAD' will be this path:NOTE: Let’s make sure the path in LD_PREDLOAD is correct, otherwise OneAgent will not load.I hope this helps !

----------------
248.13:

Thanks for share the solution. This is to install OneAgent after a container is built. In other words, if the appservices are swapped to another image, then we lost the OneAgent. Wonder if this can be included in the dockerfile to install during the container build time.

----------------
248.14:

Hi Juan, The GitHub link to the installer script doesn't seem to work - It has probably been removed. Do you know where I can find it? Francois

----------------
248.15:

Hi @bill_scheuernst . I'm not able to install it in non-containerized Linux AppServices solutions. It seems that for Linux AppServices, it is only possible for containers. --> https://www.dynatrace.com/support/help/technology-support/cloud-platforms/microsoft-azure-services/o...  I opened an idea the past 16th February -> https://community.dynatrace.com/t5/Dynatrace-product-ideas/App-Services-for-NON-CONTAINERIZED-Web-Ap... 

----------------
248.16:


https://www.dynatrace.com/support/help/setup-and-configuration/setup-on-cloud-platforms/microsoft-az...

----------------
248.17:

In the last year, i have had clients follow the documentation for linux in Azure and it worked perfectly for Azure app services.

----------------
249:

Hi,Our setup for OneAgent Installation on ECS Fargate container uses run-time Injection with the below command:   ARCHIVE=$(mktemp) && wget --no-check-certificate -O $ARCHIVE \"$DT_API_URL/v1/deployment/installer/agent/unix/paas/latest?Api-Token=$DT_PAAS_TOKEN&$DT_ONEAGENT_OPTIONS\" && unzip -o -d /opt/dynatrace/oneagent $ARCHIVE && rm -f $ARCHIVE"  Does this type of OA installation require installer command to be run in the ECS task definition? Regards



					
						Solved!
					
					Go to Solution.




----------------
249.1:


If you have followed to this configuration, you don't need to do anything else in runtime mode:https://www.dynatrace.com/support/help/shortlink/aws-fargate#runtime

	Have a nice day!


----------------
250:

The integration causes the issue which have an impact on site performance `The unload event does not fire reliably and listening for it can prevent browser optimizations like the Back-Forward Cache. Use pagehide or visibilitychange events instead.`https://gtmetrix.com/reports/www.timberland.com/badA1NJn/

----------------
250.1:

The message you've provided indicates an issue related to the unload event in a web application being monitored by Dynatrace. Specifically, it mentions that the unload event does not reliably fire, and that listening for it can prevent browser optimizations like the Back-Forward Cache. To address this issue and potentially improve site performance, consider the following steps:1. Review the Usage of the Unload Event:- First, assess why you are using the unload event. Unload events are typically used to perform actions when a user navigates away from a web page, such as cleaning up resources or recording analytics data. Make sure you genuinely need this event for your specific use case.2. Replace Unload Event with Pagehide Event:- As recommended in the message, consider replacing the unload event with the pagehide event. The pagehide event is more reliable and can serve as an alternative for performing cleanup actions when a user leaves a page. Update your JavaScript code to use this event instead.Example:```javascriptwindow.addEventListener('pagehide', function(event) {// Your cleanup or tracking code here});```3. Test Impact on Site Performance:- After making the code changes, thoroughly test your web application to ensure that the replacement of the unload event with the pagehide event does not negatively impact site performance or functionality. Monitor performance metrics to confirm that any optimizations you've made are effective.4. Consider the Back-Forward Cache:- Understand the implications of the Back-Forward Cache in modern browsers. The Back-Forward Cache aims to improve navigation speed by keeping a cached version of a page when users use the browser's back or forward buttons. Listening for certain events, like unload, can prevent the browser from utilizing this cache effectively.5. Monitor with Dynatrace:- Continue to use Dynatrace to monitor your web application's performance. Dynatrace can provide insights into how your changes impact performance and help you identify any new issues that may arise.6. Optimize Other Aspects:- While addressing this specific issue, also consider other optimizations for your website, such as reducing page load times, minimizing the use of synchronous JavaScript, and optimizing server-side processes. These optimizations can have a significant impact on site performance.7. Stay Informed:- Keep up-to-date with best practices for web performance and browser optimization. Web technologies and best practices evolve over time, so staying informed will help you make informed decisions for your web application.By addressing the issue related to the unload event and optimizing your web application's performance, you can provide a better user experience while ensuring that Dynatrace monitoring continues to provide valuable insights.

	Dynatrace Professional Certified


----------------
250.2:

But as you can see in this report the issue points directly to ruxitagentjs file.Doesn't it come from dynatrace?  

----------------
251:

Hi all,
For a customer it would be ideal if I could get an access token with custom policies instead of the pre-set write settings.
I need a token with two very specific policies assigned to it. Edit alerting profiles and edit notifications. Is it possible to connect tokens and policies or select a custom scope of tokens? As far as I know, policies are specific to user accounts but maybe someone has an idea or I am missing something.  Help is greatly appreciated!

	A Dynatrace Professional nerd working for Eviden


----------------
251.1:

Hi,I don't remember there being an option to narrow down the permissions that much. What I would try is to create permissions (Manage monitoring settings)for a specific Management Zone. Then you would gain permissions to configure alert profiles, for example."Manage monitoring settings: Allows the changing of entity settings within a management zone, for example, the ability to record or edit synthetic monitors. It also grants access to some items in the global settings menu but only allows making modifications to assigned management zones. For example, alerting profiles can only be created and changed for a specific management zone."For the API, you have to use the settings.read and settings.write scopes to make the changes you want:https://www.dynatrace.com/support/help/dynatrace-api/environment-api/settings/schemas/builtin-alerti...You can narrow down the scope by specifying additional parameters like the name of the MZ, etc....Radek

	Have a nice day!


----------------
251.2:

The problem is that these permissions are only usable for users, not tokens/API .  the read and write API settings are way to broad for us.... Maybe something can be achieved with some scripting here.

	A Dynatrace Professional nerd working for Eviden


----------------
251.3:

In my opinion, this is currently the only method. You can submit a product idea for Dynatrace to allow more complex permission management on the settings tab. 

	Have a nice day!


----------------
252:

Our Dynatrace Managed customer, would find it highly beneficial if we could add dashboards to the mobile app. They would like to give leadership access to certain high-level dashboards that cover business needs/ overall availability etc. and it would allow them to skip the learning curve associated with setting up a more-than-needed full web platform interface.Is this something that could be taken into consideration?Many thanks,



					
						Solved!
					
					Go to Solution.




----------------
252.1:

Currently, only problems are available on the mobile app. I suggest you add a Product Idea to the forum to be open to votes.

	The true delight is in the finding out rather than in the knowing.


----------------
252.2:


Hi,Product idea is here.Best regards

	Consultant


----------------
252.3:

Dear @nryan ,
The mobile app is dedicated to push notifications and quick summary information only. It is not planned to add enhanced dashboarding capability due to the restrictions of the native mobile platforms. Instead we do plan to elevate the new Dynatrace platform apps to be mobile consumable, which will then mean to simply open the Web app for dashboard within your mobile device to see the management dashboard. Same is planned for the upcoming platform problems app etc.
Best regards,
Wolfgang

----------------
253:

Hello All,
I'm having a problem when trying to create a metric.
Basically what i'm trying to do is create a metric that counts the number of exceptions from a request to a specific service.
The problem is when i filter i have the message : 
 
 
Is there any other way to do it ?
Thank you.



					
						Solved!
					
					Go to Solution.




----------------
253.1:

The error message "Hierarchy filter is not supported as filter" indicates that the filtering method you are trying to use in Dynatrace is not supported for creating the metric in the way you are attempting.To count the number of exceptions from a request to a specific service in Dynatrace, you can use other filtering options or alternative approaches:1. **Service Filter:**- Instead of using a hierarchy filter, try using a service filter. You can filter the requests by the specific service you're interested in, and then count the exceptions associated with that service.2. **Custom Metric:**- Create a custom metric for exceptions specific to the service. You can use Dynatrace's custom metric capabilities to instrument your code to capture exceptions and increment a counter metric whenever an exception occurs in the context of the service you're interested in.3. **Alerting Rules:**- You can create alerting rules in Dynatrace based on exceptions. Define alerting rules to trigger notifications or actions when exceptions exceed a certain threshold for the specific service.4. **Custom Scripting and API:**- If the built-in metric creation options do not meet your requirements, you can also consider using custom scripting and Dynatrace's API to extract and count exceptions from the service in a more customized way.5. **Dynatrace Support:**- If you're still facing difficulties or if your use case is complex, consider reaching out to Dynatrace support for specific guidance on how to achieve your metric counting goals.The exact approach you choose will depend on your specific use case and requirements. If you can provide more details about your setup and requirements, I can offer more specific guidance on which approach might be most suitable for your situation.

	Dynatrace Professional Certified


----------------
253.2:

@natanael_mendes thanks for the effort.Here is what i'm trying to do exactly :- I have a service (Proxy) - proxy is calling a lot of other services with the same request (let's call it proxy/request)When using exception count metric i can see all the exceptions generated on the proxy level.what i need is to see the exception that are generated only when calling a specific service (let's call it service X)i can do that using MDA using the filter "Called service"but now i need to display that on a Dashboard and i can't find a way because i can't create the metric with that filter.basically the filter is : any exception + on request (proxy/request) + called service (Service X)I hope this is clear

----------------
253.3:

Hi @SOBE I'll check back later to see if it's possible to pull what you need for the dashboard on my demo environment (unless someone writes back in the meantime). Alternatively, you can try to use Markdown Tile and make there a hyperlink to Multidimentional (without creating a metric) - yes I know it's a workaround, but I sometimes use it with clients.Radek

	Have a nice day!


----------------
253.4:

@radek_jasinski yes the markdown tile is my last solution if i can't find anything.Thanks for the effort and i hope to hear from you soon !

----------------
253.5:


Unfortunately, in my opinion, you are left with Markdown.DT doesn't allow you to configure metrics that way.

	Have a nice day!


----------------
253.6:

Hi,I think product idea has been raised about it.Best regards

	Consultant


----------------
253.7:

Yes but they said they'll only add this to grail and i'm a Managed user so i have to find some kind of workaround...

----------------
254:

Hi,I want to get the ID on alertingprofile. I use Dynatrace environment API / Settings - Objects. In the output of [GET] /settings/objects I have objectId but not the alertingprofileid. How to get it?{
      "objectId": "XXX",      "summary": "Default",      "searchSummary": "Default",      "created": 1651564175176,      "modified": 1651564175176,      "author": "default settings creation",      "updateToken": "XXX",      "scope": "environment",      "schemaId": "builtin:alerting.profile",      "schemaVersion": "8.3",      "modificationInfo": {        "deletable": false,        "modifiable": true,        "movable": true,        "modifiablePaths": [],        "nonModifiablePaths": []      },
      "value": {        "name": "Default",        "severityRules": [          {
            "severityLevel": "AVAILABILITY",            "delayInMinutes": 0,            "tagFilterIncludeMode": "NONE"
          },
          {
            "severityLevel": "ERRORS",            "delayInMinutes": 0,            "tagFilterIncludeMode": "NONE"
          },
          {
            "severityLevel": "PERFORMANCE",            "delayInMinutes": 30,            "tagFilterIncludeMode": "NONE"
          },
          {
            "severityLevel": "RESOURCE_CONTENTION",            "delayInMinutes": 30,            "tagFilterIncludeMode": "NONE"
          },
          {
            "severityLevel": "CUSTOM_ALERT",            "delayInMinutes": 0,            "tagFilterIncludeMode": "NONE"
          },
          {
            "severityLevel": "MONITORING_UNAVAILABLE",            "delayInMinutes": 0,            "tagFilterIncludeMode": "NONE"
          }
        ],
        "eventFilters": []      }
    }In Dynatrace configuration API / Alerting Profiles it is possible to get alertingprofileid but it is deprecated : {  "values": [    {
      "description": "Dynatrace entity 1 for the REST API example",      "id": "6a98d7bc-abb9-44f8-ae6a-73e68e71812a",      "name": "Dynatrace entity 1"
    },
    {
      "id": "ee70f7d3-9a4e-4f5f-94d2-c9d6156f1618",      "name": "Dynatrace entity 2"
    },
    {
      "id": "8cdabe77-9e1a-4be8-b3df-269dd6fa9d7f"
    }
  ]
} Any suggestion?Thx



					
						Solved!
					
					Go to Solution.




----------------
254.1:


You can still use the deprecated method, but the Alert Profile ID is also present in the URL when you select the alert profile form the UI. If that's not possible for you, you can leverage the new API via a 2 part call:  Basically you check the Alert Profiles, find the one you want and grab the Object ID, not the alert profile ID from the URL, then take that Object ID and supply it in the the settings API for that Object ID and you'll have the data you seek 

	-Chad


----------------
254.2:

Thx @ChadTurner for the reply,With the API I get value like you (objectID). But this value is différent to the id from the UI (alertingprofile).   I try to create "problem notifications" with the 2 value and I get the same result   Is it possible to define alertingProfile with his name ? Thx 

----------------
254.3:

Hi,If you are using Monaco, you can create an alerting profile, and create a problem notification linked to that alerting profile as a reference.Is this your use case?Best regards

	Consultant


----------------
254.4:

Hi @AntonPineiro ,Yes it is my use case. For profil notification is it possible to define reference without ID? With name of alerting profile?We have a CMDB with project and we want to use monaco to create SLO, alerting profile and problem notif automaticaly. Thx

----------------
254.5:


Hi,If you create all entities (alerting profile, problem notification, etc...) using Monaco, maybe it would be easier.Let me provide you an example. You can create an alerting profile and you choose ID for that alerting profile, a human name: configs:
- id: XXXXXXXX
  type:
    settings:
      schema: builtin:alerting.profile
      scope: environment
  config:
    name: XXXXXXXX
    template: XXXXXXXX.json And when you create a problem notification, you can reference that alerting profile ID: configs:
- id: XXXXXXXX
  type:
    settings:
      schema: builtin:problem.notifications
      scope: environment
  config:
    name: XXXXXXXX
    parameters:
      alerting_profile_id:
        project: alerting-profiles
        configId: XXXXXXXX
        configType: builtin:alerting.profile
        property: id
        type: reference
      recipients:
    template: XXXXXXXX.json   "configId" is a reference to id you had chosen defining alerting profile.If you create everything with Monaco, maybe it would be easier. You have more ways to reference entities in Monaco, checking this.  Best regards

	Consultant


----------------
255:

Hi,
After successful connection to AWS by Role-based authentication I cannot add Amazon CloudWatch Logs Service. When I'm trying to do so this pop up comes out:
 
I added CloudWatch permissions policies in AWS account and used this docs to connect:
https://www.dynatrace.com/support/help/setup-and-configuration/setup-on-cloud-platforms/amazon-web-s...
Also I can't use alerting rules wich is most important for me to create
 
Appreciate your help 
 

	"The lion does not ally with the coyote"




					
						Solved!
					
					Go to Solution.




----------------
255.1:


Hello @Pawel_Zalewski under role based auth you can monitor the "default" services without an ActiveGate: As you can see Amazon Cloudwatch Logs is non default so you must install and configure an Environment ActiveGate if you want to monitor either or both of the following:More than 2,000 AWS resources (AWS service instances)Non-default AWS Cloud servicesYou need an AG on your EC2 Account:Create a role for ActiveGate on the account that hosts ActiveGateDownload the YAML file with CloudFormation template.Create the stack in your Amazon Console: In your Amazon Console, go to CloudFormation.Go to Stacks and create a new stack with new resources.Select Template is ready, upload the template you created above, and then select Next.In Parameters, for Monitored Account ID, enter the ID of the account Dynatrace will monitor. Optionally, adapt other parameters as needed.Enter a name for your stack, and then select Next twice.Review your configuration, select I acknowledge that AWS CloudFormation might create IAM resources with custom names, and select Submit.3. Go to the Amazon EC2 console, right-click an instance hosting your Environment ActiveGate, and select Security > Modify IAM role.4. Select the role you created in step 1 and select Update IAM role. Part 2 Create a monitoring role for Dynatrace on your monitored account After the Dynatrace_ActiveGate_role is created on the account hosting the ActiveGate, create a role for the account to be monitored.Download a YAML file with CloudFormation template from github role_based_access_AG_account_template.yml.Create the stack in your Amazon Console: In your Amazon Console, go to CloudFormation.Go to Stacks and create a new stack with new resources.Select Template is ready, upload the template you created above, and select Next.In Parameters, enter External ID, ActiveGateRoleName and ActiveGateAccountID from the stack created in Step 2.3.2.1. Optionally, adapt other parameters if needed.Enter a name for your stack, and then select Next twice.Review your configuration, enable I acknowledge that AWS CloudFormation might create IAM resources with custom names, and select Submit.Hope it helps!!!!

	The true delight is in the finding out rather than in the knowing.


----------------
255.2:

Thanks a lot! I missed this steps:3. Go to the Amazon EC2 console, right-click an instance hosting your Environment ActiveGate, and select Security > Modify IAM role.4. Select the role you created in step 1 and select Update IAM role.Now it's working 

	"The lion does not ally with the coyote"


----------------
256:

I'm trying to loop DataCenter information based on Management Zone and Host's placed under the respective Management Zone into Dashboard Classic, could someone guide me how can I get that placed into my Dashboard Classic?



					
						Solved!
					
					Go to Solution.




----------------
256.1:

What do you mean when you write "loop DataCenter information"? Do you want to place a tile regarding DataCenter and assign it to the correct MZ?

	Have a nice day!


----------------
256.2:

@radek_jasinski - correct, I want to add a tile to reflect DataCenter Information based on Management Zone.

----------------
256.3:


You need to create a rule in MZ that assigns the appropriate elements to the DataCenter. Then on the dashboard in the settings, select the appropriate MZ.Radek

	Have a nice day!


----------------
256.4:

Sure @radek_jasinski , will give a try . Thank you !.

----------------
256.5:

Super, if you need help, ask

	Have a nice day!


----------------
257:

Hello,
I'm trying to connect a service principle from Azure to monitor a resource group but each time connecting it I'm getting an "Invalid Credential" error. To go a bit deep, I've retried to connect the ones which are already connected in our prod env to non- prod they too say the same error.
Any suggestion to fix this please? 



					
						Solved!
					
					Go to Solution.




----------------
257.1:


The only small thing I can suggest is to check the Secret Key and other values are clean, so they do not cain any spaces, special or hidden characters.You could also check in the AD Logs of Azure and maybe the activity logs and see if there is any activity for your service principle - that might contain more information

----------------
257.2:


Hello,This is issue occurred mostly the secret key got expired, please create new secret key value for the appropriate service principal and update the same in Dynatrace azure service monitoring.Thanks 

----------------
258:

Dear Community members,I know you missed me :). I have a FUNNEL Dashboard, but I want to display in the result only the last step.Is there any way to mask the other first step (s) to be displayed? Thanks for your help in advance.BRs,

	Sharing Knowledge


----------------
258.1:

I think that what you want is a single value count, you can put two things to make this work"Count" and "where" like thisSELECT count(useraction.name) FROM usersession where useraction.name="AppStart (easyTravel)" This query will bring to me the count of the user action name AppStart (easyTravel)"

	Dynatrace Professional Certified


----------------
258.2:

Thanks for your feedback, but the number will not be accurate,I want for sur the count for the last step, but for whome that are followe the specific journey.Example:Journey: action A, action B, action Cwith your query, the count of (c) will be made even if the user wasnt make the action A and/or B whcih is not what I want.

	Sharing Knowledge


----------------
258.3:

oh okay, got it. You can do this with "and" expression like thisin this query you get what you want action A, Action B, Action C but only will show up the value of action C. SELECT COUNT(*) FROM usersession where useraction.name = "AppStart (easyTravel)" AND useraction.name = "searchJourney" AND useraction.name = "bookJourney" X SELECT FUNNEL (useraction.name = "AppStart (easyTravel)", useraction.name = "searchJourney", useraction.name = "bookJourney")FROM usersession  The result of the two queries above will be almost the same but when we use "and" expression we bring only the journey that passed thru Action A,B, C When we use funnel we see the Journey that passed the thru A, A And B and A,B,C  

	Dynatrace Professional Certified


----------------
258.4:

Thanks for your effort,But this is not 100% correct, the case is more complicated than that. The and, will count the journey A, B, C but also A, C, D and all other combinaisons.So the result with and will not be equal 100% to the FUNNEL

	Sharing Knowledge


----------------
259:

Hello, 
We are facing an scenario where the client has their application in AWS Fargate, everything is fine, we are monitoring the application and the api services, but in Dynatrace is not showing anything as web application, what we see is as web request service. Btw they are using a ALB to redirect the url, we also see the balancer in the smartscape as a single process, no unify with the app and apis of aws.
We need to have the web application showing in Dynatrace to start monitoring the user experience.
 
Do you have any idea how to solve this issue?
 
Thanks.
 
Regards,
Johanna



					
						Solved!
					
					Go to Solution.




----------------
259.1:


Hello @JB when you use AWS Fargate, only the applicationMonitoring deployment without the CSI driver is supported. I'm assuming they have a web server running inside this pods, my guess is that in this mode OneAgent is not injecting the JS tags on the pages of your webserver inside this container. So my recommendation is to create an Agentless Real User Monitoring and inject the JS tags in your web server pages to be able to monitor user experience. Please let me know how it goes.

	The true delight is in the finding out rather than in the knowing.


----------------
259.2:

Thank you very much for the explanation. This was the solution!!

----------------
259.3:

@JB  Hi,Please can you tell me Out of 3 deployment options which approach you have used, particularly out of Buildtime and runtime which approach is better and what advantages it has. Thanks

----------------
260:

Hi community,
Was wondering if anyone have some deck/slide about Dynatrace feature comparison with other softwares?
The only thing I have is Gartner documentation which is long and wordy.
Thank you.



					
						Solved!
					
					Go to Solution.




----------------
260.1:


Some things about this exist. But you can only compare them using the documentation of the other software, I will leave here some links that maybe will help you:
https://www.dynatrace.com/platform/comparison/dynatrace-vs-datadog/
dynatrace.com/platform/comparison/dynatrace-vs-appdynamics/
https://www.dynatrace.com/platform/comparison/dynatrace-vs-new-relic/

	Dynatrace Professional Certified


----------------
261:

Hello Dynatrace community,
 
I need to collect business data from GCP BigQuery. I tried to integrate this into "Generic DB Query Plugin" of Dynatrace ActiveGate.
I download latest Simba driver file SimbaJDBCDriverforGoogleBigQuery42_1.3.3.1004.zip to get GoogleBigQueryJDBC42.jar and others java libraries and put them in the right directory D:\dynatrace\remotepluginmodule\plugin_deployment\custom.remote.python.dbquery\jars
I also modify lightly dbquery_extension.py and plugin.json to be able to configure a endpoint of that new defined type.
It didn't works yet but the stranger thing is that i didn't found any errors even in deep diving logs into C:\Windows\ServiceProfiles\LocalService\AppData\Local\Temp\dynatrace-ag-dbquery
Does somebody have experiences to help on that particular topic of integrations of new jdbc drivers, pls ?
 
Thanks by advance for your help.
Best regards.
rsf

----------------
261.1:

Integrating a new JDBC driver for Google BigQuery into Dynatrace's "Generic DB Query Plugin" can be challenging, and it's important to ensure that every step of the integration process is correct. Since you're not receiving specific error messages, let's go through the integration process step by step to see if we can identify the issue:1. JDBC Driver and JAR Files:- Ensure that you have the correct and compatible version of the Simba JDBC driver for Google BigQuery (GoogleBigQueryJDBC42.jar) for your Dynatrace version.- Verify that you've placed the JAR files in the correct directory (`D:\dynatrace\remotepluginmodule\plugin_deployment\custom.remote.python.dbquery\jars`).2. Database URL and Credentials:- In your `dbquery_extension.py` file, double-check the configuration for the BigQuery database URL and the credentials used for authentication. Ensure that they are correctly set up.3. Plugin Configuration (`plugin.json`):- Make sure that you've updated the `plugin.json` file to define the endpoint for the new JDBC driver type accurately.- Check that the JSON structure is correct, and all required fields are properly configured.4. Testing the Connection:- Try to test the JDBC connection separately outside of Dynatrace to ensure that the driver and credentials are functioning correctly. You can use a simple Java program or a JDBC client tool for this purpose.5. Log Verbosity:- Increase the log verbosity in Dynatrace's plugin configuration. This can sometimes provide more detailed error messages that can help pinpoint the issue.6. Restart ActiveGate:- After making any changes, ensure that you restart the Dynatrace ActiveGate to apply the updates.7. Permissions and Firewalls:- Confirm that there are no firewall rules or network restrictions preventing the ActiveGate from connecting to Google BigQuery.- Check that the credentials you're using have the necessary permissions to access BigQuery.8. Dynatrace Community and Support:- Consider reaching out to the Dynatrace community or their support resources. Other Dynatrace users may have encountered similar issues and can provide guidance or solutions specific to Dynatrace's plugin framework.9. Review Documentation:- Carefully review the documentation provided by Dynatrace for plugin development and integration, as it may contain specific guidelines or best practices for integrating custom JDBC drivers.10. Debugging:- Implement thorough error handling and debugging in your plugin code to capture and log any potential errors during the execution of database queries. This can help you identify specific issues with the integration.11. Testing in a Controlled Environment:- Always test your changes in a controlled environment to avoid impacting your production setup.By following these steps and paying close attention to the configuration details, you should be able to identify and resolve the issue with integrating the Google BigQuery JDBC driver into Dynatrace. If you encounter specific error messages or face further difficulties, please provide more details for more precise assistance.

	Dynatrace Professional Certified


----------------
262:

We are trying to build an extension for fetching Prometheus metrics from a system. We have already created the extension.yaml to define the metrics, featureset, groups etc but needs some sample alert.json  & dashboard.jsonto build the full extension bundle zip (to be uploaded to the DT tenant). Our extension would run locally as an Oneagent extension .my-sample-extension/└── src/├── extension.yamldashboards/└── dashboard.jsonalerts/└── alert.json   Can anyone help please?Thanks 

----------------
262.1:

The easiest by far is to use the Dynatrace extension addon for vscode. That one can generate both the dashboard and alert jsons. That is what my team uses for all of our extensions.

----------------
263:

I have a code like this:
 
export default async function ({ execution_id }) {
    // get and verify event context
    console.log("Get and verify event context")
    var exec_req = await fetch(`/platform/automation/v1/executions/${execution_id}`)
    var execution_obj = await exec_req.json()
    if (!'event' in execution_obj.params) {
        return { problem: null }
    }
    var event = execution_obj.params.event

    // get problem details
    console.log("Loading Problem details...")
    var problem_request = { problemId: event['event.id'] }
    var problem = await problemsClient.getProblem(problem_request)

    return { problem }
    
 
And the error is: 
 
An error occurred: Action result is too large. Do not use results for passing bulk data.
 
In the last line, returnWhat other ways are there to return a large result in wokflows? I am trying to get an answer in this documentation https://developer.dynatrace.com/develop/workflows/
Many thanks

----------------
263.1:

I forgot to mention, I need to return the information for use in another workflow task.

----------------
263.2:

The "Action result is too large" error typically occurs when you're trying to return a very large object or a result that exceeds the allowed size limit for the response. To resolve this issue, you can take the following steps:1. Check the Size of `problem`: Since the error message mentions "Action result," it's likely that the `problem` object being returned is too large. You should inspect the size of the `problem` object and its nested properties.2. Reduce the Size of `problem`: If the `problem` object is indeed too large, consider whether you can reduce its size by excluding unnecessary data. You might only need specific properties of the problem rather than the entire object.3. Pagination: If the `problem` object contains a list of items or records (e.g., a list of comments or attachments), consider implementing pagination to fetch and return smaller subsets of data at a time.4. Compress Data: If the data cannot be reduced further, you can consider compressing it before sending it as a response. JavaScript provides libraries and functions for data compression, such as `zlib` or `pako`, depending on your environment.Here's an example of how you might apply compression to the response:```javascriptimport zlib from 'zlib';export default async function ({ execution_id }) {try {// ... (fetching and processing data)// Compress the problem dataconst compressedProblem = zlib.deflateSync(JSON.stringify(problem));return { compressedProblem };} catch (error) {console.error("An error occurred:", error);return { compressedProblem: null };}}```5. Consider Streamlining: If you're working with extremely large datasets, consider a different approach that doesn't involve returning the entire dataset in a single response. For instance, you might implement streaming or provide options for users to request specific parts of the data.Remember to adjust the client-side code that consumes this function to handle the compressed data appropriately.

	Dynatrace Professional Certified


----------------
264:

Is there a way to show deployment events (or any sort of events) from Hosts or Services etc. on the Dashboard? maybe even inside the graphs that contain metrics of these assets?
 



					
						Solved!
					
					Go to Solution.




----------------
264.1:

Events are only located on the entity pages and not tile-able from what I am aware of. A RFE would need to be submitted to get this functionality. 

	-Chad


----------------
264.2:

Where does one see the ingested events? We were hopeful that we could see all ingested events for a given time period. If we send in events under "Custom Info" where would we be able to see them?

----------------
264.3:

Hi @mathias_indermu Have You tried to use RELEASES dashboard? Usually what You want to achieve by pulling events on dashboard is global understanding of Your services and their status. RELEASES built-in dashboard show all relevant events for Your processes. It requires releases to be configured and implemented obviously.

----------------
264.4:

Hi All,Maybe this integration can be useful such cases. This solution pull the Events also via Events API and vizulaize in PowerBI in time order. https://www.youtube.com/watch?v=PNX0jCL8AHcI hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
264.5:

We are considering just to send metrics instead of deployment events(They are designed pretty useless.)In this case it will be possible to correlate deployments in all charts.

----------------
264.6:


It's possible to put events on a dashboard (if you're on Grail) with the "fetch events" command (see example in https://www.dynatrace.com/support/help/platform/grail/dynatrace-query-language/commands#parse ).

----------------
264.7:

It's pretty disappointing that adding events to a Dashboard is Grail-dependent.  It seems like this will NOT be available to Dynatrace Managed customers.

----------------
265:

Is there any way to disable auto restart of Oneagent post server reboot?



					
						Solved!
					
					Go to Solution.




----------------
265.1:

If you turn off monitoring via the Dynatrace UI that should solve your problem  

	-Chad


----------------
265.2:

possible to perform using command line? so the init services which are responsible for start doesnt do anything if we disable.

----------------
265.3:


@SachinJindal you can stop oneagent from being started by modifying the systemd unit file (Linux) / configuring the sysv (Linux) or using services (Windows).What is the use case here you are trying to solve? I'd not recommend disabling the startup of oneagent and prefer the UI or API method which @ChadTurner suggests.Agent disabled in Dynatrace does not perform any actions except for sending heartbeats to Dynatrace.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
265.4:

just wanted to stop the Dynatrace for quite some days  and it shouldnt startup if Servers are rebooted assuming we dont have DT UI access

----------------
265.5:

Then only way is to modify the startup of the agent itself. Not a great idea, since you can manage it from Dynatrace UI/API afterwards.Anyway, I don't recommend shutting down OneAgent unless there are really very good reasons. I recommend to either get access to the UI/API so you can manage it from there. Doing manual startup changes is discouraged in general.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
265.6:

You can also leverage the Services portal (Assuming you have SaaS access) which lives outside your Dynatrace UI to enable/disable the oneagent. 

	-Chad


----------------
265.7:

Hello, Assuming Linux OS -The doc page is here: Stop/restart OneAgent on Linux but this doesn't answer your specific question directly.OneAgent is installed as a system service, so you can use systemctl commands to disable or enable, example:   $ sudo systemctl disable oneagent.service   $ sudo systemctl enable oneagent.serviceYou'll need 'root' - with related complications. If you have root, then I'd anticipate you should be familiar with systemctl, hence please consider above advice to disable/enable from cluster side (which admittedly still lets OneAgent initiate at the OS service level).  

----------------
266:

ive added a tag to track users sessions in the RUM, I can see users logging in with the correct username as the tag, however i have one user MR bloggs, now when i logged in yesterday with mr bloggs i never found him as a users session, so i cleared the broswer of cookies and sessions and tried again, this time i did see the sessions, excellent!!! today when i log back in as Mr bloggs and try again, same again nothing, i dont see mr bloggs sessions, surely you cant delete sessions and cookies just to track users! that would be pretty insane.  any idea?



					
						Solved!
					
					Go to Solution.




----------------
266.1:


Maybe your user tag its not correctlyHere take a look on this documentation  https://www.dynatrace.com/support/help/platform-modules/digital-experience/web-applications/addition...

	Dynatrace Professional Certified


----------------
267:

I am getting pretty proficient automating the pulling of metrics via the V2 API. My next challenge is how to create basic queries for statistics OpenShift pods from Kubernetes. I am totally stumped.  Anyone have any good examples? Lou



					
						Solved!
					
					Go to Solution.




----------------
267.1:


If there is a metric for that (Check it in the menu Metrics in UI), then you are able to pull it easily. Is there any specific metric you need to query?

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
267.2:


This is a great list of the metrics and metric keys that are in Dynatrace: https://www.dynatrace.com/support/help/how-to-use-dynatrace/metrics/built-in-metrics/saas/

	-Chad


----------------
267.3:

So for example, I am trying to pull builtin:containers.cpu.usageMilliCores for an OpenShift entity. I can easily pull that with type(CONTAINER_GROUP_INSTANCE),entityName("my-app"). However I cannot seem to pull by tag that my-app belongs to.Lou 

----------------
267.4:

Same here would like to be able to see what each container is using as a total for millicores

----------------
267.5:

i am working on automating the pulling of metrics via the V2 API , could you please help if you have any resources or steps? thank you

----------------
267.6:

@dynamic  for pulling metrics, you need to use the Metrics API - Get metric data points. You need to supply parameters such as entitySelector and timeframe at least. Metric selector and entity selectors can be tricky for beginners, however for the new Unified Analysis Screens it's easy to show it in the data explorer: And then you can just copy the metric selector from there or also use the filter part as entitySelector. 

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
267.7:

I can pull metrics from API, however, I need to automate the next page key to pull data in real-time. and then create a report based on that data.  is there an efficient way to do it? the goal is to connect to powerBi

----------------
268:

 When I met Viachaslau Balashevich, I immediately noticed how communicative and what a people person he was. He admitted he liked discussion and different people, as much as challenging them! Can only confirm that during our meeting he was challenging me as well.  
We spoke about many things: the product, the industry, the people from the IT world, but also about the importance of being human, not a machine or a robot these days. The common thread of the conversation was the value of constantly asking yourself the question “Why?”, and the critical thinking as a concept that Viachaslau believes in and represents. 
Without further ado, I’d like to invite you to get to know our Community Member of the Month - @Viachaslau. ________________________________________________________________________________________________________________________________________________
Can you share some details about your past? What is your story, and how it happened that you decided to work in the IT / APM area?   
When I was a child, like many other young boys, I dreamed about outer space. I grew up on books by Ayzek Asimov, Gary Garrison, Frank Herbert, and many others.    
After school, my path to IT could have been more straightforward. Initially, I got 2 higher educations: In History and Social science and later in International Law. It was helpful to lead my own small business in the construction area. Leading my own company resulted in having an introduction to IT. We needed a website and administration. So, it was on me to set this up. After my freelance period, I decided to go “all-in into IT” and chose to follow several IT courses. Finally, I was able to work on some severe IT projects.  
In my current project, I was introduced to Dynatrace as an APM tool for mobile and web applications. Some developers were concerned about its code customization which felt like a “burden” to them and diverted them from “real code”, but for me, it was and is a great tool that can show the fair product state and quality of systems and applications in real-time.  Scrum in the real world - product is changed in your hands. LEFT: I have some idea…. / RIGHT: MVPCan you tell us a little bit about your professional life? Where do you work, and what do you do in your job? And how does Dynatrace fit into the picture?   
I have been working at EPAM Systems for more than 7 years. Currently, I’m the IT Solution Architect Monitoring & Observability for Motorola Solutions, helping them in their digital transformation journey. One of my primary responsibilities is to care for the observability of the entire IT ecosystem. Dynatrace plays a key role in this process by supplying reliable data, based on which we can set up quality gates and deep information for operations.   Hobby and travel. LEFT: We have no mountains in the Netherlands, but we can still climb. / RIGHT: I like travel – it helps me to get new ideas and relax.What was the biggest challenge Dynatrace helped you to overcome?   
The challenging task is to build a forecast for product quality and predict problems. I must detect problems in real-time and create impact analysis as quickly as possible to limit the impact of those problems. Luckily, Dynatrace helps in this with significant amounts of built-in and custom metrics. What brought you to our Community? What made you stay? What best advice can you give someone who just started using Community? My primary stimulus for joining the Community was and still is experience exchange.  And now the Community is also helping me to find answers to non-standard questions. Tell us something about you that most people don’t know. What is your biggest joy or passion in life? 
We live close to the sea, there are a lot of parks in my city. My favorite hobbies are playing volleyball, cycling along the dunes, and having activities with my Family.  Once upon a time in the summer LEFT: Have no dog yet but like to be a dog-sitter for friends. / RIGHT: Our volleyball community.
What’s one thing on your bucket list? Your dream? 
My dream is to imagine a world without wars, where we will be focused on making life better, longer, healthier without poverty and struggling to get basic things. ________________________________________________________________________________________________________________________________________________Viachaslau, having you as one of the Community users celebrating the critical mindset is a real value, both for our Community and for Dynatrace. Looking for different perspectives and choosing the best one makes Dynatrace a better product. More is yet to come, so we’re looking forward to more challenging from you 

----------------
268.1:

Congrats @Viachaslau !

----------------
268.2:

Congrats @Viachaslau 

----------------
268.3:

Thank you) 

----------------
268.4:

Aha!! It seems that the season of music players has gone and now we are selecting athletes as member/employee of the month!Congrats, @Viachaslau !!!Now you need to set up a match with our Employee of the month. My bet is on you. Go, Members, go!!!

----------------
268.5:

Great Work @Viachaslau !!!! Another Asimov fan here.

----------------
268.6:

Super, keep it up!

----------------
268.7:

Congrats!Awesome post.Ayzek Asimov Pembroke Welsh Corgi  

----------------
268.8:

Congratulations @Viachaslau !!!

----------------
268.9:

Congrats @Viachaslau 

----------------
268.10:

congrats 

----------------
268.11:

Loved the eclectic path!I believe that such a diverse set of skills has been of great use throughout life, in so many wide-ranging use-cases!Congrats, @Viachaslau !!

----------------
269:

Hi!
We are using Generic DB Query Plugin and its behavior is strange - it is not working according to the documentation and configuration settings.
While there was just one endpoint and one query, everything worked as expected. There was one metric, and we customized the metadata for it - pretty name, units (seconds), dimensions, panels, and alerting.
Then, we created one more endpoint, that is completely different - it is gathering data from another database, with different metrics, dimensions, etc. Data is ingested correctly (based on the logs), but everything from all the queries is now mixed within that first metric created. Ie no new metrics are created from the value columns, all that is gathered is added to the first metric, and it is a mess.
Plugin documentation states that different metrics will be created. When I reached the Dynatrace team, they explained that the plugin could (for some reason) create only one metric and we are expected to differentiate by splitting. But how do we use different unit types (seconds, count, etc.) if this is a single metric? Alerting also works strangely as it triggers on data coming from various queries.
Does anybody have experience of using the DB Query Plugin with multiple databases and queries? How do we split the feeds into different metrics? Or is there an alternative to this plugin?
Thank you!

----------------
269.1:

We have a 1 to 1 ratio - 1 query for 1 server as 1 Generic DB Extension Endpoint. We have not run into any issues.

	-Chad


----------------
269.2:

Yes i agree. Everything is stored in custom.db.query metric but so it's quite difficult to manage it (filtering to select data for many dashboards).

----------------
270:

Hey guys,
 
It's possible to get metrics from monitored database like Oracle, Postgre using Grail?
Today we are using third party extension to run queries and get data but for some reason it is not fetching it correctly.
Thanks!!

----------------
270.1:

Hi,If you have extensions that monitor your databases you can fetch them by using Metric API. With Grail you can currently fetch only built-in metrics. Best Regards,Mateusz

----------------
270.2:

Hi Mateusz,is there any plan to send extension metrics to Grail ? near future ?Thanks for your answer

----------------
271:

Hi,
We face an issue monitoring calls through a DataPower.A monitored service calls a monitored web service through a Datapower but the purepath can't track the calls through it. We only see calls to an unmonitored host for these calls.
I have checked with the network team and we see 3 headers in the requests (X-Forwarded-For, X-Client-IP and X-Global-Transaction-ID), and one header in the responses (X-Global-Transaction-ID).
Is that OK, or should I see other headers (X-dynaTrace)?
Thanks for your help.

----------------
271.1:

Hi Giles,Yes, to see the transactions go through the Datapower tier, you have to ensure that the X-dynaTrace header is not stripped and is passed through Datapower to the next tier. This is what I did to see my transactions go through Datapower.ThanksNJ

----------------
271.2:

Hello Ugochukwu;Do you know where I could apply the configuration in the datapower?Thanks for your answer.RGuerrero

----------------
271.3:

Hi NJ!Could you please share any details regarding the DataPower configuration? We are currently also facing this issue. Thank you in advance!RegardsArild

----------------
271.4:

Hi Ugo,Thanks for your answer.I'll check this.Gilles

----------------
271.5:

Hi,I come back to this issue. My customer confirmed that the x-dynaTrace header is stripped.But they did not find an easy way to configure the whole Datapower to copy the incoming request header to the outgoing request without having to set up a rule on each service (more than 200).Did anyone find a solution to apply that rule to the whole Datapower config?Thanks.Gilles

----------------
271.6:

hi All,i have same issu with dynatrace not allow x-dynatrace header after IBM DP, on proses MQ, there are solution how to allow x-dynatrace header on MQ, to show service flow end to end.need help for some documentation for allow Header on MQ Proses.Thnks

----------------
272:

Hi,I do not understand if both are required to configure a custom path in a Linux server.Is log storate new one and custom log source legacy one?Both configurations are required to configure a custom path?Thank you so much!Best regards

	Consultant




					
						Solved!
					
					Go to Solution.




----------------
272.1:


Hi @AntonPineiro,The custom log storage which related to the logs that are not detected automatically by OneAgent, so you can specify the log source path. after adding the customized log source path you need to create another rule in the Log storage configuration to include/enable this custom log source and to be monitored.as for other log files that are automatically detected by OneAgent, you can create log monitoring configurations directly without creating any custom log source.so yes both are required to configure custom log path, the first step to configure the custom log path and the second step is to include/enable monitoring for this custom log.I hope this helps you and let me know if further clarifications are needed. 

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
272.2:


Hi @AntonPineiro , In response to your first question, there is no 'new' or 'legacy' in terms of log storage and the custom log source. Both are required in order for you to be able to detect a log that is not natively discovered by Dynatrace, as described by @Mohamed_Hamdy .  In addition, the documentations required for you to be able to do both can be found here, where it specifies that it must be done in two parts. Attaching the screenshot as well for visibility,https://www.dynatrace.com/support/help/shortlink/log-monitoring-custom-source  

----------------
272.3:

Hi,Thank you both. It is strange, I have just only created a log storage configuration (without log source configuration) and logs are being ingested.It is in relation to Windows Application Logs, maybe for Linux both rules are required.Best regards

	Consultant


----------------
272.4:


@AntonPineiro you definitely need log storage configuration (rules about what to ingest). If the log file is autodetected (windows event logs, standard linux log paths such as /var/log/syslog or any logs detected automatically (you can see them on the process group instance screen), then you don't need any custom log source rules.There is an exception - custom log source are still required for AIX for any logs. Autodetection is not working for AIX. Also if you still cannot see any entries, be sure to check loganalytics logs from the agent. It's not uncommon for the custom path to be blocked by security rules which can be overridden in the OneAgent configuration file.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
273:

SLO created pseudo-metrics which not possible to use in Metric key configuration.(Err: Stored metric expressions are only supported in metric-selector-based query mode.)
This leads to affective limit about 100 SLO or less:Configuration limit of metric-selector-based configurations:Static threshold: 4 out of 100Auto adaptive threshold: 0 out of 100Seasonal baseline: 1 out of 100We want to have SLO for each key user action and different API.In this case it is just impossible.
Based on standard best practices SLO should not be without the alert.
What is workaround?

----------------
273.1:

It appears that you're facing a limitation with your current service level objective (SLO) configuration related to metrics and alerting. Here's a breakdown of the issue and some potential solutions:1. **Limitation on Stored Metric Expressions:** The error message you received suggests that you're using pseudo-metrics that cannot be used in Metric key configuration, and it's also stating that stored metric expressions are only supported in metric-selector-based query mode. This limitation is restricting your ability to configure SLOs for different user actions and APIs effectively.2. **Configuration Limits:** You mentioned that there are configuration limits for different types of SLO configurations, such as static thresholds, auto-adaptive thresholds, and seasonal baselines. These limits can further restrict your ability to set up SLOs for a large number of user actions and APIs.3. **Best Practices:** You've correctly noted that SLOs should ideally be associated with alerts. This is a standard best practice in monitoring and incident management, as it allows you to proactively detect and respond to issues that violate your SLOs.To address these challenges, consider the following steps:1. **Review Metric Configuration:** Check if there are any alternative metric configurations or query modes that allow you to use the stored metric expressions effectively. Consult your monitoring tool's documentation or support resources for guidance on this.2. **Evaluate SLO Priorities:** Prioritize the key user actions and APIs that are most critical to your application or service. You may not be able to set up SLOs for every possible action, so focus on those that have the most significant impact on user experience or business objectives.3. **Combine Metrics:** If possible, consolidate metrics to reduce the number of individual SLO configurations. For example, if multiple user actions share similar performance characteristics, you can group them together under a single SLO.4. **Custom Alerting:** If you cannot configure SLOs for all user actions and APIs within the limitations of your monitoring tool, consider setting up custom alerts using a different approach. While SLOs are a preferred method, custom alerts can still help you monitor and respond to issues effectively.5. **Advocate for Improvements:** If the limitations of your monitoring tool are hindering your ability to implement SLOs effectively, provide feedback to the tool's vendor or development team. They may consider expanding the capabilities of their SLO and alerting features in future updates.In summary, while the limitations you've encountered can be challenging, careful prioritization and creative solutions can help you establish effective SLOs and alerting mechanisms for your key user actions and APIs. Additionally, providing feedback to your monitoring tool's vendor can contribute to future improvements in this area.

	Dynatrace Professional Certified


----------------
273.2:

I had a conversation with the support: limit can be increased to 500 by request for environment.

----------------
274:

Some of the actions/tasks may require credentials. Will workflows use a credential vault for tokens and passwords? 
 

 When passion meets people magic and innovation happen. 




					
						Solved!
					
					Go to Solution.




----------------
274.1:


Workflow actions for integration typically require connecting to third-party systems and coming with their own settings schema. Those connections are then managed in Dynatrace settings 2.0. Ad-hoc scripts can leverage both settings and the credential vault via the SDKs.

	Michael


----------------
274.2:

For reference, you can access the Credential Vault by following the following API instructions.https://developer.dynatrace.com/reference/sdks/client-classic-environment-v2/#getcredentialsdetails import { credentialVaultClient } from "@dynatrace-sdk/client-classic-environment-v2";

const data = await credentialVaultClient.getCredentialsDetails({
  id: "...",
});

----------------
275:

I would like to start here discussion/ experience exchange for Monaco usage beyond simple deployment templates to another environment.E.g.- custom logic/scripts on the top of JSON and YAMLs- reporting to fill UI gap in data presentation- Partial data sync insisde same envronment- replacing pure API calls with Monaco actions/configs- creation different configs based on product/mz difference- user management- different anomaly dtection rules for different host groups- Your examples)



					
						Solved!
					
					Go to Solution.




----------------
275.1:


Absolutely, let's explore various ways to extend Dynatrace Monaco beyond simple deployment templates to enhance your Dynatrace environment. Feel free to share your experiences or ask questions about these scenarios1. Custom Logic/Scripts with JSON and YAML:- Have you used Monaco to embed custom logic or scripts within your configuration templates? For instance, to perform advanced calculations, data transformations, or dynamic configuration adjustments based on certain conditions?2. Reporting to Fill UI Gap in Data Presentation:- Have you built custom reporting solutions using Monaco? This could involve extracting performance data from Dynatrace and presenting it in custom dashboards or reports tailored to your specific needs.3. Partial Data Sync within the Same Environment:- How have you managed partial data synchronization within a single Dynatrace environment? This could be useful for ensuring that specific configurations or settings are consistent while allowing for variations in other parts of the environment.4. Replacing Pure API Calls with Monaco Actions/Configs:- Share your experiences in transitioning from manual API calls to utilizing Monaco actions and configurations for more streamlined and automated management of Dynatrace settings.5. Creating Different Configurations Based on Product/MZ Difference:- Have you implemented Monaco to create and manage distinct configurations based on product-specific or microzone-specific requirements within your Dynatrace environment?6. User Management:- How have you leveraged Monaco for user management tasks, such as provisioning users, assigning roles, and configuring access controls within Dynatrace?7. Different Anomaly Detection Rules for Different Host Groups:- Share your strategies for setting up Monaco to apply unique anomaly detection rules to various host groups or services based on their specific performance profiles. If you have any questions or need further guidance on any of these topics, please don't hesitate to ask.

	Dynatrace Professional Certified


----------------
276:

Hi,
We are trying to integrate Dynatrace with Ansible Tower.
To integrate both it's neccessary configurating the job template URL. 
But our URL is a job ID that belongs to a workflow job template. This is the URL: https://xxxxxxxxxxxx/#/templates/workflow_job_template/xx
Our question is: is Dynatrace compatible with Workflow Templates to integrate it with Ansible Tower?
Thanks in advance.
Regards,
Elena.



					
						Solved!
					
					Go to Solution.




----------------
276.1:


Yes, its compatible.Look at the documentation.You can transform your message the way it fits into your workflow template https://www.dynatrace.com/support/help/observe-and-explore/notifications-and-alerting/problem-notifi...

	Dynatrace Professional Certified


----------------
277:

Hi, would it be possible to update the Gradle plugin for android to use the Gradle Plugin DSL, i.e., use the plugins block rather than the legacy classpath in a buildscript block. I think what is required is to update the artifactId in your plugin, but I'm not sure. All of our projects plugins support the plugin DSL except for the dynatrace plugin. Thanks



					
						Solved!
					
					Go to Solution.




----------------
277.1:


The Dynatrace Android Gradle plugin does not contain plugin marker artifacts and therefore the resolution via the Gradle plugin DSL does not work automatically. It is possible to manually set up the resolution step and use the Gradle plugin DSL.I can forward your feature request to our product manager. Or you post this topic via the Suggest an idea button. Then it will be automatically tracked by our product manager and he can provides updates to you and other interested customers.

----------------
277.2:

For those following along, the idea suggestion is here:https://community.dynatrace.com/t5/Product-ideas/Gradle-plugin-Add-support-for-Gradle-Plugin-DSL/idi... 

----------------
278:

Hello:I am tyring to find a way to graph/show Exceptions that contain a specific message. The exception thrown above in the title (System.Data.SqlClient.SqlExecution)Provides all the exceptions (From the Multidimensional Analysis View) that match that exception.However, the message content can vary greatly.Ideally, I would like to find all of those exceptions that contain in the message "Timeout expired." Is there a way to do this? Kindly,Chris. 



					
						Solved!
					
					Go to Solution.




----------------
278.1:


you can try using log search

	Dynatrace Professional Certified


----------------
278.2:

Would log search associate the log entries by service? I did not see a way to do that.

----------------
278.3:


Sorry for the latest reply, i was searching about and i found what you looking  Search in multidimensional analysis and filter by Exception  And put the text of the exception like this  

	Dynatrace Professional Certified


----------------
279:

Similar to "custom/generic database query" we are looking for a plug-in that allows us to make REST calls and store the result as custom metric in dynatrace. 
 
Is there a tool available to do so. The query should run every minute to create useful metrics over time. 



					
						Solved!
					
					Go to Solution.




----------------
279.1:


Hi,There are a few ways to do that.Extensions and Scripting integrationExtensions SDK 1.0You can write your own script/simple app and use REST APISee also other ways to extend Dynatrace. Best regards,Mateusz

----------------
279.2:

The challenge is nit the Rest API but the fact that the endpoint called is providing ODATA 4.0 response that has to be parsed and converted into a metric. It does not seem there is any out-of-the-box solution that supports that within synthetic scripts. 

----------------
280:


My fellow DynaMight  Patrick Hofmann pahofmann has shared several Postman collections for the different Dynatrace API's with the community. 
Encouraged by this because I use them daily, I created a Postman Collection for the new Account management API following the guidelines used in the ones created by Patrick. 
I share the steps to get this working in your Postman client.
 


1. Create an Oauth2 Client in Dynatrace
For more reference in this step you can take a look at this post from @AgataWlodarczyk with a video from @adam_gardner 


Open the User menu and select Account settings (in latest Dynatrace, Account Management).


On the top navigation bar, go to Identity & access management > OAuth clients.


Select Create client.


Provide an email of the user who owns the client.


Provide a description for the new client.


Select the required token scopes. These are the scopes that the client will be able to grant. Tokens generated by the client might have different scope sets.

Allow read access for identity resources (users and groups) account-idm-read
Allow write access for identity resources (users and groups) account-idm-write
Allow read access for environment resources account-env-read
Allow write access for environment resources account-env-write
Allow read access for usage and consumption resources account-uac-read
Allow write access for usage and consumption resources account-uac-write
Allow IAM policy configuration for environments. iam-policies-management; iam:policies:read; iam:policies:write; iam:bindings:read; iam:bindings:write; iam:effective-permissions:read.



Select Create client.


Copy the generated information to the clipboard. Store it in a password manager for future use.


 
2. Create an Environment for your Collection in Postman
 
 Environment

Select Environments.
Click the + sign.
Name your Environment.
The environment needs that you define these variables:

DT_CLIENT_ID Provided when you create the Oauth2 client in step 1.
DT_CLIENT_SECRET Provided when you create the Oauth2 client in step 1.
DT_ACCOUNT_URN Provided when you create the Oauth2 client in step 1.
DT_UUID Same value of DT_ACCOUNT_URN but stripping the urn:account:
DT_SCOPE A list of required scopes separated by a whitespace.
DT_TOKEN_URL  PLEASE DON'T CHANGE THIS VALUE  The URL https://sso.dynatrace.com/sso/oauth2/token where you need to obtain your Bearer token after create the Oauth2 client.
DT_TOKEN_NAME The name for your token.
DT_TOKEN In this variable you will store your assigned dynamic token.
DT_HOST  PLEASE DON'T CHANGE THIS VALUE  The URL api.dynatrace.com of the Dynatrace API for Account Management.


Leave this Environment Selected.

 
3. Import Dynatrace Account Management API Collection
 
 Import

Download the Dynatrace Account Management JSON from the repository.
Select Collections.
Click on Import and choose the previously downloaded JSON.
Your Dynatrace Account Management API v1 Collection has been added to your collection.

 
4. Get your Bearer Token
 
 Get your Bearer Token

 DON'T FORGET TO HAVE SELECTED THE ENVIRONMENT CREATED IN STEP 2 
Select your recently imported Dynatrace Account Management API v1 Collection.
Click on the Authorization tab.
Click on Get New Access Token.
Wait until the token has been collected.
Click on Use Token.
 BE SURE TO SELECT ALL YOUR TOKEN  And then select Set as variable.
Choose the DT_TOKEN variable to store your new Bearer Token.

 
5. Ready, Set, Go 
 
 Using Collection

 DON'T FORGET TO HAVE SELECTED THE ENVIRONMENT CREATED IN STEP 2 
Select Collections.
Then Select the Request you want to use and check the parameters.
Click on Send.
And if everything goes well you get your Response.



	The true delight is in the finding out rather than in the knowing.


----------------
280.1:

Thank you for documenting this @DanielS 

	-Chad


----------------
280.2:

Your welcome @ChadTurner. The use of Oauth2 clients to obtain valid Bearer tokens is what is coming to Dynatrace API.

	The true delight is in the finding out rather than in the knowing.


----------------
280.3:

This is gold!

	Site Reliability Engineer @ Kyndryl


----------------
280.4:

Thanks @dannemca It took me a while to implement it in Postman, but it will surely be very useful for interacting with the API. I'm thinking improvements for future releases.

	The true delight is in the finding out rather than in the knowing.


----------------
280.5:

WOW!This is a very good and detailed guide! Thanks for sharing it @DanielS !

	Certified Dynatrace Professional


----------------
280.6:

Thanks @Mizső hope it helps.

	The true delight is in the finding out rather than in the knowing.


----------------
280.7:

GOLDEN!!!

	Dynatrace Certified Professional


----------------
280.8:

Thanks @Kenny_Gillette 

	The true delight is in the finding out rather than in the knowing.


----------------
280.9:

Awesome, Thanks to share.

	Sharing Knowledge


----------------
280.10:

As a Partner who often needs to manage several Accounts, this is so very very useful!! Thank you, @DanielS !!

	Best regards, Pedro Deodato


----------------
280.11:

Glad to help @PedroDeodato 

	The true delight is in the finding out rather than in the knowing.


----------------
281:

In this exciting new series called DynaLabs, Technical Product Specialists from Dynatrace ONE will get hands-on with the Dynatrace platform, tackling one capability at a time!
"DQL" stands for Dynatrace Query Language. It is a powerful tool to explore your data and discover patterns, identify anomalies and outliers, create statistical modeling, and more based on data stored in Dynatrace Grail storage, the data lakehouse where the data is stored.
In this DynaLabs session, Dynatrace ONE Technical Product Specialist Milos Pejic @mpejic covers Dynatrace DQL and Workflows. We start by learning about the basics of DQL, such as how to create queries, filter results, and aggregate data. Then, we cover how to use DQL to create workflows, which are automated processes that can be used to monitor and troubleshoot applications. Finally, we will put our knowledge to the test by creating a simple workflow that monitors the performance of a web application.
Links discussed during the sessionGet Dynatrace: https://dynatr.ac/3qOKAoG Grail: https://dynatr.ac/3YTyt6l Dynatrace Query Language: https://dynatr.ac/3Ei0ZVK Workflows: https://dynatr.ac/47SInti 
Chapter List:00:00 - Introduction01:34 - Use Case Overview04:24 - Notebooks06:12 - DQL Syntax - fetch07:05 - DQL Syntax - filter08:25 - DQL Syntax - parse09:56 - DQL Syntax - summarize10:25 - DQL Syntax - sort10:55 - Putting it all together with fieldsAdd, expand, lookup, summarize21:37 - Timeseries
- - - Subscribe to our YT channel Stay up-to-date with Dynatrace! Follow us on Facebook, Instagram, LinkedIn, Twitter, Twitch  

 When passion meets people magic and innovation happen. 


----------------
281.1:

Learn more about DQL and workflows‌ Automations - helpful resources

 When passion meets people magic and innovation happen. 


----------------
281.2:

Thanks @AgataWlodarczyk for sharing this. We need more of this since it seems some if not most clients are still used and comfortable with the classic Dynatrace. Reason of this is that there is lack of knowledge transfer and skills translated to Partners and Customers in as much as we find the features exciting.I would suggest Dynatrace to schedule hands on sessions with Partners within specific regions  and locality because we have varying skills and expertise and knowledge and having a one size fits all approach to new features might leave some customers out due to lack of quick adaptation

	Dynatrace Certified Associate


----------------
282:

Hi There,Using metric ingest we have created a metric which is configured for 2 servers (1 live server and 1 is fallback server ), the client wants alert to be generated only when both the nodes are not fulfilling the requests, refer screen below for a sample metric created, kindly advise how we can fulfil this.Please note: with the current configured metric we are getting alerts for both the nodes as separate alert. Previously posted this in slack so far no reply https://dynatrace.slack.com/archives/C01P9N2RZQE/p1693290399106039 

----------------
282.1:

Hi @Hasan ,I am assuming both nodes are will send the same metric key.When both of them fail no metric data points will be sent into Dynatrace so data will be missing-> "alertOnNoData": true,Using a metric event like following would alert you if the metric is completely missing, i.e. primary and secondary both have failed. [{
    "schemaId": "builtin:anomaly-detection.metric-events",
    "schemaVersion": "1.0.15",
    "scope": "environment",
    "value": {
      "enabled": true,
      "summary": "Important Metric is missing",
      "queryDefinition": {
        "type": "METRIC_SELECTOR",
        "metricSelector": "very.important.metric.that.has.to.be.there",
        "managementZone": null,
        "queryOffset": null
      },
      "modelProperties": {
        "type": "STATIC_THRESHOLD",
        "threshold": -1,
        "alertOnNoData": true,
        "alertCondition": "BELOW",
        "violatingSamples": 3,
        "samples": 5,
        "dealertingSamples": 5
      },
      "eventTemplate": {
        "title": "Very important metric is missing",
        "description": "The {metricname} value was {alert_condition} normal behavior.",
        "eventType": "AVAILABILITY",
        "davisMerge": true,
        "metadata": []
      },
      "eventEntityDimensionKey": null,
      "legacyId": null
    }
  }
] 

----------------
282.2:

Hi Mark,Both nodes are sending separate metric key sharing the same below along with screenshots.Metric in Live servericardonline.prod.host119.FALCON.55382Metric in Fallback servericardonline.prodfb.host118.FALCON.55382 

----------------
282.3:

Hi @Hasan I cannot recommend using dimensions in the metric key, that is what metric dimensions are for.https://www.dynatrace.com/support/help/shortlink/metric-ingestion-protocolYou would send a metric line like this and both hosts would send this with different dimension values e.g.:icardonline,stage=prodfb,host=host118.FALCON.5538 <metric data>
icardonline,stage=prod,host=host119.FALCON.55382 <metric data> If you do not want or cannot use above's format, you still could use a metric query in the metric event adding up both metrics and alerting if data is missing, but again this is not recommended. BR,Mark 

----------------
283:

Hi all,
At the moment it seems that the Dynatrace University is down. Anyone else with that issue? I think there was an update yesterday night.
I have an exam in 3 hours and it tells me that I need to log in via the university. Is there also another way?
 
This is the error at the university.
 
 
 

	A Dynatrace Professional nerd working for Eviden


----------------
283.1:

Hi @marina_pollehn We also cannot connect to the University and tried to get in touch with with support regarding that, with no answer till now Good luck with your practical exam !!! Yos 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
283.2:

Thanks for letting me know, I was already wondering if it was just me. I am trying via a support ticket at Dynatrace and at Examity now - I hope that I can still do the exam today 

	A Dynatrace Professional nerd working for Eviden


----------------
283.3:

University is reachable again !

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
283.4:

Hi @marina_pollehn Have you successfully passed the exam?

	Have a nice day!


----------------
283.5:

Unfortunately I couldn't get to it in time. Someone from Dynatrace One reached out tonight so I will try to schedule a new appointment for next weekend. 

	A Dynatrace Professional nerd working for Eviden


----------------
283.6:

Maybe you need some help or clarification on some topics before your exam:)? 

	Have a nice day!


----------------
283.7:

Hi,I remember to see a message banner, in University, during this week, for some scheduled maintenace during this weekend.Best regards

	Consultant


----------------
284:

Hi All,Has anyone successfully integrated Dynatrace to the status API for Twilio?Details and dashboard here: https://status.twilio.com/apiJSON call (no authorization needed) here: https://gpkpyklzq55q.statuspage.io/api/v2/summary.jsonWith so many SaaS vendors (including Dynatrace) now offering status pages, I would really like to start taking advantage of these in Dynatrace. I played around with Synthetics on it, but found that the options are too limited for what we would want.I was thinking of going the custom plugin route, but I am not sure how feasible that would be due to the fact that really all metrics within Dynatrace are really based on performance and in this case we would be looking for for of an event.Looking at an example of the JSON returned, I would like to capture the components "name" and the "status" of each component. Then raise a problem if the status is anything but "operational" and then of course provide some detail in the problem that is raised such as the name, the status, along with a link back to the Twilio status page.{    "page": {        "id": "gpkpyklzq55q",        "name": "Twilio",        "url": "https://status.twilio.com",        "time_zone": "America/Los_Angeles",        "updated_at": "2020-11-02T05:16:15.468-08:00"    },    "components": [        {            "id": "ys1jhy2ys04z",            "name": "Group Rooms",            "status": "operational",            "created_at": "2019-01-10T08:35:00.743-08:00",            "updated_at": "2020-09-24T22:11:38.577-07:00",            "position": 1,            "description": null,            "showcase": false,            "start_date": null,            "group_id": "31pkbykrvbwr",            "page_id": "gpkpyklzq55q",            "group": false,            "only_show_if_degraded": false        },        {            "id": "g2dt752kwqs0",            "name": "PSTN",            "status": "operational",            "created_at": "2016-04-08T13:28:39.348-07:00",            "updated_at": "2020-10-09T08:10:00.822-07:00",            "position": 1,            "description": null,            "showcase": false,            "start_date": null,            "group_id": "j3s4w3gnsj08",            "page_id": "gpkpyklzq55q",            "group": false,            "only_show_if_degraded": false        },        {            "id": "b9z92qjr2p04",            "name": "TaskRouter",            "status": "operational",            "created_at": "2015-03-23T08:51:24.916-07:00",            "updated_at": "2020-10-29T12:46:36.773-07:00",            "position": 1,            "description": "Twilio TaskRouter service",            "showcase": false,            "start_date": null,            "group_id": "p750yl3t5mwk",            "page_id": "gpkpyklzq55q",            "group": false,            "only_show_if_degraded": false        },Curious if anyone has tried to approach this with Dynatrace?Thanks!



					
						Solved!
					
					Go to Solution.




----------------
284.1:

@Larry R. were you able to get any additional insights on this? Anything you can share with the community on it? 

	-Chad


----------------
284.2:

Hi Chad! I am actually well on my way to building an ActiveGate plugin for this. You will be able select via the UI config exactly which of all the "Twilio Services" and / or "External Connectivity" services you want to monitoring the status for in Dynatrace using the Twilio status API.Due to the limitations of Dynatrace, I am having to go through route of custom devices once again to accomplish this. That in return allows for the tagging, etc. I am just putting the finishing touches on it. I would be happy to share via GitHub as soon as I am finished. We really need something else in Dynatrace that can be created as a custom entity that is not necessarily a custom device. There are custom services (which this is what I would consider Twilio to be), but in order to define those currently in Dynatrace, it requires a process group. In the case where you want to monitor something like Twilio through their status API, there would be no process group. 

----------------
284.3:

Hi Larry - can you please send me the link - or post it here. Thanks in advance. Manish

----------------
284.4:

YAY!! Would love to see anything you have. This would be a great help!!

----------------
284.5:

I have been swamped with other work, but plan to focus on this once again towards the end of this week. Should have it done soon.

----------------
284.6:

Hi Larry.  Wondering if you were able to complete the above and can share the plugin details?  

----------------
284.7:

Good afternoon, is there any news regarding this extension?

----------------
284.8:


    Dynatrace now has the ability to model any custom entity. So you can model a "status page" then create instances of each page. From there, you can attach metrics (and events) to each "status page" Once created, get to your entities via:  https://abc12345.live.dynatrace.com/ui/entity/list/entity:TYPE   then I used the Events v2 API to create a problem opening event:   curl -X POST "https://abc12345.live.dynatrace.com/api/v2/events/ingest"
-H "accept: */*"
-H "Authorization: Api-Token ***"
-H "Content-Type: application/json; charset=utf-8"
-d "{\"eventType\":\"ERROR_EVENT\",\"title\":\"An error has occurred\",\"timeout\":1,\"entitySelector\":\"type(entity:status_page),entityName.equals(twilio-gpkpyklzq55q)\",\"properties\":{\"foo\":\"bar\",\"foo22\":\"bar2\",\"foo3\":\"bar3\"}}"  

----------------
284.9:

How your experience has grown on this and what were you able to achieve?Regards

----------------
285:

We are integrating data from K6 into Dynatrace using metric API - https://k6.io/docs/results-output/real-time/dynatrace/K6 is ingesting 6 data points for a minute - but dynatrace is aggregating the data across those 6 data points but they are looking to see how can we not aggregate the data for a minute in Dynatrace 
Below table shows they sent 10 data points for a metric



 
 
 


data:{"time":"2023-09-08T10:38:13.2067109-05:00"
value
67.38


data:{"time":"2023-09-08T10:38:23.0113171-05:00"
value
69.66


data:{"time":"2023-09-08T10:38:33.0136266-05:00"
value
63.24


data:{"time":"2023-09-08T10:38:43.0240259-05:00"
value
63.24


data:{"time":"2023-09-08T10:38:53.0269623-05:00"
value
61.76


data:{"time":"2023-09-08T10:39:03.032395-05:00"
value
59.2205


data:{"time":"2023-09-08T10:39:13.0439243-05:00"
value
60.5196


data:{"time":"2023-09-08T10:39:23.0481963-05:00"
value
63.354


data:{"time":"2023-09-08T10:39:33.0678128-05:00"
value
77.1408


data:{"time":"2023-09-08T10:39:43.0538723-05:00"
value
59.6212



 
But Dynatrace data for every minute, so there is a mismatch in calculation in Dynatrace compared to K6
 



Test Time
10:38 - 10:43
 
 
 


Metric Name
K6 Metrics
Dynatrace Metrics
api/v2/metrics/ingest data
Resolution 5 Mins


Average
64.51
65.1
64.51409
64.5


Minimum
59.22
61.8
59.2205
59.2


Median
63.24
65.1
63.23985
64.5


Max
77.14
77.1
77.1408
77.1


90th %
70.41
65.1
70.40637
64.5


95%
73.77
65.1
73.773585

64.5




 
They could use Max, but they are interested in seeing 90th and 95th percentile metrics which is huge difference compared the metrics from K6 calculation
 
Please provide suggestions



					
						Solved!
					
					Go to Solution.




----------------
285.1:


Dynatrace metrics have the lowest granularity of 1 minute regardless of the ingestion type.  You can use the max / min aggregations as you have already mentioned.What is your source of the metric data? Maybe you can capture the relevant metrics using different means (tracing) and calculate the metrics based on captured trace data. 

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
286:

Hello
We've defined tags based on environment variables for the MS SQL Server instances.
It works fine on standalone instances, but it doesn't work for instances on cluster.
The "Environment" variable is already used by the cluster configuration. The manual setup done for the Dynatrace's tag (DT_CUSTOM_PROP= and DT_TAGS=) disapears after the restart of MSSQL service.
I followed the instructions on the page : https://www.dynatrace.com/support/help/manage/tags-and-metadata/setup/define-tags-based-on-environme...
Do you know how to setup the variables for SQL server clusters ?
Thanks,
Renata

----------------
286.1:

Hi Renata,I understand that you have correctly added variables to the registry on all servers in the cluster where you have MS SQL?https://www.dynatrace.com/support/help/shortlink/process-group-properties#variablesDon't you sometimes have a mechanism in the organization that verifies the configuration of servers and, if changes are detected, restores the original one.Radek

	Have a nice day!


----------------
286.2:

Hi RadekThere is any in-house script to restore the original values of the variables.This configuration of the variables might be at the Cluster Manager level (quorum), but I don't know where/how to setup them.Regards,Renata

----------------
286.3:

To set an environment variable using PowerShell and make it persistent (available even after a system reboot), you can use the following command:[Environment]::SetEnvironmentVariable("VARIABLE_NAME", "VARIABLE_VALUE",[System.EnvironmentVariableTarget]::Machine)Where:VARIABLE_NAME is the name of the environment variable you want to set.VARIABLE_VALUE is the value you want to assign to this variable.[System.EnvironmentVariableTarget]::Machine means that the variable will be set as a machine variable, which means it will be available to all users on that computer and will be persistent.https://shellgeek.com/set-environment-variable-using-powershell/See if this works:)Radek

	Have a nice day!


----------------
286.4:

Thanks for your inputs.I need to have the "tag" on Dynatrace only in the processes and Process Groups related to the MS SQL Server Service. That's why on Windows, it has to be set in the registry of Service and not as a System Variable. If I set the variable in the system, the server and all the processes will be tagged in Dynatrace with this variable - this is not the goal. The documentation Dynatrace (Define tags based on environment variables ) says : Applying tags to hosts (instead of thoughtfully setting up environment variables as explained here) isn't recommended. The same applies to applications and processes. For details on setting up the DT_CUSTOM_PROP environment variable for Tomcat or WebSphere application metadata, Kubernetes annotations for Kubernetes-based deployments, or AWS tagging, see Application metadata & tagging. 

----------------
286.5:

If you want to set a permanent variable for a specific process or group of processes in windows then you can do it this way:You can use PowerShell to create or modify environment variables in the Windows Registry. # Define permanent environment variables for different process groups$RegistryPath = "HKLM:\SYSTEM\CurrentControlSet\Control\Session Manager\Environment"# Group A Variables$GroupA_Variable1 = "ValueA1"$GroupA_Variable2 = "ValueA2"# Group B Variables$GroupB_Variable1 = "ValueB1"$GroupB_Variable2 = "ValueB2"# Set Group A VariablesSet-ItemProperty -Path $RegistryPath -Name "GroupA_Variable1" -Value $GroupA_Variable1Set-ItemProperty -Path $RegistryPath -Name "GroupA_Variable2" -Value $GroupA_Variable2# Set Group B VariablesSet-ItemProperty -Path $RegistryPath -Name "GroupB_Variable1" -Value $GroupB_Variable1Set-ItemProperty -Path $RegistryPath -Name "GroupB_Variable2" -Value $GroupB_Variable2In the above example, you set permanent environment variables for different process groups (GroupA_Variable1, GroupA_Variable2, GroupB_Variable1, and GroupB_Variable2) in the Windows Registry under HKLM:\SYSTEM\CurrentControlSet\Control\Session Manager\Environment. These variables will persist and be available to all processes system-wide.After setting permanent environment variables, you may need to restart or refresh processes (such as Explorer or PowerShell sessions) for them to recognize the new variables.Radek  

	Have a nice day!


----------------
287:

Looks like this bug might be present again: https://community.dynatrace.com/t5/Open-Q-A/Dynatrace-display-issue-when-scrolling-down/td-p/203333.
We're using Dynatrace 1.273.109.20230821-110118 (SaaS) and Microsoft Edge for Business version 116.0.1938.62.
I see the issue when viewing data on hosts and problems.
 
Anyone else having this issue?



					
						Solved!
					
					Go to Solution.




----------------
287.1:


Was also having the same issue and seems to be resolved now. On 1.274.132.20230905-172015.

----------------
287.2:

Yeah, it's also working for us again. Microsoft Edge for Business version: 116.0.1938.76. Dynatrace version: 1.274.132.20230905-172015.

----------------
288:

Hello community, good day.
We have been working on enabling monitoring for multiple Azure web apps (Azure app services). These are all NodeJS apps that run on Linux-based platforms plans on Azure.
However after instrumentation, we have received no information about the user sessions, we double checked and the RuxitAgent JS script is being injected correctly on all web pages. So we checked again the documentation and it says something about a potential conflict with App insights.
So we have been trying to disable App insights, in our case only the Azure functions have them enabled. But so far no luck even after disabling Insights. Is it also needed to deploy oneagent on the functions?
 
Regards,
JD

----------------
288.1:

HI @jose_araya As appears in Why don't I see my applications or monitoring data?Check the following to determine the cause of the problem:Confirm that the RUM JavaScript has been correctly injected into your application HTML.Confirm that the RUM JavaScript has downloaded correctly.Confirm that RUM data is being sent to Dynatrace. HTHYos 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
289:

I have configured many AWS and AZURE CREDENTIAL for an environment. I'd like to make an api call to get list of all the entities (different entity types e.g. HOST, RELATIONAL_DATABASE_SERVICE, AWS_LAMBDA_FUNCTION, CONTAINER_GROUP_INSTANCE etc.) for a specific AWS CREDENTIAL.. is it possible?
Same is needed for AZURE CREDENTIAL also.
 

----------------
289.1:

@NavenduGupta this is possible via the configuration API:  If you are not a Dynatrace Admin you will need to have an admin supply a token for you to read those data points. 

	-Chad


----------------
289.2:

Thanks... These will only give me entityTypes/services... I want all the entities.

----------------
290:

It's the time! Here comes the brand new Community challenge! 
 
 The "Commuter" badge
Even if we don't think about it deeply, every day we're making a choice to effectively commute. Some of us take the bus, some go by train, others prefer a bike or scooter, many stick with a car or even their own feet 
 
Here in Dynatrace, we pay huge attention to the way how we commute in our daily routine, having the EcoMode program. It rewards Dynatracers who use everything but the car or get to work by public transport  Shout out to Alexander Sommer, who no matter of rain, sun, cold or heat is strongly committed to the bike as his daily mean of transportation to work.
 
And you? Tell us how you commute on your daily basis, no matter if it is a bike, car, scooter, public transport or your own feet. What do you use the most frequently? Every answer gives you 100 bonus points and a dedicated "Commuter" badge. Additionally! For every submission we plant a flower in our office  
Can't wait for your answers! Feel free to respond any way you prefer! 

----------------
290.1:

Before COVID there was a lot of commuting to customers every week. Where possible with the train but witht he state of railway in germany, a lot was flying. But for the last ~2 years my daily commute has been the ~30 steps from my kitchen to the office, no cars involved   

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
290.2:

@pahofmann Are you planning to change your commute habits to those pre-covid? 

	Keep calm and build Community!


----------------
290.3:

If it where up to me no   But I don't think it will go back to nearly as much traveling as before. I'm not really sad as it saves a lot of time and is a lot more flexible remote, though a bit of traveling again would be nice.

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
290.4:

I use to take the Washington DC Metro to work, now I don't even have to go out of the house to get to the office! Cant say I miss the old commute! 

	-Chad


----------------
290.5:

Before the pandemic, many of us had to go to the customer's office. Now in the new normality, I had to create my own office (3rd room - guests only) and don't have to move to another place but every day I've to pick up my son from the school who is ~10 minutes away from the apartment. My mobility is obviously walking less than 30 minutes. 

	-César S. - LATAM Solutions Architect


----------------
290.6:

Same here, working from home since March 2020. Before pandemic, I used to take a bus to go to office (around 40km far from my home), and sometimes, my motorcycle.
Today , the only place I go daily is to my kids school, they are near, around 10 mins on feet (their pace).
But let's say I come back to office, weekly, I would definitely ride my Dyna, it is not so eco (a bit louder too), but that's how I like it.
 

	Site Reliability Engineer @ Kyndryl


----------------
290.7:

Fantastic! Around 80 kilometers of the trip to and back from work sounds like a perfect opportunity to enjoy the motorbike season as much as possible! 

----------------
290.8:

I commute by car. I do it almost all days with electrical power, so it's almost always eco friendly. 20 Km daily. Don't have a public transport option.Probably one of us that has worked less from home in the pandemic... Always secure and abiding by the law, but sometimes I would feel that I was like in a "The Walking Dead" episode...

	Antonio Sousa


----------------
290.9:

High five, @AntonioSousa!  I'm in the office 5 days a week, got back in June 2020 already when they opened the doors to Dynatrace labs for selected groups of employees - meaning those with no good conditions to work from home (be it equipment or kids ).
I rarely use car (don't have an electric one), so in 90% of the cases it's my bike, the other 10% is either train or car 

	Keep calm and build Community!


----------------
290.10:

Great to see Alex showing how it's done biking 
Some days I drive a car, some days I take my e-bike Ampler. It has completely changed my experience of urban biking and I recommend to take a ride with an e-bike for all ages and fitness levels.
 

----------------
290.11:

Not a big bike expert at all, but your machine looks fantastic - like a perfect for long trips around forests, rural areas, or city alleys!

----------------
290.12:

I commute by subway in Osaka. The Osaka subway is the second largest in Japan after the Tokyo subway.Not only the subway, but also Japanese railways operate according to the timetable, and there is not much delay.So, train delay of0min to 1min "Good" ,  1min to 3min"Tolerable",> 3 minutes "Frustrating".  

	T.Shirai IIM Corp. Osaka Japan


----------------
290.13:

Those are some nice punctuallity goals! In Germany everything below a 5:59min delay doesn't even count as not on time in the statistics. Often if a train has to much delay it will just cancel the last stops and change direction early, as cancled trains also don't count as "late" in the statistics... 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
290.14:

The punctuality is legendary. That's the way to go! Here in Portugal we don't know what that is... And I can just imagine OneAgents sourcing that data and feeding some nice dashboard/SLOs! 

	Antonio Sousa


----------------
290.15:

Lucky, here in India it will feel like ages to wait for local trains. Units are are displayed in nos from 00 to 10. 01 unit at time is 10 seconds or sometimes its 5 mins

	KG


----------------
290.16:

In India, when it comes to metropolitan areas, Metro trains will be right on time without any delays. In Bengaluru trains are very punctual and most of the people who travels to work via Metro itself. Local trains gets delayed due to some technical reasons that to when you are going for a long journey. When you are on a journey, it is okay to get delayed here and there sometimes... 

	Love more, hate less; Technology for all, together we grow.


----------------
290.17:

I have to have this badge!
 
On average I go to the office 4 times a week, by bike (~ 20km/day). Given the fact that the pandemic chained me for nearly two years to the home office and this exercise was missing .... correct, I still need to get rid of a few kg!!!!

	Director of Product Management @ DynatraceThat means I'm better at delegation than doing actual work!


----------------
290.18:

Just curious on what the altimetry profile is like for your 20 Kms?

	Antonio Sousa


----------------
290.19:

It's actually really flat along the Danube 

	Director of Product Management @ DynatraceThat means I'm better at delegation than doing actual work!


----------------
290.20:

Hey yes.. the initial pandemic time during complete lockdown, I experimented a lot of cooking and eventually eating it . Added a lot of weight all due to sugar sweet dishes. You can try cutting down sugar completely 

	KG


----------------
290.21:

I would love to share my commuting experience to office before the pandemic (10 Km per day) . I still use my bike for local travel and weekend touring. I use to ride this own custom bike of mine which was build using scrap materials form different  type of old bikes. I tweaked its engine by adjusting the fuel flow and  also reducing the diameter of gear teeth's to increase the RPM. It eventually cover more miles than any average low end bike and was very economic for me giving a range of 110 KM in a single liter of fuel.
Its still my passion to customize bike and I can spend my weekend building one again with some electric technology movement.

	KG


----------------
290.22:

Is this a Royal Enfield? I mean the engine and chassis, since the parts may be form others manufacturers 

	Site Reliability Engineer @ Kyndryl


----------------
290.23:

Thankyou its all different OEM

	KG


----------------
290.24:

Handle is Custom made aluminum after market similar to Harley, Chassis and engine  are Hero Honda passion plus its a 110  with a custom build carburetor

	KG


----------------
290.25:

Gear box battery box Chain cover set spoke wheels are Royal Enfield, Fuel tank is Yamaha RX100, Speedometer is Yamaha enticer, and many more of same brands above all got from 2nd hand market place.

	KG


----------------
290.26:

I rebuild each parts to stock new repair needed. Working on my next project on my weekends now. It have a Hero Honda Karizma R 228 cc 2007 rebuild as new powered engine with custom Fuel injector support and a scrambler look.

	KG


----------------
290.27:

Hello everyone,Personally, I much prefer public transport AND/OR electric scooter: for an hour, I have time to read the news, catch up with friends and family, reread articles or meet new people...But since my move, the city is not well served by public transport, which forces me to take my own car morning and evening.

	Sharing Knowledge


----------------
290.28:

Sometimes public transport is a perfect area to catch up with the stuff we don't have time to read at home! But as you say, sometimes it's simply not possible to use it as frequently as we'd like...

----------------
290.29:

Totally agree! Some 25 years ago, I had an hour commute, each direction... I would have a stack of magazines (anyone remembers Byte, for instance?) and read a lot! Although I'm an Internet user since 1991, magazines were still influential during about more 10 years.Today, it's even easier, and not only in public transportation. I normally hear podcasts on my car commute, things like "Pure Performance" 

	Antonio Sousa


----------------
290.30:

Personally, I still buy magazines sometimes. It's actually more convenient while being on the journey because you save your device's battery and have some rest from screens 

----------------
290.31:

Before the pandemic I had a 40 minute car ride to work and to be honest, I kind of miss it! it was a great time to relax, listen to some music, unwind and just prepare for the next day. It also helped keep that separation between work and home. Now, just like so many else I'm just a few steps away from work every morning. I mean thats not terrible either, you get to make your own office with your own hardware allowing you to put it together in a way the suites you!

----------------
290.32:

Pre-pandemic, I was either on-premise at clients or at the office. If at clients, it would mostly be by car to the nearest Gautrain station, then Gautrain to the closest station, and then either by foot or Gautrain bus to the client.If I had to grace my colleagues with my presence at the office (yeah, right hahaha!) I'd take my car since public transport is not the greatest in South Africa.I'd cycle to work if I could, but we do not have the fantastic facilities like those which Alexander Sommer has access to.Can't say I'm missing the commute, at all!! Love working from home and dreading the day things go back to normal, which will hopefully never happen completely 

----------------
290.33:

Haha!  I think many people fell in love with remote work during the pandemic 
 
Looks like you use many ways of commuting, Andre! Nice diversification!

	Keep calm and build Community!


----------------
290.34:

Hehehe .. I am missing working from office 

	KG


----------------
290.35:

I can relate my early days, when I dint had a bike to drive. Now bikes are easy to drive on streets and save a lot of time 

	KG


----------------
290.36:

I commute to work by train. The train takes only 20 minutes even though I live just outside the city, so including walking time it takes me around 40 minutes. I quite like the ride, and some times I even had more time for my audiobook or podcast episode Can't believe you plant a flower for every answer - what a nice idea!

----------------
290.37:

We'll do and we'll document it! 

	Keep calm and build Community!


----------------
290.38:

Wonderful! I'm also going to plant one 

	Antonio Sousa


----------------
290.39:

Thanks 

----------------
290.40:

I have planted one of my favorite flower plant today. This will be my Community Pelargonium:
 
I have been doing propagation with cuttings, and it seems that Pelargoniums are quite easy to propagate. Let's see if I didn't leave to many leafs... It's my second this year, because I already have a lot of them. This Community one is derived from my most beautiful Pelargonium, also because it has some nice Dynatrace color:
 

	Antonio Sousa


----------------
290.41:

Oh, wow!  I can't guarantee our plants will be as spectacular as the one above, but we'll do our best to take a good care of them 

	Keep calm and build Community!


----------------
290.42:

Oh wow, that is amazing @AntonioSousa  Love the colors!

----------------
290.43:

I love periwinkle in different colors, will be planting it soon 

	KG


----------------
290.44:

Trains are best way to commute here in India too 

	KG


----------------
290.45:

Another Harley guy here. 70km round-trip to downtown Toronto - averaging 7L/100km. Toronto allows free street parking for motorcycles and we're allowed to use the HOV lanes. 
 
I'm looking forward to our return to the office next month (% basis).
 
 

----------------
290.46:

That's the right (and brave) attitude! 

----------------
290.47:

We're not made of sugar, right? 
 
I wish you a smooth RTO! 

	Keep calm and build Community!


----------------
290.48:

You got to be in India , can't commute with this in the traffic to Office. Yes but definitely a loved one for long rides.

	KG


----------------
290.49:

My EDC commute equipment is:
 
 
Huge fan of Brompton Bikes.

	The true delight is in the finding out rather than in the knowing.


----------------
290.50:

Yes! Brompton bikes are actually the most comfortable for the city environment, here in Poland they're getting more and more popular 

----------------
290.51:

Being one of very less outsider and I am more of an insider. I go out rarely as my work is from home. However, I always like to go and travel to the neighbouring hill station. Here are some of those pics I took when I visited the view point, 
   

	Love more, hate less; Technology for all, together we grow.


----------------
290.52:

So stunning views, you're lucky to have such landscapes in your close neighborhood! 

----------------
290.53:

Indeed, Michal.It is so peaceful that sometimes I go there to relieve my stress from life. It is just so soothing to my eyes and mind. 

	Love more, hate less; Technology for all, together we grow.


----------------
290.54:

@pahofmann, @ChadTurner, @cesarsaravia, @dannemca, @AntonioSousa, @HansLougas, @Shirai, @kurt_aigner, @techean, @Malaik, @Fin_Ubels, @andre_vdveen, @robaxelsen, @richard_guerra, @DanielS, and @theharithsa 
 
As we promised, we've carefully seeded 16 plants in our office to celebrate all of your answers submitted to the Commuter Challenge. Take a look at how they proudly grow, it's never been so green in our room! 
 
 

----------------
290.55:

Awesome! How nice of you 

----------------
290.56:

So, so nice! 

	Antonio Sousa


----------------
290.57:

Ooooohhh, so cute!!! Which one is "mine"??? I would call it Nic.

	Site Reliability Engineer @ Kyndryl


----------------
290.58:

Awesome!!   Mine could have the name of my son? He is: Rasec. He is also planting a flowers at the school. 

	-César S. - LATAM Solutions Architect


----------------
290.59:

Thanks @Michal_Gebacki 

	The true delight is in the finding out rather than in the knowing.


----------------
290.60:

Oh thats awesome! Maybe I should start growing something on my baren wasteland of a desk. Whats on the post-it notes?

----------------
290.61:

The names of the challenge participants  Here are some pictures from the backstage 
 
  

	Keep calm and build Community!


----------------
290.62:

This is awesome!!

	Site Reliability Engineer @ Kyndryl


----------------
290.63:

Make sure you water it properly. I'll check on it, the next time in Gdansk 

	Director of Product Management @ DynatraceThat means I'm better at delegation than doing actual work!


----------------
290.64:

Hello @KarolinaL Where is mine in the photo? and how it's looks like after 1 year of groowing.

	Sharing Knowledge


----------------
290.65:

I still drive to the office, but this habit should soon change to a more eco-friendly option.

----------------
290.66:

Before COVID, I went to the office every day. Whenever possible, by bus or car, but since public transportation in Brazil is complicated until I bought my car, I had to use Uber. But after the pandemic I'm trying to get active again and do more sport

	Dynatrace Professional Certified


----------------
290.67:

I move inside my house. I use frequently my speakers for listen music, videos or webinars.Best regards,

	IT Master | dynatrace Certified professional | SRE Certified | Scrum Certified | Azure Certified | https://www.linkedin.com/in/rodrigocuevas/


----------------
290.68:

I usually prefer walking in warm days, but still the car option is the best during the summer 

	Dynatrace Certified Professional - Dynatrace Partner - Yourcompass.ca


----------------
290.69:

I mostly take the bus to the office and back, though sometimes I take the metro, mostly if it's raining or if I have to stop somewhere on the metro line on the way back!

----------------
291:

Hello, I filtered the alerts inside the app using my management zone and it works fine, but I receive push notifications for all the management zones available in my account. Is it possible to apply the same filtering to the push notifications?
Thank you very much! 



					
						Solved!
					
					Go to Solution.




----------------
291.1:

Hi @gmorreal,assuming that you are using email for problem notifications, to receive alerts only for this specific management zone, you need to create an alerting profile for this management zone, and in the problem notification choose this alerting profile, The following is a sample1- Create alerting profile:From the left side menu search for settings then Alerting-->Problem Alerting profileYou can leave the default alerting profile as it is and create a new one or duplicate the default and change the cloned one, change the name, choose the management zone, and click save if severity rules are fine (you can leave the default severity rules) 2- Create a problem notificationfrom the settings --> Integration --> Problem notifications--> Add notificationchoose notification type, Add Recipient, choose Alerting profile then save Note: Don't forget to remove your email account from the default notification if you want to receive notifications only for this management zone.Best Regard,Mohamed

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
291.2:

Thanks @Mohamed_Hamdy for the quick response. I'm using the mobile dynatrace app to receive push notifications and as I said I receive notifications for all the management zones, while I would like to receive that only for the MZ that I configured in the app. Is it possible?Thanks

----------------
291.3:


Hi @gmorreal ,I do not think it is currently available for the Dynatrace app to receive the notifications by Management Zone yet. You can post as a product idea to get more insight into when and if this might be available. 

----------------
292:

I have custom action created using javascript API (dtrum.enterAction), and added few actionProperties before leaveAction. action properties are added correctly to custom action but it's not show xhr requests which occurs as part of action. If I don't set actionProperties then it shows all xhr requests correctly.What could be the issue here ?

----------------
292.1:

@DivyaP this is very interesting, can you tell us the cluster version you are on? I was going to ask if XHR monitoring was turned on, but as you said XHR works when the action prop isnt set. I'm curious if this is a bug in the cluster

	-Chad


----------------
292.2:

@DivyaP Can you share your code here? Maybe we'll see something you missed.

----------------
293:

Hello! We recently created a bunch of access groups via terraform and they do not have permission to toggle to the new Dynatrace UI. I couldn't find any documentation on this, can anyone help? The groups all have the following permissions:Account permissionsView accountManagement zone permissionsMy Management Zone NameView environmentView logsView sensitive request data A few groups also have 'manage monitoring settings' but same problem. I couldn't spot any specific permissions in the OOTB groups that enable this toggle. Maybe something pokey with terraform? We're using https://registry.terraform.io/providers/dynatrace-oss/dynatrace/latest/docs/resources/iam_group resources with v 1.35.3 providerdynatrace = {    version = "1.35.3"    source = "dynatrace-oss/dynatrace"} Thanks!



					
						Solved!
					
					Go to Solution.




----------------
293.1:


Hello @strunzo we are following a similar question here.But Management Zones permissions are not enough, you need at least View environment under Environment permissions.

	The true delight is in the finding out rather than in the knowing.


----------------
293.2:

Not sure this resolves the issue.  I have View Environment as well as the management zones, yet the toggle is not accessible.  I'm trying to find out the least amount of privileges needed to enable this for new monitoring users.

----------------
293.3:

Hello @jmcgrath04 please check that View Environment is under tenant and not MZ. 

	The true delight is in the finding out rather than in the knowing.


----------------
293.4:

Correct, I currently have View Environment, in the environment permissions as well as the MZ permissions.

----------------
293.5:

Following up, it turns out it's more the policy for the environment controlling this.  I needed to turn on 'AppEngine - Admin' in the Environment Policies.  Thanks for assisting.

----------------
293.6:

Sorry, AppEngine - User would be more correct for the group I was working with.  My admin group has the admin policy. 

----------------
294:

Is possible integrate dynatrace with movidesk?and if it is possible exist any documentation about?

	Dynatrace Professional Certified




					
						Solved!
					
					Go to Solution.




----------------
294.1:

Hi @natanael_mendes ,As far as I know, no documentation exists about integration of Dynatrace with Movidesk. To better answer your question, could you describe what information you're trying to get from Movidesk and what it does? In addition, any information provided on what you're trying to do by integrating it with Dynatrace would help too. Cheers,Taylor Sanchez

----------------
294.2:

Thanks for your answer Taylor. Movidesk is a itsm tool for open tickets

	Dynatrace Professional Certified


----------------
294.3:


What kind of integration are you looking for?If is to create tickets from Dynatrace problems, you may be able to, using the email as notification integration, since Movidesk allow you to create tickets based on emails: 

	Site Reliability Engineer @ Kyndryl


----------------
294.4:

Thanks for your Answer Danne, gon be helpful

	Dynatrace Professional Certified


----------------
295:

We are using keyRequests to mark the success on a specific java method as in:
builtin:service.keyRequest.successes.server.rate:filter(and(or(in("dt.entity.service_method",entitySelector("type(service_method),entityName.equals(~"getSomeData~")"))))):splitBy()
This works great but we run our VM's as Immutable Cattle, So when a NEW deployment occurs the KeyRequest is lost as it is tied to Outgoing Service entity ID.  The NEW VM is now under a NEW service entity ID and will require another "Mark as Key Request" to occur before Seeing in SLO. Even adding the SplitBy bridges the timeline but not any data untill the Mark as Key Request occurs again on new entity. This requires manual toil and automation outside of the event. Would making them Metrics (with DDU impact) resolve this permanently? Are there Other ways to accomplish This?



					
						Solved!
					
					Go to Solution.




----------------
295.1:


It seems like you're facing a challenge with tracking successful key requests in Dynatrace, particularly when your VMs are deployed as Immutable Cattle and the key requests are lost after each deployment. You're currently using a filter with a `keyRequest.successes.server.rate` metric, but this metric is tied to the service entity ID and doesn't carry over when a new VM is deployed. You're considering whether converting these key requests to metrics would provide a permanent solution.Here are a few considerations and potential solutions:1. **Using Custom Metrics:**Converting your key request tracking to custom metrics could be a solution, as you have control over the metric definition and how it's tracked. You could define custom metrics to track the success rate of the specific Java method. This approach might offer more flexibility in tracking success across deployments, as long as you ensure that the custom metric definitions persist across deployments.2. **Metric Separation:**When transitioning from key requests to custom metrics, make sure to carefully plan the metric names, dimensions, and definitions. You might need to update your monitoring configuration and any alerting or reporting mechanisms that rely on these metrics.3. **Custom Events:**Instead of relying solely on metrics, you could consider creating custom events that indicate the success of your specific Java method. Custom events can provide contextual information and might be easier to track across deployments.4. **Automation Integration:**If you're already using automation for your deployments, you might be able to integrate an automated step that triggers the "Mark as Key Request" action after a deployment. This way, the necessary key requests are automatically triggered after each deployment.5. **Communication Between Deployments:**Ensure that your deployment automation communicates with your monitoring system when a new deployment occurs. This communication could trigger actions such as marking key requests or updating custom metrics. This way, the monitoring system is aware of deployments and can adjust its tracking accordingly.6. **Consulting Dynatrace Support:**Since Dynatrace provides support for complex monitoring scenarios, it's a good idea to reach out to Dynatrace support to discuss your specific use case and get recommendations tailored to your environment.Ultimately, the solution you choose should align with your monitoring and operational requirements. Converting key requests to custom metrics might provide more control and resilience across deployments, but you'll need to carefully plan and implement this transition to ensure accurate monitoring and reporting.

	Dynatrace Professional Certified


----------------
295.2:

Thank You for the overview definitely food for thought leaning to converting to metric. Wondering if there is a how to to convert these. Questions like do I need to remove the key request before creating metric? thanks again

----------------
295.3:

If the Service Name/Request name is known, you can create a calculated metric from Multidimensional Analysis (https://www.dynatrace.com/support/help/platform-modules/applications-and-microservices/multidimensio...) using them as filter, and selecting the metric Successful request count, you should be able to get similar data.

	Site Reliability Engineer @ Kyndryl


----------------
296:

some basic example of to have Dynatrace log generate when there is any request fails.
React Application as Register as Custom application.
1) Error count for each Http Error code.
2) Top most three errors.
 

----------------
296.1:

@swapnil , you can set log alert rules via the following:  Keep in mind if you are Using GRAIL you will need to leverage DQL. 1 & 2 can be completed using DQL, granted I'm new to DQL so I cant give you the query for it, but maybe some other community members that are more versed in DQL can. 

	-Chad


----------------
297:

The documentation says:By default, Dynatrace alerts when average CPU usage is higher than 95% in 3 of 5 consecutive one-minute intervals or when usage is higher than 90% in a single five-minute interval.But, when we look at how we define custom settings for the CPU saturation settings, it seems to be based on the 10-second samples that are taken each minute: Now, even though the two approaches might seem similar, there are cases where it will not happen. Given that we don't have visibility into the 10-second samples (we do have the min/avg/max values), how do we know what is exactly happening with CPU saturation detection?BTW, remembers me of this Product Idea: https://community.dynatrace.com/t5/Product-ideas/RFE-Increase-resolution-of-data/idi-p/166920

	Antonio Sousa




					
						Solved!
					
					Go to Solution.




----------------
297.1:

Hi,What documentation exactly are you looking at?  The documentation here discusses event thresholds using 10 second intervals.  I believe 10 second intervals are used for infra alerting, and one minute intervals are used for graphing.  If you provide me the documentation where it says that, I can get clarification from product team and get updated appropriately.Regards,Bradley

----------------
297.2:


@bradley_danyo,The reference from documentation is here: https://www.dynatrace.com/support/help/platform/davis-ai/basics/events/event-types/resource-events 

	Antonio Sousa


----------------
297.3:

Thanks.  I've reached out to confirm and will let you know once I have more information. Regards,Bradley

----------------
297.4:

Hi Antonio,I've confirmed that the documentation you shared should be changed.  The CPU alerting now uses 10 second intervals.  Thank you for bringing this to our attention.Regards,Bradley

----------------
298:

Looking for a way to include in our application testing cycle (CI/CD pipeline for lower environments) validation code with the following steps:1) Enable Synthetic Monitor.2) Run Synthetic Monitor.3) Validate if the Synthetic Monitor succeeded or failed4) Pull important metrics from the succeeded execution (ie. failure rate, performance, availability, etc)4) Follow or fail the process according to the above result.5) Disable Synthetic Monitor.Is there a simple way through the API to determine if the Synthetic Monitor ran successfully or failed? Does anyone have a tip on how I could get the above information?  As mentioned above, want to create an Operational Framework where this can be built into CI/CD pipeline for lower environment validations / executions. Thanks for your feedback.



					
						Solved!
					
					Go to Solution.




----------------
298.1:

Does this help? https://www.dynatrace.com/support/help/platform-modules/digital-experience/synthetic-monitoring/gene...
 

----------------
298.2:


To include Dynatrace Synthetic Monitors as part of your CI/CD pipeline for lower environment validations and executions, you can use the Dynatrace Synthetic Monitoring API to programmatically interact with Synthetic Monitors and retrieve their results. Here's an outline of the steps you can follow:1. **Enable Synthetic Monitor:**- Use the Dynatrace Synthetic Monitoring API to enable the Synthetic Monitor for your application.2. **Run Synthetic Monitor:**- Trigger the Synthetic Monitor execution via the API.3. **Validate Monitor Status:**- Monitor the status of the Synthetic Monitor execution to determine if it succeeded or failed.4. **Retrieve Metrics:**- If the monitor succeeds, use the API to retrieve important metrics such as failure rate, performance, availability, etc., from the Synthetic Monitor results.5. **Follow or Fail the Process:**- Based on the results and metrics obtained, you can proceed with the CI/CD pipeline if the monitor succeeds or fail the process if it fails.6. **Disable Synthetic Monitor:**- Optionally, use the API to disable the Synthetic Monitor when it's no longer needed.Here's more detail on steps 3 and 4:**3. Validate Monitor Status:**To determine if the Synthetic Monitor execution succeeded or failed, you can use the `/synthetic/monitors/{monitorId}/executions` endpoint of the Synthetic Monitoring API. When you trigger a monitor execution, it will return an execution ID. You can then query the status of that execution ID to check if it succeeded or failed.**4. Retrieve Metrics:**If the Synthetic Monitor execution is successful, you can use the `/synthetic/monitors/{monitorId}/executions/{executionId}/results` endpoint to retrieve metrics and results from that specific execution. You can extract metrics such as failure rate, performance, and availability from the response.Here's a high-level example in Python using the `requests` library to interact with the Synthetic Monitoring API:```pythonimport requests# Set your API token and URLapi_token = "YOUR_API_TOKEN"api_url = "https://YOUR_DYNATRACE_INSTANCE/api/v1"# Enable the Synthetic Monitor# Run the Synthetic Monitor# (Code for steps 1 and 2)# Check the status of the monitor executionexecution_id = "EXECUTION_ID"execution_status_response = requests.get(f"{api_url}/synthetic/monitors/{monitor_id}/executions/{execution_id}",headers={"Authorization": f"Api-Token {api_token}"})if execution_status_response.status_code == 200:execution_status = execution_status_response.json()["result"]["status"]if execution_status == "FINISHED":# Retrieve metrics if the execution is successfulexecution_metrics_response = requests.get(f"{api_url}/synthetic/monitors/{monitor_id}/executions/{execution_id}/results",headers={"Authorization": f"Api-Token {api_token}"})if execution_metrics_response.status_code == 200:metrics = execution_metrics_response.json()# Extract and use the desired metrics (e.g., failure rate, performance)else:# Handle the case where metrics retrieval failspasselse:# Handle the case where the monitor execution failedpasselse:# Handle the case where execution status retrieval failspass# Continue with your CI/CD pipeline based on the results```Make sure to replace placeholders like `YOUR_API_TOKEN`, `YOUR_DYNATRACE_INSTANCE`, `EXECUTION_ID`, and `monitor_id` with your actual values. This code provides a basic structure for interacting with the Dynatrace Synthetic Monitoring API to achieve your desired integration within your CI/CD pipeline.  See this Documentation page:https://www.dynatrace.com/support/help/platform-modules/digital-experience/synthetic-monitoring/gene...

	Dynatrace Professional Certified


----------------
298.3:

Wow this is great details. Are you able to provide more information on Steps 1 - 3? Thanks so much.1. **Enable Synthetic Monitor:**- Use the Dynatrace Synthetic Monitoring API to enable the Synthetic Monitor for your application.2. **Run Synthetic Monitor:**- Trigger the Synthetic Monitor execution via the API.3. **Validate Monitor Status:**- Monitor the status of the Synthetic Monitor execution to determine if it succeeded or failed.

----------------
298.4:

Good afternoon and thanks for the above. Wow this is great details you provided for step 4 - 6. Are you able to provide more information on Steps 1 - 3? Thanks so much.1. **Enable Synthetic Monitor:**- Use the Dynatrace Synthetic Monitoring API to enable the Synthetic Monitor for your application.2. **Run Synthetic Monitor:**- Trigger the Synthetic Monitor execution via the API.3. **Validate Monitor Status:**- Monitor the status of the Synthetic Monitor execution to determine if it succeeded or failed.

----------------
298.5:


1. **Enable Synthetic Monitor:**- Use the Dynatrace Synthetic Monitoring API to enable the Synthetic Monitor for your application.https://www.dynatrace.com/support/help/dynatrace-api/environment-api/synthetic/synthetic-monitors/pu...
2. **Run Synthetic Monitor:**- Trigger the Synthetic Monitor execution via the API.https://www.dynatrace.com/support/help/dynatrace-api/environment-api/synthetic-v2/synthetic-monitor-...
3. **Validate Monitor Status:**- Monitor the status of the Synthetic Monitor execution to determine if it succeeded or failed.
https://www.dynatrace.com/support/help/dynatrace-api/environment-api/synthetic-v2/synthetic-monitor-...

----------------
299:

In Extensions 2.0 concepts | Dynatrace Docs is defines a set of limits "per Instance". Furthermore, it defines an "Instance" as "Per instance shows the consumption volume for one data source in OneAgent and ActiveGate." - unfortunately, it doesn't define "data source"...
I think that the correct metric for the memory limit is dsfm:extension.engine."memory_used" which can be split several ways including:

dt.extension.ds
dt.extension.config.id

I struggled to find any documentation for either of these dimensions, but suspect that "Instance" relates to "dt.extension.config.id"? Does that make sense?



					
						Solved!
					
					Go to Solution.




----------------
299.1:


Hello,In general, an instance means a configuration. For example, having one configuration added in the extension, one datasource instance is created. In addition, if a configuration has a very large number of endpoints added, then more instances are created. This is because the configuration is divided into smaller parts to not overhelm one process. In this case the config id does not change and all instances have the same config id. Best Regards,Mateusz

----------------
299.2:

Thanks Mateusz - that all makes sense. Any chance we could get the documentation to say something similar?

----------------
299.3:

I will reach out to the team to document it. Thanks for the feedback!

----------------
300:

Hi, I’m interested in monitoring CyberArk with Dynatrace. What are the available solutions for monitoring CyberArk’s performance, connection to vaults, etc?



					
						Solved!
					
					Go to Solution.




----------------
300.1:


Hi,I think there are a few ways currently. AFAIK, CyberArk shares Prometheus metrics, so you can write your own custom Dynatrace Extension to monitor itYou can use Dynatrace Synthetic If your CyberArk is Self-Hosted you can also install Dynatrace OneAgentI recommend you to contact with your local sales office in order to get the actual offer and possible options. Best Regards,Mateusz

----------------
301:

I have my databases in RDS AWS from oracle, I just activated the Oracle extension but I have problems with the data being displayed from the tablespaces, the following validations have already been done:1. Activegate already has access.2. FW does not have a block from Activegate to the DB3. The User created in DB does have all the permissions and the direct test is done in the database and gives the information.The problem we currently have is the following:1. The information is not constant as shown in the image. 2. Some databases show the following error: "Polling finished with issues for endpoints:xxxxxx.rds.amazonaws.com:1521/xxxx"

----------------
301.1:

HiIn that case, it is recommended to create a support ticket.Thanks,Mateusz

----------------
302:

Hello,I have a customer that has a few license expiration dates that he wants to track.Ultimately, our goal is to open alerts when he's 30 days before expiration. We were thinking of calculating a metric (expTimeEpoch-currentTimeEpoch), and alert based off of the outcome.He is able to get the license expiration dates as epoch/UNIX values, but not the current date and time. Is it possible to do within DT Managed? Are there other ways to open alerts based off of incoming expiration dates? Thanks in advance,Asaf

	Asaf Axelrod




					
						Solved!
					
					Go to Solution.




----------------
302.1:


Hi @AsafAx, it should be possible to do this with an extension, either OneAgent or ActiveGate.@leon_vanzyl created an ActiveGate SSL/TLS certificate monitoring plugin that does exactly that: it checks the expiration date of the certificate and gets the current time, then alerts when the expiry date is within the defined threshold.I'm sure there could be other ways of doing this, but this popped into my mind when I read your post - hope it helps!

----------------
302.2:


You might also be able to integrate it with synthetic monitors which you probably have already. There it will directly state how many days you have left before the certificate expires and a problem will be raised and remain open until the certificate issue has been solved. You can also specify how long in advance alerting should start.You can find that in your settings of the synthetic monitor if you go to HTTP requests and select visual mode. 

	A Dynatrace Professional nerd working for Eviden


----------------
302.3:


Hi,The question is what licenses you want to monitor. If it is about SSL certificates then you can monitor as colleagues described above.In my opinion you should create a simple script/plugin that verifies the licenses and returns the values to DT. It can return all values and create thresholds in DT based on that, or it can return only those that need intervention.https://www.dynatrace.com/support/help/extend-dynatrace/extend-metricsRadek

	Have a nice day!


----------------
303:

I am trying to perform Dynatrace Managed migration. I have followed the steps using backup and restore a cluster. Everything works fine until Failed to start Dynatrace Server. I keep getting the error below:
dynatrace-server.service - Dynatrace ServerLoaded: loaded (/etc/systemd/system/dynatrace-server.service; enabled; vendor preset: disabled)Active: failed (Result: exit-code) since Fri 2023-09-08 03:06:17 +08; 17s agoProcess: 272397 ExecStart=/opt/dynatrace-managed/server/services/server.sh start (code=exited, status=3)
Sep 08 02:51:13  sudo[272428]: dynatrace : problem with defaults entries ; TTY=unknown ; PWD=/ ; USER=root ;Sep 08 02:51:13 sudo[272428]: dynatrace : TTY=unknown ; PWD=/ ; USER=root ; COMMAND=/opt/dtrun/dtrun /opt/dynatrace-managed/installer/bin/configurator ->Sep 08 02:51:15 server.sh[272397]: It's running after 0 secondsSep 08 02:51:16 server.sh[272397]: Waiting 900 seconds until it's listening ...Sep 08 03:06:17 server.sh[272397]: It's still not listening after 900 secondsSep 08 03:06:17 server.sh[272397]: Not runningSep 08 03:06:17 server.sh[272397]: Starting Server ... failed, it's running but not listeningSep 08 03:06:17 systemd[1]: dynatrace-server.service: Control process exited, code=exited status=3Sep 08 03:06:17 systemd[1]: dynatrace-server.service: Failed with result 'exit-code'.Sep 08 03:06:17 systemd[1]: Failed to start Dynatrace Server.
Please advise on the error above. Appreciate your opinion on this. Thank you.



					
						Solved!
					
					Go to Solution.




----------------
303.1:

Hi @KeanBoon ,This question might best be served as a Chat question on D1 or Support so that you can provide the entire relevant output, logs, and specific steps taken for installation. Cheers,Taylor S.

----------------
303.2:


This specific line tells the Server process is running, however it hasn't complete the startup:

Sep 08 03:06:17 server.sh[272397]: Starting Server ... failed, it's running but not listening

In order to find out, you have to look into the server.log. Usually such situations occur when where's a connectivity issue with other nodes or a misconfigured operating system. As suggested, the fastest way to solve it - get in touch with us via Zendesk - visit Support Center - https://support.dynatrace.com/

	Senior Product Manager, Dynatrace Managed expert


----------------
304:

Hi，friends
hope to get help.
Monitoring k8s, only monitoring a specific namespace, can this be implemented, if so, what configuration needs to be done.



					
						Solved!
					
					Go to Solution.




----------------
304.1:

Although the help document, found some relevant information, but still a little bit not understand.Configure monitoring for namespaces and pods | Dynatrace Docs 

----------------
304.2:

Hi @Lwl ,you can go with the same way mentioned in the link you've shared or before the implementation for monitoring K8s, You can create the needed rules as per the following screenshot from the UI settings, I do recommend using do not monitor as this works for me to exclude some namespaces  

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
304.3:

Thank you for your reply.

----------------
304.4:


The solution depends on the Dynatrace deployment model you use in k8s see https://www.dynatrace.com/support/help/shortlink/how-it-works-k8sIf you use classic full stack (still the default if you deploying it using the guided UI approach), then the container rules mentioned by @Mohamed_Hamdy  apply. If you use the cloudNativeFullStack or application only, it's described on the page mentioned by @Lwl - you define monitoring rules in your kubernetes deployment by labeling the namespaces and setting the annotiations at pods to exclude a particular pod from being monitored (if required).

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
305:

Hi,I have created a variable group_by in Dashboards/Notrbook to be able to group the result of a query. But I don't know how to transform this string into a valid value:fetch events
| filter event.kind == "DAVIS_PROBLEM"
| summarize {count = count(),event.status_transition = takeLast(event.status)}, by: {status = event.status_transition,`interval` = bin(timestamp, $group_by)} I haven't seen how I can do that in the documentation: https://www.dynatrace.com/support/help/platform/grail/dynatrace-query-language/functionsMany thanks



					
						Solved!
					
					Go to Solution.




----------------
305.1:


Hi @Duran_Narbona 
There is a similar example in our help: https://www.dynatrace.com/support/help/shortlink/dashboard-component-variable#resolution-in-dql-comm...
Just add 2 variables to dashboard, one for resolution and one for unit.
Then the query can look like this:
fetch events
| filter event.kind == "DAVIS_PROBLEM"
| fieldsAdd toDuration(multiplier)
| summarize {count = count(),event.status_transition = takeLast(event.status)}, by: {status = event.status_transition,`interval` = bin(timestamp, duration($resolution, unit:$unit))}
 
Best,Sini
 

----------------
306:

My company has an application that leverages about 60 % java kafka and 40% Go Kafka messaging. We have the OneAgent in our env and on all the microservices but DT Go Kafka is not supported today. Anyone here try to instrument this another way? Using OTEL or OA SDK and have any recommendations for us to be able to trace request from the front end all the way back? 

----------------
306.1:

If Dynatrace's official instrumentation for Go Kafka isn't supported in your environment, you can consider alternative approaches to instrumenting your Go Kafka microservices for distributed tracing. While Dynatrace provides OneAgent and SDKs for certain languages like Java, Go might not have native support yet. Here's a general approach you can consider:1. **OpenTelemetry (OTel) for Go:**OpenTelemetry is a set of APIs, libraries, agents, and instrumentation to provide observability for applications. You can use the OpenTelemetry Go library to manually instrument your Go Kafka microservices.- You would need to import the OpenTelemetry Go library into your Go Kafka application.- Use OpenTelemetry to create and propagate traces as messages flow through your Kafka producers and consumers.- Ensure that you follow the OpenTelemetry guidelines to set up span contexts and propagate them in Kafka messages.2. **Custom Instrumentation:**If OpenTelemetry is too heavy or doesn't fit your needs, you can implement custom instrumentation for your Go Kafka microservices.- Create custom functions or wrappers around Kafka producer and consumer libraries to record trace data.- Manually create and propagate trace context in your messages.- Send trace information as custom headers or metadata within Kafka messages.3. **Third-party Libraries:**Some third-party Go libraries and frameworks may offer built-in support for distributed tracing. Check if any of these libraries align with your technology stack and can help with tracing Kafka messages.4. **Integration with Existing Dynatrace Instrumentation:**Since you are already using Dynatrace OneAgent for Java, consider ways to integrate Go-based tracing into your existing Dynatrace environment. This may involve custom scripts or integrations to bridge the gap between Go-based tracing and the Dynatrace ecosystem.5. **Collaboration with Dynatrace Support:**Reach out to Dynatrace support or your Dynatrace account manager to inquire about any updates or upcoming support for Go Kafka. Dynatrace may have future plans for Go instrumentation, and they can provide guidance or beta solutions.In any case, regardless of the approach you choose, the goal is to ensure that trace context is correctly propagated within your Kafka messages so that Dynatrace can correlate requests across different microservices, regardless of the language they are implemented in. Be prepared for some development effort to instrument your Go Kafka applications and ensure that trace information is correctly captured and reported to your observability platform.

	Dynatrace Professional Certified


----------------
306.2:

Thank you, One more question around this, if we have the OneAgent on the Go service with deep monitoring. Can we instrument the Go kafka tracing through the OneAgent detection and transmission or do we have to leverage the Dynatrace OTEL Metrix Exporter method? Since there is a cost in metric units for us to leverage exporters but when using the OneAgent OpenT* Sensor method, there is no cost since the OneAgent is handling the transmission and protocols within the trace. 

----------------
307:

I have an application that started showing a lot of HTTP/971 error codes. Never had heard of these HTTP codes, looked online, didn't find anything.
Then I found in the UI that it referred to "Canceled". After some more searches, found a page in the documentation, in that these errors are specific to Dynatrace RUM https://www.dynatrace.com/support/help/how-to-use-dynatrace/real-user-monitoring/setup-and-configura...
They are the following:
 
 
They can be configured to not affect Apdex, which they do by default in Applications created after version 1.238

	Antonio Sousa


----------------
307.1:

Great Tip! thanks @AntonioSousa 

	-Chad


----------------
307.2:

Hello Antonio. So does that mean that these codes can be removed without problem for Apdex issues?

----------------
307.3:

As always, I also got this exotic. Does anyone know some undocumented JS agent flags like cux = 0 that could help in this case and remove this status codes from application\affecting application?Customer faced with problem that these JS codes impact on customer "best frontend code ever".Regards,Alex Romanenkov

	DT_NGINX_ALL_WHITELISTED=1


----------------
307.4:

@Romanenkov_Al3x Did you remove them from the error detection rules for the web application?

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
307.5:

Hi Julius.I have already removed this rule, but it didn't help. Customers code works only without JS agent loaded on page. Problem related to file uploading when agent is injected and customer code look like works without "No response" http codes.Dynatrace documentation:For applications created with Dynatrace version 1.238+, the RUM JavaScript reports some request errors using custom status codes 970–979 when the real HTTP status code can't be captured. Note that these custom status codes are not real HTTP status codes; they just mean that the RUM JavaScript detected an error fired by the framework you use. Customer wan't change his "very good code" because it's insanely expensive.I have already checked behavior with extended log of JS agent loaded on page. Already checked all information from support archive and HAR sessions of problematic behavior.Also - I have tried to exclude this page with injection rule. It also didn't help Regards,Alex 

	DT_NGINX_ALL_WHITELISTED=1


----------------
307.6:

So the issue is the web application does not work properly when RUM JS code is injected? Or do they complain about seeing the 97x errors in the waterfall?

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
307.7:

Yes, the issue is that the web application does not work properly when RUM JS code is injected.I see 97x errors in problematic sessions. 

	DT_NGINX_ALL_WHITELISTED=1


----------------
307.8:

Then you should open support ticket for that. Most likely the application is written in a way that including the RUM breaks it. The 97x errors are just the effect of the application itself not working.I'd not recommend turning off the capture of 97x errors.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
307.9:

Thanks. I will.

	DT_NGINX_ALL_WHITELISTED=1


----------------
307.10:

What was the outcome of the support ticket?  I'm seeing the same issue. Thanks!

----------------
308:

We are seeing occasionally millions of logs are being injected by one log source in a 24 hour period. We would like to create an alert when any log source writes more than 100k logs in a 24 hour period. I have tried to figure this out with Dynatrace documentation and few forums, but without success. Anyone has done this in the past?



					
						Solved!
					
					Go to Solution.




----------------
308.1:


Create a Threshold Alert: Once you have the custom log metric, you can set up an alerting profile in Dynatrace to trigger an alert when the metric exceeds 100,000 logs in a 24-hour period. Here's a general outline of the steps:a. Navigate to the alerting configuration section in your Dynatrace account.b. Create a new alerting profile or use an existing one.c. Configure a new alert condition. Choose the custom log metric you created in step 2 and set the threshold to 100,000 logs.d. Define the alerting criteria, such as the evaluation interval (e.g., every 5 minutes) and the number of consecutive violations required to trigger an alert.e. Configure alert notifications to be sent to the appropriate teams or individuals when the condition is met.

	Dynatrace Professional Certified


----------------
309:

S3 Storage Lens metrics glossaryMetric name CloudWatch and export Description Tier Category Derived Derived metric formulaTotal storageStorageBytesThe total storage, inclusive of incomplete multipart uploads, object metadata, and delete markersFreeSummaryN-

----------------
309.1:

I dont see it in the built in, but would be a great RFE 

	-Chad


----------------
310:

Hello - we sometimes get alerts on our Dynatrace showing increased failure rate, this is due to 404's coming in from customers incorrectly posting to our API.This can be bothersome as it's not actually an error, despite the alert that it causes.Is there any way to make it so that this isn't seen as an error? Or perhaps to change the error code that would be output in this scenario? This doesn't happen frequently enough for Dynatrace to filter it out. 



					
						Solved!
					
					Go to Solution.




----------------
310.1:


Hi,Yes, you can configure service failure detection.Best regards

	Consultant


----------------
310.2:

Excellent thank you   

----------------
311:

Hi
Can anyone please advise on the below?Is there a way of streaming data from 'Dynatrace Log Monitoring' to an external endpoint where it can be leveraged as input for further processing? I am trying to figure out how to forward logs  from Dynatrace to ServiceNow.
 
Kind regardsMoses



					
						Solved!
					
					Go to Solution.




----------------
311.1:

We have the same need to be able to export a subset of logs to our SIEM solution or even Cloud storage for archiving or data analytics. 

----------------
311.2:


Hi, You should try this Envirnment v2 API. It is early adopter... I have never used it but looks promising.   I guess this is the most important part of the GET log export. Log Monitoring API - GET export logs | Dynatrace Docs  Log viewer | Dynatrace Docs I hope you can use it such purposes. Best regards,Mizső 

	Certified Dynatrace Professional


----------------
311.3:

Hi,I am trying this api call, but i struggle on how to send the query in the body. i tried with a json body like this:{"status":"ERROR"}as a response i get also log entries with status "INFO".The manual somehow doesn't explain how to setup the query

----------------
311.4:

ok, just found out that i need to add it to the paramaters of the API call 

----------------
312:

Hello Experts
 
We have an SMS gateway called "RiCH T2," which provides a REST API to send SMS notifications. Does anyone know how we can use this REST API to configure SMS alerting in Dynatrace?
Usually, we use this API in all our other applications by just supplying the below inputs.
 
1.       User name and password (Static and fixed input)
2.       Sender (Static and fixed input)
3.       Text (Dynamic input based on event/problem)
4.       Number(Static and fixed input)
5.       Reference id (Static and fixed input)
 
"https://xservices.rich.sa/RiCHClientServiceREST.svc/SendSMSloginGet?username=*****&password=*****&Sender=***&Text=test_dynatarce_sms&number=*****&referenceid==REFID" 
 
 

----------------
312.1:

interesting method. You could cut out the gateway and just leverage the Dynatrace alerting via email and supply the carrier @ address and phone number to get SMS Messages on users phones. 

	-Chad


----------------
312.2:

We have fixed this using vendor's provided Rest API and custom payload. API:https://xservices.rich.sa/RiCHClientServiceREST.svc/SendSmsToList Payload:{"username": "******","password": "******","Sender": "***","Text": "{{ProblemID}} - {State} - {{ProblemTitle}}","Array": ["****","****","****"],"MsgBodyType": 0} 

----------------
313:

Hi all,I'm developing a dynatrace app and I would like to get the data for the user session query API as I have always done from Postman From the documentation I have seen that the portion of the code needed to fetch the data of user session query is this: import { rumUserSessionsClient } from "@dynatrace-sdk/client-classic-environment-v1"

export default async function fetchDataUserSession() {
const response = await rumUserSessionsClient.getUsqlResultAsTable({
  query: "SELECT * FROM usersession",
  startTimestamp: 0 ,
  endTimestamp: 0,
  pageOffset: 0
});  but whenever I call this method I get this error:Request failed: {"code":403,"message":"OAuth token is missing required scope. Use one of: [environment-api:usersessionquerylanguage:read]"}In the previous version of dynatrace I used to create an API token and put it on the header of the HTTP call to dynatrace.In another application, I used to call the dynatrace user session query: def callDynatrace(startDate,endDate,query,token,mainUrl ):
    query_params = {
      "query": query,
      "startTimestamp": date_to_milliseconds(startDate),
      "endTimestamp": date_to_milliseconds(endDate),
      "addDeepLinkFields":False,
      "explain": False
    }
    headers = {
      "accept": "application/json",
      "Authorization": "Api-Token " + token
    }  In this new version of dynatrace, it seems that the authentication method has been changed... especially in the developement of the app.Thank you in advance,Andrea

----------------
313.1:

easy fix, your token dosnt have the needed read access. Go back in t your Dynatrace UI and make a new tokens with the access as defined in the error message. Existing tokens you cant add permissions to, so tokens and permissions will always be net new FYI. 

	-Chad


----------------
314:

Hi,As Dynatrace developers its important to understand how metrics are sent to Dynatrace. Of course utilizing Dynatrace's OneAgent built-in detection is the first step to reaching observability. We also have access to intelligent extensions like Micrometer for building our own defined custom metrics through the Meter interface.
 
Micrometer Docs
Dynatace Micrometer Docs
 
If you are familiar with the separate APIs, there are actually multiple methods of metric ingestions between version 1 and version 2 of the API. Correct me if I'm wrong but I believe version 2 came out when the OneAgent was implemented?
 
I recommend checking out the Dynatrace Meter Registry source code. It provides a lot of interesting insight on how Micrometer sends metrics to the API. For example there are two exporters that correlate to the two API versions. 
 
Dynatrace Meter Registry code
 
 
Taking a look at the Dynatrace Meter Registry Builder object you can see the HttpUrlConnectionSender() method. This is used to configure your organization's proxy server on the registry. This method uses a unique Micrometer interface called HttpSender which enables build REST communication for Micrometer metrics.
 
Let's take a look...
 
Here you can see that we a Proxy parameter.
 
So you'll want to create a Bean method that builds a proxy-based Meter Registry. Furthermore, you'll want to obtain those proxy parameters via property files using the "@Value" parameter annotation.
@Bean
public DynatraceMeterRegistry myfunction(DynatraceConfig config, @Value("{com.foo.barr.dynatrace.proxy}")){
            your logic...
            return registry
}
 
 
 
 
 
 

----------------
314.1:

Thanks for sharing this @Nick-Montana 

	-Chad


----------------
315:

If instead of usual service detection over a .NET process, you are getting Requests executed in background threads (Microsoft.AspNetCore.Hosting.HttpRequestIn)
 
 
 
Try out below options to rectify it .1)  Create a span exclusion rule as expalined below:
 
 
2) Disabling the feature (OpenTelemetry (.NET) [Opt-In])
 
Thanks 

----------------
315.1:

Thanks for sharing this! 

----------------
316:

You have deployed new /already have few standalone  .NET exe processes that are shown in Dynatrace UI , but wondering why services are not getting auto-detected for them. What should be done about it ?Here, you are running into the default behaviour for .NET where only w3wp (IIS) processes are instrumented automatically. In other words , Dynatrace doesn't automatically perform deep monitoring on all .NET processes as there are many arbitrary processes that rely on these processes.More details on this can be found at https://www.dynatrace.com/support/help/platform-modules/infrastructure-monitoring/process-groups/con...So, first sugggestion would be to configure custom service detection rule , which will help to list the expected service.This can be esaily set up using the details mentioned in this link https://www.dynatrace.com/support/help/platform-modules/applications-and-microservices/services/serv...If Custom Service creation rules are not making any improvements, I would recommend to try utilising the Dynatrace .NET one agent SDK https://github.com/Dynatrace/OneAgent-SDK-for-dotnethttps://www.dynatrace.com/support/help/extend-dynatrace/extend-tracing/oneagent-sdkIf still desired services are not getting reflected , please do reach out to Dynatrace Technical support with relevant detailsThanks !

----------------
316.1:

Thanks for sharing this, It would be nice if the system did reference which rule was being triggered for denial of deep monitoring, otherwise you have to kind of comb through them all. 

----------------
317:

Hello, so there is this legacy application in our company which runs Java Web Launcher (jp2launcher.exe) and several Chromium.exe processes. Unfortunately, this app gets stuck at random times when doing routine operations and it DOES NOT when OneAgent service is stopped. When it's stuck the jp2launcher.exe usually stays eating a lot of CPU. So clearly Dynatrace somehow interferes with it. We tried making Custom process monitoring rules to exclude those processes:Do not monitor if EXE name begins with "jp2launcher"Do not monitor if EXE name begins with "chromium"but it doesn't seem to have any effect. We also disabled Real user monitoring for jp*launcher process group, but with no effect.application currently stuck and Java Web Launcher using CPU endlessly: Affected systems: w2k19 server and w2k16 server, but probably it doesn't matter.Upgrading Java is not easy as the app relies on the specific version. Currently there are either jre1.8.0_341 or 1.8.0_371 on these servers.Any ideas what to do except having these few affected servers entirely excluded from Dynatrace? 

----------------
317.1:

Hi,1. Make sure you restart the processes.2. I think the rule may be case sensitive.Regards,Bradley

----------------
317.2:

@McVitas,I would say in this case that you open a Support case, if you haven't done already. Looking at the logs will be essential here, and they should be able to help you.

	Antonio Sousa


----------------
317.3:

I agree with Antonio

	Have a nice day!


----------------
318:

Please help me out with possible ways to transfer splunk logs to Dynatrace & Integration process too... Thanks in Advance

----------------
318.1:

Hi,Maybe this other thread is useful.Best regards

	Consultant


----------------
319:

Hi Community Do you know if Dynatrace can monitor a Web Application using Taro (https://docs.taro.zone/en/docs/) ?I imagine it's like other unknown JavaScript frameworks and it's working with RUM Agent.Thanks 

----------------
319.1:

Hi,I cannot find any specific entry in Dynatrace Hub.I would say you are right.Best regards

	Consultant


----------------
319.2:

Hi,If you find that one of the technologies used in this application is JavaScript, you can try using the Dynatrace RUM API. However, I do not give any guarantee that it will work.Radek

	Have a nice day!


----------------
320:

Hi! Does anyone know if it's possible that the dt-app server serves the generated production bundle instead of the dev bundle? I can build it with npx dt-app build --prod , however it doesn't seem that there is a possibility to serve it then 
Starting a webserver doesn't do the trick because usually the dt-app / whatever does some magic, so some scripts / css files etc. cannot be found if I simply serve it with another server
But maybe it's also super easy and I don't see it :mild-panic:
My use-case is that I'd like to check the performance of my app, but in development mode React does some things that aren't necessary in production so this would negatively impact the analysis. Any idea how to achieve that?



					
						Solved!
					
					Go to Solution.




----------------
320.1:


Not yet possible but there is a workaround – Quick workaround: Deploy the app with a different id / in a different DT environment, so you can test the production build there.

----------------
320.2:

Its been a year since the last update, is there an API sandbox avaialble yet?

----------------
320.3:

hi @netfreq 
What do you mean with "API sandbox"? can you please elaborate?
There is an environment called "Discover Dynatrace" to which everyone has access to and can explore it: https://wkf10640.apps.dynatrace.com/ . But you are not allowed to deploy or install new apps.
Best,Sini

----------------
321:

Hi Team,I am trying to configure the Generic DB Query Plugin for MSYQL 5.7 and its keep on getting failed with below error. Can you please help me with this issue. I have provided username, password, port number and all the mandatory configuration in the plugin.Custom DB Query Extension errorError running queries: Could not connect to the database using com.mysql.cj.jdbc.Driver: com.mysql.cj.jdbc.exceptions.CommunicationsException: Communications link failureThe last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server. Regards,Bhargav 

----------------
321.1:

Hello,
 
Here is the documentation for the Custom DB Query extension.
 
Custom Database Queries | Dynatrace Hub
 
I just wanted to confirm that those were the steps you were following, you have the active gate set up and can communicate with it / have downloaded the extension to it, but you're getting errors on being able to connect to the database within the dynatrace extension? 
Thanks

----------------
321.2:

Hello,Yes, I have followed the same steps mentioned in the documentation, still getting the error. Can you please check once.Thanks,Bhargav

----------------
321.3:

I have the same issue

----------------
321.4:

The error message you're encountering suggests that there is a problem with the communication between your Dynatrace Generic DB Query Plugin and the MySQL database. This issue can be caused by various factors, and here are some steps to troubleshoot and resolve it:1. **Network Connectivity and Firewall Issues:**- Ensure that your Dynatrace server and the MySQL database server can communicate over the network. Check for any firewall rules that might be blocking the connection.- Verify that the port you specified in the plugin configuration (typically 3306 for MySQL) is open and accessible from the Dynatrace server.- If your MySQL database is hosted on a remote server, make sure that it allows external connections and that the host and port settings are correct.2. **MySQL Server Status:**- Confirm that the MySQL server is running and accepting connections. You can do this by logging into the MySQL server directly or using a MySQL client tool.- Check the MySQL server logs for any errors or issues related to connections. Look for log files in the MySQL data directory or wherever your MySQL server is configured to store logs.3. **MySQL User Privileges:**- Ensure that the MySQL user specified in your Dynatrace plugin configuration has the necessary privileges to connect to the database and perform the required queries. You can check and grant privileges using the MySQL `GRANT` statement.4. **MySQL JDBC Driver:**- Verify that you are using the correct JDBC driver for MySQL. In your case, you are using the `com.mysql.cj.jdbc.Driver`, which is appropriate for MySQL 5.7. Ensure that the JDBC driver JAR file is included in your Dynatrace environment and that it's compatible with the Dynatrace version you are using.5. **Connection String Configuration:**- Check the connection string in your plugin configuration. It should include the correct hostname or IP address of the MySQL server, port number, database name, username, and password.6. **Dynatrace Plugin Configuration:**- Review your plugin configuration in Dynatrace and double-check that all required fields are filled in correctly. Ensure that there are no extra spaces or special characters causing issues in the configuration.7. **Test Connection:**- Some plugin configurations provide a "Test Connection" or "Test" button. Try using this feature to validate the database connection from within Dynatrace. It can help identify specific issues with the configuration.8. **MySQL Server Version Compatibility:**- Make sure that the MySQL server version you are connecting to is compatible with the JDBC driver you are using. The `com.mysql.cj.jdbc.Driver` is suitable for MySQL 5.7, but if you upgrade to a newer version of MySQL, you may need to update the JDBC driver.By systematically checking these points, you should be able to identify and resolve the issue that is preventing your Dynatrace Generic DB Query Plugin from connecting to your MySQL 5.7 database. You can see the documentation page herehttps://www.dynatrace.com/support/help/setup-and-configuration/technology-support/dynatrace-extensio...

	Dynatrace Professional Certified


----------------
322:

Need help! I'm adding the MS SQL Server extension but I'm getting this error:Failed to assign monitoring configuration to ActiveGate. Reason: The monitoring configuration requires ActiveGate version 1.257.0 or later that supports data source sqlServer and belongs to group "my-group"I installed ActivateGate version 1.269.183 so I'm confused as to why I'm getting this error. 

----------------
322.1:

Hi @Gerbert Did you assign your AG to my-group? If you filter your Active Gates by groups  under deployment status do you see your AG? Yos

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
322.2:

Hi @Yosi_Neuman,Thanks for the response. Yes, I can confirm that I was able to assign the AG to the group. I only have one AG and group as of the moment.

----------------
322.3:

And your active gate shows under modules extension 1 & 2 enabled?  

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
322.4:

Yes, they are enabled. I attached the screenshot.

----------------
322.5:

Ammmm .... contact support via in product chat or open a ticket Yos 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
322.6:

Just an update. After talking to support, I reinstalled the ActiveGate and it worked.

----------------
323:

 Travel Planner badgeHello! We're happy to be back, introducing the newest Community Challenge. This time we want you to dream big. Let's share a list of your dream travel destinations! Name places, famous attractions, landmarks, cities, or simply countries that you want to visit... Sooner or later 
Feel free to make a list of the top 3, top 5, or even top 10 locations that you'd like to see in a lifetime. Every participant of this month's challenge gets a unique "Travel Planner" badge, and bonus 100 points! Let's create together an unforgettable travel plan  
Let me start this month's challenge to mention my top 5 places I'd love to see at least once 
1.  South Island, New Zealand 
2.  Cape Town, South Africa
3.  Shanghai, China
4.  Nuuk, Greenland
5.  Poland, Kiribati

----------------
323.1:

This month's challenge is an easy one! But difficult because there are so many places left where I would love to go! As I got one off my list this year, here are my Top 10:Rio de JaneiroIcelandPragueCanadian Rocky MountainsMaldivesSantoriniMachu PicchuHawaiiIbizaBudapest

	Antonio Sousa


----------------
323.2:

Prague and Budapest are perfect city break locations - and not so distant, highly recommend them!

----------------
323.3:

Hooo Love it. I want to visit in the next coming years:1- Seychelles.2- New Zealand: Auckland, Queenstown, etcss.3- Pérou: Machu Picchu.4- Scotland: a big trip in much places.5- Ireland. 

	Sharing Knowledge


----------------
323.4:

Ireland rocks! They really call it a "green island" for a reason, it's so relaxing to travel around rural areas there 

----------------
323.5:

 I don't have a lot of places on my list but the following cities and countries are always in my mind and I hope to travel to someday:1- Osaka, Kyoto, Tokyo - Japan2- Seychelles3- Napoli - Italy

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
323.6:

My very first place is not a place in fact, but the reason why. I just want to see the northern lights... just that.Anywhere where I can see the northern lights.Then I would visit some places with a beautiful beach view.FijiHawaiiPhilippinesAnd then, some place with snow.SwitzerlandNorwayFinlandSo, if Norway was also a beach place, I would list only that country to my list 

	Site Reliability Engineer @ Kyndryl


----------------
323.7:

Huuummm, beach and snow at the same time??? This is not an easy one.But one of the most interesting places where I've been is Marakesh, in Morocco. You've got the Atlas mountains very near, with Oukaïmeden being the highest ski resort in Africa. And golden sandy beaches are not far away! So, it might meet your requirements, with additional things too!Additionally, it's where I had the most surreal temperature experience: 46ºC, very low humidity and windy. Got in the pool, it was OK, but when I got out, I started shivering with cold! It lasted about 30 seconds. I couldn't believe it, so I got in the pool again  I had to think a little bit what was going on, so I shivered several times, in and out of the pool  To understand what was going on, my previous experiences with zeers helped a little bit 

	Antonio Sousa


----------------
323.8:

LOL, I am imagining you getting in, getting out the pool and taking notes on a notebook for experience purposes.I remember when I went to Chile, San Pedro de Atacama, in the geysers, outside around -9ºC, inside pool (thermal waters from underground) around 40ºC. It was a pain to get out and put clothes on. And I have it on tape, https://youtu.be/JSgd2vM2_jc?t=96 

	Site Reliability Engineer @ Kyndryl


----------------
323.9:

Let's kick the temperature difference a little bit higher? How about entering the 300 Club? https://en.wikipedia.org/wiki/300_Club

	Antonio Sousa


----------------
323.10:

Iceland should tick three boxes off your list: snow , beaches (black sand!)  and northern lights!  

	The only constant is change. Finding ways for great things to happen!


----------------
323.11:

Hi,Difficult answer but:  Tokio, Japan.  Pekin, China.  Paris, France.  Tenerife, Spain.  New York, USA.Best regards

	Consultant


----------------
323.12:

I'd go with the following:
1. New Zeeland, preferably with a helicopter to the places where they shot Lord of the Rings.
2. Iceland during a northern light. Even though I'm from Sweden I never saw a really clear one. Iceland seems like a great place to see it first
3. Hawaii, the relaxed island vibe seems great
4. One of the Caribbean islands, perfect beaches and crystal clear water sounds like a nice vacation

----------------
323.13:

Last month there were northern lights visible across half of Poland, sadly the sky was rather cloudy. Seems like I'll need to travel somewhere above the Polar Circle to see this phenomenon after all 

----------------
323.14:

This is a good one ! Still waiting for the opportunity to visit Lapland and ride a dog sled And definitely will want to visit again:The Rocky Mountains with RVNorthern India on a motor bike Hạ Long Bay with a cruise ship Drive slowly all The Pacific Coast Highway Road Trip Track by foot from the old city of Jerusalem to the deepest place on earth the Dead Sea Now I really need a vacation  

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
323.15:

I love to travel, and out of many places I want to go, I chose three places.1. Montreal, CanadaMy daughter was studying abroad in 2019 at McGill University in Montreal. She often told me about the charm of Montreal, which is called the "Paris of North America."2. New York Yankees StadiumI like baseball, so it's a place I'd like to visit once.3. Grand CanyonIt happened in 1996 when I visited the United States on my honeymoon. My wife and I flew from Las Vegas to the Grand Canyon on a small plane. However, due to bad weather, we were unable to land at the airport and the plane turned back, which was very disappointing. It's been a long time since then, but I hope to visit the Grand Canyon one day.

	T.Shirai IIM Corp. Osaka Japan


----------------
323.16:

In a nutshell...I would love to go everywhere and see everything! 

 When passion meets people magic and innovation happen. 


----------------
323.17:

My personal top 5 places  :1. Tahiti2. New Zealand 3. Hawaii4. Canada5. Antarctica 

	Observability consultant - Dynatrace Associate/Pro/Services certified


----------------
323.18:

My list in no particular order: - Maldives- Greece- Austria- Hawaii- ParisWe are going back to Slovakia in about a month and will be flying into Austria. Maybe we will have some time to visit the beauty of Austria  

	-Chad


----------------
323.19:

Seems like you're having a outstanding passion for Europe, Chad!

----------------
323.20:

How about visiting any of the Dynatrace offices in Austria? Vienna, Linz, Graz, or Innsbruck, for example? 

	Keep calm and build Community!


----------------
323.21:

Oh boy, so many great options listed above! So many destinations I'd like to see one day 
 
But if I had to come up with a list:
1. Norway - the last country in Scandinavia I'm yet to visit. I'm so fond of Sweden and Denmark, no doubt that I will love Norway too!2. Iceland. Seems like such a magical place, with black sands, blue ice and northern lights 
3. USA: would love to have an opportunity to go on a road trip all over the states one day, to hike in as many national parks as possible, and see some locations from the movies as well.
4. Japan. From stories and videos I've seen, it's another world! Such a different culture that I'd love to dive in!
5. Madagascar. For the name itself (and the cartoon ), but I'm sure there will be lots of amazing stuff to see and experience as well.
 

	The only constant is change. Finding ways for great things to happen!


----------------
323.22:

My bucket list:Alaskan cruiseWrigley Field (Chicago Cubs game)RomeIsrael as an adult (I went as a kid)Australia

	Dynatrace Certified Professional


----------------
323.23:

I have been a traveler since I was of legal age, but my pending places are:JapanEgyptGreeceNorwayGermany

	The true delight is in the finding out rather than in the knowing.


----------------
323.24:

Some of the favorite places I already visited are Thailand and Scotland.Still on the bucket list:Sout KoreaJapanNetherlands IcelandSo many more for the latter list, can't mention them all 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
323.25:

Don't you live around the corner from the Netherlands?  If you ever decide to come you can drop me a message and I can point out some things to see.

----------------
323.26:

Yes, it's ~7h by train so not really sure why I haven't made it yetThanks will pick you up on that when I finally make it 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
323.27:

It's tricky to choose, but here are the places I'd love to see:Tierra del Fuego & Patagonia, ArgentinaLofoten Islands & Northern Lights, NorwayReykjavik & volcanoes, IcelandTokyo & Mount Fuji, JapanPotala Palace, TibetQuébéc, CanadaAtlas Mountains, MoroccoThe coast of Oman, by motorcycleShipwreck Lodge on the Skeleton Coast, Namibia

----------------
323.28:

Such a solid selection, I can add all of these positions to my list as well!

----------------
323.29:

Hi @derick_hewetson this is a lovely trekking at the end of the world .

	The true delight is in the finding out rather than in the knowing.


----------------
323.30:

When heading from Tokyo to Nagoya on the Tokaido Shinkansen, you can see Mt. Fuji on the right side of the direction of travel, and on the left side when heading from Nagoya to Tokyo. But only when the weather is fine.

	T.Shirai IIM Corp. Osaka Japan


----------------
323.31:

Very difficult to choose only five: 1.  See the Stromboli volcano again but in this case at night,2.  Island of Madeira3.  Iceland4.  Route665.  Dubai Aura Skypool

	Certified Dynatrace Professional


----------------
323.32:

Regarding Skypools, I personally would love to see one day Marina Bay in Singapore, even more exiting views guaranteed!

----------------
323.33:

EasyJapon (Osaka, Tokio)  Norway (northen lights)  Iceland (black beach)  Argentina (The land of Fire)  

----------------
323.34:

1.  French Polynesia (cocorico!)2.  Japan3.  Egypt 

	Observability Engineer at Phenisys - Dynatrace Professional


----------------
323.35:

Places I want to visit1. Italy 2. Greece 3. Thailand4. Japan5. Egypt6. Hawaii (been there already but want to keep going back)

----------------
323.36:

Well, this one's hard... because when you live in a place as beautiful as Palmela, you don't even dream of going out  Whenever we go out and then return, there's no words to describe the feeling of seeing our amazing Castle appearing on the horizon... that's when you know you're home  However, I do have some places I would like to visit (even knowing I will be homesick for the duration of the trip  ).Some of them I see already here on the list, but here goes:Positano, Italy  Santorini, Greece  Route 66, USA  Bali, Indonesia  Kakslauttanen, Finland  

	Best regards, Pedro Deodato


----------------
323.37:

Hi,You hit it right with the topic of the thread in my person's case I just returned from a month-long motorcycle trip through southern Europe with my fiancée. We rode without having a plan for the whole trip and how much time we would spend in a particular place. If we liked it we would stop for a longer period of time, and otherwise we would escape further even on the same day (as we did in Ksiamil (Albania)). We tried local cuisines, slept in strange places, helped with Parma ham production and in the olive grove. We didn't think about anything related to work and everyday life. Back to the days of school vacations and carefree days.Below is the route of our trip:Warsaw - Znojmo (Czech Republic)Znojmo - Belgrade (Serbia)Belgrade - Sarajevo - Mostar (Bosnia and Herzegovina).Mostar - Korcula - Dubrovnik (Croatia).Dubrovnik - Kotor - Budva - Vlora (Albania).Vlora - Corfu (Greece)Corfu - Thessaloniki (Greece)Thessaloniki - Istanbul (Thrace)(Ferry) Istanbul - Athens (Greece)4 days in southern GreeceZakinthos (2 days)Kefalonia (2 days)(Ferry) Patras to Brindisi (Italy)Sicily (4 days) (Italy)Messina - Naples (Italy)Naples - Roma (Italy)Northern Italy (Bologna, Pisa, Milan, Garda)A few days back in the Polish Jura Krakowsko-Czestochowska.Next year we are planning the same one-month trip only in India. And this year still a mass of shorter and longer trips combined with remote work - eh too bad we already have a lack of available vacation PS: For the trip I packed as a spare Dynatrace socks (it turned out that I didn’t do laundry beforehand xD). Special motorcycle socks didn't make it and were terribly uncomfortable. My everyday choice was just DT socks. Send me more of them because they are awesome for a motorcycle - I don't know how this is possible, but it is xD      

	Have a nice day!


----------------
323.38:

That's an amazing experience! I'm dreaming about a similar road trip to explore Balkans, in my case in the meantime I want to include Romania, Bulgaria, Northern Macedonia, Albania, and Montenegro. I have a prepared map for that journey, waiting for a proper time 

----------------
323.39:

I recommend it - you can get an amazing break from work, etc. If you would like I can share a more detailed route 

	Have a nice day!


----------------
323.40:

Bike photo, I need to see your bike photo!!!

	Site Reliability Engineer @ Kyndryl


----------------
323.41:

Hehehe no problem! Catch them    

	Have a nice day!


----------------
323.42:

That's not a bike. That's a spaceship!!! My wife is pushing me to replace my current uncomfortable hard choper for a big trail, as we had in past (Tiger 800 xRX). Let's see, one day... 

	Site Reliability Engineer @ Kyndryl


----------------
323.43:

You can always have two  thank you - problem solved The new Triumphs are great!

	Have a nice day!


----------------
323.44:

Love the pics (and the socks :D)! 

	The only constant is change. Finding ways for great things to happen!


----------------
323.45:

I want to visit in the next coming years:1. Norway2. Sweden3. Germany

----------------
323.46:

My travel list will be as follows:1- Maldives2- Japan3- Iceland4- Rio de Janeiro5- Hawaii

	Dynatrace Certified Professional - Dynatrace Partner - Yourcompass.ca


----------------
323.47:

1.  Seoul, South Korea2. Grenoble, France3. Mdina, Malta4. Kyoto, Japan5. Cartagena, Spain

----------------
323.48:

I Love Travelling, My Dream Rides are  Ladakh  Kedarnath  Regards,Venkat

----------------
323.49:

1. Melbourne2. Tokyo3. Hong Kong4. Tallinn5. Oslo

----------------
323.50:

1-Paris2-Las Vegas3-Tokio (Japan at all)4-Santiago5-Ibiza

	Dynatrace Professional Certified


----------------
323.51:

AustraliaJapanMaldivesFranceSingapore

	IT Master | dynatrace Certified professional | SRE Certified | Scrum Certified | Azure Certified | https://www.linkedin.com/in/rodrigocuevas/


----------------
324:

Is there a way to programmatically define custom entry points for creating distributed traces as part of .NET application code?  My current company uses Dynatrace and we have to work with the operational team to use some sort of UI within Dynatrace to discover classes and select a particular method.  Developers are not given access to this functionality (it sounds global rather than scoped to our apps).  If developers refactor our code, we can break this making the integration fragile.By comparison, competitor's products (NewRelic and DataDog) offer .NET nuget packages that we can just annotate and method and we're done.  What's the equivalent for Dynatrace?  Can OpenTelemetry help me out here somehow?Thanks much

----------------
324.1:

You can create custom services for thislook at the documentation pagehttps://www.dynatrace.com/support/help/platform-modules/applications-and-microservices/services/serv...

	Dynatrace Professional Certified


----------------
324.2:

This is what we do today, but it's a manual task via the Dynatrace UI correct?  We need something that is baked into code, so that when our app deploys it has the proper entry points instrumented.

----------------
324.3:

Hi,You can check Monaco, custom services is supported.Best regards

	Consultant


----------------
325:

Hello, we're using OpenTelemetry to auto instrument several Java applications running on Websphere Application Server.
However the issue we have is that some of the services appear with a too general endpoint name.
It seems that the span name is generated with a generic http.route attribute that is masking part of the whole request, so the endpoint name that appears in Dynatrace is equally generic and broad. Only when viewing the details of the trace/span, we can see the actual http.target and the real URI of the request.
Example:
http.route says /example/*.go
http.target is /example/login.go
 
The endpoint name ends up being only GET /example/*.go
This causes that all the traces/spans that share that same generic http.route are being grouped incorrectly inside that endpoint when they are very different URIs and requests.
 
We would like to have the endpoint name called GET /example/login.go
So the endpoint would correctly group only those login requests inside it.
We're using the new Unified Service capabilities to enrich the OpenTelemetry information and its representation in Dynatrace Services.
We're using auto-instrumentation OpenTelemetry for Java.
Any ideas?
Regards,
JD

----------------
325.1:

It sounds like you are encountering an issue with the naming of endpoints in Dynatrace when using OpenTelemetry to instrument Java applications running on Websphere Application Server. The problem appears to be related to the generic `http.route` attribute being used for the span name, which results in less informative endpoint names.To achieve more specific and informative endpoint names in Dynatrace, you can consider the following approaches:1. **Custom Instrumentation**:- One approach is to perform custom instrumentation of your Java applications using OpenTelemetry. This will allow you to define how the span names are generated. You can extract the actual endpoint information from the `http.target` attribute and set it as the span name. This way, you can have more specific endpoint names in Dynatrace.2. **Attribute Extraction and Transformation**:- You can configure OpenTelemetry to extract the relevant information from the `http.target` attribute and transform it into a more meaningful span name before it's reported to Dynatrace. This can be done using OpenTelemetry's attributes processor or a similar mechanism depending on your OpenTelemetry configuration.3. **Dynatrace Service Naming Rules**:- Dynatrace provides the ability to create custom service naming rules. You can define rules that use the extracted information from `http.target` to create more specific service names in Dynatrace. This can help in better grouping and visualization of your traces.4. **Dynatrace Custom Attributes**:- You can also use custom attributes in Dynatrace to store additional information related to the service or endpoint. This can be used to add more context to your traces and help differentiate between different endpoints.5. **OpenTelemetry Instrumentation Configuration**:- Check your OpenTelemetry instrumentation configuration for any settings related to span naming. Some instrumentation libraries allow you to customize how span names are generated. You might find an option to use a specific attribute as the span name.6. **OpenTelemetry Updates**:- Ensure that you are using the latest version of the OpenTelemetry instrumentation for Java. Newer versions may provide enhanced capabilities for customizing span names or extracting attributes.7. **Collaborate with Dynatrace Support**:- If you are still facing difficulties after trying the above steps, consider reaching out to Dynatrace support. They may have specific recommendations or updates related to their integration with OpenTelemetry.By combining these approaches, you should be able to improve the specificity and accuracy of endpoint naming in Dynatrace, allowing for better trace grouping and analysis. Remember to thoroughly test any changes in a non-production environment before applying them to your production setup.

	Dynatrace Professional Certified


----------------
325.2:

Thanks for your tips!So as far as current Dynatrace capabilities, we cannot change the naming for these endpoints?We have worked with Service Naming Rules and Service Request naming rules but in this case for Unified Services ingested with OpenTelemetry, the naming section doesn't show up inside those services. And we don't have the option right now to customize the OpenTelemetry instrumentation, we can only work with auto-instrumentation.Strange thing is, some services DO have the correct endpoint names, and others do not.

----------------
326:

Hi Everyone,
When I'm installing OneAgent on a Host, is it possible to install another monitoring tool (e.g. Bizagi Diagnostics)?
I'm asking because I have an OneAgent installed on a Bizagi Server and When I install the Bizagi Diagnostics Software I get an error. When I uninstall the agent and try again to install the tool, it installs successfully.
Could you give me a reason about this?
Thank you in advance
 
 



					
						Solved!
					
					Go to Solution.




----------------
326.1:


its possible but not for all the tools, oneagents need instrument the technologies that are monitored, and other tools do the same thing.When you got a agent coflict you can see in the deployment status the agent that are in conflict See this pagehttps://community.dynatrace.com/t5/Open-Q-A/Conflicting-monitoring-agents-temporarily-deactivated/td...

	Dynatrace Professional Certified


----------------
327:

Vous avez peur des données sensibles dans les journaux (logs) ? Inscrivez-vous pour tester le prototype du scanner de données sensibles! https://forms.office.com/r/PEdH9rEDS7 

----------------
327.1:

pas acces au formulaire....

----------------
327.2:

Salut Nicolas. Je te ferais signe quand c'est ouvert vue que tu'es intéressé

----------------
328:

Hello
can Dynatrace   monitor Napse Vtol application ?
 



					
						Solved!
					
					Go to Solution.




----------------
328.1:


i think that dynatrace can but in the documentation i cant see nothing about this, but you can see all technologies that dynatrace support https://www.dynatrace.com/support/help/setup-and-configuration/technology-support

	Dynatrace Professional Certified


----------------
329:

Hi everyone,
 
The problem is Logs not available for MZ level.
MZ level contains Access Environment, and View Logs
Inside the MZ, I have specified 

Aws Account ID equals 
Entities matching type("host"), entityName.startsWith("foobar")
Entities matching type("Service")
Web applications where name contains "hello"

Using the preview, appeared on Aws Account ID with type AWS Lambda Function
Also, Entities matching type ("Service"), <Lambda name> in <region>, type RPC service
 
Now, when I go to Applications & Microservices > Services > {Lambda name} in {region} > Related Logs
It's missing the logs. Only when I gave Environment level : Access Environment and View logs, the logs appears.
Any ideas why?
 
Thank you
 
Best Regards,
Abner



					
						Solved!
					
					Go to Solution.




----------------
329.1:


Hey Abnerlusung i sugest you to read this page of documentationhttps://www.dynatrace.com/support/help/observe-and-explore/logs/log-monitoring/analyze-log-data/mana... Management zones are an information-partitioning mechanism that allow you to focus on specific parts of your topology. You can customize a management zone to include a specific set of monitored entities via management-zone rules. Use one of these two methods to analyze logs generated by a management-zone entity.

	Dynatrace Professional Certified


----------------
330:

ive been reading this article about java memory mangement, 
https://www.dynatrace.com/resources/ebooks/javabook/analyzing-java-memory/
i am really intrested to see what OOTB monitoring does dynatrace provide for JVM enviornments, i do see bits of JVM monitoring GC, etc, however my question is 
 
is there a standard dashboard OOTB that does all the JAVA stuff, EDE, young, heap etc GC and CPU etc i wud have though its someting that dynatrace would have built in?
if there is none of this stuff what bout other ways to see all of this stuff, when i do create a dashboard i get minimal options however there is JVM metrics i can see,  anyone else done this before?

----------------
330.1:

There is no standard OOTB dashboard that contains all of that information AFAIK; however, this is available under the Overview of the Process that has the JVM's in question. (All of the tabs below the Process selected should show you the JVM metrics.)In terms of creating a dashboard, it is possible for you to create something that contains metrics that Dynatrace natively collects. That information can be found here: https://www.dynatrace.com/support/help/shortlink/built-in-metrics#jvmYou can simply configure those metrics in the Data Explorer, then pin them to a dashboard. Links below are for Data Explorer & Dashboarding:Data Explorer: https://www.dynatrace.com/support/help/observe-and-explore/explorerDashboard: https://www.dynatrace.com/support/help/observe-and-explore/dashboards-classic/dashboards/create-dash...

----------------
331:

 The "Gamer" badge
Hello, Community Friends! Once again, we invite you to take a look at some after-hours activities. Let's share the names of our favorite games, both current obsessions and those that used to make time fly... years ago 
Post one or a few game names (photos, print screens of cover arts are welcomed as well)! Promote contemporary stuff or go a little bit nostalgic... And don't worry repeating! It will only highlight how meaningful some titles are for whole generations. And traditionally, everyone who takes the challenge receives a unique "Gamer" badge and 100 bonus points as well! 
 
Let me start with something so obvious and yet so timeless: GTA San Andreas, of course.
 
 

----------------
331.1:

So many to choose from, so little space!
Favorite childhood game: The Legend of Zelda, Ocarina of Time.I'm currently listening to an album with a more epic take on Zelda songs: https://open.spotify.com/album/5VgztJRvkD0xFqFfMZcxDW?si=ik6WBUd-SV-FDcNFS_jOig
  
 
Most hours spent in one game: I guess an MMO, probably World of Warcraft or The Lord of the Rings Online 
Currently playing: Diablo 4 and Factorio. Diablo 4 is great in couch co-op. Factorio makes me feel like I'm an engineer in my spare time as well.
 
 

----------------
331.2:

Hard to choose but,The first one: Countles hours/days/weeks... in Diablo 2, not the new Resurected version, but the classic one, i think i replaced my mouse like 2 times because of this game. The second one: maybe the Half Life (the full series), the story is just amazing, with amazing gameplay. (and Counter Strike, because it was a mod for this game at the beginning.)        The third one: World of Warcraft, i think, this game took quite a few hours of my life... The grind was real  Now Legend of Zelda Tears of the Kingdom, and Diablo 4 ofc.

----------------
331.3:

Ooo Diablo! I completed many times each of the four parts! I love this game:)

	Have a nice day!


----------------
331.4:

This challenge topic sent me down the nostalgic rabbit hole, beware 
As a late-late millennial, my childhood still happened in the pre-PC games era. Instead, I had Sega console!  
Hours were lost to these games:
 Sonic The Hedgehog
 Jurassic Park’s Raptor Mode
Then a neighbour of mine got the first PS, and we got obsessed with:
 Mortal Kombat
And in my teens, of course:
 Need for speed: Underground
 Sims 1 (and 2 for a moment)

	The only constant is change. Finding ways for great things to happen!


----------------
331.5:

Remembered another one 
 Neighbour from hell

	The only constant is change. Finding ways for great things to happen!


----------------
331.6:

My gaming skills (and availability) has gone long time ago...These are the ones that still present in my mind from when I was a kid, playing in a small tube TV at my parents room;The Fantastic Adventures of Dizzy: https://www.deadpark.com/30-minute-reviews/the-fantastic-adventures-of-dizzy-nes/I started to learn english with this one. In order to complete the tasks, you should pay attention to the instructions, so to avoid being lost or enclosed somewhere in the game, I had to use a dictionary. I have a lot to thank for from this game for this. When I got my hands in a computer, these were the ones that I spent more time on.Carmageddonhttps://en.wikipedia.org/wiki/Carmageddon Believe me or not, I have learned to drive with this game. Doing exactly the opposite I was supposed to do when playing. The Incredible Machinehttps://en.wikipedia.org/wiki/The_Incredible_Machine That' another one that I remember part of my (young) life was spent out. I loved the challenges by each level.You know what.. I think I will find this one out and start playing it again... That's your fault, @Michal_Gebacki 

	Site Reliability Engineer @ Kyndryl


----------------
331.7:

I'm facing it regularly, don't blame the timeless perfection of this game! 

----------------
331.8:

@dannemca Carmageddon is awesome game @dannemca Carmagedon is awesome game. I even played it last year 

	Have a nice day!


----------------
331.9:

Not really a gamer. But I played this a lot: I recently discovered that Tetris was taken to new levels in the last decade. With hypertappers, Tetris seems to have started a whole new era, and the values obtained since then were absolutely unimaginable when I was playing it: https://tetrisinterest.com/tetris-champion/Some years ago, I was also much into chess: Nowadays, I don't play a lot...

	Antonio Sousa


----------------
331.10:

I have just watched the Tetris film yesterday. Great movie, btw.

	Site Reliability Engineer @ Kyndryl


----------------
331.11:

@dannemca,Nice coincidence!

	Antonio Sousa


----------------
331.12:

Hi, these should be in my list:Championship Manager: Season 01/02  Age of Empires II: The Conquerors  Commandos: Behind Enemy Lines  Best regards

	Consultant


----------------
331.13:

Time to make me feel old.  My favorite games are story games.  Originally they were by Sierra: King's Quest, Space Quest and Police Quest. King's Quest Space Quest Police QuestThen Links 386  I started playing games again a few years ago on PS4.  Favorites: Uncharted IV (why I got back into gaming), Star Wars Battlefront II, Spider-Man, and Red Dead Redemption II (Hope they remaster the first one). Uncharted IV Star Wars BattleFront II SpiderMan Red Dead Redemption II (I think my favorite game of all time.  Finishing my 3rd play through right now). Notable mentions:Nintendo games: Super Mario Bros., Contra, Punch-Out, etc. https://www.denofgeek.com/games/best-nes-games-all-time-ever/PS4: God of War, Horizon Zero Dawn, Last of Us, Assassin's Creed series, Tomb Raider series. Guess I have played a few games   

	Dynatrace Certified Professional


----------------
331.14:

Tetris Zybex  Montezuma Quake III Arena Need for speed underground   

	IT Master | dynatrace Certified professional | SRE Certified | Scrum Certified | Azure Certified | https://www.linkedin.com/in/rodrigocuevas/


----------------
331.15:

Great challange! Another one where the list could go on and on For competitive I really enjoy(ed) Starcraft 2 and World of Warcraft, those probably have the most time invest as well     Favorite childhood game I agree with @Mike_L, Ocarina of Time was amazing. That also led to my triforce.   Also Knights and Merchants was really fun for an early RTS:   Currently I'm playing Diablo 4 and Factorio always comes back for me, the factory must grow!     

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
331.16:

Oh, I forgot Starcraft 2. The number of hours I spent in there with ladder, direct strike and co op must be quite substantial as well. I'm looking forward to Stormgate as it's created by many of the same people. It's been quite some time since I've been excited by a new RTS.

----------------
331.17:

Yes, excited for Stormgate as well. The dev talks for it sounded pretty good as well 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
331.18:

Getting a dose of stormgate sooner than anticipated   

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
331.19:

Nice! Congratulations 

----------------
331.20:

 Starcraft 2 

	DT_NGINX_ALL_WHITELISTED=1


----------------
331.21:

Such a great game! Not sure if I played it more or watched more games 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
331.22:

I usually fall asleep when I watch GSL\ESL\Katowice games. But this is not because the games are not interesting, only because I want to sleep 

	DT_NGINX_ALL_WHITELISTED=1


----------------
331.23:

What a lovely challenge . for me as an old Gamer (Ps3, Ps4, Ps5, Xbox and for sure PC) i have some great figures to mention: God of War, Red dead redemption and Max Payne    

	Dynatrace Certified Professional - Dynatrace Partner - Yourcompass.ca


----------------
331.24:

Currently these two ofc    And for some reason, even though it was waaaay before my time, PacMan remained a favorite.   

	A Dynatrace Professional nerd working for Eviden


----------------
331.25:

PacMan is a favorite too!

	Dynatrace Certified Professional


----------------
331.26:

What better to promote Community gamification, than games themselves, huh?  Happy to see that some of my all time favorites are already on the list!I've played World of Warcraft for SEVERAL years: my main was a very happy Tauren Warrior (tank).Met very nice people through the game, and also brought a lot of my IRL friends to play! Lots of fun!  I even got an Horde T-Shirt when I got my Mists of Pandaria expansion pack, back in 2013! For the Horde!   However, my heart will always go to the best WoW expansion ever: Wrath of the Lich King!What a blast!  Being a World of Warcraft gamer, naturally I also delved into the realms of League of Legends (back when LoL was just an excuse to have a break from WoW, while we waited for instance queues).In WoW, I was a tank and helped protect others... in LoL I've always played support: not much of a damage person, here! But I loved being a part of a team, and supporting my team (literally) throughout every match!Played LoL since Season 1, and kept playing also for several years.  In the meantime, I also played some CS:GO, but my all-time favorite FPS is, definitely, Crysis!Wonderful graphics, but - most important - very thrilling and exciting, keeps you hooked from the first minute!  Saved the best for last, the game that introduced me to what gaming is all about: living a story!Do not be fooled by my first two choices, which are online and focused on competing!Even in those, you are always either a caracter in some story or - better yet - part of a team: a team member (in every team, in every context, really) is always a sort of a character in some story (most of the times, a story much bigger than the character itself).The first game that led me to this crazy storytelling/storyliving world was a very simple, friendly but albeit wonderful game: Sly Cooper.I first got it when I was something like 7 or 8 years old, and played it at least once a year since: to revive those cheerful childhood moments, and to remind myself of what a warm feeling it is to go through with a great story!  

	Best regards, Pedro Deodato


----------------
331.27:

Finally, I've found one that plays League Of Legends! I'm a main Jungler and secondary supporter  I hope we meet sometime at the Summoner's Rift! 

	Senior Product Manager, Dynatrace Managed expert


----------------
331.28:

okay here we go1. House of the Dead (1&2)2. DX-Ball3. Need for Speed4. GTA5. Roadrash6. Lots of mobile game (Candy Crush, Subway Surfers, Temple Run)7. Bloons Tower Defense 8. Skyrim9. Dota 10. League of Legends
 
 
 
 
 
 
 

----------------
331.29:

 to League of Legends!

	Senior Product Manager, Dynatrace Managed expert


----------------
331.30:

Super Mario 

----------------
331.31:

The original Super Mario was only 40kb, and it's a classic that can't be topped

----------------
331.32:

Classic!

	Dynatrace Certified Professional


----------------
331.33:

Hi,There are three games in my memory from my school days:- Turok - Worms Armagedon - Serious Sam II Turok is one of the first games I had on my computer - I remember the guy who sold us the computer saying that if I go back and forth on the map my computer will crash xDWorks Armageddon and Serious Sam II, on the other hand, meant many hours of playing with friends from the estate.Who among you also carried the whole computer in a suitcase to play arm in arm with a friend in one room?Radek

	Have a nice day!


----------------
331.34:

Hey, how about playing some online game together? If we already have such a topic then maybe we can make a DT Community team  Any suggestions?

	Have a nice day!


----------------
331.35:

I'd be more than happy to play together Among Us!

	Senior Product Manager, Dynatrace Managed expert


----------------
331.36:

I'm in!  Anyone else? 

	Have a nice day!


----------------
331.37:

The Community is already on the topic of organizing a global Community event  That would be sooooo cool!

	Keep calm and build Community!


----------------
331.38:

Great thread already So my absolute favorite at the moment is Disco Elysium - I always loved RPGs, but this was the first one, that I really felt that I can roleplay not just from the class point of view (mage, warrior, etc.), but as a real character. If someone played Planescape Torment or the classic point-and-click adventure games in the past, they will feel at home with this one. Besides that, here is a list of my other favorites:-Elden Ring-Witcher 3 (mandatory position for everyone from Poland I guess  )-The Legend of Zelda - Wind Walker-Quake-Doom Eternal-Binding of Issac-League of Legends (more as an esport viewer at the moment)-Halo
-Hollow Knight

	If you have any questions about the Community, you can contact me at maciej.neumann@dynatrace.com


----------------
331.39:

Currently playing a lot of Diablo IV and Fall Guys, which are the complete opposite of each other :

 
 
 


Games I've played a LOT of and mean a lot to me include the Halo, Destiny, and Overwatch games:

 
 
 
 


And one of the best, unknown party games out there (which is still playable via Backwards Compatibility on the Xbox One today) is Fuzion Frenzy! 

 
 



----------------
331.40:

YESSSSS! Fuzion Frenzy was such a great game. I remember a lot of laughs, anger, and joy at the same time with this game. LOL!

----------------
331.41:

 So many great moments online with friends or at home. Also Monkey Island, Starcraft, Tetris, Duke Nukem and Zelda Series. Love to see that Factorio is on the list of many.Scoop, Someone at Dynatrace recently showed me game ports that run as an application on the latest Dynatrace. PacMan, Doom. 

	The true delight is in the finding out rather than in the knowing.


----------------
331.42:

We're also gamers at Dynatrace!
 
 
 
I'm looking forward to your games deployed at Dynatrace AppEngine!

	Senior Product Manager, Dynatrace Managed expert


----------------
331.43:

aaaaa and immortal Doom!
 
 

	Senior Product Manager, Dynatrace Managed expert


----------------
331.44:

Starcraft II  The peak of my gaming career was the solo murder of a raid boss in a very famous online MMORPG when all my teammates died. I hit him solo for 3 hours. Heroes of Might & Magic IIII don’t play anymore, HoMM3 - just watch twitch streams and fall asleep Alex

	DT_NGINX_ALL_WHITELISTED=1


----------------
331.45:

the following are my favorite games - Metal Gear Solid 3  - Resident Evil 3 & 4 - Dino Crisis 2- FIFA All Versions- Medal of Honor online 

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
331.46:

Well, I've been playing Civilization Series since 2007. But in my early days I was addicted to Diablo, Warcraft, SimCity and Transport Tycoon.
 Transport Tycoon Civilization

----------------
331.47:

Transport Tycoon, of course! 
I had such fond memories of that game that when I decided what to do with some spare time I created my own 3d engine to make an online multiplayer spin on it.
Just found an old video I made with some updates: https://www.youtube.com/watch?v=RDW2FpxPpOw&ab_channel=StateofFortune

----------------
331.48:

I loooove Transport Tycoon, the game is still alive and well with OpenTTD, such a delightfully relaxing game.

----------------
331.49:

If anyone here plays Chess at Chess.com please add me there https://www.chess.com/member/andrelcsilva 

----------------
331.50:

Regret you haven't seen my face while scrolling through all these posts - like a child in the toy shop! So many memories and adventures, starting with Tetris and Perestroika -> Soviet Mind games   through Civilization, Heroes of Might and Magic I, II, III, and IV, and many, many more games. 
 
Currently, I'm a big fan of Riot Games - including League Of Legends, Teamfight Tactics, Legends of Runeterra, and Valorant! I'm also an e-sport fan!
 
So screenshots of two games that were not mentioned yet and that are close to my heart - Among Us - which helped to survive socializing during the pandemic and Team Fight Tactics:
 
 
 
 
 
 
 


	Senior Product Manager, Dynatrace Managed expert


----------------
331.51:

Ammm nostalgia  Prince Of Persia , Tetris & Minesweeper

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
331.52:

Tetris of course!  Minesweeper - forgot about that.  Man I played that a lot too

	Dynatrace Certified Professional


----------------
331.53:

I don't consider myself a gamer, but please let me share some electronic and computer games I have enjoyed over the years -We got an Atari 2600 as a Christmas present (1979?) - and spent many hours on Space Invaders. Sadly I disposed of this 2600 system and carts when I moved in 2003. Another hit, in the 80's this time - Coleco Electronic Quarterback. I don't know what happened to this unit.  Late 90's MS-DOS game Scorched Earth Late 90's Windows 3.1 game 'Ski Free' (or something like that).   Dopewars - late 90's early 2000's Palm Pilot era 

----------------
331.54:

Ohhh, great games, Scorched Earth was great, recently I've found Forts, a new game that reminds me of it.

	The true delight is in the finding out rather than in the knowing.


----------------
331.55:

How could I forget Scorched Earth in my list! And Worms.

----------------
331.56:

MS3

----------------
331.57:

The first of then will always be Gta SA and Gta V. But i really like to play the classic like Bomber Man 2. with this 3 games, i can say that takes 90% of my entire life gameplays.   there is also a game that looks like Gta but a brazilian version, the name is 171 and its disponible at steam in a beta version:    

	Dynatrace Certified


----------------
331.58:

thinking about this i found a duality in my classic games list, in one hand i played resident evil which for me was one of the best and scariest games at that time. on the other hand i had Crash Bandicoot, that for me was one of the funniest in my chilhood, a complete classics.   

----------------
331.59:

Oh my god, Crash Bandicoot!! Thanks for bringing back all the memories 

	The only constant is change. Finding ways for great things to happen!


----------------
331.60:

Oh....UNREAL TOURNAMENT  (1999)Amaaaazing storyline and MUSIC Probably it was the time when I fell in love with electronic sounds...UNREAL TOURNAMENT SOUNDTRACK 

 When passion meets people magic and innovation happen. 


----------------
331.61:

And my first game ever...LOTUS Lotus Esprit Turbo Challenge (1990)My first "speeding" in a red car with a joystick in my hand, driving through long tunnels...It also was the time when I fell in love, with.... cars and speed And I've just realized that maybe because of that I have a red car  with a manual gear   

 When passion meets people magic and innovation happen. 


----------------
331.62:

So many good memories!
I am a old blizzard fanatic myself so all the Diablo 2, World of Warcraft and Starcraft brings a lot of memories!
But my favorites all time are from the Final Fantasy franchise specially this master piece https://en.wikipedia.org/wiki/Final_Fantasy_VII
I spent my whole childhood playing that game. And of course:
 
 
 
A honorable mention to:
 
 
 

----------------
331.63:

I played Games on Amiga 500, PS1, PS2 and the PC - With my Brother and sister. We loved the below:
 
 
 

----------------
331.64:

Reading all of the comments....SO MANY GREAT GAMES AND MEMORIES!!! Between PC and consoles, my gaming library is around 500+ games and it keeps growing. I'd add Contra on Nintendo and Shinobi on Sega. From current gen console, I enjoyed Assassin's Creed games, Cyberpunk2077 - with all of its flaws -  and God of War games so much I opted for the collector's edition.
Yup, that's Mjolnir aka Thor's hammer .
 God of War Ragnarök
 Cyberpunk 2077

----------------
331.65:

Great success for this challenge Dofus was my first (and last) MMORPG ! So many hours on it : My first video game ever :  My first Zelda in 2001, and it still my favorite licence today:  

	Observability Engineer at Phenisys - Dynatrace Professional


----------------
331.66:

I used to play "Die Siedler" A LOT 
 
Couple of years ago I learned there is sort of a community remake, free and open source called Widelands( https://www.widelands.org/ or https://en.wikipedia.org/wiki/Widelands). It works very well already and there is versus mode. If you like games like this I highly recommend it
 
If you own a VR Headset and like CoOp games I highly recommend https://vrgiants.com/ 
 
The Person wearing the Headset plays a giant, that is chained to the ground and the other player plays a dwarf. Together you have to solve puzzles. It is done by a guy (Wolfgang Tschauko) whos Master Thesis was about bodily presence in virtual reality. I also quite like it for Teambuilding and communications training (Keep Talking and nobody explodes is also perfect for the latter but too stressful for many people).

----------------
331.67:

My favourite games of all time are 2, 

NFS Most Wanted (2005 Edition) 
FIFA (Now EA Sports FC)
 
 


I played these games for over 1000 hours, and still, it feels fresh and wanna play more and more. They bring that kid in me. 

	Love more, hate less; Technology for all, together we grow.


----------------
331.68:

What a great Challenge! So many of these submissions have brought me back to my childhood. But there were few big ones that were missing for me: Stronghold Crusader - "Not enough wood my lord", Why is there never enough wood!?  Lemmings:  Flight Simulator:  Train Simulator:  Tremulous:  

	-Chad


----------------
331.69:

Oh No! More Lemmings.    Great Great Game.

	The true delight is in the finding out rather than in the knowing.


----------------
332:

Hi,I have try to use the new Grail visualisation with metricsHowever, some builtin metrics are not existing yet in Grail (I am using this as reference https://www.dynatrace.com/support/help/shortlink/built-in-metrics-on-grail)I am thinking of synthetic metrics : Browser monitors metrics are not there (it's only one example..)
Will it be available soon and migrated over the time ? any timeline ?Best regards,Christophe



					
						Solved!
					
					Go to Solution.




----------------
332.1:


Hi,
We're gradually working on migrating metrics to Grail and we're at the moment working on the first Synthetic metrics. We don't have a timeline for when all of the Synthetic metrics will be available in Grail but you'll gradually see more and more of them available in Grail as we progress with the migration.

----------------
332.2:

We have slightly changed the strategy of synthetic metrics rollout.
First set of metrics will be available as a preview with Dynatrace version 269. It will cover huge majority of HTTP and 3rd monitors metrics plus basic set of Browser monitor metrics.
I will be happy to discuss reasons details of your use case, what are the main goals you would like to achieve with synthetic metrics in Grail. I would like all community participants to consider my comment as an invitation to such discussion and participation in preview. Please, leave comment under that message if you're interested in. 
 
Best Regards,
 
Jacek

----------------
332.3:

Hi Jacek !Unfortunately, I missed your response  in May ...but if you need any feedback about synthetic metrics, I'll be happy to discuss. Christophe

----------------
333:

We have a Windows application running on OA v1.263 that is having issues with starting up when OneAgent deep monitoring is enabled. The service is running on a Windows Server 2016.
When we try to "start" the service we get the error below:
 
"Windows could not start the SERVICE_NAME service on Local Computer. 
Error 1053: The service did not respond to the start or control request in a timely fashion."
 
We were speculating that it might be Firewall related? But wanted to see if anyone else has seen this before. We also have a ticket opened so will pursue that as well. 
 
Thanks!
Steven

----------------
333.1:

I remember this can happen if you did not perform the latest Windows update - some of them are needed to run applications. So you could try updating Windows. Does running in admin mode help?There are many more options but these are the easier ones to try I guess...Otherwise you could still consider changing the timeout settings in the registry editor.

	A Dynatrace Professional nerd working for Eviden


----------------
333.2:

Hi @marina_pollehn  Thanks for the feedback, I can certainly review those items and see if we can implement them.  Thanks,Steven

----------------
333.3:

@marina_pollehn Do you know what type of changes must be made in registry for timeouts? I can certainly have the team look into that. 

----------------
333.4:

I definitely can't recall it from the top of my head anymore but I found  a small manual online which should explain the method a bit  (Personal note: You might want to do a Registry Backup before as playing with the Registry Editor can also go wrong if there is any typo or the wrong button pressed) Changing the Service startup timeout (ServicesPipeTimeout) in Windows (citrix.com)To increase the service startup time yourself, create the following registry entry:Subkey:HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\ControlName: ServicesPipeTimeoutType: REG_DWORDData: The number of milliseconds that you want to give the services to start in.To create this registry entry, follow these steps:Click Start, click Run, type regedit, and then click OK.Locate and then click the following registry subkey:HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\ControlRight-click Control, point to New, and then click DWORD Value.In the New Value #1 box, type ServicesPipeTimeout, and then press ENTER.Right-click ServicesPipeTimeout, and then click Modify.Click Decimal, type the number of milliseconds that you want to wait until the service times out, and then click OK.For example, to wait 60 seconds before the service times out, type 60000.Quit Registry Editor, and then restart the computer. Then again, no guarantee that this will solve your problem, just one of the many scenarios that could be the problem. If you managed to solve it either with this method or with the DT support pls let me know - interested in what the root cause was in the end 

	A Dynatrace Professional nerd working for Eviden


----------------
333.5:

Thanks! Will have to keep you posted.

----------------
334:

Hello,
 
I have an issue with Trace menu.
 
I have a service that gives back a response between 200 OK or 400 Bad Request. When the return is 200 OK, the Trace menu will bring up other service information with details. When it returns, 400 Bad Request brings up this message.
 
Trace diagnostic messages






 
Some data could not be collected or transmitted. This is most likely due to a resource congestion on network, host or process level in your monitored environment (Diagnostic code: C0)


 
Required information was not sent by the OneAgent. If this happens regularly, this might indicate a OneAgent bug (Diagnostic codes: C6, A6)






 
What can I do? currently I have updated dynatrace oneagent version 1.271.135. Thank you.



					
						Solved!
					
					Go to Solution.




----------------
334.1:


This means basically means OneAgent was unable to capture all the information. First, check if you are running a supported version of NGINX and then you can reach out to Dynatrace One to provide you with more detailed information on why this is happening. 

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
335:

Dear All,Is the log viewer elapsed time in milliseconds or microseconds? Particularly for the SQL statements. Regards,Babar



					
						Solved!
					
					Go to Solution.




----------------
335.1:


By default the sql statements are im miliseconds.but when a trace is saved to either a file or a database table, the Duration column value is written in microseconds

	Dynatrace Professional Certified


----------------
335.2:

Hello @natanael_mendes Thank you for your comments. Are you referring to the MDA or log viewer elapsed time? Is the screenshot I shared will be considered as milliseconds?Regards,Babar

----------------
336:

Hello,    i want format result  query on summarize, the default it's 2.34K i need number detail, example : 2341.- Thans a lots



					
						Solved!
					
					Go to Solution.




----------------
336.1:


Hi Ellery,I do not think that there is a way currently to format the 'Single Value' to not append the 'k'; however, if you look at the value under the 'Table' tab, it should show you the detailed number that was collected from the count() call. I will also add that in Grail Notebooks, you are able to add more Formatting options as oppose to the Advanced Views in logs. The output there should show you the value as a single number without the appending 'k' if you deselect 'View value formatter'. Cheers, Taylor

----------------
337:

Hello, I am using Generic DB Query Plugin (version 3.5.0) and MariaDB version below: I don't see support for MariaDB but I do see support for MySQL, does anyone have this working? If yes, which version of JDBC are you using? Thanks

	The true delight is in the finding out rather than in the knowing.




					
						Solved!
					
					Go to Solution.




----------------
337.1:


This is not possible, both the driver class name and the connection string are built for MySQL. So we don't support MariaDB at this time.You do have the option to edit the extension code and add this driver and connection string (making the extension unsupported), or get in touch with us (extensions team) for a paid engagement where we can add that support for you. You can get in touch with us via your account manager

----------------
337.2:

Thanks @david_lopes 

	The true delight is in the finding out rather than in the knowing.


----------------
337.3:

Hi @DanielS, I know of one case where they successfully connected to MariaDB using the standard MySQL option. Instead of using jdbc:mariadb://localhost:3306/mydatabase for the connection string (which failed, by the way), they tried jdbc:mysql://localhost:3306/mydatabase and it worked.It's worth a shot, but if it fails, pick an option that David suggested 

----------------
338:

Hi community, how are you, have you encountered the error in the following screenshot, Dynatrace actively throws an exception, at the moment I can't assess if it will have an impact on my application, to add: my version of the probe is 1.267, my cluster version is 1.268
 
 

----------------
338.1:

Hi, I think it may be best to open a ticket with Dynatrace support team.https://support.dynatrace.comRegards,Bradley

----------------
339:

Best Practice how to setup route Problem Alert Notifications to Platform [OS] or Apps Support Team



					
						Solved!
					
					Go to Solution.




----------------
339.1:


Setting up routing for problem alert notifications in Dynatrace to the appropriate Platform or Application Support team is essential for efficient incident management. Here are some best practices for doing this:1. **Understand Your Teams and Escalation Paths:**- Before setting up routing, ensure you have a clear understanding of your organization's support teams, their responsibilities, and the escalation paths for different types of issues. This will help you determine which team should receive which alerts.2. **Custom Alerting Profiles:**- Create custom alerting profiles within Dynatrace based on your teams or applications. For example, you might have an "Application A Support" alerting profile and an "Infrastructure Team" alerting profile.3. **Alerting Rules:**- Configure alerting rules within each alerting profile to define the conditions under which alerts should be triggered. These rules should be specific to the needs of each team or application.4. **Notification Channels:**- Set up notification channels within each alerting profile. Notification channels define how and where alerts are sent. Common notification channels include email, SMS, Slack, and custom webhooks.5. **Integration with Incident Management Tools:**- If your organization uses incident management tools like ServiceNow, JIRA, or PagerDuty, integrate Dynatrace with these tools to automate incident creation and assignment. This ensures that alerts are routed directly to the appropriate support teams.6. **Define Escalation Policies:**- Define escalation policies within your incident management tools or within Dynatrace itself. These policies should outline the steps to take if an alert isn't acknowledged or resolved within a certain timeframe. Escalation may involve notifying higher-level teams or personnel.7. **Team and Role-Based Access Control:**- Implement role-based access control in Dynatrace to restrict access to specific environments, applications, or alerting profiles. This ensures that only the relevant teams have access to the alerts that concern them.8. **Regular Review and Testing:**- Periodically review and test your alerting configurations and routing. Make sure alerts are reaching the right teams and that your escalation policies are effective.9. **Documentation:**- Maintain documentation that clearly outlines the alerting and routing procedures. This documentation should be easily accessible to all team members involved in incident management.10. **Training and Onboarding:**- Ensure that team members are properly trained and onboarded regarding the alerting and incident management processes. This includes understanding how to respond to alerts and follow escalation procedures.By following these best practices, you can effectively route problem alert notifications to the appropriate Platform or Application Support teams, improving incident response and resolution times in Dynatrace.

	Dynatrace Professional Certified


----------------
340:

Information about the Synthetic Screenshots: Reference screenshots are taken when the monitor is created or edited, and subsequently, every 24 hours from a random monitoring location.Screenshot retention is based on execution retention. They are considered part of the execution data for the execution when they were taken. The default retention time for screenshots is 35 days, however, it can be less in some Managed Environments depending on their storage settings.Screenshots are captured at the end of each script event, even those without timings.Success (expected) screenshots are only taken on the first execution, so if your monitor is always successful and has no screenshots, it is possibly always on a re-run.You can verify the origin of a screenshot by following these steps:Navigate to the Synthetic dashboard and click on "Analyze executions."Select the specific execution you're interested in from the list.Above the screenshot, you will find a label displaying the date and location, indicating, "Screenshot from <date> in <location>."Click on this link, and you will be instantly directed to the execution where the screenshot was taken or attempted to be taken. Example: Troubleshoot: — Both Dynatrace SaaS and Managed (Public and Private Locations):Confirm that the executions are not always re-runs. Go to the Synthetic, click on “Analyze executions”, and in the execution time, select different timings and confirm the “Execution type” is standard (and not re-run) for some of the executions.— Dynatrace SaaS (Private Locations - Stores screenshots in S3):Ensure that the ActiveGate can access the Amazon S3 service.The following domains in the firewall configuration must be allowed:ruxit-synth-screencap.s3-accelerate.amazonaws.com for screenshot storage.ruxit-synth-screencap.s3.amazonaws.com for screenshot access and viewing.— Dynatrace Managed (Public Locations:):Note: Cluster-side screenshot storage is the default for newly created Managed Clusters since version 1.216.Make sure the endpoint below is allowed to receive data on your Cluster ActiveGate: /beacon/synthetic/screenshot/[uuid] - Where uuid is the Environment ID.— Dynatrace SaaS and Managed (Private Locations):How to identify issues in the logs:In the browser_#.log file (/var/tmp/dynatrace/synthetic or %PROGRAMDATA%\dynatrace\synthetic):Look for any errors related to "SCREENSHOT" or "SCREENCAP." These errors are related to taking and storing the screenshots locally on the Virtual User Controller (VUC).In the vuc-browser.log file. (/var/log/dynatrace/synthetic/ or <LOG>/synthetic/log or %PROGRAMDATA%\dynatrace\synthetic\log):Check for "[SCREENCAP]" errors. These errors occur when uploading the images from the VUC to either S3 or the cluster. Known issues/errors: ERROR AwsS3CloudFileManager: [SCREENCAP] Exception caught while uploading file /var/tmp/dynatrace/synthetic/screenshots/ AmazonS3Exception: Forbidden (Service: Amazon S3; Status Code: 403; Error Code: 403 Forbidden…)ERROR AwsS3CloudFileManager: [SCREENCAP] Exception caught while uploading file /var/tmp/dynatrace/synthetic/screenshots/image.jpeg AmazonS3Exception: URLBlockedServers (Service: Amazon S3; Status Code: 403; Error Code: 403 URLBlockedServers)Possible solutions:1 - Proxy needed between the AG and Amazon S3:Add the proxy connection details to the [synthetic] section of the ActiveGate custom.properties file (which are located in the ActiveGate configuration directory)Example:[synthetic]
proxy-server=<proxy between AG and S3>
proxy-port=8080
proxy-user=username
proxy-password=password2 - Proxy not needed:Add "proxy-non-proxy-hosts" to specify a list of hosts that require communication without proxy.More information: https://www.dynatrace.com/support/help/shortlink/synthetic-proxy-authentication3 - Need to separate the S3 and Monitor proxy settings:Since release 1.227 you can selectively enable proxy for Monitors or S3, by adding the following flags to VUC user.properties (default path /var/lib/dynatrace/synthetic/config/user.propertiescom.vuc.proxy.s3.enabled=false
com.vuc.proxy.monitor.enabled=trueRestart vuc.service/ Dynatrace Synthetic service after this update.ERROR AwsS3CloudFileManager: [SCREENCAP] Exception caught while uploading file /var/tmp/dynatrace/synthetic/screenshots/ SunCertPathBuilderException: unable to find valid certification path to requested target.- It usually means that there is a certificate issue when ActiveGate is trying to connect to Dynatrace.Possible solution:You will probably need to add the certificate to truststore. Here you can find the documentation with more information.ERROR AwsS3CloudFileManager: [SCREENCAP] Exception caught while uploading file C:\\ProgramData\\dynatrace\\synthetic\\temp\\synthetic\\screenshots\\image.jpeg to S3 bucket... Proxy Authentication Required (Service: Amazon S3; Status Code: 407; Error Code: 407 Proxy Authentication Required; Request ID: null; S3 Extended Request ID: null; Proxy: <yourproxy>)- Proxy credentials are needed.Possible solution:You will have to add the following details to the [synthetic] section of the custom.properties file (which are located in the ActiveGate configuration directory)Example:proxy-user=username
proxy-password=passwordAfter saving it, the proxy password will be encrypted. You can then restart the Dynatrace Gateway and Dynatrace Synthetic services.

----------------
340.1:

Thank you for sharing this @Dyna_Patrick 

----------------
341:

Thought this would be easy 
Currently combining 4 Dynatrace environments (1 for each of our AWS estatesDEV->UAT->STG->PRD), into 1 environment, then using MZ to split the data.
I created 4 MZ rules, and used the AWS account ID to split the data, but this is not reflected in Services / Traces etc.? I would of thought that logically a service running on ECS would just be connected without any hassle? But none of my services show when I select a MZ - so it seems I also need to tag these as well.
Can I tag at our activegateway? Or use the gateway id as a way to split data into MZ?
Frustrated, should be easy

----------------
341.1:

Hello @Mat-Moo you can use entity selector to tags your services running on AWS, in my case type(SERVICE),fromRelationships.runsOn(type(AWS_LAMBDA_FUNCTION),fromRelationships.isAccessibleBy(type(AWS_CREDENTIALS),awsAccountId("XXxxXxxxxXXXX")))  

	The true delight is in the finding out rather than in the knowing.


----------------
341.2:

Thanks, it kinda makes sense, but I'm still not there. I'm using ECS Fargate on AWS, [API requests] if I get the ECS service entityId, I can see a link to the Host, and the host should give me the ability to check AWS accountID? Could I use the activegatewayId as the MZ definer? Be nice to have an easier way to explore relationships etc. except via api post request 

----------------
341.3:

If you are using Fargate, I wrote the following article. It would be easy to separate in host groups and later assign host and services to MZ. I'm doing that. AFAIK you can't use AG id.

	The true delight is in the finding out rather than in the knowing.


----------------
341.4:

We deploy the same container over all the AWS estates, do adding to the container doesn't make sense to me?Your original reply makes sense, I'm just struggling with the syntax - If I understand this, I need to follow the tree, Service -> Host -> account id, I don't use lambda but I can see that the fromRelationships connects to a HOST, so I thought i could do something liketype(SERVICE),fromRelationships.runsOn(type(HOST),fromRelationships.isAccessibleBy(type(AWS_CREDENTIALS),awsAccountId("XXxxXxxxxXXXX")))

----------------
341.5:

@Mat-Mooyou need to query the entities API to have all valid relationships but based on what you say:type(SERVICE),fromRelationships.runsOnHost(type(HOST),fromRelationships.runsOn(type(EC2_INSTANCE),fromRelationships.isAccessibleBy(type(AWS_CREDENTIALS),awsAccountId("XXxxXxxxxXXXX")))) Hope it helps!!!

	The true delight is in the finding out rather than in the knowing.


----------------
341.6:

All starting to click, but so close but so far. When I use the above and do preview I get no matching entities. Looking at my API responses, runsonHost is good, but then runsOn(type(EC2_INSTANCE) - nothing I can see in the api responses. In fact the fromRelationships only contains a single item. which is a RELATIONAL_DATABASE_SERVICE.The service is linked to a PROCESS_GROUP which has the AWS_CLUSTER name, I'm wondering if I can use that property metadata to link instead? but this is where my entity selector syntax lets me down - type(SERVICE)->fromRelationship(PROCESS_GROUP)->isAccessableBy(typeAWS_Credentials),awsAccountID("XXX"))Thanks for help so far btw

----------------
341.7:

Hi @Mat-Moo under {{baseUrl}}/entityTypes?pageSize=500 you can see the relations. But may be this approach is better. type(SERVICE),fromRelationships.runsOn(type(PROCESS_GROUP),metadata("AWS_ECS_CLUSTER:arnecs:us-west-2:XXXXXXXxxxXXXXXxxXX"))  

	The true delight is in the finding out rather than in the knowing.


----------------
341.8:

I've just realised the ARN includes the AWS account id, so it could be as simple as type(SERVICE),fromRelationships.runsOn(type(PROCESS_GROUP),metadata("AWS_ECS_CLUSTER:*XXX*")) - but now I can't figure out the wildcard selection (Not sure it's possible) - or even metadata.startsWith("AWS_ECS_CLUSTER:xxxx"))

----------------
341.9:

Unluckily it isn't possible to use Wildcards at that level.

	The true delight is in the finding out rather than in the knowing.


----------------
341.10:

BTW your last answer is almost perfect, but with 20+ clusternames, would be hard to maintain, hence the wildcard

----------------
341.11:

type(SERVICE),fromRelationships.runsOnHost(type(HOST),fromRelationships.isNetworkClientOfHost(type(RELATIONAL_DATABASE_SERVICE),fromRelationships.isAccessibleBy(type(AWS_CREDENTIALS),awsAccountId("XXXXX"))))Bit messy but works - I have some services that use non-relational DB's though so need to look at those now as well. In the meantime, looking at the one-agent see if I can inject a tag to make life easier

----------------
342:

Hi dear community,
 
After happy implementation of custom integration for Problems notifications  to our legacy incident managemement system with no webhook we are facing following problem:
 
After problem is reopenend (so, new event are merged to existing problem), our webhook is triggered (again) causing reperative creation of incidents.
 
We've set up problem notification exclusivelly not to be triggered if new events are merged, but seems like reopening the problem is not being covered with it...  
 
Anybody here with same problem? 
Anybody here who solved it?
 
Regards,
Ingrida



					
						Solved!
					
					Go to Solution.




----------------
342.1:

When you are creating a custom integration with webhook you have a few options, one of which is not to alert if the problem occurs again, which is probably what is happening in your environment. I recommend disabling it to avoid this barrage of notifications  

	Dynatrace Professional Certified


----------------
342.2:

Hi @natanael_mendes ,Thanks for replay and proposal.Actually this is how we set it up:... "webHookNotification": {      "acceptAnyCertificate": true,      "notifyEventMergesEnabled": false,      "notifyClosedProblems": false,  ...Still not working   

----------------
342.3:


I got an advice from DT Support to open RFE for it as "it works as designed". Hence: Ability todisable WEbhook activation in case of reopening of the Problem - Dynatrace Community

----------------
343:

What does it mean for field Actions and field Errors in the following user action analysis?  



					
						Solved!
					
					Go to Solution.




----------------
343.1:


Hi,Action means how many actions of a certain type you have per minute on your application. (For example, there are 1.63 shares of /Journey per minute.)Errors means how many JS errors you have per minute for that action per minute.You can find more details here: https://www.dynatrace.com/support/help/platform-modules/digital-experience/rum-concepts/user-actionsRadek

	Have a nice day!


----------------
343.2:


Totally with @radek_jasinski but I think the number of errors is referring to all types of errors, so that would be request, JavaScript and custom errors for user actions. Good example is this one: In the list it has 1.87 errors per minute. If I go to the user action overview, it gives me the same amount of error per minutes but the graph shows that these errors are almost exclusively request errors. And this means the number is also equal to the number of CDN errors, 3rd party errors and 1st party errors combined    

	A Dynatrace Professional nerd working for Eviden


----------------
343.3:

@marina_pollehn thank you for expanding my answer 

	Have a nice day!


----------------
344:

Hello,
My question is about relative and absolute JavaScript URLs. We have a website monitored by OA, and it has automatic injection that works perfectly. However, there is an issue when the site uses a login page hosted outside our domain, and the client is redirected to perform the login and then returns to our site. On the redirection page (the one without our agent), we encounter a 404 error with the Dynatrace JavaScript files, and the URL for downloading them is changed to that redirected site, most likely because it's relative. So, my question is, can we ensure that the JavaScript files are downloaded with absolute URLs?   any suggestion to approach that scenario ?   

----------------
344.1:

Hi @Saharnir,I'm trying to understand the scenario, but I think you can go to the application's advanced setup and specify the source path for loading the JS. also, you can Specify the path where the JavaScript tag should send monitoring data, such as adding the activegate as endpoint

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
344.2:

Site 1: amazon.com - OA is installed, and JavaScript downloads are working perfectly. You can observe the URLs like https://amazon.com/ruxitagent......js However, after a few seconds, the site redirects you to the login site, mylogin.amazon.com, which doesn't have OA installed as it's an IDM service. Due to this automatic redirection, you can notice that the URL for downloading the JavaScript has changed. It now appears as mylogin.amazon.com/ruxitagent......js, and this change is a result of using relative URLs.After completing the login process, the customer is redirected back to the initial site, amazon.com. I hope this explanation clarifies the situation.  

----------------
345:

Possibility of creating a maintenance window in the response time metrics. To avoid nightly server restarts

----------------
345.1:

@jmmatia1 I don't quite understand what you would like to achieve:) Maybe describe your issue in more detail?Radek

	Have a nice day!


----------------
345.2:

Just as there are metrics that exclude maintenance windows:Availability rate - excl. maintenance windows (by location) [browser monitor].I would like to be able to configure a VM to exclude response time (performance) metrics from maintenance windows when there are server reboots

----------------
345.3:

Unfortunately, there is no option in the Maintenance Windows settings that you are looking for. This can be set at the host (or group host) or process (or group process) level. Alternatively, try to narrow the area with tags, but only to the level of a single process.

	Have a nice day!


----------------
345.4:

I believe you can achieve that by using tags, please check the below document for that.https://www.dynatrace.com/support/help/shortlink/maintenance-window-define#scope 

	Dynatrace Certified Professional - Dynatrace Partner - Yourcompass.ca


----------------
345.5:

Yes, but he will not narrow down to a specific metric (Response Time) - as I wrote

	Have a nice day!


----------------
