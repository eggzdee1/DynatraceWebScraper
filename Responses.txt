1.1:

Am I going down the wrong path for the query key. Rather than querying by Kubernetes namespace, should I stick to tag?Thinking about it, maybe tag is a wiser choice since services can span both cloud and non-cloud applications.

----------------
2.1:


Uggh, figured it out... For anyone that stumbles across this, it's really weird.Apparently there are two ways of filtering timeseries data in DQL:in and lookup. in has better performance, but you're restricted to use whatever fields are part of the timeseries command output, which are just the metric, the timestamps, and the entityID of whatever you're querying.  No name data or anything like that (which honestly makes it kind of useless... Who wants to display metric data with Entity ID's?  People want readable names...)lookup doesn't perform as well, but, you can add in any fields you want to be fed to the output, so you aren't stuck with just the entity id.  This is what I ended up with (this query returns the average CPU of all hosts in a specific management zone, grouped by the host groups):timeseries usage=avg(dt.host.cpu.usage), by:{dt.entity.host}
| lookup [fetch dt.entity.host
| fieldsAdd hostGroupName, managementZones],lookupField:id , sourceField:dt.entity.host
| filter matchesValue(lookup.managementZones ,"Zone 1")
| summarize AvgCpu = avg(arrayMax(usage)), by:{lookup.hostGroupName}    Now I just need to add some time filters to the query and figure out how to get it to work in an API call and I can finally be done with what should have been an incredibly simple task...

----------------
3.1:

Hi,What type of problem do you mean?R.

	Have a nice day!


----------------
4.1:

If you need a host to have both the tags TYPE:Oracle Database Server and Capability:Global Money Transfer, then you can merge your filters in step 4 and 5 with an and as you suggest in the following way::filter(and(in("dt.entity.host", entitySelector("type(~"HOST~"),tag(~"TYPE:Oracle Database Server~")")),in("dt.entity.host", entitySelector("type(~"HOST~"),tag(~"Capability:Global Money Transfer~")"))))If you need hosts that have any of the tags, then you can just do::filter(in("dt.entity.host", entitySelector("type(~"HOST~"),tag(~"TYPE:Oracle Database Server~",~"Capability:Global Money Transfer~")")))Hopefully this helps.

----------------
4.2:

Hey Victor,Thanks for replying. I guess the Victors stay together. LoLI have tried the query with the AND operator, but for some reason, it doesn't return any data. I ended up using Dynamic Filters for the Capability, since the value would be universal for all tiles in the Dashboard, so I don't need the filter in the query themselves.But I appreciate you taking the time to help out.

----------------
5.1:

Hi Stephen - DQL is only used for querying logs and events with Grail: DQL Documentation.
 
For the metric selector, metric queries are handled differently, and do not use DQL. I'd recommend checking out the Data Explorer Advanced Mode to get a better idea of how metric queries are handled.
 
 

----------------
5.2:

I don't think that's true Chris, at least not anymore.  DQL can query metrics via the timeseries command:DQL commands | Dynatrace Docs

----------------
5.3:


Hello @StephenLHChan,With the rollout of the latest Dynatrace, the DQL can also query metrics. Here you can find the documentation article with the list of all metrics supported by Grail:Built-in metrics on Grail 

	If you have any questions about the Community, you can contact me at maciej.neumann@dynatrace.com


----------------
5.4:

Hello @MaciejNeumann A question about calculated metrics.., is there a way to query them? thanks!Jose A

----------------
5.5:

Hello @JAR1 , calculated service metrics (metrics starting with calc:service) are not yet available on Grail.
@StephenLHChan , the Grail metric key is dt.host.cpu.load15m and documentation for querying metrics in DQL can be found here

----------------
5.6:

Do you know when this will be available?  We are looking to do a workflow that has logic like:If calc:service_metric1 + calc:service_metric2 > 20 Then Enable Alerting Profile via api xIf not Disable Alerting Profile via api xIs this possible since these are Calc:service metrics?  If not when is this functionality expected? 

----------------
5.7:

So is there a way to use DQL in API queries?  So far in all the docs, I don't see any mention of using DQL commands and queries in the API, only in the new web console.  Is this coming down the pipe? I ask because I find the Dynatrace API extremely complex and very limiting compared to many other API's I've used for similar tools. However, if we could use DQL queries in our API calls that would pretty much solve all of the issues I have with the Dynatrace API and make it extremely powerful.

----------------
5.8:

Yes there is.It's not that easy to find the documentation for it.Endpoint: /storage/query/v1I use this endpoint to fetch metrics data.

----------------
6.1:


Hi @srpuvvala If you have it within a single DT cluster then you can move license allocations between environments. Otherwise, contact Dynatrace (preferably the licensing department via a ticket in support)Radek

	Have a nice day!


----------------
7.1:

Hey,I assume you instrument your app with the Dynatrace Android Gradle plugin, because user actions like "Touch on ImageView" are only generated when auto-instrumentation (via the plugin) is enabled. You can verify this assumption by looking at the build.gradle files and check if the snippets from this page were added.The linked setting "withActivityMonitoring" only deactivate monitoring for activity lifecycle events. Only the action "Loading SmartphoneHomeActivity" falls into this category. The other actions are generated by the different auto-instrumentation features of the Dynatrace Android Gradle plugin.The Dynatrace Android Gradle plugin allows users to deactivate all auto-instrumentation features via the plugin DSL. When you want to deactivate ALL auto-instrumentation features, then Dynatrace recommends to remove the plugin snippets from your build.gradle files and instead use standalone-manual instrumentation, because the plugin affects the build time of non-incremental builds.When the standalone-manual instrumentation is used, only two monitoring features are enabled by default: crash reporting and activity lifecycle monitoring. You can deactivate both features via the configuration builder (see JavaDoc)

----------------
7.2:

Hi,thank you for your meaningful answer. I double-checked but it does not seem we are using the plugin. We did not see any code snippet that you mentioned...We have simply added this: dependencies {    implementation("com.dynatrace.agent:agent-android:8.273.1.1003") in the build.gradle.kts fileAnd then start the monitoring using this guide:https://www.dynatrace.com/support/help/platform-modules/digital-experience/mobile-applications/instrument-android-app/instrumentation-via-oneagent-sdk/oneagent-sdk-for-android#start-oneagentDo you have any other clue?Thanks a lot,Andrea

----------------
7.3:

User action monitoring is only available with auto-instrumentation or by manually generating "Touch on <component>" user actions. Based on the user actions names, I would assume that these actions are generated by auto-instrumentation. Because of the flexibility of Gradle, there are several other possibilities how the Dynatrace Android Gradle plugin could be added to the Android build.We would have to take a look at the monitoring data or the agent debug logs to determine who generated these user actions. Therefore I recommend to create a support ticket, where you can privately share details about your app and Dynatrace can assist you in troubleshooting this problem.

----------------
8.1:

Hi @veranikabarel!From the error you're getting, I suspect that you're utilizing the "Run Javascript" action to read/write AppState. Unfortunately, it won't work, as the State API requires app context (its ID, to be precise) to work, whereas "Run Javascript" is an ad-hoc action with no app context (ID).To make it work, you would need an app function. Also, you can find more details about the State SDK client in the documentation.Please let me know if I can help you further.

Senior Software Engineer @ Dynatrace


----------------
9.1:


Hello @henk_stobbe As I know from my experience (I have several cases) it is not possible.If you have Dynatrace features (sensors) (parts of OneAgent) that instruments some endpoint classess/methods you can only switch it OFF or ON.For this cases Support highly recommended use OneAgent SDK and instrument only methods that have value for Customer team. Anyway, if this behavior has changed, I will be happy to see that I am wrong Also, btw, from a research perspective, you can reach the support. They have all the tools to determine what happens during the instrumentation process. Regards, Alex Romanenkov

	DT_NGINX_ALL_WHITELISTED=1


----------------
9.2:

Hi Alex,Maybe in a furure release! Look below at the time, is is a bug or can we time travel (-; Thanks Henk

----------------
9.3:

Looks like my fault, I've changed the message 100500 times.

	DT_NGINX_ALL_WHITELISTED=1


----------------
10.1:

Hi @uzahid,It is not possible.When you have already choosen your metrics and try to change the vizualization you can see an information about if you chose that vizualization there will be limitation eg. only one matric vizualization is possible.Based on the documnetation:"By default, this visualization shows the first metric of a multi-metric query."https://www.dynatrace.com/support/help/shortlink/visualization-honeycomb#change-metric-selection I hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
10.2:

@Mizső is correct, just keep in mind, the older, original out of the box honeycombs take in multiple metrics. For example the honeycomb of host health and service health. That provides all infrastructure level metrics in a Green/Red Fashion honeycomb which you could leverage depending on your metric scope. Anything outside of that metric scope for the out of the box, original honeycomb, you are left with the data explorer result. 

	-Chad


----------------
11.1:

Unfortunately, we do not support that currently. In case that happens, you need to reinstall a node so the new network configuration is applied across all cluster nodes. 

	Senior Product Manager, Dynatrace Managed expert


----------------
11.2:


Here are the instructions to 'fix' a node that lives on a box with a change in IP:
 

Change directory to the directory containing the Dynatrace Managed install (i.e., /opt/dynatrace-managed)cd /opt/dynatrace-managed/
Run this command to find all files with the 'old' IP address (replace <OLD_IP_ADDRESS> with the old IP address, like 192.168.137.150)find . -type f -exec grep -H <OLD_IP_ADDRESS> {} \;
You should see an output.
Run this command to replace the old IP with the new (make sure this time it's STATIC) IP address:find ./ -type f -exec sed -i 's/<OLD_IP_ADDRESS>/<NEW_IP_ADDRESS>/' {} \;
For example, if the intentions is to change the node's IP from 192.168.137.150 to 192.168.1.127, the command would look like this:find ./ -type f -exec sed -i s/192.168.137.150/192.168.1.127/' {} \;
Once the command is done executing, verify it was successful by using the original search command with the new IP:find . -type f -exec -H <NEW_IP_ADDRESS> {} \;
Again, replacing <NEW_IP_ADDRESS> with your new IP, e.g., 192.168.1.127
Start the node using the /opt/dynatrace-managed/launcher/dynatrace.sh script


----------------
11.3:

Have you verified it works? There might be also some database changes required.

	Senior Product Manager, Dynatrace Managed expert


----------------
11.4:

Hello @Radoslaw S. and @Kia F.I've just did this, and it worked.Do you think there could be any repercussion?Best regards.

----------------
11.5:

It is worked with me as well. 

----------------
11.6:

Hey,I will share my experiences with following these steps in case there is somebody out there about to do these changes.While Dynatrace server was functional with the new IP address, I encountered issues with update and installer packages. It seems like the old IP address might be hard coded into the packages, which caused issues with Dynatrace updates.I got the following error after automatic Managed update attempts:Cannot check Elasticsearch indices on Dynatrace cluster nodes. Error: Failed to send GET request to http://<Old IP address>:9200/_all/_settings/index.version.createdI then decided to install another cluster node in the new network alongside the old one as an intended workaround to get the updates working. When running the Managed installer on the new node, I got another timeout caused by a request to the old IP address that was no longer in use, failing the installation.I did not want to go through checking and/or modifying the installer packages in case the IP was hard coded in them. I ended up running the script above again with IP addresses in reverse and moving the original node back to the old network, then opening the required ports between the two nodes that were now in different networks. This restored the functionality of Managed updates and installations.While Managed server was functional after running the commands above, I would still highly recommend doing the network switch the supported way to get the latest updates and being able to install more cluster nodes.Br,Lauri

----------------
12.1:

Hi @Bert_VanderHeyd ,you can use a more specific entitySelector in your metric query to get the calling PGIs of the PGI (for my example PROCESS_GROUP_INSTANCE-19A05BD896B3AD67) you want to check e.g.: type(process_group_instance),fromRelationships.isNetworkClientOf(entityId(PROCESS_GROUP_INSTANCE-19A05BD896B3AD67))The :parents suffix will as well give you the host where the calling PGIs come form.So your complete query could look like thisbuiltin:tech.generic.network.traffic.trafficIn:filter(and(or(in(
"dt.entity.process_group_instance",
entitySelector("type(process_group_instance),fromRelationships.isNetworkClientOf(entityId(PROCESS_GROUP_INSTANCE-19A05BD896B3AD67))")
)))):splitBy("dt.entity.process_group_instance"):sort(value(auto,descending)):limit(20):parentsHope this helps.BR,Mark 

----------------
13.1:

Hi @DStocklandyou can filter through the events for this information. using the API you can determine the timeframe and the entity it happened on"events": [
    {
      "eventId": "6798745626705320663_1696483060541",
      "startTime": 1696483060266,
      "endTime": 1696483064123,
      "eventType": "PROCESS_RESTART",
      "title": "Process restart",
      "entityId": {
        "entityId": {
          "id": "PROCESS_GROUP_INSTANCE-04FB78E5D361DA42",
          "type": "PROCESS_GROUP_INSTANCE"
        },
        "name": "IIS app pool .NET v4.5 Classic"
      },
...For each instance count them up and you have your result.BR,Mark

----------------
14.1:

Hi @beigert ,
Can you add this in your module name resolution config (jest.config.ts):
  moduleNameMapper: {
    "^@dynatrace/strato-design-tokens/(.*)$": "<rootDir>/node_modules/@dynatrace/strato-design-tokens/$1",
    "^@dynatrace/strato-design-tokens$": "<rootDir>/node_modules/@dynatrace/strato-design-tokens",
  },
and check if this fixes your problem?
 
Best,Sini
 

----------------
14.2:


it helps a little bit: tests that don't import anything from `strato-components-preview` works. However rest of them fail with the same error:```FAIL src/app/components/BuildsOverTimeContainer.spec.tsx● Test suite failed to runJest encountered an unexpected tokenJest failed to parse a file. This happens e.g. when your code or its dependencies use non-standard JavaScript syntax, or when Jest is not configured to support such syntax.Out of the box Jest supports Babel, which will be used to transform your files into valid JS based on your Babel configuration.By default "node_modules" folder is ignored by transformers.Here's what you can do:• If you are trying to use ECMAScript Modules, see https://jestjs.io/docs/ecmascript-modules for how to enable it.• If you are trying to use TypeScript, see https://jestjs.io/docs/getting-started#using-typescript• To have some of your "node_modules" files transformed, you can specify a custom "transformIgnorePatterns" in your config.• If you need a custom transformation specify a "transform" option in your config.• If you simply want to mock your non-JS modules (e.g. binary assets) you can stub them out with the "moduleNameMapper" config option.You'll find more details and examples of these config options in the docs:https://jestjs.io/docs/configurationFor information about custom transformations, see:https://jestjs.io/docs/code-transformationDetails:/Users/przemyslawbeigert/code/dynatrace/pipeline-observability-application/node_modules/@dynatrace/strato-components-preview/index.esm.js:2export * from "@dynatrace/strato-components-preview/buttons";^^^^^^SyntaxError: Unexpected token 'export'> 1 | import { Flex, Skeleton } from "@dynatrace/strato-components-preview";| ^2 | import { TimeseriesChart } from "@dynatrace/strato-components-preview/charts";3 | import Colors from "@dynatrace/strato-design-tokens/colors";4 | import { InformationIcon } from "@dynatrace/strato-icons";at Runtime.createScriptFromCode (node_modules/jest-runtime/build/index.js:1505:14)at Object.<anonymous> (src/app/components/BuildsOverTimeContainer.tsx:1:1)at Object.<anonymous> (src/app/components/BuildsOverTimeContainer.spec.tsx:10:1)```

----------------
14.3:


@beigert unfortunately I can't help you further. Please create a support ticket in  https://one.dynatrace.com/hc/en-us/requests with a reference to this thread and the error messages. Our developers need to have a detailed look at it.
Thx,Sini

----------------
14.4:

It works, however after clear the cache by `rm -rf node_modules/.cache`. However pls update docs: https://developer.dynatrace.com/develop/testing/unit-tests/

----------------
14.5:

Just synced with the team about this.
this workaround won't be needed anymore with design system version 0.106.2 and design tokens version 0.19.0

----------------
15.1:

Hi @nutsy4sure I guess it depends on. At one of my clients I see a similar situation:My mteric experssion is:builtin:kubernetes.pods:filter(and(eq(pod_phase,Failed))):splitBy("dt.entity.cloud_application"):sort(value(auto,descending)):limit(10)Dashboard filtered for the last 5 minutes (it has not been changed since 9 days becasue nobody cares about the failed pods, they are still there).      I hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
15.2:

Thank you for the reply, but it sounds like you are just confirming my experience. The pods failed and vmware reacted the way it should and spun up a new one. At that point, I dont care about the failed pod. Different circumstances, I might not want it to disappear for investigation purposes, but I want this dashboard to be "real time", and days old failures that vmware long ago recovered from, isnt reflecting the current status. 

----------------
15.3:

Hi @nutsy4sure,It is not VMware, it is kubernetes. And based on the metric expression this is the actual status for the last five minutes: 1 runnning pod and 4 failed pod.You should find another solution. Maybe you could count one of the kubernetes event which refers to the failed pod (with eg. pod name dimension). Then it can be vizualized well. eg. I hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
16.1:

Hi @AmayShah !Are you able to poll the device from the ActiveGate?snmpwalk –v 2c –c yourcommunity yourTargetIP 

	Observability Engineer at Phenisys - Dynatrace Professional


----------------
17.1:

Hi @phmonte,I recommend you that if you find an impediment in the configuration of bizevent for .NET, use the Support portal. The agents will help you with more detail, for example asking for images, logs, and any other file that helps to identify and reproduce your problem. Here, the community will help too, but could be answered in hours or maybe days.https://dt-url.net/lb626l9 

	-César S. - LATAM Solutions Architect


----------------
17.2:

Hi @phmonte,What happens when you enable the configuration of bizevent?Your application is not working? Do the captured events contain empty values on the request body variable?Could you share with us a screenshot of the error you refer to?

	-César S. - LATAM Solutions Architect


----------------
17.3:

Thanks for responding @cesarsaravia The oneagent log file does not save any error or action information other than conventionally.I made a drawing to show what is happening. Remembering that the error only happens with the Request Body, the other options are working correctly. 

----------------
17.4:

Hi @phmonte Did you enable the feature flag of capturing .net bizevents? If yes, do you restarted the Asep.Net application?  

	-César S. - LATAM Solutions Architect


----------------
17.5:

Yes, it is enabled and I tried restarting it again.I tested with other apps (another OneAgent/Webapp) and I have the same problem.   

----------------
17.6:

@phmontedid you got any update on this?I am suspecting I am facing the same issue.

	Site Reliability Engineer @ Kyndryl


----------------
17.7:

So far, no updates @dannemca 

----------------
18.1:

I don think this falls under a RFE. moving it to Q&A @Bill_Demsky can you provide an example of the filter that you are using? I've tested it out on my end and it is functioning as designed. What cluster Version are you on?   

	-Chad


----------------
18.2:

Hi, I do face the similar issue. Can any one has hints to filter out cluster level problems / filter to search problems under cluster . I can get problems if I use at workload levels But I want to see the filter with Cluster level. How many problems under each cluster in problems page.

----------------
18.3:

I'd Suspect that the Cluster Level monitoring isn't completed. Hence why you dont see them in the problems page. You can verify by going to a node and looking to see if the K8 Cluster is listed in the properties. 

	-Chad


----------------
18.4:

Yes. I cloud see the cluster details in a node properties. and I tried with tagging the cluster name as well. But Still i can't see the problems if I filter as Entity : Kubernetes Cluster(KUBERNETER_CLUSTER). It result with 0 problems. 

----------------
18.5:

Make sure that your time frame is wide enough to include a kubernetes problem. What cluster version are you on? In our instance it is working as designed on the most recent cluster version:  If you are at the most recent version of the Cluster then you might want to open up a support case. As a work around for the time being I recommend crating a Auto Tag that provides the value of the K8 Cluster to the related hosts, processes and services. This will then allow you to sort problems by tag being "K8 Cluster:<Value>" 

	-Chad


----------------
19.1:

Hi,Do you know if your tenant is Grail enabled? Or are you going to use Logs Classic?Best regards

	Consultant


----------------
19.2:

I believe that the team set it up with Logs Classic, but if you tell me that it only works with Grail enabled then I can speak with them about the importance of that feature.

----------------
19.3:

Hi,I would try to ingest logs using Log storage configuration (Logs Classic) And you have Log processing examples (Logs Classic).Best regards

	Consultant


----------------
20.1:

Hi @erh_inetum ,What types of problems are you reffering to? For example, anomaly detection for resources have dual thresholds (i.e. Memory usage plus page faults) so a problem won't be raised until both thresholds are met.In case of problems like "failure rate increased", you can make the thresholds more sensitive either globally or for specific services.Regards,E.

----------------
21.1:

One of the first problems I noticed was with basic functionality. There is no way that I can find with the new interface to switch between environments. Links to the community from the new interface result in an error. 

----------------
21.2:

It took me a bit to find it but its hidden behind the profile icon on the bottom left of the page.    its that "latest dynatrace" toggle. 

	HigherEd


----------------
21.3:

Sorry I should have been more clear. I did find how to turn off the latest Dynatrace interface. In the new interface there is no way to switch between multiple Dynatrace tenants. Either need to bookmark the urls or switch to the old interface to find all of our tenants. 

----------------
21.4:

As a partner supporting multiple dynatrace customers with sometimes more environments, we are a heavy user of the switch function. So it's often back to the old UI too until Q3 for this function.

	Kind regards, Frans Stekelenburg                 Certified Dynatrace Associate | measure.works, Dynatrace Partner


----------------
21.5:


Hi Mike! The "environment switcher" is planned to be available in the third calendar quarter. Our current concept includes indicating the current environment in the user menu, filtering for all environments users have access to, favoriting of environments to have them show up on top and allowing to switch environments quickly through the search (e.g. CMD/CTRL+K > search for environment > ENTER to open environment)
 
 

----------------
21.6:

Thanks -- this makes sense and I'm glad that it is planned, but it does seem like this is a blocker for some of my organization to easily use the new interface and switch between environments. Will Dynatrace hold off on making this the default interface until this change is made?

----------------
21.7:

While we wait you can create a new notebook and put the links on it:  

	The true delight is in the finding out rather than in the knowing.


----------------
21.8:

Did not find a way to switch between environments 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
21.9:

Amm, yep not straightforward to get use to this latest Dynatrace look and feel 
But just look on this as a menu change from the old vertical menu to a new spread on all over the page menu 
You still able to get to all the "old" entries from the Dynatrace upper left entry  
 
HTH
Yos 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
21.10:

Hi Yos! The general look and feel certainly changes. While that is by design, we're aware that it will take a while to get used to. Just a couple of tips:

The main landing page (accessible through the "Dynatrace" entry) is not actually a menu, but an early version of a fully customizable home screen. Think of it like the desktop on Windows / OSX. It just happens to look like a menu at the moment, because we pre-populated it for everyone accustom to the previously overcrowded left-hand product menu.
The new left-hand menu is the place where the latest Dynatrace already allows for quite some customization. It allows to pin / order your most important apps and will also show all other recently used ones for you to quickly get back to. We pre-populated it with the list of "favorites" from the previous left-hand menu.

PS: Please keep us posted about your early impressions! We'll help to sort out any issues you might face.

----------------
21.11:

Hi @rowinho Since we deal with few SaaS environments, the name of the environment at the top search old UI  is missing in the new UIWithout this search currently we don't know to which environment we are logged to  Old UI: ThanksYos  

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
21.12:

I seem to have to missed the boat on this one, and I can nowhere find an introduction to it (only for the now classic? release). Where can I find the announcement of the new dashboarding and the changes/advantages it entails? Pointer to a release note perhaps?I see the documentation is already updated.Update: OK, so actually interpreting the (Saas) release notes of 1.265, where it is introduced as 'the new Dynatrace'. Dynatrace SaaS release notes version 1.265 | Dynatrace Docs

	Kind regards, Frans Stekelenburg                 Certified Dynatrace Associate | measure.works, Dynatrace Partner


----------------
21.13:

It might take a while until you get your environment(s) converted. 

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
21.14:

Being a "power user" I really find the DQL and "all things grail" extremely powerful, but I have two doubts about adoption:I don't think regular users will be able to use DQL for accessing data without any in-product guidance (wizard helping you build your query) or intensive training. Mainly just for creating a simple dashboard from metrics or logs. FinOps - since you are charged for every DQL query, I find it impossible to plan the licenses even for a short term. Having the license costs under control will be significantly more challenging than before. 

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
21.15:

The FinOps / DQL licensing is a great challenge. I see so many risks, that driving adoption will not be an easy task...

	Antonio Sousa


----------------
21.16:

I completely agree. I understand the concept and vision but keeping costs under control is going to be difficult and will likely hold back adoption in our environment.

----------------
21.17:

A comment on the wizard/guided approach as it relates to the cost comments.

Usage and cost of Grail-related capabilities are shown in the Account Management portal with a drill-down to a prepopulated notebook to provide insights into query usage and the user/app running them. 

 
 
($/usage values are for demo purposes only)

We are also working on features to detect and notify you when higher-than-expected usage is detected on a capability. While this may not directly address the planning aspect of your post, it can help keep costs under control.


----------------
21.18:

Good to know this is at least already addressed at least to some degree. With broader usage more FinOps problems start to appear. @mark_eshelby with Log management / Business events it's clear how the billing works - what about upcoming Metrics on Grail / Traces on Grail?

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
21.19:

I think I saw already somewhere another post, but the Problems and Security counters in the top bar, I miss them too.You can put the Problem app on the sidebar, but we're missing the counter/indicator. RFE: Bring back the live count of problems on the "Problems" app icon in the new Navigation panel - ...

	Kind regards, Frans Stekelenburg                 Certified Dynatrace Associate | measure.works, Dynatrace Partner


----------------
21.20:

I really miss links to API swagger pages, cannot understand why they are gone in latest ui...

	Alanata a.s.


----------------
21.21:

Yeah, I know this new look is still in heavy development, but holy smokes, there is so much that is missing to make this an even close to reasonable replacement for the old look...  Just simple stuff like switching the environment and clicking to the API (as you pointed out) are missing completely...  Not to mention that I really liked having the search box be at the top rather than a clickable link.  Even though it's the same number of clicks, it just felt way better having the search bar at the top of every page...  Not to mention that the results that the old search provided seems far superior to what I'm getting in the new one.

----------------
21.22:

I remember a Dynatrace presentation back in the day 'Dynatrace for AppMon users'.Today was my first experience with the new UI - is there anything like a 'The new Dynatrace UI for Classic UI users' guide available?I predict a big shock for my user base once this eventually gets to us. 

----------------
21.23:

You can now switch between environments :    

	Observability Engineer at Phenisys - Dynatrace Professional


----------------
21.24:

This is helpful, but it would be nice if it included a context menu with the different environments like the old UI has today which is what @rowinho's screenshot above appeared to show. In some cases like this one, the new UI tweaks involve more page loads and clicking around then the old UI which is less than ideal.

----------------
21.25:

Hi community members,I would like to update you on a few topics mentioned in this thread.The Environment switch will be introduced soon and is available for you in CQ4. You can then see your environments if you have access to more than 1 in the user menu and will be on click redirected to the particular one. We will also indicate in which environment a user currently is in.Finding and charting metrics will become much easier with the introduction of our query builder. Accessing data will therefore be much easier for non-power-users and user who are not yet familiar with our DQL. You can expect a first version of this in CQ4 as well.Some were concerned about having the license costs under control. Assigning Dynatrace costs to teams and adding transparency to teams is a key investment area of licensing in upcoming calendar year 2024. This improvements are going to be supported with our newest subscription model “Dynatrace Platform Subscription”.There won’t be a problem indicator integrated into the new UI version anytime soon. However, we’re working on customizable “home” or “launch” pages so that users can set them up individually for their needs. One option for this is to integrate the open problems count and/or system notifications.

----------------
21.26:

We definitely need to have the open problems counter put back the way it was. I'm not sure why that functionality was removed in the first place. It's great to see that no matter where you are in the tenant to keep track of how many open problems we have. 

----------------
21.27:

Has anyone been talking about the new global search feature? I find it doesn't accurately search through all my entities the way the "classic" global search did. It's fairly unusable at this current time. For example, when searching for a simple host by name I will often see the message "no entities found". In the "classic" global search I was able to paste in IP addresses and it would link me to the host it belonged to. It seems the new search feature is not actually searching through the entire tenant the way the "classic" search did, and also doesn't include related links to documentation. Can we at least get the same global searching features that we're used to? 

----------------
21.28:

The new dashboards need to be discussed as well. While it's great to be able to use DQL to drive the tiles, the look and feel of the new tiles is not that great. I would particularly like if they had a more similar look and feel as the old tiles, but driven by DQL instead of Data Explorer. It seems the scaling of the legend in each tile is nonexistent. The legend text appears to stay the same size no matter the size of the tile. We're used to having lots of tiles and data on each dashboard but this limits that capability. We have large screens in our NOC that display our very detailed classic dashboards and our executives are very happy with them. They can easily see all the important metrics around our services/infrastructure at-a-glance. 

----------------
21.29:

One of the things I'm interested in is being able to search directly to particular settings from the search bar. For example, we can go directly to the "request attributes" page in the old tenant by searching for it, but in the new one there is not quite that same level of direct access. 

----------------
21.30:

New left nav panel:  I like the idea of going back to my recent page, however I think this functionality should be reversed. It would work better if, when clicking on the app in the left nav, it did the "relaunch" feature. If I want to go to a recent page, that should be what pops up when I hover over the left nav app. Maybe even store the most recent two or three pages for each app? There also seems to be some apps that don't have a relaunch feature, which has caused me to get stuck in an app before where I had to refresh the entire page to effectively relaunch the app.

----------------
22.1:

Excited but also a bit sad to say goodbye to this shape of the newsletter 

----------------
22.2:

"Next edition will surely include some "wow" factor!" Eager to see the new changes 

----------------
23.1:


Hi Aurelien,
and thank you for the question! We have announced the availability of Grail and Dynatrace Platform on Azure in the first quarter of 2024 in a press release today. GCP follows after Azure, however, there is no timeline I can share with you at the moment. 
Thank you,Milan

----------------
23.2:

Thank you @milansteskal for your feedback.Regards.

	Observability consultant - Dynatrace Associate/Pro/Services certified


----------------
24.1:

As you posted this in the extensions forum I'll answer from an extensions point of view. Containerized ActiveGates are currently not able to run extensions.

----------------
24.2:

I think this doc page may help you:
https://www.dynatrace.com/support/help/shortlink/ag-container-differences#purposes
 

	Senior Product Manager, Dynatrace Managed expert


----------------
25.1:

Hi @beigert,To validate the workflow definition locally in Typescript, you could leverage the Workflow type from the "@dynatrace-sdk/client-automation". We're aware that the typing still isn't perfect, but we're working on it. Please let me know if I can help you further.

Senior Software Engineer @ Dynatrace


----------------
26.1:

Hi Team,Could you please help me on this??Regards,Heramb Sawant

----------------
26.2:

Hi Heramb, 
Yes, we will launch an E-Mail O365 for Workflow action presumably within the next two months, followed by a generic E-Mail Action. I am additionally curious in your use case to create a dashboard with workflows - can you elaborate on this? ThanksAlexander 

----------------
26.3:

Thanks @Alexander_Mohr. On top of a slack message, one of our clients in Israel is also interested in being able to trigger an email via a workflow. Looking forward  

----------------
26.4:

Hi Alexander,We have below 2 use case where we are looking for sending e-mail notification.1. We would like to create workflow that will perform a taske.g. SRG validation. Post this validation I want to send an email to a specific set of people and notify them about SRG results. 2. We have workflow( in future it will be part of jenkins pipeline)  which does some automation task like ingesting events into grail Bizz event and  followed by creating or updating (using document service) existing dashboard tiles with data  fetch from grail. Next step will be sharing this dashboard URL to appropriate audience through email with some custom message. Regards,Heramb sawant  

----------------
27.1:

I love that you are doing this

	Dynatrace Certified Professional


----------------
27.2:

thanks!!!

	Dynatrace Professional Certified


----------------
27.3:

Thanks for sharing this 

	-Chad


----------------
27.4:

Excellent idea to see what is coming!

	Antonio Sousa


----------------
27.5:

Good to know:) thank you

	Have a nice day!


----------------
27.6:

Very good! thanks much. 

----------------
28.1:

Such an inspiring story!  Thanks a lot for sharing, Marina! 
Congratulations on becoming our Community Member of the Month! 
PS. I had a similar dilemma when I was graduating from high school  I was very much into European Union and I love history! But in the end, I decided to take the final exams in mathematics and physics - then chose the Technical University in Gdansk where I graduated from Computer Science 

----------------
28.2:

Super @marina_pollehn ! proud to have you in my team!

----------------
28.3:

Congrats @marina_pollehn  and well deserved! You're a valued team member supporting customers worldwide, spreading the added value of observability powered by Dynatrace. Keep up the good work!

----------------
28.4:

Congrats @marina_pollehn ! Way to go! Awesome story!

----------------
28.5:

Super! Congrats Great story:)

----------------
28.6:

Congrats

----------------
28.7:

Such an inspiring story, I need to give some credit to these amazing pictures - the first one reminds me of my first flight to the Nederlands, that's the exact view that welcomed me right ahead of landing! 

----------------
28.8:

Hi @marina_pollehn,Congrats!!! Thanks for your contribution to the Community.Best regards, Mizső

----------------
28.9:

Thanks everyone for the nice comments  

----------------
28.10:

Well Deserved @marina_pollehn !!!! Thank you for your contribution to the community.

----------------
28.11:

Congratulations Marina!!  

----------------
28.12:

Congrats @marina_pollehn ,"When answering a question, you often need to do some testing on your own or you need to research until you finally find the solution you had hoped for. This keeps me curious and up-to-date." -> This is clearly something I have noticed in your replies, some of them to my own questions  Thanks so much for this posture!BTW, the dancers are back  one more Salsa dancer in the Dynatrace Community...

----------------
28.13:

Congrats @marina_pollehn 

----------------
28.14:

Congrats, @marina_pollehn !!! I knew that you will be here soon or later!!And @AgataWlodarczyk , we should create a book with all those inspiring histories from this "Member of the Month" section.

----------------
28.15:

@marina_pollehn Congrats!!!

----------------
29.1:


Yes, is possible.Look this    Documentation pagehttps://www.dynatrace.com/support/help/platform/davis-ai/anomaly-detection/metric-events

	Dynatrace Professional Certified


----------------
30.1:

That's intended, only important and recognized technologies are shown under "Technologies and processes", you will notice all Dynatrace processes and any processes of unknown technology will not show up there and you will need to find them through the host screens.

----------------
31.1:


JMX is excluded from the certificate requirement, it just needs to exist on the Dynatrace cluster. I'll ask for the documentation to be updated.

----------------
31.2:

@Mike_L  thank you!

----------------
32.1:


Seems like the MBean you're capturing is for the connector itself, which can only have the values for running, paused or stopped. If you're expecting to see failed, it might mean you actually want to capture a task's status instead of the connector itself, so maybe something like this is what you're looking for:        - subgroup: Connect.ConnectorMetrics
          query: kafka.connect:type=connector-metrics,connector=*,task=*
          featureSet: connect-metrics
          dimensions:
            - key: connector
              value: property:connector
            - key: task
              value: property:task
            - key: status
              value: attribute:status
          metrics:
            - key: kafka.connector.task.status
              value: const:1
              type: gauge Source: https://docs.confluent.io/platform/current/connect/monitoring.html#connector-metrics

----------------
32.2:

Good catch here! I have added this in but our count is still not matching up with Kafka shows. Do you know if the status metric is 'exposed' only once when the status is changed?Our thought process was that we may have tasks that have been in a failed state for a period time before the extension started collecting the metric. We are trying to do some testing here to get more info.

----------------
32.3:

As per the documentation, it should be the current state, so there's definitely a difference between how the MBean exposed metric is being counted and how your Kafka console is counting it. Difficult to troubleshoot further.

----------------
32.4:

So, I found that the status metric in dynatrace is only updated after I push a newer version of the extension. The change is not relevant, I simply update the version to allow for it to be uploaded. Once I apply the new version to the monitoring configuration I can then see something such as the below in the logs. After a minute or so of 'installing' the newer version then I see that updated status in dynatrace.Ever seen something like this or know what could be causing this? Below is the yaml I have so far.2023-09-27 14:14:02.599 UTC [003b195f] info [java ] [metrics ] Uninstalling monitoring config of JMX extension 'custom:kafka.jmx.misc.metrics' (version 1.0.2)2023-09-27 14:14:03.600 UTC [003b195f] info [java ] [metrics ] Installing monitoring config of JMX extension 'custom:kafka.jmx.misc.metrics' (version 1.0.3) 

----------------
32.5:

The logs are completely normal, it's just telling you it's going to download and use the new version since you updated it. What exactly do you see in Dynatrace, that you feel only gets updated when you upload a new version? Consider that with the above definition, the metric's value is always 1 and only the status attribute changes over time. Also, consider checking the configured frequency, if any, as it might just capture the metric every X minutes and you might not be giving it enough time.

----------------
32.6:

I am fine with a value of 1 always showing, I understand why that is occurring. What I don't understand is why the status of the connector task is only updated when I publish a new version of the extension. A datapoint is logged in data explorer every 1 minute but the status is only ever updated when I update the extension.

----------------
32.7:

I think I understand the issue, when you set the value to const:1, the JMX Datasource is reading the MBean once and then providing a constant value, including the dimensions, even if the value of the dimension changes.Can you try changing the whole thing to something like this:        - subgroup: Connect.ConnectorMetrics
          query: kafka.connect:type=connector-metrics,connector=*,task=*
          featureSet: connect-metrics
          dimensions:
            - key: connector
              value: property:connector
            - key: task
              value: property:task
            - key: status
              value: attribute:status
          metrics:
            - key: kafka.connector.task.status
              value: 
                attribute: status
                accessor: equals("running")
              type: gaugeThis will give the metric a value of 1 if the status is running or 0 otherwise, and should update every time the value of status changes.

----------------
32.8:

Thank you for continuing to look at this! I have made this change and waiting on the app team to change a connector status to see if this gets picked up.Question, is there a way we can have the extension to always report back the current status? Our use case is alert if the status is not running and if the above changes works then we should be good but taking it a step further it would be good to always get the current status rather than logging a 0 if the status is not running, the task status could be any 1 of the below according to https://docs.confluent.io/platform/current/connect/monitoring.html#common-task-metricsAs a note, we originally were looking at the connector status but the app teams has since come back and wanted to alert if the task status is anything but running.unassigned, running, paused, failed, or destroyed

----------------
32.9:

As an update to my post above, I may have spoken too soon. I am seeing other status' showing in dynatrace now so it looks promising so far. Still waiting on our app team to help me validate things.

----------------
32.10:

I was just typing:If you have the dimensions section in your metric inside the yaml file, just like we can see in my example above, then you will get the current status as a dimension, regardless of the value. It is not the most elegant solution, but you can always create a metric event in Dynatrace for a specific value of a dimension in a metric, so in this case you would need to alert when status = unassigned, when status = paused, when status = failed and when status = destroyed, so a total of 4 metric events for this. Or you can alert when the value is 0 and show the value of the status dimension on the description of the metric event.Seems like you figured it out, but still leaving it here for clarification 

----------------
32.11:

Ok here is where I'm at. For 2 different connectors we switched the status from running to paused. It was tracking correctly in Dynatrace. Whenever it was running we would get a datapoint with value of 1, as expected from what you noted above.What is not working correctly (based off previous comments above) is the status dimension will still show the previous status, it does not get updated unless I upload a new version of the extension. The datapoint value is correct, it will drop to a 0 when it isn't running but it will still show a status of paused (we are testing by switching from paused to running then back to paused).The example below is from when a connector was paused. We started it back up and as noted by the '1' it reflects as running (which was correct) but the status never changed, it only changes after updating a new version of the extension. Here is the yaml. The first query is meant to capture the task status because that is what the use case is for, alert if a task hits failed state. The 2nd query is for the connector status which likely can be removed, i just left it in because we were originally looking at the connector status until the use case changed.  

----------------
32.12:

@victor_balbuena i think until we get this dimension status tracking correctly this is not going to work for us. It's great that we have running connectors showing as 1 but we can't alert if below 1 because below 1 could be from the connector being paused or failed, we only care if the connector is failed.Having the status dimension reflect the true status should allow us to alert for what we need.

----------------
32.13:

I undersand your pain but I'm not a support person, I'm just trying to help you because I happen to know about extensions and JMX  I really thought what I mentioned above could work, because I'm as perplexed as you, I've never seen it happen before in any JMX extension in EF2.0. Maybe there is an underlying bug somewhere here...

----------------
32.14:

No worries @victor_balbuena! I appreciate all the time spent here. I think it is an improvement from what we have but still lacking some. I'm hoping our account reps can help us push this along to get more visibility on this, maybe from the extensions team.

----------------
33.1:

Hello,In order to get that information dashboarded you would have to be able to get a metric to display in data explorer. Please try looking through the kubernetes built in metrics found here, https://www.dynatrace.com/support/help/shortlink/all-metrics#kubernetes.If there is not a metric for "pod uptime" it may have to be a custom metric, or you can post this in the Ideas channel for suggesting the creation of such a metric.

----------------
33.2:

i think that if you use builtin:host.uptime maybe works, but i dont know for sure.You can try create metrics to do this. anyway take a look of this documentation pagehttps://community.dynatrace.com/t5/Container-platforms/Assigning-a-hostgroup-to-an-OpenShift-pod-quo... Feel free to ask if you got any doubts

	Dynatrace Professional Certified


----------------
33.3:

Hi @VENKY1544,AFAIK there is not an OOTB solution. Maybe you can play with Environment APIv2 Monitored entities:GET / entities provide a list of entities with fist seen and last seen attribute, you can filter only for pods by type("CLOUD_APPLICATION_INSTANCE")orGET / entities / {entityId} but in this case you should know the individual entity ids.I hope it helps to start thinking.Best regards,Mizső 

	Certified Dynatrace Professional


----------------
33.4:

hi @VENKY1544 , did any of the comments above help you? You can accept any of them as solutions if they work  

	The only constant is change. Finding ways for great things to happen!


----------------
34.1:

Growing up in Sweden with roots in the northern parts of the country I always loved the flat bread from that part of the country.
My favorite was a filling with vegetables, sausage, potato and mix of cottage cheese, apple and more. Whenever I go back to Sweden to spend time with the family I always make sure that it is on the menu!
 
 
 
Recipe (In Swedish, but google translate should help): https://ugnstrull.se/recept/gourmetrulle-med-steppsallad/

----------------
34.2:

For me it's Sterz, especially "Heidensterz" (buckwheat) with beans, lightly fried in lots of lard served with sour mushroom soup. Sterz would be in a large p0t in the middle, you'd take a spoon full, dunk it into the soup and eat it. Delicious.Recipe here: https://burgenland.orf.at/v2/radio/stories/2891920/

----------------
34.3:

Being a Ukrainian, there's only one type of food I am legally allowed to talk about /jk
Borshch 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
If I feel particularly homesick, this is the only thing to bring me up  But there's no borshch like the one my mom makes, so every time I come home I ask her to cook it. 
Another thing that always makes me nostalgic is poppy seed rolls 
 
It was always on the table in my grandma's house when I came over 

	The only constant is change. Finding ways for great things to happen!


----------------
34.4:

 In portuguese bife com batata frita or steak with fries, my favorite food of all time. Like a real brazilian, this plate are in almost every table  in the houses from Brasil in the sundays   Recipe here: https://www.tudogostoso.com.br/receita/95741-bife-acebolado-com-batata-frita.html

	Dynatrace Professional Certified


----------------
34.5:

This is a risky post! ...now I can't stop thinking about all of these dishes For me, it is the Mediterranean cuisine and specifically the Libyan couscous which can be served with vegetables, meat, chicken or fish!  The picture showing below is Libyan couscous with meat, chickpeas and onion topping. Served with salad on the side called "sharmola" which is made with tomatoes, cucumbers, onion, jalapeno and a little bit of olive oil and a pinch of salt.  

----------------
34.6:

Hi All,It's a specially different, but I will put here some pictures of what my wife prepare everymorning for kids in the LunchBox.Everything is home made (even the CupCakes).It's a little difficult to eat healthy everyday but we try  

	Sharing Knowledge


----------------
34.7:

WOW what a challenge , as @Mo_Azuz  wrote me also can not stop drool after looking ay your photos  For me any thing that include dough is like a red rag But on top of that every thing need to be hot .... very hot !!!Lately we have found at a neighbor garden an Habanero bush  And now we are practicing at home few dishes     

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
34.8:

These revolting, delicious, revolting concoctions were only available for 1 year but they left a lasting impression and we all miss them!  

	Senior Client Services Analyst


----------------
34.9:

It  looks like really different, i really would like to taste it.

	Dynatrace Certified


----------------
34.10:

They had a flavor profile similar to Boston cream pie or Bavarian cream donut.

	Senior Client Services Analyst


----------------
34.11:

Growing up in Hawaii, I've always had different types of Asian cuisine that you normally can't find anywhere else (nor can it be replicated anywhere else for that matter). One of my favorite dishes growing up (and still is, to this day but I can't find anywhere since I've moved) is Ube Pancakes!  It might look a little too sweet, but the flavor is incredibly balanced, considering the main ingredient is purple yam! So I guess that covers the guilt of it being an 'unhealthy' breakfast option, but it's definitely one for the books if you're ever heading to Hawaii!

----------------
34.12:

Hi,Sure is not best food or healthy food, but talking about nostalgic, 90s...  

	Consultant


----------------
34.13:

Sugar watches!  

	Keep calm and build Community!


----------------
34.14:

"Taste from the past"? Seems like I have to go with our ancestors, and the "pastel de nata":

	Antonio Sousa


----------------
34.15:

Grandmother used to prepare yummy "Idli, vada with sambar and chutney"  

	Dynatrace Certified


----------------
34.16:

Had this a couple of weeks ago, with mint sauce, they were awesome.

----------------
34.17:

One of nostalgic recipes that really makes me to remember my childhood in my entire life, and that i reaaly like its called "Feijoada", basically made of cooked black beans and Assorted Meats. Usually it's served with white rice, sautéed collard greens, and sliced oranges on the side.Feijoada is a hearty and flavorful dish that brings a taste of Brazil to the plate.   

	Dynatrace Certified


----------------
34.18:

My favorite taste from the past, without hesitation, the "breton galette" from my grandma !A Breton galette is a traditional flat cake or pancake from the Brittany region of France. It is made primarily from buckwheat flour and is often served with savory fillings such as eggs, cheese, ham, and vegetables.I ate it every wednesday after the school.  

	Observability consultant - Dynatrace Associate/Pro/Services certified


----------------
34.19:

I love it:) i'm already hungry  

	Have a nice day!


----------------
34.20:

When I was growing up, my grandmother (Nana) was an amazing baker. My wife decided to give those recipes a shot and WOW! She could not have matched the taste any better. The cookies with the jam in the middle she called Scandinavian cookies. The loaf is called Mandelbrot. There are many versions of this but she made it with jam, nuts and raisins.    

----------------
34.21:

Strawberry soup is great. Every summer my mother used to cook this soup for me, but with noodles and mint leaves

	Have a nice day!


----------------
34.22:

I'm the biggest fan of homemade craft pizzas. I could cook and eat them every day, but only if I know that my dish is healthy. I make pizza on spelt dough with lots of vegetables and natural sauces. That's why I don't order pizzas to go. My wife jokes that I put my pizza dough in all the free food containers in our home. One time, I prepared 15 kg of pizza dough and invited all my neighbors for a month of dinners. They still can't look at the pizza  

	Have a nice day!


----------------
34.23:

It wasn't too long ago that I had this, and actually I wouldn't mind some right about now , but its a very old recipe....Haluski - Slovakia  With a cold glass of Kofola! All in a traditional Slovak setting, such a great experience!  Resturaunt: https://www.syrex.s | https://www.syrex.sk/koliba If you find yourself in that part of Slovakia, you might as well also visit Juraj Janosik:            

	-Chad


----------------
34.24:

Well, for me definitively would be the Mate.  I remember drinking it with my grandma seeing her garden and talking a lot.It is a very popular infusion in South America especially Argentina, Uruguay and Paraguay. Famous People Drinking Mate Obama Hetfield (Metallica) Zoe Zaldana Lionel Messi      

	The true delight is in the finding out rather than in the knowing.


----------------
34.25:

You're missing another famous drinking mate (chimarrão) Danne Aguiar 

	Site Reliability Engineer @ Kyndryl


----------------
34.26:

For me the taste I will never forget is the one of chanterelles fried in butter. I used to collect them very early in the morning after every night fishing trip with my uncle. The last time we went on one together was probably about 10 years ago, but it really feels like it was yesterday whenever I have a chance to eat them... 

----------------
34.27:

Something I'll never forget is the "Meet and spinach cannelloni" from my grandma also as Argentinean the "Family Asados"       

----------------
34.28:

For me there's two word 1. Biriyani "Biryani is a mixed rice dish of South Asia. It is made with spices, vegetables, rice, and usually some type of meat (chicken, goat, lamb, beef). In some cases without any meat, and sometimes with eggs and potatoes." In terms of dishes this is my most favorite as every bite is a mouthful of flavor.  2. Fuchka (aka panipuri) These are both highly known south Asian cuisine. "Panipuri is deep-fried breaded sphere filled with potato, onion, or chickpea. It is a common street food in the Indian subcontinent. It is often spiced with tamarind chutney, chili powder, or chaat masala. A variant, fuchka, uses spiced mashed potatoes as the filling." My childhood evening snack is based on this, since this is street food my family would not always appreciate me eating those but I would secretly meet up with friends after school just to have these.

----------------
34.29:

My mother used to make this dessert when I was a child. Here in Brazil we call it "Sorvete americano" (American Ice cream). It is basically make with milk (condensed, cream), eggs and chocolate. When I grew up and moved away from my parents home, I learned how to make it and at least once per month it is part of my children joy after lunch.

	Site Reliability Engineer @ Kyndryl


----------------
34.30:

How much do we have to bribe you so you'll bring some for us, too?

----------------
34.31:

You will be surprised as how easy is to make it!!First layer: 1 can of condensed milk, use the same can with fresh milk, and 3 eggs yolk.Mix all together in the fire until it get creaming consistence.Second layer: 1 can of milk cream, 1 cam of condensed milk, 6 spoons of cocoa powder (or sugar chocolate).Mix all together in the fire until it get creaming consistence.Wait for the first layer to get cold before drop this one over it. You can use some biscuits as an additional layer, so they don't get mixed.Third layer: mix all the remain 3 eggs white until it gets the whipped cream consistence, then add 3 spoons of suggar, mix a bit, then add 1 can of milk cream and mix, until you get a creaming consistence.Add it over the chocolate layer.Let it rest at the freezer and enjoy!!!

	Site Reliability Engineer @ Kyndryl


----------------
34.32:

Growing up on the East Coast of Canada, in Nova Scotia, seafood played a major role in what we ate. There are two things I stuff myself with whenever I get back for a visit. Fried clams, and my mother's seafood chowder.The seafood chowder has several types of fish like salmon, flounder etc., shrimp, lobster, clams, mussels, scallops potatoes, onion, milk, butter and other herbs and it is delicious.   The clams are taken from the shell and dunked in a thick batter, then deep fried. I like them with ketchup:   

----------------
34.33:

For me it's "Hollerröster" (did not find an english translation) which always takes my back too my childhood. It is mainly cooked from elderberry, some vanilla pudding, spices (cloves, cinnamon) and sometimes also some plums or apples. It still is one of my favorite foods, but hard to get somewhere if you don't cook it on your own. Tastes great on its own or also makes a delicious side for "Kaiserschmarrn".Picture is not from me, just for illustration purpose.  

	iOS help: https://www.dynatrace.com/support/help/shortlink/ios-hub


----------------
34.34:

The nostalgic dish for me is "Naporitan". This is a pasta dish seasoned with tomato ketchup that has been eaten in Japan since the 1950s. It is still served at many restaurants, most convenience stores, and is still made at home.It's strange, but even though it's called Naporitan, I think it's a dish unique to Japan. 

	T.Shirai IIM Corp. Osaka Japan


----------------
34.35:

For me as an Egyptian, it will always be "Koshary"    

	Dynatrace Certified Professional - Dynatrace Partner - Yourcompass.ca


----------------
34.36:

Hello,
as a kid I was in love with (and still I'm in love with) so-called Kiachln or Bauernkrapfn. It's kind of a donut made of yeast dough.The basic variant without sugar on top or without marmalade is the best as it's the pure taste.
I remember that my grandma made 40-50 of them for our family 
 

----------------
34.37:

This reply will be a small love letter to my German grandparents :D. I was very lucky as my grandparents live within 15min walking distance of my parents and I spent many afternoons and weekends (I guess when my parents had enough of me and my sister :D) at their place. My grandpa taught me how to make flour with a small hand mill and my grandma always had the most amazing recipes. If we were very lucky, she brought the ice machine upstairs, and we would make ice cream from frozen fruits, whipped cream and sugar. She also taught us how to make 'Königsberger Klopse', an old Prussian recipe. We usually ate them with potatoes which we mashed on the plate so they would absorb the sauce.  Here is an English recipe of the dish: German Meatballs in Gravy (Konigsberger Klopse) Recipe (thespruceeats.com)For some reason, she also made the best mashed potatoes. Even if I use exactly the same measurements of the ingredients mine simply do not taste the same. Also her 'Quarkbällchen' became famous in the entire neighborhood. I am not allowed to share the recipe here so here is an alternative one in English :D. EASY Donut Hole Recipe (Quarkbällchen) - dirndl kitchen  

	A Dynatrace Professional nerd working for Eviden


----------------
34.38:

From my Spanish side, the "roscos de anís" my mom would make every year: 
 
From my Belgian Side: Friet met stoofvlees, which is a traditional Belgian dish consisting of french fries (friet) served with a hearty beef stew (stoofvlees). The beef stew is typically slow-cooked in a rich, flavorful sauce made with beer, onions, and various spices.
 
 

	WHomES


----------------
34.39:

Hi guys have a look at the multicourse Kashmiri dish Wazwan that every Kashmiri loves to eat. Almost all the dishes are meat-based using lamb or chicken with few vegetarian dishes. It is popular throughout the larger Kashmir region. Wazwan is a revered Kashmiri culinary tradition, renowned for its opulent multi-course feasts prepared on special occasions. It features a sumptuous array of dishes, from aromatic gravies to succulent kebabs, each meticulously crafted by skilled chefs known as "wazas." This gastronomic experience embodies the warmth, culture, and hospitality of the Kashmiri people.   

----------------
34.40:

Brazilian hot dog is my favorite snack! 

----------------
34.41:

In Sao Paulo they even put mash potatoes with it: 
 
It is as odd as the pizzas with peas ( the so called "portuguesa")
 
 

	WHomES


----------------
34.42:

This looks amazing!! Do you have a recipe, maybe? I'd like to try it  

	The only constant is change. Finding ways for great things to happen!


----------------
34.43:

 My wife has a mold to make Oreshki 

----------------
34.44:

For me, I like seafood, but the most important thing that I can't live without is Turkish Coffee. 

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
34.45:

What a risky one, indeed!! And although I also very much support @natanael_mendes ' Bife com Batatas Fritas as a taste from my past too (obviously!), the one that really strikes me as nostalgic is the very typical "Bifinhos com Natas e Cogumelos": "Little Steaks with Cream and Mushrooms".Here in Portugal, this dish is present nearly everywhere as it is very simple, cheap and very very yummi It regularly served with a brutal dose of french fries and rice, so you can dip both in the amazing sauce after finishing the meat To me, besides being something that I eat since I was a small child, it has always been the greatest example of comfort food  

	Best regards, Pedro Deodato


----------------
34.46:

look so good!!!

	Dynatrace Professional Certified


----------------
34.47:

We use to live in Germany/Holland many years ago when I was a kid.  Still remember and love a good Tartare sandwich Does anybody still eat there?  People go crazy in US when they here I use to eat this.  

	Dynatrace Certified Professional


----------------
34.48:

I LOVE a good tartare sandwich! With some pickles and a smidge of whole grain mustard 

	The only constant is change. Finding ways for great things to happen!


----------------
34.49:

We upgraded this sandwich in Belgium and it is called Martino: 
 
So apart from the steak tartare, we put: onions, ketchup, mustard(Dijon),tabasco,gerkins,capers, rucula, salad ( last two not for me).

	WHomES


----------------
34.50:

Wow, so many original, amazing dishes, haven't heard before about nearly half of them - kudos! 
For me, the taste from the past (and fortunately, present as well!) is already mentioned before by @Ana_Kuzmenchuk borscht, but in its white version. The difference is, that the main ingredients aren't beets, but mushrooms, which I love! The mandatory addition to it has to be "uszka" - impossible to translate, but they're similar to ravioli 
 
 White borscht with "uszka"
 
This dish is so special for me, because each year for Christmas Eve my grandma cooks it by herself from scratch, forming hundreds of "uszka" to show her love to us. This is something my family eats only once a year to celebrate the fact that despite living away from each other, we manage to gather around and enjoy grandma's fantastic cuisine together!

----------------
35.1:

Hi @agonzalez, did, you by chance, find the solution to this on your own? I think our Community would really appreciate it if you published it. If not, let's bring this post back up the activity feed so more people could see it and had a chance to help you out  

	The only constant is change. Finding ways for great things to happen!


----------------
36.1:

As always a super session with the news!

	Have a nice day!


----------------
36.2:

This is fantastic to see embedded in the release notes of the new version. This will make it much easier for teams that leverage the tool to be able to understand all the new features.

----------------
37.1:


Hi Ram,I have experienced the same phenomen, the support said:The reason there are some database instances are not returning the detailed data is that they are being called by ComputeNodes, which are not a supported node type. If we take a look at the calling service, which is an IBM Integration Bus, and select the code tab we can see the DB call comes directly from that ComputeNode.IIB ComputeNode uses the ESQL, rather than SQL, which we cannot parse.

	Sharing Knowledge


----------------
37.2:

Hi Malaik,Thanks for the clarification. 

	Ramanan Raghunathan


----------------
38.1:


Hi,We offer a chrome browser extension which you can roll out to your employees. For some office365 apps like Sharepoint you can add our RUM JavaScript snippet in the page template.Please look at:https://www.dynatrace.com/news/blog/real-user-moni...andhttps://www.dynatrace.com/support/help/user-experi...

----------------
38.2:

Hey,Is there a browser extension or similar for edge or IE?Typically these would be used for Office365 apps.

----------------
38.3:

Official browser is IE and we need also other than sharepoint O365 apps monitored.

----------------
38.4:

According to the document, it seems to support Microsoft Edge in the future releases.Future releases will include browser support for Microsoft Edge and Mozilla Firefox. https://www.dynatrace.com/support/help/user-exper...I can not find about IE...

----------------
38.5:

Hi, Is their an alternative for M365 since te browser plugin is getting out of support? regardsKevin

----------------
39.1:


You can go ahead and enable it if you are using java web/app servers for RUM.Documentation is internal and nothing is publicly available. Most of the changes are architectural to solve certain quirks that the older version had and you won't really see any noticeable impact after enabling it Yes you can enable it at the process group levelYou would have to restart the process 

	-Chad


----------------
39.2:

			
				
					
					
						Thank you Chad for your answer
					
				
			
			
				
			
			
				
			
			
			
			
			
			
		
----------------
39.3:


Dear @Chad T.,Dear @Axel V.I have to add to / refute parts of Chads statement!v2 (very bad choice for the name) was maybe initially planned to "improve" or supersede the existing version. However, since v2 is technically different and tries to tackle different cases it should be seen as an alternative approach not an improved version! Hence, if everything works find now and you don't have any class cast exceptions (that's what v2 its build for) then I strongly recommend to stick with the existing version and not enable v2.Heads up here: we will "remove" v2 from the UI in the foreseeable future and only make it available for our support teams to enable it / switch between the approaches if needed. v2 will be an "alternative approach" and therefore a troubleshooting "feature" only. To correctly call it by the name! Pls. let me know if anything is unclearregardsThomasProduct Manager RUM web

----------------
39.4:

Thank you so much Thomas, i appreciate it! 

----------------
39.5:


Dear @Thomas Z., i want to explain my answer. I have an application that run in Webmethods Application server. This Webmethods is officially supported, but RUM injection doesn't work. I opened a ticket to Dynatrace support and they told me that RUM is not supported because this application doesn't use Java Servlet (processes instrumentation is OK). Also, they told me to try ith RUM V2, but there are few chances that it works.So, do you know if RUM V2 might work?Thank you and best regards

----------------
39.6:

Anytime! If I were you, and since "This Webmethods is officially supported" I would push Support to properly troubleshoot this case! If its not because of class cast exception than they have to properly follow it up with development and they have to check whether and how we can fix this. In my humble opinion as simple as that! And please feel free to mention me in the ticket then I can also follow the ticket! thanksThomas

----------------
39.7:

Thank you @Thomas Z.! Support told me that Webmethods are supported for OneAgent instrumentation, but RUM is not supported. This is ad extract from support answer:"First of all there is no official support for RUM for WebMethods Integration Server 0 in other words Dynatrace OneAgent is not able to inject JS library into its HTML pages because these are not Web request services but web services. The documentation only says that OneAngent is able to monitor "Java internals" of this product but not injecting RUM portion.RUM is supported only for "Java servlet-based web applications" and we don't inject RUM into webMethods, as they use something different than servlets and marked as webService which means XML/JSON. Anyway we had once a customer who swiched Java Monitoring to V2 and for WebMethods and it worked well.""if we don't use Servlets than there are small chances RUM V2 will help, sorry ... "So, i don't know if open a new support ticket or try RUM V2...

----------------
39.8:

Dear @Axel V., shortly got in touch with the dev for the Java injection. Yes we don't support auto injection for Webmethods. BUT. what you can do in this case is the following: have an agent on the server capturing the server-side metricshave an application for automatic injection and create an injection exclusion rule to never inject automaticallyinsert manually. make sure the beacons are sent via an Active GateThis way you should be able to monitor that setup full stack! regards ThomasHope that helps. Support should know about this and help you set it up correctly! 

----------------
39.9:

Hello @Thomas Z. and thank you so much! So, i must try to enable manual injection, right?Application settings -> Injection -> "Manual insertion" tab This is correct path for solution? If not, can you tell me the correct path in settings?Thanks for your usefull help, Best regardsAxel

----------------
39.10:

exactly! And don't forget to also add an exclusion rule to not inject automatically for the domain/the whole web site

----------------
39.11:

			
				
					
					
						Perfect, thank you Thomas, i'll update thread if i'll have news. Best regards

----------------
39.12:

Hello,Today we had an issue  with an IBM tool: java.lang.ClassCastException: com.dynatrace.agent.introspection.uem.impl.CacheHookingRequestWrapperSupport advised to turn on: Java Real user monitoring v2 [Opt-In]This fixed the issue. So my question is,Does turning this on, turn off the old stuff (-;?And is your previous (excellent) explanation  now obsolete? KR Henk  

----------------
40.1:

Hey @elenaperez ,Seems like you are looking at two different metrics here. The one above is builtin:tech.generic.cpu.usage meanwhile the one below is builtin:process.cpu. If you were to chart in your dashboard the one above, the "small" numbers of that metric would show up in the dashboard as well. The other metric (builtin:process.cpu) has actually stopped being populated, at around the same time that there is the drop of CPU usage in your other metric.So the problem is no longer charting small numbers, because of course the Data Explorer can do that, but why did the second metric (builtin:process.cpu) stop being populated so harshly for so many processes. For this, I don't have an answer, but hopefully someone else does, reads my comments and can add their more professional insights into why it could disappear.Hopefully this helps.

----------------
41.1:

@xu_guo,Thanks a lot! I believe these codes should also be in the documentation.BTW, do the 97? codes also appear in synthetics?https://www.dynatrace.com/support/help/how-to-use-dynatrace/real-user-monitoring/setup-and-configura...

----------------
41.2:

Hi @xu_guoDo you have any idea how to get past and fix the error 12020 - The site unexpectedly closed the connection.

----------------
41.3:

There is also an error code 12006 Site Reported Unexpected, if anyone has experience with that. 

----------------
41.4:

12006 Site Reported Unexpected is the Chrome ERR_UNEXPECTED error. This is usually caused by an authentication issue. If you curl to the application from the ActiveGate, do you get a successful response? Often it is the case that a proxy is required to allow the ActiveGate to access the application. Or if you are already using a proxy, possibly you need to bypass it for the affected application. You can see the different scenarios available here

----------------
41.5:

Hello,We're observing "The request failed with error 12100: ABORTED", any idea what exactly this means? and possible causes?Couldn't find any details in the docs. Thanks,Sravanth.

----------------
41.6:

 "The request failed with error 12100: ABORTED" is seen where the request got aborted, and the browser doesn't provide any more details. Do you see the same in DevTools?
 

----------------
41.7:

Hi @HannahM ,No, we observe this error only in waterfall analysis of the synthetic executions and is intermittent with no real trend.

----------------
41.8:

OK, I would open a chat in the WebUI and provide a link to monitor and if possible a Har from when the page was loaded. Thanks

----------------
41.9:

Are these codes in the doc anywhere? What does this one mean?"healthStatusCode": 17,"healthStatus": "CONSTRAINT_VIOLATED_VALUE",

----------------
41.10:

Is that from a Browser Monitor or HTTP Monitor? We mention it here for HTTP Monitors

----------------
41.11:

@HannahM Can you please tell me how to resolve the 403 error of the synthetic monitor?The URL is getting loaded when I try in the browser, but somehow, it is throwing a 403 error in Dynatrace.I have created RUM for this application, but no user actions are getting captured, to troubleshoot this I created the synthetic monitor which is throwing a 403 error.Can you please help me with this?

----------------
41.12:

Hi @Vaishnavi_Ubhe,Is your synthetic running against public Dynatrace robot? Private location?Best regards 

----------------
41.13:

@AntonPineiro Is it running against a private location. 

----------------
41.14:

403 is a forbidden error. Have you added credentials to the monitor to allow it access? If you open the page from the Private location does it have access? Sometimes customers need to explicitly allow certain machines to have access using a proxy or network rules. 

----------------
42.1:


Hi,I think that no but you can tags those entities where you are interested base on rules.Best regards

	Consultant


----------------
42.2:


Correct, it's not possible to customize the identifier itself. Also, service detection rules can override that.If you need ID agnostic dashboard, you need to filter by tags, management zones, or other means as @AntonPineiro mentions. Some built-in widgets for Dashboard Classic such as the service tile won't allow you to do that, in that case - you can either display the data using Data Explorer tile (preferred) or you can configure the IDs in the dashboard JSON based on entity IDs lookup (you need to look up the IDs and update dashboard accordingly).

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
43.1:

I would say it goes, as the request for the Adobe objects are visible in the waterfall, which I just checked in a synthetic measurement for a client that I know uses Adobe.

	Antonio Sousa


----------------
43.2:

Hi Antonio,first of all, thanks for your support!Do you know how can I filter the Dynatrace traffic in Adobe Analytics?Regards

----------------
43.3:

@mkat,Sorry, but I don't know...

	Antonio Sousa


----------------
43.4:

Hi @mkat Can Adobe Analytics filter out requests according to the user agent?Dynatrace default synthetic user agent is: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/{version} Safari/537.36 RuxitSynthetic/1.0 v0 t0 cfeatureHash=7efgijmoqtvx caes=1 ccux=1 sia=1 smf=1 HTHYos -----With google search found this Adobe Analytics - Bot Filtering using User Agent  so it look like there is a way in  Adobe Analytics to filter out request by user agent. 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
44.1:

Hi,I would raise a ticket to Dyntrace support.Best regards

	Consultant


----------------
45.1:

Can you tell us where are you seeing this data? If it is in a Dashboard, you can click on the tile and see the details, where you can see the query for it. 

	Site Reliability Engineer @ Kyndryl


----------------
45.2:

If you can provide a screen capture that would be best. Users commonly confuse Unique users and Session Count which then raise questions like this.  

	-Chad


----------------
45.3:

Enterprise Web DashboardTotal VisitsSELECT count(*) AS "Total Visits" FROM usersessionWHERE userType = "REAL_USER" AND applicationType = "WEB_APPLICATION"Unique VisitorsSELECT count(DISTINCT internalUserId) AS "Unique Visitors" FROM usersessionWHERE userType = "REAL_USER" AND applicationType = "WEB_APPLICATION"

----------------
45.4:

I dont see any issues with the query you are using. I know there can be issues with live sessions vs completed sessions when using the USQL vs nonUSQL as USQL wont look at live sessions, but that isn't the case here. I've tested it in our environment and its working as expected. What cluster version are you on? 

	-Chad


----------------
45.5:

We are on Dynatrace Managed version. 1.272.139I just went in to the dashboard to confirm the query were correct. The issue still happen but intermittence. This time round it occurs for last 7 days.U just need to play around with all the pre-set last xx hours/days to reproduce the issue.  How can I tell if the query are USQL or nonUSQL? Are those the default query?One thing I notice in the view details. Not sure if it matters and if they are the default. Total Visits. Compare with previous timeframe - DISABLEDUnique Vistors. Compare with previous timeframe - ENABLEDDynamic time-frame shift - CHECKED Kindly advice

----------------
45.6:

I cant get the issue to reproduce, but my cluster version is 1.276.181.20231002-204711 - is it possible to upgrade your cluster and see if the issue is still present? 

	-Chad


----------------
45.7:

Dynatrace Managed current latest version release is 1.274.I assume the release for 1.276 would be in a few days time.FYI. This issue was reported few months back when our users discover it.There were trying to use custom time like past 9 hours.At that time we were on Dynatrace Managed version 1.268.Anyway, would keep this thread active and see if others faces the same issue.

----------------
46.1:


Hi @susmita_ally Yes of course you can set Anomaly Detection at service level for a specific Host Group.The easiest way is to select your Host Group from Deployment Status and go to its settings. In the next step you will be able to set the entire Anomaly Detection configuration for the selected Host Group.    Radek

	Have a nice day!


----------------
46.2:

This may help you: https://www.dynatrace.com/support/help/shortlink/host-groups#how-host-groups-affect-your-monitoring-...

	Have a nice day!


----------------
47.1:

Hi @susmita_ally I'm not sure if you can include so many conditions in one Alerting Profile, but it needs to be checked I would first of all start by configuring the Metric Events and secondly add the created metrics to the Alerting profile.https://www.dynatrace.com/support/help/platform/davis-ai/anomaly-detection/metric-eventshttps://www.dynatrace.com/support/help/observe-and-explore/notifications-and-alerting/alerting-profi...Radek

	Have a nice day!


----------------
48.1:

you can create new metrics for this, and them they will be available on the grail

	Dynatrace Professional Certified


----------------
49.1:

did you see the response time?Look this documentation pagehttps://www.dynatrace.com/support/help/platform-modules/applications-and-microservices/services/anal... The Response time chart illustrates how the response times of the requests triggered by this service were distributed during the selected timeframe 

	Dynatrace Professional Certified


----------------
50.1:

Probably not the answer you are looking for, but you can combine metrics when you create SLOs and then set custom alerts on these SLOs.Unfortunately, SLOs do not support dimensions so you need 1 SLO for each host (and consequently, 1 metric event per host).The below SLO example adds CPU usage and Memory usage of a specific host "hostname" and divides by 2. When the SLO reaches 90% it means both CPU and Memory are at their 90% usage:(builtin:host.cpu.usage:filter(and(or(in("dt.entity.host",entitySelector("type(host),entityName.equals(~"hostname~")"))))):splitBy("dt.entity.host")+builtin:host.mem.usage:filter(and(or(in("dt.entity.host",entitySelector("type(host),entityName.equals(~"hostname~")"))))):splitBy("dt.entity.host"))/2

----------------
51.1:

This is a good question! I also thought that request attributes and business events seem like they could work well together, and I'm interested to see what co-existence Dynatrace has planned for them. 

----------------
51.2:


Hi Daniel, I think I have the answer,https://community.dynatrace.com/t5/Open-Q-A/Request-attributes-as-source-of-truth/m-p/224497#M28800In simple terms, request attributes  not always captured, and that 's  what is needed for business events,(-; KR Henk

----------------
52.1:


Hello @henk_stobbe,from my point of view, the info should be reliable as long as the technology is fully supported, controlling the number of traces captured per process/minute if needed (check Adaptive traffic management for more details), using request attributes, and if you are using log monitoring, you can use traces log enrichment that will help with more details as well.I hope I have understood you correctly and I hope this helps.

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
52.2:

Hi Mohamed,Great answer, thanks.My concern was basicaly that other observability vendors all implement things like tail based and or head based sampling to limit resource usage. So after reading about adaptive traffic, I conclude that  OneAgent uses head based sampling. (to keep it simple)So the text "all requests, from end to end", should be read as  "all request, that are captured, are captured end to end" But it is possible that not all requests are captured.This means that request attibutes can also be sampled, and that answers my question thx!KR Henk KR Henk  

----------------
52.3:

My experience is - if there is no adaptive traffic management, request attribute values are accurate. For high throughput services (way above the default limit of 1000 captured traces per process group), the counters for request attribute values might not be 100% correct (e.g. you have 2450 instead of 2445 as the counter), but still precise enough for observability - alerting, dashboards, etc.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
53.1:

I can confirm to you that, right now, only Dynatrace employees (mostly the extensions team) can use Python in the EF2.0 framework. I don't think anything has been announced as per availability or dates for customers/partners to use the same framework.

----------------
53.2:

Too bad. consider this an RFI then?

----------------
53.3:

We have it on the roadmap and expect to share our plans in the next 60 days.

----------------
54.1:


Automation Workflows can be used to generate and update notebooks or dashboards via document store SDKs and APIs. The links to those can be sent as part of a report.  
Creating status artifacts (e.g. picture or pdf) is currently not supported. 

	Michael


----------------
54.2:

@michaelwinkler Can you send a guide on how to create and update notebooks via API in a workflow? 

----------------
54.3:

Hi,
Using the document SDK in a typescript workflow action is the easiest. 
Would you mind sharing some more information about your use case and what you are trying to achieve?
Thank you,
Michael

	Michael


----------------
54.4:

Sure. We're currently setup with alert profiles and notification profiles through PagerDuty via custom API integration. We'd like to have some workflows with specific problem triggers (probably just for our tier 1 applications) that would run queries against the entity(ies) impacted by the problem, and then generate a notebook with those results (along with some other, possibly templated information). As a final step, we'd like to have the workflow reach out to the PagerDuty API to update the related incident with the link to the notebook. Basically, we want to try to reduce MTTR by having initial queries for problem related data run automatically and a notebook generated to capture it all. This would include custom metric and log data that may not already be included in the Davis AI problem analysis. Having a notebook with queries and data ready to go would provide a great starting point for PlatOps troubleshooting and analysis since they're already running similar queries manually today.

----------------
54.5:

Hi,
It could potentially be more convenient to have a dedicated notebook and/or dashboard for said Davis problems and Tier 1 applications, which is accessed and run on demand (instead of building it every time a problem occurs).
The workflow could look like the following:
- Davis Problem trigger (filtering on specific problems and applications)
- sending a slack/teams message to the corresponding team with the link to the notebook/dashboard
- informing Pagerduty
btw: We just recently released "Pagerduty for Workflows" which includes six different workflow actions to easily integrate with Pagerduty. 

	Michael


----------------
54.6:

That would work, although we want to make sure we preserve the notebook for later use. If we do what you suggested, we'd be overwriting the notebook every time the problem trigger initiated.

----------------
55.1:


Hi @GP_Stanley , The extension creates log files which can be found on the ActiveGate server : C:\ProgramData\dynatrace\remotepluginmodule\log\remoteplugin\custom.remote.python.sapor/var/lib/dynatrace/remotepluginmodule/log/remoteplugin/custom.remote.python.sapThe logs in that directory should help pinpoint what is going on with the endpoints such as a timeout or another error. 

----------------
55.2:

Hello,I have got same problem with "SAP Application Server (version 1.158)" extension. I configure endpoint, it's seems ok but not data collected.I look into log file on ActiveGate host in C:\ProgramData\dynatrace\remotepluginmodule\log\remoteplugin\custom.remote.python.sap\SAPPluginRemote.log Below is extract 2023-10-03 12:26:58.966 UTC DEBUG [Python][6239264261536217212][SAP_BS7][28772][ThreadPoolExecutor-0_0] - [query] Monitoring WS-HTTP2023-10-03 12:26:58.966 UTC DEBUG [Python][6239264261536217212][SAP_BS7][28772][ThreadPoolExecutor-0_0] - [query] Monitoring ESI2023-10-03 12:26:58.966 UTC DEBUG [Python][6239264261536217212][SAP_BS7][28772][ThreadPoolExecutor-0_0] - [query] Monitoring ALE2023-10-03 12:26:58.966 UTC DEBUG [Python][6239264261536217212][SAP_BS7][28772][ThreadPoolExecutor-0_0] - [query] Monitoring RFC2023-10-03 12:26:58.966 UTC DEBUG [Python][6239264261536217212][SAP_BS7][28772][ThreadPoolExecutor-0_0] - [query] Monitoring CPIC2023-10-03 12:26:58.966 UTC INFO [Python][6239264261536217212][SAP_BS7][28772][ThreadPoolExecutor-0_0] - [query] Skipping execution 1, executing every 5 minutes2023-10-03 12:26:58.966 UTC WARNING [Python][6239264261536217212][SAP_BS7][28772][ThreadPoolExecutor-0_0] - [query] No file found, start process2023-10-03 12:26:58.966 UTC INFO [Python][6239264261536217212][SAP_BS7][28772][ThreadPoolExecutor-0_0] - [runJava] Using java path: ../../../gateway/jre/bin/java.exe2023-10-03 12:26:58.966 UTC INFO [Python][6239264261536217212][SAP_BS7][28772][ThreadPoolExecutor-0_0] - [runJava] ['../../../gateway/jre/bin/java.exe', '-Xmx1536m', '-cp', 'D:\\dynatrace/remotepluginmodule/plugin_deployment/custom.remote.python.sap/SAPRFC.jar;D:/dynatrace/remotepluginmodule/plugin_deployment/custom.remote.python.sap/Jars/sapjco3.jar', 'com.dynatrace.saprfc.Main', 'C:\\Windows\\SERVIC~2\\LOCALS~1\\AppData\\Local\\Temp/10.156.38.2700200/']2023-10-03 12:26:59.454 UTC INFO [Python][6239264261536217212][SAP_BS7][28772][ThreadPoolExecutor-0_0] - [query] [WinError 2] The system cannot find the file specified: 'C:\\Windows\\SERVIC~2\\LOCALS~1\\AppData\\Local\\Temp/10.156.38.2700200/javaRunning.dt.sap.lock'2023-10-03 12:26:59.454 UTC INFO [Python][6239264261536217212][SAP_BS7][28772][ThreadPoolExecutor-0_0] - [query] No previous data found, awaiting next execution I didn't see where is the problem.Could you help me on this, please ? Thanks by advance. 

----------------
55.3:


Please create a support ticket for it.
In 99% of the cases a log such as that means that something went wrong with the "SAP Java Connector configuration" section of the help page: https://www.dynatrace.com/support/help/setup-and-configuration/technology-support/dynatrace-extensio...Either the redistributable isn't installed, or you downloaded a 32 bit version of the sapjco3.jar, or you don't have access to read the sapjco3 file.

----------------
55.4:

 && cd D:/dynatrace/remotepluginmodule/plugin_deployment/custom.remote.python.sap && D:\dynatrace\gateway\jre\bin\java.exe -Xmx1536m -cp SAPRFC.jar;Jars/sapjco3.jar com.dynatrace.saprfc.Main C:\Temp # Exception in thread "main" java.lang.ExceptionInInitializerError: JCo initialization failed with java.lang.UnsatisfiedLinkError: D:\dynatrace\remotepluginmodule\plugin_deployment\custom.remote.python.sap\Jars\sapjco3.dll: Can't load IA 32-bit .dll on a AMD 64-bit platform And i figure out what it is. I installed SAPJco version 32 bits because current default jvm on this server is 32 bitsBut ActiveGate Dynatrace is in 64 bits and you can test loading of SAPJco.jar with it.D:\dynatrace\gateway\jre\bin\java.exe -jar D:\dynatrace\remotepluginmodule\plugin_deployment\custom.remote.python.sap\Jars\sapjco3.jar

----------------
56.1:


Have you seen this blog post ? It explains it pretty well.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
56.2:

Hi Folks,Have you seen such a memory pattern? Do you thnik it is a memory leak in a jvm?I could not recognize any process which is responsible for this pattern. Thanks in advance for your help.Best regards,Mizső

	Certified Dynatrace Professional


----------------
57.1:

Greetings, @radek_jasinski !Me and @AntonioSousa will be there!See you Thursday! 

	Best regards, Pedro Deodato


----------------
57.2:

Hello @radek_jasinski I will be there till Saturday. see you there 

	Dynatrace Certified Professional - Dynatrace Partner - Yourcompass.ca


----------------
57.3:

Super:) we need to go out for a beer and food together then 

	Have a nice day!


----------------
57.4:

I would say that we gather after the event. I believe there's an "after Innovate", we just have to figure out a place at Intercontinental where we can all meet 

	Antonio Sousa


----------------
58.1:

Hi @radek_jasinski Thanks for sharing this information.Best regards,Mizső

	Certified Dynatrace Professional


----------------
58.2:

Hi @radek_jasinski Did you tried to downgrade the JS agent to the one before latest, in order to check if the new JS agent version is the RC?Yos 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
58.3:

Hi Yos,No, I haven't tried this, but it doesn't matter if the RUM configuration for the XHR was automatically removed during the upgrade.I'm still waiting to hear from support.Radek

	Have a nice day!


----------------
58.4:

Hi Radek,The reason I suggested to try downgrade the JS agent version was, because we had the same issue (losing XHR action) after upgrading to Managed 269. While waiting for support answers, we downgrade the JS version to 263 (latest that support IE7-10) and that solved the issue of missing XHRs. Then we found out with support that there was a use of old Angular that is not support  by JS agent version 265 and on.HTHYos  

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
58.5:

Hi Yosi,This is a different situation. In my case, it looked as if various configuration elements were spontaneously disabled after a cluster update. the XHR was switched off, data collection stopped. After re-enabling the configuration, everything returned to normal.I have never encountered a similar situation in DT.

	Have a nice day!


----------------
58.6:

Understood 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
59.1:

Hi @Rinu Have you tried monitoring the Solace MQ using Syslog? Then you can pull metrics from syslog into DT. Another thing is whether you have an API in Solace MQ after which you can pull the relevant metrics and send to Dynatrace?https://docs.solace.com/Monitoring/Monitoring-Events-Using-Syslog.htmRadek

	Have a nice day!


----------------
60.1:

Hi @elenaperez I recommend to use containerized AG (or AGs depends on the size of kubernetes cluster). CPU and Memory modification depends on also the size of the culster (I mean the number of pods). After the install you can follow the AG cpu and memory consumption and modify it if it will be required.To connect the kubernetes cluster api is more simple with containerized AG, than with extrenal AG.I hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
60.2:

And if cpu / memory are under stress how should it be scaled? Vertical or horizontal?

----------------
60.3:


At a first step the vertical scale is sufficient. 

	Certified Dynatrace Professional


----------------
61.1:

 Hi,Have you tried downloading the list of monitors via GET through the API: https://www.dynatrace.com/support/help/shortlink/api-synthetic-monitors-get-allRadek

	Have a nice day!


----------------
61.2:

@MartijnA Did the hint from Radek help you?

 When passion meets people magic and innovation happen. 


----------------
61.3:

@AgataWlodarczyk , partly. I created a python script that reads out the third party synthetics via the API, but the API does not give back all the results correctly. Sometimes it gives me the monitor(s) per application, but sometimes it states that there is no monitor connected to the application while it actually is. I'm still trying to work out why this is happening.

----------------
61.4:

Interesting. What API endpoints are you using? I can see if I can reproduce it also. Thanks

----------------
62.1:

Below is a screenshot after executing the condition. Though the trigger has required tag, the flow is discarded saying the condition doesnt match. Please help!!  

----------------
63.1:

Did you check if out of the box global policies available in account management view cover your needs?There is no limit for number of policies bound to particular group, however there is a limit for number of policy bindings within a level - account or environment - 15 000.

----------------
63.2:

Yes I did and did not see one or two that matched what we trying to do.

	Dynatrace Certified Professional


----------------
63.3:

Is there a max groups that can be created in Dynatrace for SAML SSO?

	Dynatrace Certified Professional


----------------
63.4:

I'm aware of limit of 50k groups for single account

----------------
63.5:

Hello @Kenny_Gillette the following is my power user policy:ALLOW settings:objects:read, settings:objects:write, settings:schemas:read WHERE settings:schemaId IN ("builtin:synthetic.browser.name", "builtin:synthetic.browser.scheduling", "builtin:synthetic.http.name", "builtin:synthetic.http.scheduling", "builtin:synthetic.browser.assigned-applications", "builtin:synthetic.http.performance-thresholds", "builtin:synthetic.browser.kpms", "builtin:synthetic.http.assigned-applications", "builtin:synthetic.http.cookies", "builtin:synthetic.browser.performance-thresholds");
ALLOW settings:objects:read, settings:objects:write, settings:schemas:read WHERE settings:schemaId IN ("builtin:failure-detection.service.http-parameters", "builtin:failure-detection.service.general-parameters", "builtin:anomaly-detection.metric-events", "builtin:metric.metadata", "builtin:settings.calculated-service-metrics", "builtin:tags.auto-tagging", "builtin:tags.manual-tagging", "builtin:alerting.maintenance-window", "builtin:alerting.profile", "builtin:problem.notifications", "builtin:monitoring.slo");
ALLOW settings:objects:read, settings:objects:write, settings:schemas:read WHERE settings:schemaId IN ("builtin:rum.mobile.name", "builtin:rum.mobile.key-performance-metrics", "builtin:rum.mobile.request-errors", "builtin:rum.source-mappings", "builtin:rum.web.name", "builtin:rum.web.request-errors", "builtin:rum.web.custom-errors");
ALLOW settings:objects:read, settings:objects:write, settings:schemas:read WHERE settings:schemaId IN ("builtin:settings.mutedrequests", "builtin:settings.subscriptions.service");

	The true delight is in the finding out rather than in the knowing.


----------------
63.6:

Going to try this.

	Dynatrace Certified Professional


----------------
63.7:

I believe the same set of permissions can be granted by assigning "Settings Writer" policy to the user's group.

----------------
64.1:

Congrats, Sini!  You're our good soul, always ready to help and support I hope you'll visit the two continents that are still missing the checkmarks on your list 

----------------
64.2:

Congrats @sinisa_zubic ,Besides the Community, huge kudos for your training sessions!

----------------
64.3:

Congrats 

----------------
64.4:

Well deserved, thrilled to see you being honored @sinisa_zubic!

----------------
64.5:

Hi Sini,Congrats!!!  Well done! Keep going on! Thanks for your support! Best regards,Mizső

----------------
64.6:

Congratulations Sini. You're so knowledgeable on so many subjects. I'm glad to have had the opportunity to work with, and learn from, you. Keep doing what you're doing!

----------------
64.7:

Good Work @sinisa_zubic !!! Congratulations

----------------
64.8:

Congratulations Sini!! 

----------------
64.9:

Congrats @sinisa_zubic

----------------
64.10:

Congrats, @sinisa_zubic !! Thanks for the learning! When the "Escape from sharks 101" will be out?

----------------
64.11:

congrats

----------------
65.1:

Great Tip @JonathanV 

	-Chad


----------------
65.2:

Nice one Jonathan, do I require admin privileges to the VM to be able to carry out the installation? Also must I log in to the VMs be able to carry out the installation 

----------------
66.1:


Hi,regarding "initial value not set", this means that the attribute is set after span creation, so the OneAgent does not know of it when he decides based on the "Span capturing" settings if the span should be captured or not. Have you tried directly setting the attribute directly in the tracer.spanBuilder("span").setAttribute(...)..  And regarding setting the parent, try this:void parentOne() {
  Span parentSpan = tracer.spanBuilder("parent").startSpan();
  try {
    childOne(parentSpan);
  } finally {
    parentSpan.end();
  }
}

void childOne(Span parentSpan) {
  Span childSpan = tracer.spanBuilder("child")
        .setParent(Context.current().with(parentSpan))
        .startSpan();
  try {
    // do stuff  } finally {
    childSpan.end();
  }
}Let me know if it worked! Cheers,Josef

----------------
66.2:

Hi @josef_schiessl , Thanks a lot for the reply! Regarding your first point you are totally right, after also setting the Attributes when creating the Span the message dissapears  Regarding your second solution about setting the parent. Unfortunately that seems like what I was already doing and even after copying your code 1 on 1, I get the same results. Do you have any other idea what I can try? Kind regards,Erik

----------------
66.3:

Hi Erik!I just verfied this with the team and you are doing everything correct.This is currently a limitation by the OneAgent, so spans are always reported in a flat hierarchy. But this is currently actively being worked on for all technologies. So this will work in the near future! Cheers,Josef

----------------
66.4:

Hi @josef_schiessl  Thanks again for answering, much appreciated!Any idea when this will be released? I know that the automatic instrumentation is planned for OneAgent 1.237. Will this feature then also be released? Kind regards,Erik

----------------
66.5:

Hi,I cannot give you an ETA - for Java it will not be in 1.237, but as I mentioned, its currently being worked on so it should not be too many versions from that.  Cheers,Josef

----------------
66.6:

Alright thanks! 

----------------
66.7:

No worries 

----------------
66.8:

I'm curious about what progress the Dynatrace team has made on the flat vs. nested hierarchy capability with native tracing tools, such as with the ActivitySource and Activity types in .NET. Is there a setting that needs to be turned on within Dynatrace to change flat span hierarchies into nested relationships, or is this feature still not yet supported in .NET?

----------------
67.1:


Hi @freudi,
It sounds like you want to ingest dimensions with your metric. Something like a status code "OK" would make sense here. But a timestamp here would not make sense, as it would increase the number of unique dimension key-value combinations and likely cause you to run into dimensionality limits.
The agent accepts data according to the metric ingest protocol. Adding a status code dimension may look like this:
/opt/dynatrace/oneagent/agent/tools/dynatrace_ingest "my.http.status.metric,status=${status} ${value}"
I hope this helps answer your question.
Take care,Nick

----------------
68.1:

Hi,If that information is in a tag, you can create a renaming rule adding those tag as name.Best regards

	Consultant


----------------
68.2:

I have not seen anywhere to do this. I'm familiar with how to rename things like process groups but not clear on how to do that for aws services like ebs or efs

----------------
68.3:

Hi,Does that entity appear when you filter it by tag or name in Technology Overview?Best regards

	Consultant


----------------
68.4:

I cannot find it there. I always get to it via the AWS menu then going through the account that has the service, or using data explorer to chart out the metric I care about.

----------------
68.5:

Is this possible with generic entities? 

----------------
68.6:

I'll update this to note that the EFS entity I am referring to is a custom device and not a process group.

----------------
69.1:


Hello @Sahil2308,In this documentation article, you can check out the expression reference for result() which will allow you to access the result of a preceeding task within the workflow:Introduction to workflows - Expression reference 

	If you have any questions about the Community, you can contact me at maciej.neumann@dynatrace.com


----------------
69.2:

Thanks @MaciejNeumann  

----------------
70.1:

we just leverage the clearing of the API and provide the key for the next page and so on. Its simple enough but im sure you could automate it with a postman script. 

	-Chad


----------------
70.2:

Same as @ChadTurner , we have done it in Linux shell, python and even MSDOS .bat scripts Have had some problems, but it was in our coding...

	Antonio Sousa


----------------
70.3:

I mostly use Python or cURL to fetch the data. But I'm really interested in how the paging should be used in the Power Query feature of Excel. 

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
70.4:


I usually use the Python API client, that one handles the next page key automatically so I don't have to care about it https://github.com/dynatrace-oss/api-client-pythonTo get all hosts and even handle the too many concurrent request message automatically is as simple as:dt = Dynatrace("environment_url", "api_token", too_many_requests_strategy=TOO_MANY_REQUESTS_WAIT )
for entity in dt.entities.list('type("HOST")', fields="properties.memoryTotal,properties.monitoringMode"):
    print(entity.entity_id, entity.display_name, entity.properties)

----------------
70.5:

Thank you to everybody who answered.I'm taking my time to go trought the process of learning, thinking, practicing. Especially thank you for pointing me to the DT git repo. direction.

----------------
70.6:

I have the same problem and have yet to find a simple solution as well.  Mike_L's link is honestly extremely helpful but I'd rather not rely on it since it doesn't support all API's and it's not logic i can apply elsewhere.  I've tried similar approaches using postman and insomnia REST Clients but they handle nextpages in a way different than DT approaches it. I've coded solutions in Python and PHP but they're clunky and honestly my code is embarassing to get it working. I'm posting in response because the "Next Page" thing is actually a cause sometimes for me to just not want to use the API.  I know I'll only get a partial result set and it's too time consuming to put all the JSON responses together. This is even an issue with PowerBI and Excel reporting because they too can't handle the API's NextPage thing. Is DT considering any solutions for this?  Being that DT is all API First it would be helpful to the clients if the APIs can be a bit more client friendly.  (don't get me start on inconsistent FROM string defaults)

	HigherEd


----------------
70.7:


Hi, I have created a PowerQuery to go through pagination and get the whole list. What you need to do is to create Function and call it recursively.In my case, I need to query all problems from last quarter.So I have created this function named getProblemAPIResult(), and from the code below you can see it is calling itself passing nextPageKey. (api as text, headers as record, parameters as text, nextPageKey as text, currentList as list) => 
let
    apiResult = if nextPageKey = ""
    then Json.Document(Web.Contents(api & parameters, headers))
    else Json.Document(Web.Contents(api & "?nextPageKey=" & nextPageKey, headers)),
    newList = List.Combine({currentList, apiResult[problems]}),
    hasNext = try apiResult[nextPageKey],
    returnList = if hasNext[HasError] 
    then newList
    else getProblemAPIResult(api, headers, parameters, apiResult[nextPageKey], newList)
in
    returnList Then the rest is easy, you call this function passing API, all necessary parameters and keep last 2 parameters empty.Only the function calling matters, the rest are just table transformation.let
    problems = getProblemAPIResult(APIURL & "/v2/problems", [Headers=[Accept="application/json; charset=utf-8", Authorization="Api-Token " & APIToken]], "?pageSize=500&from=" & fromTime & "&to=" & toTime, "", {}),
    #"Converted to Table" = Table.FromList(problems, Splitter.SplitByNothing(), null, null, ExtraValues.Error),
    #"Expanded Column1" = Table.ExpandRecordColumn(#"Converted to Table", "Column1", {"problemId", "displayId", "title", "impactLevel", "severityLevel", "status", "affectedEntities", "impactedEntities", "rootCauseEntity", "managementZones", "entityTags", "problemFilters", "startTime", "endTime"}, {"Column1.problemId", "Column1.displayId", "Column1.title", "Column1.impactLevel", "Column1.severityLevel", "Column1.status", "Column1.affectedEntities", "Column1.impactedEntities", "Column1.rootCauseEntity", "Column1.managementZones", "Column1.entityTags", "Column1.problemFilters", "Column1.startTime", "Column1.endTime"}),
    #"Expanded Column1.managementZones" = Table.ExpandListColumn(#"Expanded Column1", "Column1.managementZones"),
    #"Expanded Column1.managementZones1" = Table.ExpandRecordColumn(#"Expanded Column1.managementZones", "Column1.managementZones", {"name"}, {"Column1.managementZones.name"}),
    #"Invoked Custom Function" = Table.AddColumn(#"Expanded Column1.managementZones1", "problemStart", each EpochToICTDateTime([Column1.startTime])),
    #"Invoked Custom Function1" = Table.AddColumn(#"Invoked Custom Function", "problemEnd", each EpochToICTDateTime([Column1.endTime])),
    #"Added Custom" = Table.AddColumn(#"Invoked Custom Function1", "Duration (min)", each ([Column1.endTime]-[Column1.startTime])/60000)
in
    #"Added Custom" Hope it helps.Regards,Satit

----------------
70.8:

Hi satit_dpm, when I created the function named getProblemAPIResult() and the rest api everything work, but when y try to save i got the error: Expression.Error: A cyclic reference was encountered during evaluation.I think the problem is here, do you know how to fix it?returnList = if hasNext[HasError]then newListelse getProblemAPIResult(api, headers, parameters, apiResult[nextPageKey], newList)

----------------
70.9:

Hi, Unfortunately, I am unable to reproduce your issue This works fine in Excel using the same PowerQuery code I have posted.Could you tried using the code below as-is?(api as text, headers as record, parameters as text, nextPageKey as text, currentList as list) => 
let
    apiResult = if nextPageKey = ""
    then Json.Document(Web.Contents(api & parameters, headers))
    else Json.Document(Web.Contents(api & "?nextPageKey=" & nextPageKey, headers)),
    newList = List.Combine({currentList, apiResult[problems]}),
    hasNext = try apiResult[nextPageKey],
    returnList = if hasNext[HasError] 
    then newList
    else getProblemAPIResult(api, headers, parameters, apiResult[nextPageKey], newList)
in
    returnListRegards,Satit

----------------
70.10:

Hi there!! I'm trying to create a dataflow in power platform. I solved the issue with an "@" where the function is called recursively. (reference).But now, I have a new issue. In power platform, I could create the query but I can't save it. I got this error: "One or more tables references a dynamic data source."In power platform I have this problem:"This query refreshes with no problems in Power BI Desktop. However, when you publish a report that uses this code to PowerBI.com and try to refresh the dataset, you’ll see that refresh fails and returns a rather unhelpful error message:Data source error Unable to refresh the model (id=1264553) because it references an unsupported data source.The problem is that when a published dataset is refreshed, Power BI does some static analysis on the code to determine what the data sources for the dataset are and whether the supplied credentials are correct. Unfortunately in some cases, such as when the definition of a data source depends on the parameters from a custom M function, that static analysis fails and therefore the dataset does not refresh."I change the code as Chris says using RelativePath and Query in web.content, but I couldn't fix it.I tried the "skip connection" and use base_url with xxxx.live.dynatrace.com xxx.live.dynatrace.com/api , xxxx.live.dynatrace.com/api/v2 and none of then work.So this is my code: let
  getMetricsAPIResult = (base_url as text, next_url as text, qty as text, nextPageKey as text, currentList as list) => 
  let
    apiResult = if nextPageKey = ""
    then Json.Document(Web.Contents(base_url,
      [
        RelativePath = next_url,
        Query = 
          [
            pageSize = qty
          ],
          Headers=[Accept="application/json; charset=utf-8", Authorization="Api-Token XXXX"]
      ]
      ))
    else Json.Document(Web.Contents(base_url,
      [
        RelativePath = next_url,
        Query = 
          [
            nextPageKey = nextPageKey
          ],
          Headers=[Accept="application/json; charset=utf-8", Authorization="Api-Token XXXX"]
      ]
      )),
    newList = List.Combine({currentList, apiResult[metrics]}),
    hasNext_tmp = apiResult[nextPageKey], 
    hasNext = if hasNext_tmp is null 
    then try apiResult[nextPageKeyError]
    else try apiResult[nextPageKey],
    returnList = if hasNext[HasError]
    then newList
    else @getMetricsAPIResult(base_url, next_url, qty, apiResult[nextPageKey], newList)
  in
    returnList,

  consulta = getMetricsAPIResult("https://{environmentid}.live.dynatrace.com", "/api/v2/metrics", "500", "", {}),
  #"Converted to table" = Table.FromList(consulta, Splitter.SplitByNothing(), null, null, ExtraValues.Error),
  #"Expanded Column1" = Table.ExpandRecordColumn(#"Converted to table", "Column1", {"metricId", "displayName", "description", "unit"}, {"metricId", "displayName", "description", "unit"}),
  #"Transform columns" = Table.TransformColumnTypes(#"Expanded Column1", {{"metricId", type text}, {"displayName", type text}, {"description", type text}, {"unit", type text}}),
  #"Replace errors" = Table.ReplaceErrorValues(#"Transform columns", {{"metricId", null}, {"displayName", null}, {"description", null}, {"unit", null}})
in
  #"Replace errors" 

----------------
70.11:

Hi,Sorry, I am not able to support on this issue as Power platform is not really my forte Regards,Satit

----------------
70.12:

@satit_dpm wanted to say Thank you.  We were able to successfully implement the solution at our company and it's bringing a entirely new value into focus using PowerBI.  I think we can finally build the Problems dashboard we've been dreaming of all these year.

	HigherEd


----------------
70.13:

Glad to hear this helps you All the best for your dream project

----------------
70.14:

https://github.com/dynatrace-oss/api-client-python how we can pass to and from client to fetch the entities 

----------------
71.1:


Hi,Is that a label as plain text that appear in the webpage?If yes, I would remove "{" and "}" in specific text field and I will remove "{window[0]}, just blank.Best regards

	Consultant


----------------
71.2:

Hi @AntonPineiro,I have not understand correctly the explanation about the brakets...It works fine based on your guidance.Thanks very much.Best regards,Mizső 

	Certified Dynatrace Professional


----------------
71.3:

Hi,You are welcome.I wanted to say removing placeholders, only specific text. It means "my text" instead of "{my text}".Best regards

	Consultant


----------------
72.1:

@Iplinsky , if a week ago everything is normal, and now the RUM Javascript is gone, it's normal to receive that error. I would try to figure out why the Javascript is gone.

	Antonio Sousa


----------------
72.2:

Exactly. I'm investigating why the agent's javascript isn't in the application, thus generating these Unexpected Traffic errors.

	Dynatrace Certified


----------------
72.3:

The main question is whether the overall level of user actions on the RUM application level is dropping during the problem:

If it's also dropping, then, as Antonio mentioned, we should debug why there is no RUM script in the HTML
If overall user action levels are OK, it might be a geolocation issue, especially if your users are from private networks (192/172/10). The "Unexpected low traffic" alarm is sensitive to situations if the traffic drops in a particular location. If some private client addresses are not assigned to any location, then this alarm does not see traffic from these addresses, and it starts beeping ...

Please let us know which of these situations you're facing.

----------------
72.4:

@Iplinsky an you provide @Adam-Piotrowicz more insights so he can help to solve the issue? 

 When passion meets people magic and innovation happen. 


----------------
72.5:

I completely forgot that I made this post. I was investigating what's going on

	Dynatrace Certified


----------------
72.6:

The traffic drops in everywhere. When i go to network in browser, sometimes i don't see the agent beacon... Creating new sessions in browser, sometimes it's not there. The configs are to monitor 100% of user sessions 

	Dynatrace Certified


----------------
72.7:

 Sometimes, error 405 from different browsers like chrome, edge, opera, networks from different locations with or without vpn. Completely random. Sometimes, just dessapear

	Dynatrace Certified


----------------
72.8:

I've checked waf configs theres no logs, also in Dynatrace too

	Dynatrace Certified


----------------
72.9:

I also get this errors above, like 100k per day. Maybe correlated with this? maybe not? ... 2023-09-28 07:07:23.730;BVLYNHGUIS;Unexpected errror in {Application Name};The controller for path '/rb_bf26736qil' was not found or does not implement IController.;http://{Application URL}.com.br/rb_bf26736qil?type=js3&sn=v_4_srv_1_sn_51344D2F76F8E05FF15451993FC2E3C2_perc_100000_ol_0_mul_1_app-3Aa8a1d4c97d4aae93_1

	Dynatrace Certified


----------------
72.10:

You need to adjust the settingsThe default is too sensitive and will spam you with problem tiles.Since Davice can not handle weekends and public holidays you can use it only for outage monitoring with very low sensitivity.

----------------
72.11:

It's correctly adjusted. The big and real question/probllem is Why the agent javascript isn't in the application, thus generating these Unexpected Traffic errors besause rum is not been monitored.

	Dynatrace Certified


----------------
72.12:

take a look on caching in CDN/LB - it could be that some instances have different content w/o JS snippetThis valid to AEM or similar systems with replication deployment 

----------------
73.1:

Thanks for the tip Chad, appreciate 

	Dynatrace Professional Certified


----------------
73.2:

This is great information Chad, thank you!

----------------
73.3:

The Pro!

	Dynatrace Certified Professional


----------------
74.1:

I edited your post because you were publicly sharing your PaaS token.

	The true delight is in the finding out rather than in the knowing.


----------------
74.2:

Hi @ManasaM. Please check if you are using Alpine images because you select in options flavor=musl&include=all

	The true delight is in the finding out rather than in the knowing.


----------------
74.3:

Hi Daniel. Thank you for your response. For the oneagent container image I've provided "alpine:3". Is there anything else that I'm missing?

----------------
74.4:


Assuming that you follow the procedure step by step, try to change this: DT_ONEAGENT_OPTIONS- this is the flavor (valid options are default or musl for Alpine images) and the technology (code module).Syntax for default is flavor=default&include=all.Syntax for musl is flavor=musl&include=all.Have in mind that your install-oneagent is alpine but may be others you are trying to set with OA are not.You have set the musl in Options but maybe the Fargate containers are different. 

	The true delight is in the finding out rather than in the knowing.


----------------
74.5:

Thanks for the suggestion. Initially DT_ONEAGENT_OPTIONS was set to flavor=musl&include=all and that worked without any issues for all services running node image alpine. The other services I was trying to onboard were not running on Debian Linux. And setting the DT_ONEAGENT_OPTIONS to flavor=default&include=all worked. 

----------------
75.1:

Is Service Naming rules an option for this case?

	Site Reliability Engineer @ Kyndryl


----------------
75.2:

@dannemca,It's not an option. To make an analogy for you, I have to rename things like:/prod/service/03   ->   Loja São Paulo/prod/service/07   ->   Loja Rio de Janeiro/prod/service/23   ->   Loja Salvador Bahia

	Antonio Sousa


----------------
76.1:


Hi @OustiDiousti 
Please check out our documentation about how to query entities in Grail: https://www.dynatrace.com/support/help/platform/grail/querying-monitored-entities#entity-tags
Basically you need to expand the array of tags and parse it
 
fetch dt.entity.host
| expand tag_string=tags
| filter contains(tag_string,"invoiced_team")
| parse tag_string, """(('['LD:tag_context ']' LD:tag_key (!<<'\\' ':') LD:tag_value)| (LD:tag_key (!<<'\\' ':') LD:tag_value)|LD:tag_key)"""
Best,Sini

----------------
77.1:

After reading through the documentation, found out its being removed: looking forward for the updated videos and documentation.

----------------
77.2:


hi @Sahil2308 
We are aware that the that the FormatterOptions got removed and the tutorial will be soon updated.
Best,Sini

----------------
78.1:

There are a couple of options:

Set the proxy at the ActiveGate level and add in exceptions for resources that should not use the proxy. https://www.dynatrace.com/support/help/platform-modules/digital-experience/synthetic-monitoring/priv...
Set up a Proxy PAC file with the settings you would like and add this file to the configuration of your Browser Monitors. https://www.dynatrace.com/support/help/platform-modules/digital-experience/synthetic-monitoring/priv...


----------------
79.1:

What's the JS doing? Is it changing somethng on the page? If so, can you make the event wait for that change to complete?
 

----------------
79.2:

@Keith can you provide the details needed so we can close the thread?Thank you. 

 When passion meets people magic and innovation happen. 


----------------
80.1:

Are you trying to use a Private Location for your AG testing an internal app? check with networking to ensure communication is allowed.

	-Chad


----------------
80.2:

@Peter_Youssef Did Chad's answer help you?

 When passion meets people magic and innovation happen. 


----------------
81.1:

Hi @Alex7 You need to pull this kind of information with extension for example ms-sql instance-metrics or mysql connections HTHYos 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
81.2:

Is there such an extension for Postgres?

----------------
81.3:

Yes  (Active connections Number of active connections to all databases running under PostgreSQL)https://www.dynatrace.com/support/help/setup-and-configuration/technology-support/dynatrace-extensio...

	Have a nice day!


----------------
81.4:

If looking for that information client side, there are several J2EE implementations that give you the information by connection pools, namely JBoss, Tomcat, Weblogic and WebSphere.

	Antonio Sousa


----------------
82.1:

At the moment, this is "by design" apparently. I also have a customer struggling with this (they're just using the '#' wildcard in their filenames but also would like to know the concrete filename the entry was pulled from).I'd be curious whether anyone else has an idea.

----------------
82.2:

We have encountered similar issues and disappointment with this.  What completely stumps me though is why the documentation for defining custom log sources under Log File Matching states "Custom log sources can contain wildcards..." when using them may very well break your ability to search the data you just defined for ingestion.  If you use a * anywhere in the middle of the path to the log file the UI will provide a link to your newly defined file as expected.  But here's the challenge, you can't search this new log source.  When you try the UI presents the following message: "Unexpected error: Invalid DQL query: [2,10] MATCHES_VALUE: Wildcard '*" in the middle is not supported".  This can be worked around by playing with the advanced search, but I can't imagine explaining this to everyone at the company that wants to search their data.  I suppose another option/workaround might be fully qualifying the path and filename (removing the wildcard altogether) for every log source that's not automatically discovered but yikes!  I'm going to assume this is all just something I've not given enough thought to yet because I know Dynatrace is better than this.  

----------------
82.3:

Hi Alvin,there are two issues present here:1. If you have custom log sources with wildcards, these wildcards are used to match files, but they are not resolved on UI, i.e. log source name still has wildcards. Shortly speaking, this is good for some use cases, and bad for other ones. Having acknowledged these shortcomings, we came up with an idea to allow for decorating log records with an additional attribute carrying the origin file name. This is planned for CQ4'23. The solution is decided so there is a high chance to deliver it as planned.2. You cannot use a '*' character in the middle of a log query. This character is interpreted always as a wildcard (which is not the intention here but would work in most cases) and the wildcard is allowed only at the beginning and at the end of matched value. We have a story to provide a possibility to mask the wildcard character to match it literally which would cover your use case, but unfortunately we do not have capacity to implement it in CQ4'23, at least for now. A workaround is possible in most cases. You can use "'prefix*' and '*suffix'" instead of "`prefix*suffix'" condition. I am aware that is not very elegant.

----------------
83.1:

ActiveGate extensions in EF1.0 use Python 3.8, however, you don't have to worry about that, as it comes bundled with the ActiveGate regardless of what other versions you have installed on your server.

----------------
84.1:

Hi @gauresh_shinde, The answer is no, You can get the voucher by attending the event hosted on 31 October APEC by amplify powerup Thanks

----------------
85.1:

Hey @agrawal_shashan ,Is it possible that the ActiveGate you're set up is not correctly linked to your tenant, as in, there is no communication to it somehow? Does it appear if you search for it under Deployment Status -> ActiveGates? And does it have the AWS module enabled? For your second question, it is the ActiveGate itself that connects to your AWS account, polls the metrics from AWS Cloudwatch and then sends them to the Dynatrace cluster - everything happens in the ActiveGate.

----------------
85.2:

Hi @victor_balbuena Thanks for the response. So right now I have an EC2 instance in a AWS account (XYZ) where I have also deployed Dynatrace Active gate. This EC2 instance has connectivity open to our Dynatrace Managed Cluster.And in Dynatrace UI also I am just trying to connect to this same AWS account (XYZ) for now but it gives me that error which I pasted. Just trying to understand when I click on connect, what happens? Does Dynatrace managed cluster tries to connect to AWS or is it Env Active gate on AWS tries to pull the metrics from the same account?FYI.. AWS module is enabled on the Env Active gate.

----------------
85.3:

Hey @victor_balbuena I was actually connecting from wrong Dynatrace Env but I rectified it and now trying from the correct tenant/env. But now I am getting a different error which says "Invalid Credentials".Also below are the logs from Env Active gate -2023-10-02 09:09:34 UTC INFO    [<XXXXXXX-XXXXXXXX-XXXXXX>] [<vtopology.provider>, RoleCredentialsProvider] Cannot obtain CLIENT short term credentials for arniam::XXXXXXXXXXXX:role/Dynatrace_ActiveGate_role ; AWSCredentialsImpl {identifier: XXXXXXXX, accessKey: null, secretKey: null, tenantUUID: XXXXXXX-XXXXXXXX-XXXXXX, iamRole: Dynatrace_ActiveGate_role, accountId: XXXXXXXXX, externalId: *****, label: Dynatrace Integration, partition: aws, detectedPartition: aws, monitorOnlyTaggedEntities: false, includeTags: [], excludeTags: [], excludedRegions: [], logConfigSQSesEnabled: false, logConfigSQSes: [], version: 2.0, legacyServices: [ebs_builtin, lambda_builtin, ELB_builtin, loadbalancer_builtin, s3_builtin, dynamodb_builtin, ec2_builtin, asg_builtin, rds_builtin], services: []} [Suppressing further identical messages for 10 minutes]
com.amazonaws.SdkClientException: Unable to execute HTTP request: Connect to sts.amazonaws.com:443 [sts.amazonaws.com/209.54.180.124] failed: connect timed out
        at com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleRetryableException(AmazonHttpClient.java:1219)

2023-10-02 09:09:34 UTC WARNING [<XXXXXXX-XXXXXXXX-XXXXXX>] [<vtopology.provider>, AWSFastCheckCallable] Credentials refresh failed: {status: ERROR_BAD_CREDENTIALS, statusInfo: Service failed to assume role provided in credentials, credentials: AWSCredentialsImpl {identifier: XXXXXXXXX, accessKey: null, tenantUUID: XXXXXXX-XXXXXXXX-XXXXXX, iamRole: Dynatrace_ActiveGate_role, accountId: XXXXXXXX, externalId: *****, label: Dynatrace Integration, version: 2.0}, exception: com.amazonaws.SdkClientException: Unable to execute HTTP request: Connect to sts.amazonaws.com:443 [sts.amazonaws.com/209.54.180.124] failed: connect timed out} 

----------------
85.4:


When you click on connect, it's the ActiveGate reaching out to test the connection to AWS, so it acknowledges the connection works before it's set up. Dynatrace Managed is not involved in this step. Once it is set up, the ActiveGate will try to send the data to Dynatrace Managed, but Dynatrace Managed does not reach out to any resource ever.As per the issue, we are falling into AWS teritory now, so it might make more sense if some expert from AWS takes a look or you talk to Dynatrace support directly. Having said that, something you can look into is the outbound security rules of your EC2 instance (where the ActiveGate is running), to allow for requests and data to leave the ActiveGate.

----------------
85.5:

Hi @victor_balbuena Your information has been immensly helpful. Thank you very much.Again looking at this documentation it says "Make sure that your Environment ActiveGate or Managed Cluster has a working connection to AWS. Configure your proxy for Managed or ActiveGate, or allow access to *.amazonaws.com in your firewall settings." And in the logs I can see its trying to make a connection to sts.amazonaws.com:443but failing. Trying to understand if it is the Active gate which tries to make this connection?Best Regards,Shashank

----------------
85.6:

Yes, it is the ActiveGate in this case 

----------------
85.7:

Hi Agrawal,Did you change MonitoringRoleName after upload YAML file from github role_based_access_monitored_account_template.yml in Stack Details? In your screenshot I see in field "IAM role that Dynatrace should use to get monitoring data":Dynatrace_ActiveGate_rolebut in default is:Dynatrace_monitoring_roleBest RegardsPaweł

	"The lion does not ally with the coyote"


----------------
86.1:

Hi @lucas_hocker 
the standard way of ignoring certificate errors does not work yet. In the next month you should be able to use the https node module which which you should be able to skip the certificate check for a reuquest.
Best,Sini

----------------
87.1:

Don't let the Professional expire. Somewhere it says that if that happens, you have to start from the Associate again...

	Antonio Sousa


----------------
87.2:


It's in the University:  

	Antonio Sousa


----------------
87.3:

Exactly...I too once missed the renewal date of my PRO certificate and had to go through the whole path again.

	Have a nice day!


----------------
87.4:

@AntonioSousa is correct, unfortunately this means that you'll have to start with associate again, as your initial associate certification is probably older than the professional. Also, if you retake professional (regadless of if its a renewal or if you start from associate again) you will have to do both the written and practical again. So unfortunately this would mean 3 exams before you can be on your way to master 

	A Dynatrace Professional nerd working for Eviden


----------------
87.5:

My humble opinion: there should be a grace period of, say, 6 to 12 months after Professional cert expiry, where you can retake the Professional exams without starting from Associate. If you have successfully passed the Professional cert within the last 3 years, IMO the Associate exam is trivial; basically a formality.

----------------
87.6:

In my way of thinking is easier to get all five AWS certs instead get Dynatrace Master certified.Main reason is that AWS Certs requires no human interaction. It all depends only on you, your knowledge, your skills, your experience, your passion. It is impossible to win the game - where there are no clear rules for victory and defeat.It is better to set real goals and achieve them.Good luck!

	DT_NGINX_ALL_WHITELISTED=1


----------------
88.1:


You can use the Dynatrace API to automate the process, but you will need to build the logic into whatever script or job you decide to run to delete them.So the steps would be:Get all maintenance windows with the Settings API v2 using the builtin:alerting.maintenance-window schema ID.With the list of IDs, get every maintenace window via the same Settings API v2, different endpoint .For each maintenance window, dive into the body response of the call and check if the scheduleType is ONCE and if the endTime is in the past (we ignore recurring maintenance windows since they are never expired).If the above verifies, save the ID of the object and make one last call to the Settings API v2, delete an object to delete it.It's a bit complicated, but it's the only way as the maintenace window doesn't have an expired field or something else we can check apart from the one mentioned above.

----------------
88.2:

Yep this works. @victor_balbuena thanks for quick help

----------------
89.1:

This seems very interesting! Going to check it out when I have a little time.

	Antonio Sousa


----------------
89.2:

Thanks @pahofmann for sharing, sure will be useful. I cant find the way to get the json files.  

	Sharing Knowledge


----------------
89.3:

You can get from from the API Explorer. 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.4:

Hi @pahofmann ,How can I download the collection from the github ? 

	Sharing Knowledge


----------------
89.5:

The collections are saved as .json files in the repository. You can either copy them from the specs folder or just download the whole bundle from the releases page.

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.6:

Thanks a lot man Good day  

	Sharing Knowledge


----------------
89.7:

Updated to 220, including cluster APIs.

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.8:

With one of the recent Postman version the UI changed a bit.  The environments can now be found in the left side menue:  

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.9:

Yes, i used this version after my last post Thanks or your update.Very Useful

	Sharing Knowledge


----------------
89.10:

Latest Release updated to Version 1.226 (Cluster API 1.224)

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.11:

It was very much helpful and this acts as a utility to have. It saves a lot of time while working with customers. Thanks for sharing.

	Love more, hate less; Technology for all, together we grow.


----------------
89.12:

Updated to 1.234: Github Link. 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.13:

top nodge, we are currently working on an API v2 version for integration to Splunk , having this so visual in postman really helps. works like a charm.

----------------
89.14:

Update to 1.248: Github Release Link.  Also automated the process so future updates can be more frequent or be done by the user if in a hurry.

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.15:

Updated to 1.250: Github Release Link.  Also there is a Insomnia Version now: Community Thread  -  Github 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.16:

hi @pahofmann the links on your initial page are now not working (404), I guess because of the update? (pahofmann/dynatrace-postman-collections: Summary of postman collections for all dynatrace APIs. (git...

	Kind regards, Frans Stekelenburg                 Certified Dynatrace Associate | measure.works, Dynatrace Partner


----------------
89.17:

Thanks, updated  

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.18:

Thank you x 2 ! 

	Kind regards, Frans Stekelenburg                 Certified Dynatrace Associate | measure.works, Dynatrace Partner


----------------
89.19:

Updated to 1.258 (Environment) and 1.256 (Cluster): Github Release Link 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.20:

Updated Env and Cluster to 260: Github Release Link 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.21:

Thanks for keeping this updated.

	The true delight is in the finding out rather than in the knowing.


----------------
89.22:

@pahofmann  thank you for maintaining this and please keep posting as you make updates. This is a very useful solution you've created here.

	HigherEd


----------------
89.23:

Thanks, always nice to hear. Will do.

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.24:

Update to Environment 1.270 and Cluster 1.268: Github Release 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.25:

Updated to Environment/Cluster 1.274: Github Release. 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
89.26:

@pahofmann Firstly thanks for this its to truly helpful. Is there a way I can get the metadata / manifest file for the API's. In OCI DI you have to create a REST API task that requires you to add a json or yml manifest file for the API you calling. 

----------------
90.1:

@sivart_89,Not seen one before like that.The errors you are seeing seem to be on the ActiveGate side. As metrics are flowing in, seems it might not be impacting measurements.Maybe it would be better to open a Support ticket, Dynatrace should be able to dig into your other log lines and find out what the problem might be.

	Antonio Sousa


----------------
90.2:

Definitely would suggest to open a support ticket. We would need more details in addition to this log line. Generating support archive might be very helpful.

----------------
91.1:


Direct monitoring via OneAgent is not possible.You can use the built-in JMX extension to extract the required parameters. On the GemFire side, you need to run the JMX support (https://docs.vmware.com/en/VMware-GemFire/10.0/gf/managing-management-jmx_manager_operations.html).Please note that such an operation consumes DDU licences.Radek

	Have a nice day!


----------------
92.1:

Hi,There is API/endpoints that accept OTeL You can check them under the link:https://www.dynatrace.com/support/help/extend-dynatrace/opentelemetry/getting-started/otlp-export But I recommend using some collectors to minimize traffic:https://www.dynatrace.com/support/help/extend-dynatrace/opentelemetry/collectorAs of installing OneAgents on personal laptops/workstations - I would highly discourage You from that.The each workstation will be utilizing Licenses, Each will need access to ActiveGates or Dynatrace (network traffic).The best approach would be to test it out on test environments rather than Dev Personal devices.Still technically You can install OneAgents on them if You really want to - using exactly the same procedure as on servers. Hope it answers all questions.

----------------
92.2:

Thank you Michal for your quick feedback and response. Let me go through this solution and will revert back if I need any additional feedback/support.Thank you again for your support

----------------
93.1:

Hello,
Would you be able to specify a bit more which service specifically? Are you trying to do the following step of creating an aws policy for dynatrace to be able to ingest cloudwatch metrics directly from aws?
https://www.dynatrace.com/support/help/shortlink/aws-monitoring-guide#aws-policy-and-authentication
Thank you

----------------
93.2:

Hi, I have followed all the steps for the integration of AWS services to Dynatrace. I also already ingested the cloudwatch metrics. However when I want to add another service (e.g. sqs, s3 bucket, etc.) I get error but checking the credentials, policies and yaml file, those services are enabled in the policy.Thank you

----------------
93.3:

I'm having the same issue trying to add additional AWS services. If I don't add any services, AWS saves fine, but when I try to add anything additional, I get that error.We just turned on Grail, I wonder if this has something to do with it.

----------------
93.4:

Having the same issue when I try and update default services by adding s3

----------------
93.5:

I'm having the same issue when trying to connect other AWS services.Is there any solution for this?

----------------
93.6:


Hi All,I used 'Management Account ID' in AWS organization menu as ActiveGate account ID and it works now

----------------
94.1:

Hi @AntonPineiro  I agree with you. Searching/filtering in this tab is very hard and you have to look for everything manually. A filter option would be useful. Community Team do you have the option to enable filtering there?

	Have a nice day!


----------------
95.1:

Thanks for this question, I was wondering the same thing too

----------------
95.2:

Hi,Are you talking about configurations as dashboards, alerting profiles... ?If yes, you can use Monaco.Best regards

	Consultant


----------------
95.3:

Hi Anton,I'm basically trying to use Dynatrace on the Community page itself. I want to get the data from our vendor's API to our internal Dynatrace API. However, the access to Khoros API is limited, I can't create any pipeline, I can only send calls to it. In this scenario, is it still worth it to look into Monaco? I just wanted to ask this question before I read all about it.

----------------
95.4:

Hi,Monaco is only to be talking between Dynatrace APIs between environments.I do not know if your use case can be done inside Dynatrace. I would to do it outside Dynatrace using some program language to pull information from Khoros API, parse or extract what you want, and push to Dynatrace API.Best regards

	Consultant


----------------
95.5:

I'm not familiar with the Khoros API myself, but reading about it for 5 minutes, it seems to be able to return data in JSON format for various statistics. If this is what you're trying to get in Dynatrace somehow (hopefully in the form of either metrics or logs) seems like an extension is the way to go. It will read the data from the Khoros API, modify it to the Dynatrace format and ingest it directly.Or as @AntonPineiro suggests, do it outside of Dynatrace.

----------------
96.1:


You can't do this with out-of-the-box functionalities of Dynatrace unfortunately, at least until your tenant gets moved to DPS, where you will have new metrics with a lot more freedom. With current consumption metrics, you need to have an extension or a script that calculates the consumption per application (or usually, management zone) by using these metrics and then ingests the calculated consumption back into Dynatrace.With DPS , new metrics will appear in Dynatrace which you can easily split by Management Zone by default.

----------------
96.2:


For host units, you can use a simple script which will provide you with a host unit metric split by host. Unfortunately, this is not built into the product.For DEMs and DDUs there are metrics already. For DEMs you need some calculations as metrics are session based , not DEM units based.Assuming you have management zones set up (or tags at least) per application, then you can put this data on the dashboard (Dashboard classic) and filter it by Management zone or tag in Data Explorer.  

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
97.1:

Thanks @MaciejNeumann. Great policy!@MaciejNeumann wrote:Dynatrace Community focuses on user-to-user interaction; it’s a place where we can exchange information and learn from each other to become better professionals. 100% agree with your statement.There is a new tag to identify such content?

	The true delight is in the finding out rather than in the knowing.


----------------
97.2:

Hi @DanielS,At this moment, we won't introduce a special label for AI-generated content, but we'll monitor the situation and introduce one if needed.And, as always, all users can report inappropriate content to us if they notice something breaking the Community rules.

	If you have any questions about the Community, you can contact me at maciej.neumann@dynatrace.com


----------------
98.1:

There is no way to get the graph as an image via the API, unfortunately. Since the dashboard export provides always one page, the only solution I can think of your problem is to divide up your dashboard in multiple dashboards, one for each graph maybe, and export each one individually - then merge them. I would suggest a product idea for your use case, but given that dashboards classic is going away for the new grail platform dashboards, I doubt they will allocate any resources on it.

----------------
98.2:


I know it's a workaround, but try the Chrome add-on: GoFullPage - Full Page Screen Capture.I use it often, for reports for my clients.

	Have a nice day!


----------------
99.1:


There's a couple of solutions that come to mind.One way is to install the OneAgent along with the ActiveGate and monitor the ActiveGate process with it. The upside is you have a lof of visibility into the ActiveGate thanks to the OneAgent but the downside is that it will consume licenses. Some people are afraid this is not possible, but it's absolutely compatible to have both on the same machine.Another solution is to use the built-in metrics for self monitoring, like dsfm:active_gate.communication.agent_modules.connected. You can create metric events for this metric for the host.name or dt.active-gate.id dimensions, and alert when data is missing or the value is 0, which could indicate a problem. The upside is it costs no licenses and it's a built-in solution, the downside is you have to create the metric events yourself and make sure they are configured correctly with the host names or active gate IDs you're interested in. You can obviously also use any of the other dsfm:active_gate metrics to monitor your ActiveGates in many different ways (CPU, Memory, network, agent load, etc.).Hope this helps.

----------------
99.2:

Thanks @victor_balbuena But adding OA will cost HU, adding custom metric ,which I was also thinking about, will consume DDU Actually we are looking for something more strait forward  like the OA alerts on system notifications Yos 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
99.3:

The second solution does not consume any licenses, metric events do not consume DDUs, and the metrics I mention above are not custom metrics, they are built-in, so they also do not consume DDUs.

----------------
99.4:

Understood, forgot about the ability to set the alert on missing information.Tried it and its works, thanks !Yos 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
100.1:


Hi @elenaperez,regarding pulling the container image and then pushing it to their private repo, it will be pulled from the environment and it will contain the environment configuration.if you are searching for a reusable image that doesn't contain any configuration related to your environment, I think you might find it in the below linkhttps://www.dynatrace.com/support/help/setup-and-configuration/dynatrace-activegate/activegate-in-co... 

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
101.1:

Hi @Jamz ,would please provide some details, are you facing this in Managed or SaaS, classic dashboard or new dashboard?is it possible to provide some samples with screenshots?

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
102.1:

Hi @Keith_Harding ,Please note that Dynatrace OneAgent doesn't cache the data to avoid making utilization issues on the monitored server, that's why it's recommended to use the ActiveGate and to be installed closest to OneAgent with fewer/no firewall points between them, as the ActiveGate bundles OneAgent Traffic and is not limited to that, you can find more details here regarding ActiveGate purposes and functionality. and check ActiveGate acts as a secure proxy as wellalso, I think it would be better as well to check and understand the Network Zones Best regards,Mohamed Hamdy

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
102.2:

Dynatrace OneAgent does cache data. I say this from experience, and even yesterday I had one case where I had infrastructure data for several hours, before the agent connectivity was back up. The application modules/subagents seam to have a different behavior, also from empirical observations.I'm not sure if the data that @Keith_Harding references is still valid, because it's some years old, but would love to know more details.

	Antonio Sousa


----------------
102.3:

Thanks Antonio, thats great real world info.It would certainly be a good to see an official answer.  Some of the info I saw was "we don't cache because we don't want to use to much resource on the machine"  which makes sense but as you say in some cases it does cache.I also heard that they may drop metric granularity as the time unable to connect grows - that makes sense.You pont about different behaviour per module makes sense.  Caching some metrics is probably low disk need but caching traces and logs could require a lot of disk evry quickly.Thanks for your thoughts. 

----------------
102.4:

Thanks Mohamed, much appreciated.  For anyone else looking I also found out:If connection is lost data doesn't get dropped immediately. OneAgent has 10 MB buffer, whereas, Activegate has 100MB buffer. Until these are full, data isn't dropped.There is no pushback mechanism from ActiveGate to OneAgent. ActiveGate buffers are larger and compressed.Data can be lost if buffers are full. However, this rarely happens. Summary metrics take up small sub-sections of the buffer and retained to ensure data loss doesn't happen. Granular metrics are more likely to be lost and deprioritise in the event of an inability to connect with clusters.Dynatrace also has automated monitoring and alerting of conditions where large numbers of OneAgents stop sending.And this is a previously similar question:https://community.dynatrace.com/t5/Dynatrace-Managed-Q-A/Does-OneAgent-or-ActiveGates-retain-data-wh... 

----------------
103.1:

You can use the DEMO but i think you will not be able to do what you want https://{environmentid}.apps.dynatrace.com/ui/

	Dynatrace Professional Certified


----------------
103.2:

I wrote my own http server to handle this, I never saw a solution for this. 

----------------
103.3:

Hi @WilliamSca , You can use the trial for this, https://www.dynatrace.com/trial/

	Site Reliability Engineer @ Kyndryl


----------------
103.4:

Do you mean the Python SDK for extensions? If so it comes bundled with oneagent_simulate_plugin.
Or do you mean the Python SDK for tracing Python applications?

----------------
104.1:

Could the Exchange Server extension help with this?

----------------
104.2:

Nobody for help me?

----------------
104.3:

Do you see anything in the logs when this scenario occurs? If so, perhaps you could use Log Analytics/ Log Monitoring: https://www.dynatrace.com/support/help/observe-and-explore/logs
 

----------------
104.4:

I've searched for similar in the past but Dynatrace does not monitor such things. I'm not sure of the term here but it's what tools like Exoprise do, not Dynatrace.We started to go down the route of MS Graph API and even monitoring the MS Regional Health public monitors.  Neither solution can get you the detailed, real-time metrics you need from a third-party perspective.  In order to do this you will need some direct trigger or event monitor. Some fancy business process rule in Dynatrace that somehow uses Application Monitoring to ensure the QR codes are being picked up at the same rate the emails are going out.  Every time your application sends an email, capture it in Dynatrace as the first leg of your conversion process. Then monitor the number of requests you receive for picking up the QR code. Have Dynatrace monitor the delta between these two numbers and if too large send an alert because it would indirectly indicate the emails are going out but not being received because the QR codes are not being accessed. Outside of the above, we have an internal test that schedules an email to go out every 1 hour to a tool named Healthcheck.io.  If an email is not received every 1 hour the alarms go off.  This isn't the best solution because there are 300,000 Microsoft email servers around the world and our test could cross a healthy server while the critical email crosses an unhealth server. We'll never get alerted.  This is a fundamental issue you can't do anything about by simply monitoring Office365 exchange servers.  You essentially need to turn your email process into a TCP like transmission vs a UDP.

	HigherEd


----------------
105.1:

At the moment, tokens use their own scopes so you can't use policies on them, that's correct. I could see the benefit of being able to provide policies for API tokens as well.The only workaround today is personal access tokens which inherit the permissions of the user that created the token, so this means also the policies attached to the customer.

----------------
105.2:

Using personal access tokens is difficult because it would require some kind of technical user which we don't have. It's not the biggest deal off course since we treat tokens as secrets. But if one would leak, it would give access to all settings while it could be restricted.

----------------
106.1:

The GitHub page has some more details and it seems it is not possible through the [[outputs.dynatrace]] configuration section: https://github.com/influxdata/telegraf/tree/master/plugins/outputs/dynatraceAny ideas?

	Antonio Sousa


----------------
106.2:

Looking further at the Telegraf configuration, it seems it can be done with "namepass".Anyone managed to limit data ingestion by this or other way?

	Antonio Sousa


----------------
107.1:

Hi @gilles_tabary You can check and allocate the maximum ingest of log events per minute in CMC at environment setting.By click on the refresh cluster limit you will have the CLUSTER level overall limit. It can be splitted by the environments. in this example the cluster limit is ~ 168k (based on the memory and cpu capacity). Env1 has 140k / minute, Env2 has 20k Env3 has 8k... With these two metrics you can monitor and alert the incoming or rejected logs:dsfm:server.log_and_events_monitoring.events_incoming_count:splitBy():sum:sort(value(sum,descending))dsfm:server.log_and_events_monitoring.events_rejected_count:splitBy():sum:sort(value(sum,descending))I hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
107.2:

Thanks. I new about that already. Any thing about the actual question ?

----------------
107.3:

You should probably consider increasing the maximum number of log events per minute regardless, as per Mizső's message, but to answer your original question:The message you see about logs being trimmed doesn't always mean that your logs are actually being trimmed. It is a message generated by the DAVIS AI which could be over-reacting by seeing a spike in log ingest and thinking that logs will need to be trimmed, even if there is no data loss. So basically, we need to understand if this is the case, or data is being trimmed for real.The way to do this is to check, as per the first case, if your log events are being trimmed to the maximum set for the environment. If this is the case, you need to increase the maximum to avoid data loss. If logs are not really reaching the maximum set for the environment (or maybe only once or twice in a row), then the case is that DAVIS AI is calculating, because of a spike, that there will be too many logs, even if this is not true. In this last case, there will be a delay in log ingestion (hence why increasing the maximum is still advised), but no data will be lost.Hopefully that helps you understand which one is your case.

----------------
107.4:

Hello.Interesting point about Davis. Thanks.After much chating, here is my understanding. Say trimmed warning in CMC has a timestamp equal to 10:23:12. In the log viewer, set time frame exactly to one hour long from 09:23 to 10:23. Then, watch the graph (i.e. the plot). Don't search or try to filter for a special kind of log line, i.e. log events, especially attribute "dt.ingest.warnings" or table format field named "trimmed"  are not to be used, this is not where to look at or what to search for. On the graph, check how high the bars reach. Each bar shows on a one minute interval the number of log events ingested. This is what could be compared to the "Maximum number of log events per minute" set in the CMC. If bars consistently (many minutes in a row) reach approximately this Maximum (not higher, not lower) it may show there could be a problem indeed. If bars are higher than this Maximum it shows (as stated by @victor_balbuena) that all events got eventually ingested, but with a delay. If bars are lower : no problem.Let me know if this is an acceptable statement (otherwise I'll correct it as to not induce confusion in readers.  )I feel the FAQ doc coud be amended with maybe decorated screen shots, stating explicitly where to look at exactly, what to expect, what not to expect, what could be considered as a confirmation of the problem, or a confirmation there is no problem. Regards.

----------------
108.1:

While there are a lot of people that has helped me both personally and professionally over the years, I'm going with the one person who influenced me the most out of everyone, my mom.My parents separated when I was 3 years old, and while they had split custody of me and my older sister, I was always drawn to stay more with my mom. She worked as a nurse initially, but later took the step to start her own company, traveling all over the world to give lectures about Dementia.She has since retired, but my entrepreneur spirit and drive to help people whenever I can undoubtably comes from her and all that she did for myself and my sister.  

----------------
108.2:

Thanks a lot for sharing this story, Mike  This is a wonderful inspiration.

	Keep calm and build Community!


----------------
108.3:

Years ago a family friend got me into Computers. As a young child we built 4 boxes, it was these afternoon builds afterschool that really sent me into the technology field.  
In terms of Dynatrace, my Wife and @andreas_grabner have inspired, motivated and pushed me to develop unique solutions, use cases and methods inside of Dynatrace. If it wasn't for their support, I don't think I would be so involved with Dynatrace and the Community. I will be forever thankful for their support and the support of all the great Dynatrace Associates and customers I have met over the years as each and every single person has played a role in where I am today. 
In the Dynatrace Community, @Karolina_Linda  was very influential in my community activity. I remember back when I  started in the community at my first Dynatrace Organization. Looking for solutions to unique problems to which at times I couldn't find written solutions. Karolina drove me to not only solve these problems but then formulate documentation on it for the rest of the community. My first 'how to'  in the community was the documentation on how to set up the Dynatrace UFO for customers who were managed. My documentation was the first for Managed Customers which was the spark that propelled me to where I am now in the Community, all thanks to Karolina and her efforts. Over the years she has developed an amazing team of Community Administrators all of which I have interacted in some fashion. 
My Wife, @andreas_grabner and @Karolina_Linda thank you for your inspiration and motivation which has propelled me to where I am today. I will forever be grateful and cherish our friendship! 

	-Chad


----------------
108.4:

Ohhh, thank you Chad for your kind words! 
You've been the Community team's motivation throughout all these years! I'm grateful for having such a helping hand in the times when there was no Community team, always providing feedback, catching issues faster than the lightening, and simply being supportive 
I'm also very grateful for the friendship we've built! 

	Keep calm and build Community!


----------------
108.5:

I am over 30 years old and I really know that I have a long way to go, to learn, know, and trip on. I started my journey in IT at 17/18 years old when I was a student, but the public person who had most influenced me and I learned a lot from his biography was Steve Jobs. I remember his presentations like the first iPhone, after time I viewed the presentation of the first iPod, and it was amazing the form this person share a story, the revolutionary of the industry.Then I learned from his book and videos about his biography and every time I deeping into his history I always learn something new.I think Steve Jobs, Steve Wozniak, and Bill Gates were the top of the IT industry since the 70s/80s and they marked the pathway to a new generation.

	-César S. - LATAM Solutions Architect


----------------
108.6:

As a child I read Leon Uris's Battle Cry , the powerful descriptions of turning young people from different backgrounds into a unit of combat soldiers and continuing "see" them struggling on battlefields, gave me a different perspective on how to overcome obstacles and reaching goals in my life. 10 yeas ago, while I was already a senior systems analyst in information systems department of a large insurance company,  I met, in the elevator, one of our business client, he looked at me and said: "Listen Yosi, you must reinvent yourself" punched me on my shoulder and left the elevator. I was stunned for few moments, but in next few weeks I thought about this sentence again and again. Then I realized that I really have nothing more to contribute in the field of systems analysis .... A year or so after this evaluator conversion, I found myself starting from scratch to learn a different angle of IT, this time it was monitoring ......

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
108.7:

An interesting challenge indeed! Because there have been so many Guru's in my life! And that's the problem: naming one or a few, seems so injust for the remaining!Anyway, probably the one that I cite the most is the President of the Institution,  at the time where I started my first real professional job. He's not amongst us anymore, but he really pushed us/me to some great realizations some 30 years ago! Besides being President of that Institution, he was very good technically. So we were doing remote working in 1995, not only at home but anywhere in the country with GSM. We were also already experimenting with "paperless office" at the time... And we were taking networking to it's limit, and guess what? The main tools that were helping me achieve that, were monitoring/observability tools of the time. No kidding!His name was Fernando Mendes.

	Antonio Sousa


----------------
108.8:

A little controversial these days, but I should remember Mr. Richard Stallman and free software movement started decades back. It has allowed me to think and seeing things from a different angle.Thank you for freedom to learn new things, studying what is happening behind the scenes and sharing knowledge with others.

	Consultant


----------------
108.9:

This is a very good highlight! The open-source movement is really a great inspiration in the last 3 decades!

	Antonio Sousa


----------------
108.10:

Throughout my professional journey, several individuals have inspired me and helped me become who I am today. Even though they might remain anonymous to you, I will mention them as they have been colleagues, mentors, and sometimes even friends to me:Hassan and Clement (managers) taught me not to underestimate myself and to highlight my work.Pascal (CTO) taught me not to let myself be walked over.Guillaume made me dream with his pre-sales vision, his technical expertise, and imparted an effective work methodology to me.I hope to someday contribute as much as I have received.

	Observability consultant - Dynatrace Associate/Pro/Services certified


----------------
108.11:

A great challenge this month. I do not have a reference in capital letters, but throughout my life I have learned many things from a large number of people with whom I have been related, even from those who are not a role model I have learned the value of some things that we take for granted.I am honestly very grateful to the entire Dynatrace community, all the community team, my fellow Dynamights, the Dynatrace team, all the active members of the community. From all of them I learn different things every day and I am not referring to the content but to values such as perseverance, drive to face challenges, team spirit, recognition among many other values. I am very proud to be part of this group of people from whom I acquire new values.On a personal level, I agree that children are a constant source of learning. As well as many values that my parents gave me. I can't imagine that I would be the person I am without their dedication and effort.And of course, I would also like to add, as a fan of reading, all the positive things that books can bring.

	The true delight is in the finding out rather than in the knowing.


----------------
108.12:

 The people who made a big impact on my journey were my family (Mom) and my mentors, bosses. My mother always trusted and believed in every professional decision I made, even if she was afraid that I would get into trouble she always believed in me and gave me all the support I needed, so in my list of people who inspire me she comes number 1, she worked harder than anyone I know. I love you mom and thank you for everythingSecond comes my  3 mentors. When I was 19 years old and entering this market, with little vision, my mentors saw potential in me and gave me all the tools I needed to develop as a professional, they taught me lessons that no college could, a few months ago I got my professional certification, something that seemed so far away when I started, I just have to thank my team and those who bet on me and believed and say that you were rightNOTHING RESISTS HARD WORK.The next step is master and Dynamight certification, and I hope to meet and be inspired by my fellow forum members.and of course inspire many people in the future 

	Dynatrace Professional Certified


----------------
108.13:

I'm a huge believer in every person entering our lives for a reason, so I'm grateful to everyone who's only briefly crossed paths with me, walked along for some time, or keeps me company on my journey to this day 
But if I has to highlight one person who made the biggest impact on my life, I would have to go with my Dad. He taught me to be curious, to question everything, be bold, and brave, and true to myself, to love books and history and know their worth, and to smile even when it seems like it's the end of the world. But most importantly, he taught me what true Humanity is.
The struggle always brings truth about people to the surface, and the war in my country made me reevaluate a lot of relationships, but not the one with my family  It was so easy to just give up and spiral into fear or depression, but instead he chose to focus on helping people. He's volunteering since day one, and us (my sister, my mom and me) were never more proud of him! 
 A "clipping" from the local newspaper about his initiative A "tiny" army of trench stoves (they stopped at 1000!) he and other volunteers made last year.
And on the happier side of things, my dad at his favorite's band concert 
 
He also taught me a thing or two about good music 

	The only constant is change. Finding ways for great things to happen!


----------------
108.14:

Lovely words, congrats to every great Dad!!!

	The true delight is in the finding out rather than in the knowing.


----------------
108.15:

In terms of Dynatrace my former coach @jeroen_peperka1, who answered a lot of my Dynatrace question (especially during the first months),dragged me into the Dynatrace rabbit hole and became a good friend (yea I hope he feels the same :D).Also, @henk_stobbe (our mighty DynaMight) and @michiel_otten (former community member of the month) who almost always know the solution and help out wherever they can within the team - even if its not for their own customer or credits.And lastly, @Mr_Bluethumb, my very first 'coachee' whom I was allowed to teach Dynatrace to from the very first minute onwards (well okay I'll admit we also shook hands before), kept challenging me with questions and who can stand more than perfectly well on his own feet now - and even solves my RegEx problems.

	A Dynatrace Professional nerd working for Eviden


----------------
108.16:

Hi!,
Throughout my life, my mum has been an unwavering source of support, guidance, and inspiration, playing a crucial role in helping me achieve my goals. Her influence can be traced back to my earliest days, as she nurtured my curiosity and encouraged me to explore the world around me. In my formative years, my mum was my first teacher, instilling in me the values of hard work, determination, and resilience. She recognized my strengths and weaknesses, gently pushing me to embrace challenges and learn from setbacks.
 
Nowadays my career is moving on because of my colleague Sebastian Krystosik (@skrystosik) who showed me that every successful person should be constantly developing to achieve goals. He gave me a helping hand when I looking for a job and now he is supporting me to become a better employee and Dynatrace Guru 

	"The lion does not ally with the coyote"


----------------
108.17:

Thx nice words  I missed that post before 

	Regards, Sebastian


----------------
108.18:

Hello Team, The most important and valuable person is Mohamed SAW. But after that a lot of people in my life: my Grand parent. Have a good day.BRs,

	Sharing Knowledge


----------------
108.19:

Before beginning my graduation, I had decided that I would pursue my childhood love, technology. So, every step in my life was aimed at realizing that dream. A few months into my studies, I noticed there were many subdivisions, so I took some time to study and become familiar with some of them that had caught my attention. After this "sabbatical period," I realized what I truly wanted, and then some companie really believed in my abilities and taught me all the necessary steps. They turned me into who I am today, probably one of the youngest certified to achieve professional certification at just 20 years old. This opportunity has taken my career to a new level, and I am deeply passionate about the Dynatrace platform and the community. None of this would have been possible if my mentors didn't believe in me. I am truly thankful for everything, especially @natanael.

	Dynatrace Certified


----------------
108.20:

we made it boy, proud of you

	Dynatrace Professional Certified


----------------
108.21:

Hello All,Lets keep it very short. My Guru, and for me still the king of Appmon (-;  Andreas Grabner!Still creating great online content, in which he always explains everything clear and understandable. I think it is a combination of teaching, story telling and passion. He is always exploring one topic at the time, at a  very precise level so you understand it.  Giving you enough knowledge to  start using it yourself and  explore further.    So for me, if there was a Dynatrace hall of Fame.........KR Henk

----------------
108.22:

My Guru, who introduced me to the incredible platform Dynatrace approximately 6 years ago, illuminated the path not only for me but also for countless others with his inspiring approach and unwavering enthusiasm.I would like to nominate Ibrahim, Mohammed as the "GURU" He is helping everyone to learn, explore our potentials and reach to the new heights. Under his guidance, our team has flourished, amassing nearly a hundred adept Dynatrace consultants from India. Collaborating with him has not only been professionally enriching but has also led many to regard him as their revered "GURU," sought after for invaluable career counsel. 

----------------
108.23:

I don't have any specific Guru in my life... what I have the most are 'anti-gurus', if we could call them like this, lol.I learn with their mistakes, and try to avoid their steps to be successful.I do have lot's of people that inspired me doing the right thing, but I definitely learn lot more with those which failed.Please don't see this as a bad thing (or pessimist). Failures are part of the system, and I think I learn way more with them.I do learn with the people which receive lots of lemons from life.

	Site Reliability Engineer @ Kyndryl


----------------
108.24:

That's definitely a way to learn  cheers to all the anti-gurus out there! I'm a huge fan of being just as honest about your failures, as about your victories. Let people around you learn from yours and make their own!

	The only constant is change. Finding ways for great things to happen!


----------------
108.25:

Hi,From a young age, I was fascinated by maritime transport, perhaps because my father is a sailor. The person who served as a role model for me was Captain Karol Olgierd Borchardt. Captain Borchardt was known for his exemplary leadership and extensive experience in the maritime industry. He not only instilled in me a deep appreciation for the sea but also inspired me to pursue my dreams.Thanks to his influence, I initially set my sights on becoming a seafarer, but the birth of my son prompted a change in my career path. I decided to shift my focus to the world of Information Technology (IT), which had always been my second passion. This transition allowed me to be closer to home and avoid the long periods of absence associated with a maritime career.In the field of IT, one of my guiding lights has been Ivan Alexander Getting. Ivan Getting is renowned for his significant contributions, including the invention of the Global Positioning System (GPS). His groundbreaking work in GPS technology has revolutionized navigation and positioning worldwide, demonstrating the immense impact that one individual can have on technology and society.As for my current role model, I won't reveal their identity, but I've come to understand that sometimes we don't have to look far to find inspiration. This individual holds a special place in my life, reminding me that meaningful role models can be found in those closest to us, guiding us on our journey through life.Radek

	Have a nice day!


----------------
108.26:

My Ideal person whom I call GURU is "Mr.Rakesh" who shaped me during my childhood (My school teacher - Mathematician)."Mrs.Anita (College professor) who understood my capabilities and bring out my stage fear.In profession my Guru is Andreas Grabner whom I admire the most. Still lots of learnings from his content.Cheers!RN

	Dynatrace Certified


----------------
108.27:

For me it would definitely be my parents, for all the hard work and sacrifice they made for me is something I would always be indebted to. They are also both teachers so they are also the one who taught me the basics before I started school as a kid. We had a big combined family with aunts, uncles and grandparents but they set a good example for me how to not only maintain work life but also family. 

----------------
108.28:

Each journey in my life has its own experience and Gurus that I have met, and definitely, my parents and my wife are at the top of the list as they are always the source of support.as for my Dynatrace journey, I would like to thank my colleagues, and community members, and special thanks to my Dynatrace role model @thomas_brandl

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
108.29:

For my personal life, My mother was my guru that pushed me through my educational life and in collage, also supported my hobbies and interest in IT world.In Dynatrace world, i always see @ahmed_el_jafouf as a Dynatrace hero, his support and encouragement since 2015 made me eager to go deeper into Dynatrace world. Also the rocking star @thomas_brandl who doesn't hesitate to provide any help at any time.

	Dynatrace Certified Professional - Dynatrace Partner - Yourcompass.ca


----------------
108.30:

Thanks for the kind words, Islam! Working with you is always inspiring and enjoyable 

----------------
108.31:

Lots of people have come and gone in my life, and many have made a big difference to my journey. Some have even inspired me. I've got to give a shout out to @miro_subasic , who is a great mentor and a top-notch leader when I first started at my current job. And I can't forget the impact of books and talks from folks like Brian Tracy, The Dalai Lama, and Khalil Gibran. I try to read every day, and it's amazing how many different people, from all sorts of backgrounds, can give you a fresh perspective or a bit of inspiration.

	WHomES


----------------
108.32:

Thank you Koen for the kind words. Really happy and glad to have on our team

----------------
108.33:

From a Dynatrace perspective: @andreas_grabner @andreas_grabner  @andreas_grabner He has inspired me and so many in this community.  Starting with his podcasts to all the other videos he does.  He is a great communicator and looks like a natural.  

	Dynatrace Certified Professional


----------------
108.34:

For me is Linus Torvalds   On August 25, 1991, he sent the historical email to comp.os.minix asking the community members about the features they’d like to see implemented in his OS.His vision of collaboration, open source, and community is what makes him a great person and they are some of the things that I admire.> yes Guru god level. Any doubt?

	IT Master | dynatrace Certified professional | SRE Certified | Scrum Certified | Azure Certified | https://www.linkedin.com/in/rodrigocuevas/


----------------
108.35:

Oh my: "it probably never will support anything other than AT-harddisks" 

	Antonio Sousa


----------------
108.36:

There is no doubt everyone around us can be our Guru's. Regardless of what we may think, we don't know everything, and that's why I try to learn from everyone around me. That being said, I can definitely name a few that have been (and some are still) playing an important role model to me.I'll start with my parents. Their ability to put a side all difficulties and enjoy life, insist on moving forward, despite all obstacles, insisting on being independant have thought me not to give up on anything. My father's experience in business management taught me how to be a manager and how to make clear and rational decisions.There was also my first CEO, who taught me how to deal with software products and how to speak to customers and show values. There are many more and some of them you may know, but I would love to take the opportunity and give a big kudos to a friend of mine, a Dynamight himself, who is my guru in his eagerness to learn all the time, in his commitment to customers and yet his commitment to his family, and this is @Yosi_Neuman . So big Kudos to you Yos. When I'll grow up, I want to be like you 

----------------
108.37:

I'm speech less ......  

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
108.38:

Yosi, full respect 

	Have a nice day!


----------------
108.39:

There's definitely a countless amount of individuals who've inspired me along my journey, and no amount of words can express my gratitude to them for how far I've come. With that being said, there are few and far between who have stuck out, the most prominent being my uncle. My Uncle: When I was younger, I had a fairly large interest in fantasy books and technology. My uncle took notice of this and continuously gave me gifts that would help nurture these interests, and continuously encouraged me to follow these goals to create things. Through a combination of imagination and science, he was able to show me that anything was possible - even if it is outside of the realms of what most people believe. We created video games, engineered things out of Legos, and so much more. To this day, much of what he's not only taught me, but been involved in has allowed me to not be afraid of my own creativity, and to embrace different ways of thinking to not only challenge myself, but help others. 

----------------
108.40:

I think its great if you have someone to look up to and there are important people in all of our lives - but I do not want to post some "Guru" here. I think it is far more important to try to be the best version of yourself, as this will help all of us the most.

	iOS help: https://www.dynatrace.com/support/help/shortlink/ios-hub


----------------
109.1:


Hi. Both settings are connected. In order to monitor Go statis processes:In Settings the option "Enable Go static application monitoring" must be enabled.Rule #47 must be disabled.Also there is in Host settings a Go section where you can enable Go statisc monitoring only on individual hosts. Also in this case is needed to disable Rule #47.   

----------------
109.2:

Hi @joseandrescalvo,Thanks very much for your explanation and help.Best regards,Mizső

	Certified Dynatrace Professional


----------------
110.1:


Yes, those two refer to the same thing. I don't believe there's any other videos, or better resources for it than what you already linked, just the blog post (which has less information imo).

----------------
110.2:

Hi Victor thank for confirmation - I was a little bit confuse at the beginning.Do you know if after adopting such solution I'll still be able to integrate other kind of monitoring that are not on Azure? (Suppose that I want that kind of agreement but after a while I realize I also need to monitor something legacy in my datacenter)Regards

----------------
110.3:

You mean, monitor other assets outside of Azure in Dynatrace? Absolutely, Dynatrace aims to be a single pane of glass for all your monitoring needs after all 

----------------
110.4:

With that same SAAS environment ID right?(Sorry don't want to give anything for granted)

----------------
110.5:

Yes, within the same SaaS environment ID, you can monitor all your Azure assets with this integration, or any other, and include all your local datacenters as well as any other providers (like AWS or GCP) if needed(No problem, it's the right thing to make sure everything makes sense  )

----------------
111.1:

Hi,for debugging such an issue I would suggest to open a support ticket at https://support.dynatrace.com/But I can give some hints to validate before:1% is a pretty low traffic control value - so if you have more Android users than iOS it might happen that this 1% is mainly filled with Android users as session selection is based on random and not OS familyThere is a webrequest related limitation between Dynatrace and Firebase Performance Monitoring: https://www.dynatrace.com/support/help/platform-modules/digital-experience/mobile-applications/instr...Strange thing is the difference between TestFlight ans AppStore release, as there should not be any difference, as you can use the same build.

	iOS help: https://www.dynatrace.com/support/help/shortlink/ios-hub


----------------
111.2:

I have created a separate dashboard just for our iOS app to see if 1% was the reason. However that didn't solve the issue either.I am using Firebase only for crashlytics but I disabled the performance monitoring just in case. It didn't help.

----------------
111.3:

Please open a support ticket so we can have a closer look.

	iOS help: https://www.dynatrace.com/support/help/shortlink/ios-hub


----------------
111.4:

@enum when your issue is solved maybe you can share a solution with other users? They would be grateful to have some hints if a similar issue will appear. 

 When passion meets people magic and innovation happen. 


----------------
112.1:

Hi @alejandro_herna ,An example can be found on the GitHub link on how to configure the .yaml file here:https://github.com/dynatrace-oss/cloud-snippets/blob/main/aws/role-based-access/role_based_access_AG...Given that you are attempting to do this with AWS, this should suffice as a starting point.Cheers,Taylor S.

----------------
112.2:

Thanks, but I need an example for multiple accounts

----------------
113.1:

But what do you want to push to splunk from DT? User Sessions? Problems via Webhook? Sebastian 

	Regards, Sebastian


----------------
113.2:


Hi Sangeetha,The easiest way to do this is to set up the Dynatrace App for Splunk and the Dynatrace Add-on for Splunk.The Add-on is responsible for executing the rest API calls and collecting the data from DynatraceThe App provides a collection of dashboards and saved searchesThe Dynatrace Add-on for Splunk contains four distinct input types.Timeseries Metrics: a pre-defined collection of Dynatrace metrics that feed the App's dashboards as well as ITSI’s APM Module (Note: by default the Dynatrace App for Splunk assumes all data is written to a "dynatrace" index)Entity: Selectively choose which entities to collect data for (Applications, Services, Hosts, Processes &/or Process Groups)Problem: Details about problems that Dynatrace detects within a given environmentTimeseries Single Metric: Any single timeseries metric that Dynatrace tracksSee links below for details Dynatrace App for Splunk Dynatrace Add-on for SplunkThanksNJ

----------------
113.3:

Hi, has anyone been able to send the user session data from dynatrace to splunk? using the app and the add-on?

----------------
113.4:

We are currently using the plugin, but I'm really more interested in exporting user session data.  I've been told to point DT to Splunk's endpoint.  Still trying to determine what that is.

	Dynatrace Certified Professional


----------------
113.5:

@sebastian k. @William S.Have you guys been able to figure this out? Like you, I'm trying to push user session data from DT to Splunk but I'm trying to figure out how to set up an endpoint in Splunk. I was able to do this with ElasticSearch easily, but I'm having difficulties with Splunk. 

----------------
113.6:

Hi guys, this may be what you need: https://docs.splunk.com/Documentation/Splunk/latest/Data/UsetheHTTPEventCollector#HEC_functionality_...

----------------
113.7:

It seems the plug-in does not permit to request USQL API but only timeseries ...Any update on this ?

----------------
113.8:

Is this plugin use v1 or v2 api on Dynatrace?

----------------
113.9:

Do we have a solution for importing Splunk logs into Dynatrace?

----------------
113.10:

Hi,You have these options to ingest logs into Dynatrace.Best regards

	Consultant


----------------
113.11:

Thanks) I know these DIY options,I am looking for a DYNATRACE solution like an extension or ready-to-go scrips.

----------------
114.1:


Hi Lucas, 
we have an item on our roadmap that will address your issue. We expect to deliver this in CQ3 this year.
Best regards,
Florian

----------------
114.2:

Hi Florian - 
I was wondering if there is an update on this feature,
 
deb

----------------
115.1:


Hi davide_piras, The resource parameter is simply to let dynatrace SSO know that the token will be scoped to a particular account as users can be on multiple accounts.  What you see is URL encoded.  It will look something like this:  urn:dtaccount:00000000000-0000-0000-000000-0000000000000 where the "0"'s would be replaced with our account UUID.  Once you make the request you will get a JSON payload payload with a field called "access_token".  You can copy this and paste it into the the swagger and run the request. Thanks,Ryan

----------------
115.2:

Thanks Ryan, the documentation page doesn't only have that error, also the scope to be used is not:scope=account-idm-read+account-idm-writebut the correct value is:scope=account-idm-read account-idm-writewithout a plus, I got help from the consultant in the in-product chat, i understand url is encoded but as it is not clickable anyway and values should be replaced, that page would be more helpful if explaining clearly in details which value in each parameter for instance with a screenshot from Postman, SoapUI or whatever other http client... anyway all worked now for me and i could successfully retrieve that token. Thanks,Davide

----------------
115.3:

Hi Davide, I really appreciate the feedback.  I'll take this back to the team and see if we can come up with some simpler explanation. Cheers!Ryan

----------------
115.4:

Hi, I have the same problem, is not working for mehttps://www.dynatrace.com/support/help/shortlink/account-api-authentication#request-a-token  

----------------
116.1:

Hi,I would say yes if you that file is reachable. It means, if you can make a JavaScript code to reach content in that file, and paste it in that field.Best regards

	Consultant


----------------
116.2:

Do you have a sample of the Java Script code I can test?Regards,Mustafa.

----------------
116.3:

How is the file getting updated? Is it another monitor that is creating the booking reference and this one does something with it? If that's the case, you might be better using the Credential Vault. So the first monitor could create the PNR and use the Credential Vault API to update an existing credential, and then the 2nd monitor can just reference it. 

----------------
116.4:

Do you have an example?Regards,Mustafa.

----------------
116.5:


In the first script, store the PNR value in a Credential Vault entry. CREDENTIALS_VAULT-xxx is the credential vault entry where you are storing the PNR, CREDENTIALS_VAULT-yyy is the token needed to update the crdential vault entry. 
api.startAsyncSyntheticEvent();
var PNR = yourPNRvalue;
url = 'https://yourTenant.live.dynatrace.com/api/v2/credentials/CREDENTIALS_VAULT-xxx';
pdata = '{  "name": "YourCredentialName",  "type": "TOKEN",  "token": "' + PNR + '"}';
api.info(pdata);
fetch(url, {
        method: 'put',
        body: pdata,
        headers: {
            'accept': 'application/json; charset=utf-8',
            'Content-Type': 'application/json; charset=utf-8',
            'Authorization': 'Api-Token ' + api.getCredential("CREDENTIALS_VAULT-yyy", "token")
        }
    }).then(function(res) {
        ResponseCode = res.status;
        api.info("responseCode = " + ResponseCode);
        return res.text();
    })
    .then(function(data) {

        if (ResponseCode == 204) {
            api.finish();

        } else {
            api.fail('Update failed: ' + ResponseCode);
        }
    })
    .catch(e => api.fail(e));
Then in the  second script you can retrieve the PNR and set a variable with it to be used elsewhere in the script
var PNR = api.getCredential("CREDENTIALS_VAULT-xxx", "token");

api.setValue("PNR", PNR);

----------------
116.6:

@Mustafa_ERZURUM did it help you?

 When passion meets people magic and innovation happen. 


----------------
117.1:

Looking forward to the next steps. Integrating metrics will be a vital aspect of the transition from the Old Dashboard to the New Dashboard. It will be intriguing to observe how DQL functions in conjunction with the 'Split by' feature, especially when utilizing TAG values. In our current dashboards, creating panels is incredibly user-friendly and doesn't require any coding. I'm eager to see how this process will evolve.

----------------
117.2:

Hi @alter I have good news preview, synthetic metrics are already available in Grail as a preview. Interested in trying it? please, reach out to your CSM and ask him about contacting me regarding that topic. I'll be happy to have a call with you, to run quick demo and discuss your needs
 
Best Regards,
 
Jacek
 

----------------
117.3:

Hello @Jacek_Janowicz , is there an update on when RUM and Synthetic metrics will be available in production?

----------------
117.4:

Hi @heybeckerj 
Most likely synthetic metrics in Grail will be released as GA with new Synthetic Monitoring application. As mentioned above subset of those metrics is available as a preview. Are you interested in call to discuss enabling it for you ? Best Regards,
Jacek

----------------
117.5:

Hello @Jacek_Janowicz , yes please. I would appreciate that

----------------
118.1:


Hi @veranikabarel ,
which version of the @dynatrace/strato-components-preview package do you use?
I just tested it with the latest version 0.104.1 in a CodeSandbox, and there it works: https://codesandbox.io/s/vhj56f

----------------
118.2:


"0.99.3", I will upgrade the version and try to import, thanks!

----------------
119.1:

Great write up. Really helpful info. Thanks Patrick. 

----------------
120.1:


I think you're confusing terms here, what you're using in your screenshot is a metric selector, which doesn't use DQL. Inside that metric selector, you're using a filter which follows the syntax <dimension, value> where dimension is the metric dimension to filter by and value if the value used to filter that dimension. The value seems to look fine, as it's an entity selector that selects some specific process group instances. However, the dimension is wrong as the metric builtin:tech.jvm.memory.gc.suspensionTime does not have a dimension with value builtin:tech.jvm.memory.gc.suspensionTime. Instead, your filter should look like: filter(and(or(in("dt.entity.process_group_instance",<value>), since dt.entity.process_group_instance is an actual dimension of the metric.

----------------
121.1:


I am unsure if this is what you're looking for and if you want to refer to the timestamp of each event in terms of a metric, but if you select Synthetic sessions in the top of a browser monitor, this will show all recorded synthetic sessions like this.   If you select one, you get the timing of each synthetic event. Is this what you are looking for?

	A Dynatrace Professional nerd working for Eviden


----------------
121.2:

@marina_pollehn,Yes, thanks! Was concentrating on the screen that has the events / screenshots, and totally forgot about the session data!Going to put in a Product Idea so that for each measurement there can be a link to the session.Edited: Product Idea here: https://community.dynatrace.com/t5/Product-ideas/Link-from-a-Synthetic-measurement-to-the-correspond...

	Antonio Sousa


----------------
122.1:

@GregOReilly Your last paragraph sounds like a great RFE. I am still quite new to Grail but maybe our other community members that have more experience in Grail can lend you a hand with formulating the query 

	-Chad


----------------
122.2:

I tried to figure out any way to get log size distribution, but there are no good options. You can get the events count, but not the size - there is no direct correlation between the number of events and total size as the sources differ.The only way to actually see the size is to check the small info button: But using this method, to get a distribution of log sizes by log source, we will have to query the data for a large period for a particular log source, and write it down. Then query the next log source, and write it down, etc. This is nuts! It won't show anomalies in sizes over some days, and if we need to split even further (by pod/container/etc/error level) - again run 1 query at a time and write it down.  There isn't a single command or function that would actually return the size. It seems like it is intentionally hidden, as obviously the size is known (see above) + there is a parameter limiting the amount of data to fetch: Anyone got any ideas how to gather the stats? It is important for license management and keeping the sizes in check

----------------
123.1:

This is a very spot-on description of the new search.If you know exactly where to find something and what it is called - then you might 'find' it - but then - why even bother to search? Some stuff is still not searchable and you are better off just clicking by guessing than using the search.You really need to work on this - a lot.If it ain't broke don't fix it. 

----------------
123.2:

Hi Nathan, thanks for your feedback! We're aware about the need to "simply search for hosts" or similarly prominent artifacts. We're do plan to improve the current search experience for entities in Grail and we'll provide further details, once an update is available.

----------------
123.3:

For many people at my company, we used the old search quite religiously for learning - finding things in Dynatrace we never knew existed there before. Maybe we know a service name (or part of one). Maybe we know the prefix to a host name, but nothing more. The old search was like one-click to Universal Searching Awesomeness.I have lots of folks that are avoiding switching to the new GUI simply because they miss/love the old search.

----------------
123.4:

Hi all. Thanks for the feedback. We're aware of the limitations you're facing, and are working on improving the experience. It seems like most of the feedback is about searching across multiple entity types simultaneously. In the meantime, while we're working on improvements, I recommend typing ">" followed by "Entities" to search across a selection of common entities. We have similar 'umbrella' categories for "Kubernetes" and "Applications". If there is a need for additional 'umbrella' categories – please provide feedback on those that would be most useful to you.
 
@uhh you mention that "Some stuff is still not searchable" – can you please provide some details on which categories/sources are missing, and I can confirm if these are on the roadmap. 
 
@nathan_tennant you're right, the docs were outdated. They should be fixed now. 

----------------
124.1:


Hi,You can use the Table tile on the dashboard and, once you have selected the correct measure, split it by host name or host group:  

	Have a nice day!


----------------
124.2:

Thank you so much, man. Very lucky and happy to see you again.  

----------------
124.3:

You're welcome 

	Have a nice day!


----------------
124.4:


Here is another way looking for process that starts with admin:builtin:tech.generic.mem.usage:filter(and(or(in("dt.entity.process_group_instance",entitySelector("type(process_group_instance),entityName.startsWith(~"admin~")"))))) :parents:splitBy("dt.entity.process_group_instance","dt.entity.host"):sort(value(auto,descending)):limit(100)   

	Dynatrace Certified Professional


----------------
124.5:

Hi, friend.This is really good.

----------------
125.1:

Hey WellPP,Maybe someone else has a solution but I cannot find one at the moment with DQL. Metrics on Grail is not quite GA so there are a lot of missing metrics. For a full list of available ones, you can find that here: Built-in metrics on Grail | Dynatrace DocsUsing the classic metric selector, to do what you're looking for I'd make the request associated with checking out a key request which would allow you to graph the errors using the following metric keys.builtin:service.keyRequest.errors.fourxx.countbuiltin:service.keyRequest.errors.fourxx.ratebuiltin:service.keyRequest.errors.fivexx.countbuiltin:service.keyRequest.errors.fivexx.rateAlso regarding SRG, it supports SLOs which support the classic metric selector.Hope this helps!

----------------
126.1:

Hi @danielD I can see these two examples. Fist is the Saas, the second is the Managed format.https://{your-environment-id}.live.dynatrace.com or https://{your-domain}/e/{your-environment-id}I think the first could be https://{your-environment-id}.apps.dynatrace.com in case of SaaS with the new look.Best regards,Mizső

	Certified Dynatrace Professional


----------------
127.1:

Thanks for sharing @Kenny_Gillette 

	The true delight is in the finding out rather than in the knowing.


----------------
127.2:

Thanks Kenny! This is good info to have on hand. 

----------------
128.1:

Thank you!

	Have a nice day!


----------------
128.2:

These are some good tips, cheers. 

----------------
129.1:


Hi @natanael_mendes I think if you push back events or metrics about the tests via DT API endpoints the answer is yes. Dynatrace and load testing tools integration | Dynatrace DocsOtherwise if you use only request attributes for analyse the tests I thnik the answer is no, becasue there is not any external data ingestion to DT.Dynatrace and JMeter integration | Dynatrace DocsI hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
130.1:

You can do this on the host level Take a look on the documentation pagehttps://www.dynatrace.com/support/help/platform-modules/infrastructure-monitoring/hosts/configuratio... go to host>settings>anomaly detection

	Dynatrace Professional Certified


----------------
130.2:


If you are looking to impose an alert criteria on a process that runs on a host and alert on the process consumption outside of the host overall consumption, it can be done via Custom Metric Events:  go to settings>anomaly detection>Metric Events - and add one in  

	-Chad


----------------
130.3:

hi Chad, i have setup'd Custom Metric Events, to generate alerts for generic.cpu.totalTime , but i'm observing the alerts are raised for the The Process total CPU time value of 0 µs.i have applied Static threshold of 14Mins, still the alert are raised for The Process total CPU time value of 0 µs was above your custom threshold of 14 min.Can you advise, what settings or attributes can be configured to alert only when the CPU time cross the threshold 

----------------
130.4:

Can you share a screen shot of the metric event you created? It should look something like this:   

	-Chad


----------------
130.5:

please see the snaps attached

----------------
130.6:

Sorry for the delay, been pretty busy today. The reason why you are being alerted even at the 0 Upsidedow "h"s is because you have selected to be alerted on missing data. I suspect that there is occasionally a delay in the metrics being passed for example its looking for data every 1 min, 8:00 data arrives, 8:01 no data, 8:02 no data - At this point an alert is triggered, 8:03 current data and missing data from 8:01 and 8:02 shows up, giving you the illusion there was no gap in data but there was. Turn off the alert on missing data and see if your problems go away. 

	-Chad


----------------
131.1:


From support:Based on feedback from our lab, this was the timeline of changes, and indeed some changes would have affected your cluster version: Before OA 1.267, network drives were not monitored on Windows.In OA 1.267, Windows network disk monitoring has been introduced. That's why the network share metrics are showing up.As soon as that version was rolled out to our customers, we discovered that the implementation was causing multiple problems, so we decided to disable it again with a debug flag temporarily.We made multiple improvements, and the whole feature will be reenabled in OA 1.277. We hope this helps explain the situation. Going forward, if you do not want to have network drives monitoring, we can disable it by setting a debug flag. Alternatively, you can update OneAgent to a newer 1.267/1.271/1.273/1.275 version that just sets it by default. Please let us know which route you'd prefer to take, and if there are any questions.

	Dynatrace Certified Professional


----------------
132.1:

Question for clarification here on this - what exactly do you mean by up or down? There are a couple of visualizations that are available OOB from the classic dashboards. If you can describe what visualization you're looking for, we could look for a solution from there.  In terms of if a status is UP or DOWN, that could also depend on what you categorize as up or down for your specific environment (percentage of availability that classifies it as such).  For now, linking this here to look into: https://www.dynatrace.com/support/help/shortlink/available-tiles#visualization-types

----------------
133.1:

Hi,Leider kann ich dieses Mal nicht teilnehmen. Ich komme die Nacht vor dem Treffen aus dem Urlaub zurück und 6 Stunden Fahrt sind dann nicht mehr drin :(. Wird so ein Treffen öfters stattfinden? Eventuell auch in der Norddeutschen oder Westdeutschen Region? Ich finde das Treffen wirklich eine tolle Initiative. 

	A Dynatrace Professional nerd working for Eviden


----------------
133.2:

Hi,
wir werden uns bei dem ersten Treffen die Karten legen, wie wir weitere Usergroup-Treffen organisieren. Mal schauen, was der 12.10. an weiteren Ideen und Vorschlägen mit sich bringt. Gern informiere ich Dich danach bilateral über das Ergebnis und das weitere Vorgehen.

----------------
134.1:


Hi @MSK Its look like your esayTravel is not connected to your tenant as it shows dynatrace  At least with windows installation, If it is connected it should show your environment version  I would recheck the settings in easyTravelConfig.properties to ensure the connection  HTHYos 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
134.2:

@Yosi_Neuman , Thanks for your response. I have updated the config files as suggested do we need to add the token as well? config.apmTenantToken?If yes what capabilities this token should have.  
config.apmServerProtocol=https://{environmentid}=live.dynatrace.comconfig.apmServerWebPort=443config.apmServerPort=443config.apmServerWebURL=https://{environmentid}/live.dynatrace.com config.apmTenant=<abc1234>config.apmTenantToken=?

----------------
134.3:

HI @MSK You do not need to set the APM part, just the dynaTrace one.This is how  easyTravelConfig.properties looks at my installation  HTHYos 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
134.4:

Hi @Yosi_Neuman , I have updated the dynatrace configuration as below .. still the real user traffic is not getting generated.    

----------------
134.5:

Ammmm, @MSK do you see any errors on the log file of weblauncher.sh ?  

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
135.1:

If, as your post mentions, this is just about extensions 2.0 in Dynatrace, you just need to update the extension and its related activations in the Dynatrace UI, the new version is downloaded from the cluster automatically by the ActiveGate or OneAgent and you don't need to worry about that part of the process. These two buttons on the UI are enough, which you can also trigger via the API for further automation. 

----------------
136.1:

i think yes, cause dynatrace can monitor all dependencies across your environment. but if no, you can create a custom service or a custom extension. Take a look on these documentation pages https://www.dynatrace.com/support/help/platform-modules/applications-and-microservices/services/serv... https://www.dynatrace.com/support/help/extend-dynatrace/extensions

	Dynatrace Professional Certified


----------------
137.1:

You can find a test exam and training materials in the Preparation tab of the Associate Certification in Dynatrace University: From my own experience, practice is your best ally. If you have access to a Dynatrace environment where to try things out, just try out all of the settings in Dynatrace and understand how they work. Also, just take some time to read through the Dynatrace Help pages to see everything that is doable with the product. 

----------------
137.2:

I totally agree with @victor_balbuena .If you have time and any demo \ Free trial environment the best option to deploy simple application with classic tiers ( web - app - db) and have Hands-On.Your own experience and practice will immediately remove any complexity from 75% of the questions.The exam itself is very simple if you have worked enough with the product.Good luck on the exam!Alex Romanenkov

	DT_NGINX_ALL_WHITELISTED=1


----------------
137.3:

Hello,i don't have full access for Dynatrace Demo trial Community/university please let me know, how can i get full access , please suggest or help me to get it 

----------------
137.4:

Ideally, you should set up a ticket used the Univesity request type and describe your problem. https://support.dynatrace.com/

	Have a nice day!


----------------
137.5:

You should be able to get a Dynatrace SaaS environment trial through dynatrace.com, if you haven't used it up already: If you have access to demo, it's still worth checking all the settings and see what they do, even if you can't create/modify them. 

----------------
137.6:

Hello, I have created and using but I am unable to change and modify them, please help me,Please check screen attached

----------------
137.7:

You probably need to give yourself permissions, then. Which is a good first thing to learn towards the Associate exam On the bottom left of your screen, go to Account Management, choose your Dynatrace account, and on the top bar, choose Identity Access and Management -> People. On this new section, click on the triple dot on the right for your user, and choose to Edit user. Make sure to select all the groups needed, but Monitoring Admin should be enough: Save, give it a couple of minutes, and see if that solves the issue. More about user permissions here: https://www.dynatrace.com/support/help/managed-cluster/users-and-groups-setup/user-groups-and-permis...

----------------
137.8:

Hello,I am unable to find settings, please help me. please refer attached snap.  

----------------
138.1:

Why I got this error:  2022-02-02 19:06:29 WebLaunche WARN [DocumentStarter] Exception occurred while opening URL: http://localhost:8094/. Exception: Cannot run program "firefox": error=2, No such file or directory

----------------
138.2:

Hi EveryoneI had the same error: "WebLaunche WARN [DocumentStarter] Exception occurred while opening URL: http://localhost:8094/. Exception: Cannot run program "firefox": error=2, No such file or directory"My Fix:I figured that firefox was not install on my VM. I ran "yum install firefox" (as root) then relaunched my weblauncher "./weblauncher.sh" and the error stopped popping up. Hope that helps

----------------
138.3:

Hello,I have installed the Easy travel app in windows 10 but i can't find the link for Dynatrace .exe file for download and install, could you please share link for me to download and use. 

----------------
138.4:


It worked. 

----------------
138.5:

May you explain how you did it? im having the same issues: sudo ./weblauncher.sh[sudo] senha para mardata:fev 11, 2022 10:55:45 DA MANHÃ com.dynatrace.diagnostics.uemload.utils.RentalCarsGenerator generateUserFileINFO: Creating files with Rental Cars.fev 11, 2022 10:55:45 DA MANHÃ com.dynatrace.easytravel.spring.PluginNotificationConfigFileGenerator generateConfigFileINFO: Creating pluginNotificationConfig.json file.2022-02-11 10:55:46 WebLaunche INFO [Init] -----------------------------------------------------------------------------2022-02-11 10:55:46 WebLaunche INFO [Init] easyTravel Demo Application - Copyright (C) 2010-2022 dynaTrace software GmbH2022-02-11 10:55:46 WebLaunche INFO [Init] -----------------------------------------------------------------------------2022-02-11 10:55:46 WebLaunche INFO [Init] Procedure: WebLauncher2022-02-11 10:55:46 WebLaunche INFO [Init] Version: 2.0.0.33732022-02-11 10:55:46 WebLaunche INFO [Init] Build Date: Fri Jan 21 09:38:55 WAT 20222022-02-11 10:55:46 WebLaunche INFO [Init] Platform: Linux 5.13.0-28-generic, amd642022-02-11 10:55:47 WebLaunche WARN [PluginFinder] Specified classpath directory 'C:\Program Files\IBM\WebSphere MQ\java\lib' not found or is not a directory.WARNING: An illegal reflective access operation has occurredWARNING: Illegal reflective access by org.apache.catalina.loader.WebappClassLoaderBase$1 (file:/home/mardata/easytravel-2.0.0-x64/lib/catalina.jar) to method java.lang.ClassLoader.registerAsParallelCapable()WARNING: Please consider reporting this to the maintainers of org.apache.catalina.loader.WebappClassLoaderBase$1WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operationsWARNING: All illegal access operations will be denied in a future release     ^CStopping HTTP Service Thread and Engine because scenario is not executing any more or a shutdown request was received.Checking Linux headless processes are not left in memorylooking for[/home/mardata/easytravel-2.0.0-x64/weblauncher/../chrome/chromium-browser]or [/home/mardata/easytravel-2.0.0-x64/chrome/chromium-browser]]or [/home/mardata/easytravel-2.0.0-x64/weblauncher/../chrome/driver/chromedriver_linux64]]or [/home/mardata/easytravel-2.0.0-x64/chrome/driver/chromedriver_linux64]Linux Process check completeKilling Chrome processes finished

----------------
138.6:


Try to remove extracted folder and repeat installation again. I am getting problem on "credit card C app whatever" complaining about one lost log. I removed app folder and extracted again and it works.   

----------------
138.7:

I removed extracted folder and repeat installation, and same problem: ./runEasyTravel.shstarting easyTravel===================OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.2022-02-11 16:09:33 Launcher INFO [Init] -----------------------------------------------------------------------------2022-02-11 16:09:33 Launcher INFO [Init] easyTravel Demo Application - Copyright (C) 2010-2022 dynaTrace software GmbH2022-02-11 16:09:33 Launcher INFO [Init] -----------------------------------------------------------------------------2022-02-11 16:09:33 Launcher INFO [Init] Procedure: Launcher2022-02-11 16:09:33 Launcher INFO [Init] Version: 2.0.0.33732022-02-11 16:09:33 Launcher INFO [Init] Build Date: Fri Jan 21 09:38:55 WAT 20222022-02-11 16:09:33 Launcher INFO [Init] Platform: Linux 5.13.0-28-generic, amd64Unable to init server: impossível ligar: Ligação recusadaException in thread "main" org.eclipse.swt.SWTError: No more handles [gtk_init_check() failed]at org.eclipse.swt.SWT.error(SWT.java:4725)at org.eclipse.swt.widgets.Display.createDisplay(Display.java:1040)at org.eclipse.swt.widgets.Display.create(Display.java:1020)at org.eclipse.swt.graphics.Device.<init>(Device.java:175)at org.eclipse.swt.widgets.Display.<init>(Display.java:586)at org.eclipse.swt.widgets.Display.<init>(Display.java:577)at com.dynatrace.easytravel.launcher.LauncherUI.init(LauncherUI.java:74)at com.dynatrace.easytravel.launcher.Launcher.run(Launcher.java:194)at com.dynatrace.easytravel.launcher.Launcher.main(Launcher.java:159)Stopping Engine because shutdown request was received.Checking Linux headless processes are not left in memorylooking for[/home/mardata/easytravel-2.0.0-x64/chrome/chromium-browser]or [/home/mardata/easytravel-2.0.0-x64/chrome/chromium-browser]]or [/home/mardata/easytravel-2.0.0-x64/chrome/driver/chromedriver_linux64]]or [/home/mardata/easytravel-2.0.0-x64/chrome/driver/chromedriver_linux64]Linux Process check completeKilling Chrome processes finished

----------------
138.8:


you must run linux app using sudo ./weblauncher.sh.Locate this script in webapp folder.  chmod a+x sudo weblauncher.shsudo ./weblauncher.sh

----------------
138.9:

Hi Sir ,I run sudo ./weblauncher.shand still run into the same issue .First of all why does it look for Websphere in my local (C:\Program Files\IBM\WebSphere MQ\java\lib) . Please see the exception below . (Note :I have installed the EasyTravel on Ubuntu 20 linux ). Appreciate your help. Thanks 2023-02-17 18:51:02 WebLaunche WARN [PluginFinder] Specified classpath directory 'C:\Program Files\IBM\WebSphere MQ\java\lib' not found or is not a directory.WARNING: An illegal reflective access operation has occurredWARNING: Illegal reflective access by org.apache.catalina.loader.WebappClassLoaderBase$1 (file:/home/ubuntu/easyTravel/easytravel-2.0.0-x64/lib/catalina.jar) to method java.lang.ClassLoader.registerAsParallelCapable()WARNING: Please consider reporting this to the maintainers of org.apache.catalina.loader.WebappClassLoaderBase$1WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operationsWARNING: All illegal access operations will be denied in a future release2023-02-17 18:51:05 WebLaunche WARN [DocumentStarter] Exception occurred while opening URL: http://localhost:8094/. Exception: Cannot run program "firefox": error=2, No such file or directory  

----------------
139.1:

Hello,You need to check the permissions on the VM, seems that the web launcher can't execute the creditcardauthorize process. Thanks,Islam

	Dynatrace Certified Professional - Dynatrace Partner - Yourcompass.ca


----------------
139.2:

Thanks! I tried to install it as root, executed successfully.

----------------
139.3:

Great 

	Have a nice day!


----------------
139.4:


I recommend using ET with root rights (then you will avoid such situations) - unfortunately this software is quite unreliable and generates a large number of problems.

	Have a nice day!


----------------
139.5:

Thanks! I tried as you suggested and was able to successfully run ET.

----------------
139.6:


Hi DXC_Yoshi,
Is the same user (azureuser) is used to install and run easyTravel? easyTravel should not be installed & run as root.
It may help if you send a listing from the easyTravel installation directory (/home/azureuser/app/easytravel/easytravel-2.0.0-x64) containing file owners and permissions.

----------------
139.7:

Thanks to your answer, my problem is solved.

----------------
140.1:


Two OneAgents on one host is not possible.

	Antonio Sousa


----------------
140.2:

I (and @MartijnA) wonder: on Linux (where suchs things are possible), what will happen if you install a second agent in another path. My hypothesis (not tested) is, that the 2nd install does not spot the 1st install nor its configuration, and will come a long way. It's the things like service (start) name configuration and watchdog part where things will become complicated.Bottom line, kids do no try this at home 

	Kind regards, Frans Stekelenburg                 Certified Dynatrace Associate | measure.works, Dynatrace Partner


----------------
140.3:

Hi @soportetr,it's not possible to install two OneAgents on the same host, however, you can use oneagentctl and in your case, you will be using OneAgent communication settingsthe following is an example:Linux or AIX:./oneagentctl --set-server=https://my-server.com:443 --set-tenant=abc123456 --set-tenant-token=abcdefg123456790 --set-network-zone=<network-zone> --set-host-group=<host-group> --restart-serviceWindows:.\oneagentctl.exe --set-server=https://my-server.com:443 --set-tenant=abc123456 --set-tenant-token=abcdefg123456790 --set-network-zone=<network-zone> --set-host-group=<host-group> --restart-servicenote: you need to restart the monitored processes and based on a case that I have faced, I think it will be recommended to restart the server.

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
140.4:

Hi,I agree with @Mohamed_Hamdy last comment of restart of server. I too faced this; and recommend restarting the server. note: you need to restart the monitored processes and based on a case that I have faced, I think it will be recommended to restart the server.

----------------
141.1:


This will be possible, but you will need to integrate Dynatrace with some other automation tool like Jenkins. Basically, the workflow will be triggered by any of the available tirggers, like CPU usage passing a specific threshold, and it will send a request to a Jenkins endpoint that will trigger the restart of the server - Dynatrace will not be able to restart the sever itself.You can learn more about workflows here:https://www.dynatrace.com/support/help/platform-modules/cloud-automation/workflowshttps://developer.dynatrace.com/develop/workflows/

----------------
142.1:


Hi @PrateekGupta I hope it helps: Best regards,Mizső

	Certified Dynatrace Professional


----------------
143.1:

Sorry need to upgrade small mistake we had done Port opening from AG to Cluster node on 443 not for 9998 wrongly posted.

----------------
143.2:

Hi @Siddhesh9,is it possible to provide us with the error or the logs, if this is not possible, I do recommend opening a support ticket and the logs and other details related to the issue.https://support.dynatrace.com/

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
144.1:


The issue is coming from different data types: the source field "affected_entity_ids" is an array, while the lookup field "id" is a string. The quickest fix here would be to use "expand" to break down the array, e.g: 
fetch events, from:now()-24h, to:now()
| filter event.kind == "DAVIS_PROBLEM"
| fields event.start, event.end, display_id, event.category, event.name, affected_entity_ids, root_cause_entity_id, event.status, resolved_problem_duration
| expand affected_entity_ids
| lookup [fetch dt.entity.service], sourceField:affected_entity_ids, lookupField: id

	I had a life once. Then I bought my first computer ...


----------------
145.1:

Thank you @AgataWlodarczyk for this Notice

	-Chad


----------------
145.2:

If there's one thing you can count on, it's google discontinuing something 

----------------
145.3:

can we put this link in the documentation as well.

----------------
145.4:

It's a sad news as we just enabled RUM browser extension monitoring. The timeline section  motioned about Google Chrome only.  Will it apply to MS Edge as well? is Edge a better choice from now on to Jan., 2024? Will MS Edge continue to support RUM extension?

----------------
145.5:

The announcement is for both Chrome and Edge.

----------------
145.6:

This is a big ouch, as we're left with just two options, OneAgent and Agentless 

----------------
145.7:

Sad news, Thank you @AgataWlodarczyk  for this Notice. We are missing one easy way of agentless injunction.

----------------
145.8:

January 2024, will it still be useable or a Hard cutoff? Completely done by Jan 2024? Is it based on a particular version? Old versions that would still have extensions - an old version might still work? Asking for one of my clients that uses SAP C4C. Thanks.

----------------
145.9:

thanks @AgataWlodarczyk for this notice

	Dynatrace Professional Certified


----------------
146.1:


Dynatrace has just announced this feature for all Azure and AWS services. This will roll out in Q2 of this year 

	-Chad


----------------
146.2:

Hi @Chad T.  Do you have any other information on this?  We actually have a slightly different request.  We are using Dynatrace for log monitoring and we previously had Logz.io which had the capability to export our logs to cold storage like AWS S3 so that we could keep them for our 1 year data retention period.  Is this possible?

----------------
146.3:

hey @Michael P. - currently it is not possible in Dynatrace. We have this on mid term RoadMap - unfortunately this will not be delivered in next 6 months.

----------------
146.4:


@bill_scheuernst you can now forward logs from Azure to Dynatrace on SaaS, put them in context, do analytics and set metrics and alerts. Give it a try and let me know what is your feedback. Starting point is here: https://www.dynatrace.com/support/help/technology-support/cloud-platforms/microsoft-azure-services/s...
 

----------------
146.5:

WE have integrated this but the logs are are not connected to the Azure app service traces as in https://www.youtube.com/watch?v=Ac5_aPBx2f0

----------------
147.1:

Currently there isn't an ability for that other then grabbing the API data for All the Defined windows. This would be a great RFE.

	-Chad


----------------
147.2:

@ct_27,Have you been able to solve this, or created a Product idea?

	Antonio Sousa


----------------
147.3:

I never got what I really wanted because DT makes it too difficult. Seriously, they need to over hall their Maintenance module because what they have now apparently is not flexible enough to provide customers the basic capabilities we're asking for and thus every day it's holding Dynatrace back more and more. BUT we built something that's good enough....our own in-house solution (using NodeRed) that sends a daily report at 3:00pm every day with a list of...- Problems OPEN TODAY && are CURRENTLY OPEN- Problems OPEN BEFORE TODAY && are CURRENTLY OPEN- Problems OPEN BEFORE TODAY && CURRENTLY OPEN && have NO ALERTING PROFILE assigned- All other Problems OPEN TODAY && CURRENTLY CLOSED- A list of HOSTS, ExternalSynthetics, Synthetics, HTTPChecks, and HYPERVISOR actively in Maintenance mode.----Where entity has tag with key MM_ON (this is how we manually put things in maintenance mode) This report has been a game changer for us because we visually see repeat bad behaviors.  What I thought Dynatrace AI was supposed to do for us but hasn't.  So we've been able to adjust maintenance windows to improve our Availability, we've noticed systems with errors that repeat on unusual patterns, we've seen related systems report unrelated problems that actually helped us catch unusual issues.  TODO: I have started development of a NodeRed UI to allow for realtime reporting of hosts in maintenance but I took a detour to try and do it the DQL in the Gen3 Dashboard.  Bad idea......I just got myself wrapped around the axel and walked away. Never completing the work. Need to get back to the NodeRed solution.

	HigherEd


----------------
148.1:

 MartinWhat is transaction storage was explained in that thread. https://community.dynatrace.com/t5/Dynatrace-Managed-Q-A/Transaction-storage-on-Dynatrace-Managed/m-...It's stored as flat file, not any database. 

----------------
149.1:

@dannemca I've worked with customers across all types if Dynatrace License models. We have a DPS licensing dashboard, this dashboard is very in-depth and covers all environments with the ability to click into a specific environment and get even more granular with the consumption.   

	-Chad


----------------
149.2:

@dannemca is it enough for you?  

 When passion meets people magic and innovation happen. 


----------------
149.3:

It does helps, but I am not satisfied yet. Let's see if someone else has others examples to share.

	Site Reliability Engineer @ Kyndryl


----------------
150.1:

Hello @lplinsky,It appears there was an error when trying to invite a new user to your account.  In order to triage this, we would need more information:1) The account you were working in,2) When you tried to complete the invite3) The user email you were trying to invite4) The user account you were logged in with

----------------
150.2:


It was some bug on tenant. Dynatrace solved it

	Dynatrace Certified


----------------
151.1:


@DuaneRoelands, seems like a typo in your scopes param, try this:/api/v2/settings/objects?schemaIds=builtin:host.monitoring&scopes=HOST-29200A0CBEF971B4

	Site Reliability Engineer @ Kyndryl


----------------
151.2:

Sometimes the answers are simple.  Thank you!

----------------
152.1:

If you are ingesting your Tags from AWS then you should be able to transmit them via problems into your Service Now Integration as well. 

	-Chad


----------------
152.2:

AWS tags that are associated with problems automatically go into ServiceNow?  Perhaps we aren't seeing any yet because we haven't had any problems in our new AWS environment yet. If that's the case, we will try setting up ServiceNow rules based on our AWS custom tag.

----------------
152.3:

If you are ingesting the AWS tags into Dynatrace - You must have them show up in the Dynatrace Tags section first.  Then you can set your Service Now Integration to include tags:   

	-Chad


----------------
152.4:

My AWS tags do show up in Dynatrace, so that part is good. Do I have to add {Tags} to the ServiceNow Description field in the box above for them to be sent over, or is that automatic?

----------------
152.5:


You will need to add it. Whatever is in the Description is what you will pass into ServiceNow. Remove any of those placeholders, and you will not pass along that data Such as {State} - removing that will remove the "Open" or "Resolved" in the description of the alert in ServiceNow.   

	-Chad


----------------
152.6:

Got it.  I'll give that a try and see what we get when we start seeing problem cards for cloud resources.  Thanks!

----------------
152.7:

Sounds good  

	-Chad


----------------
152.8:

@ChadTurner I came across this post while searching for something similar. We have built integration Between AWS and Dynatrace using oneagent and also tested integration with ServiceNow. As per your post, the tags are showing up in ServiceNow, so all good here. But in order to make proper CI binding in ServiceNow, we will need to also push AWS account ID associated with the resource as a tag/value pair to ServiceNow. I was wondering if there is any options available to add AWS account ID as custom tag either while ingesting data from AWS to ServiceNow (may be through custom processing rule in Settings-> Log monitoring -> processing) or while pushing data to ServiceNow. Please let me know if such a thing is possible.    

----------------
152.9:

I would recommend setting the tag at the AWS level and then ingesting it into Dynatrace. Then as alerts fire via your SN integration the tags will show. Much like its been described in the other comments on this thread. 

	-Chad


----------------
152.10:

Hi @ChadTurner , thank you for getting back on this. This is precisely what was recommended but challenge is that this being an existing environment with 150+ accounts and 10s of applications/teams it would not be possible to get everything on AWS tagged with AWS account ID tag. While we are putting conscious effort to get the tags updated on AWS resources, it will take considerable time/.effort to do that. Even then, there will always be resources which would not be properly tagged.  Thus I was thinking if there is any approach to add tag on the resources in Dynatrace or into the notifications pushed into ServiceNow based on the account associated with the resource which is generating notification.

----------------
152.11:

AWS doesn't have an auto tag feature? Unfortunately even if you were to set a tag in Dynatrace, i dont think its going to be a dynamic value. Meaning if you found the ID in the properties, you might not be able to set it as a value for the tag like you can for say IP Address. AWS side might be the best way if they have an auto tag feature or if you associate an application ID to the entities for your SN CI linkage

	-Chad


----------------
152.12:

There is no such option in AWS to set a default tag.As mentioned in my first post above, I tried setting up a custom rule under Settings-> Log monitoring -> processing to add AWS account ID as an attribute. This way every time a log is ingested from AWS Account account ID is captured as an additional attribute. But I am not sure if there is any way to push this account ID as an additional tag/value on associated resources.USING(INOUT aws.account.id:STRING, content)| FIELDS_ADD(AWSAccount_ID: IF(aws.account.id <> '',aws.account.id))I am trying to see if we can enrich the tags on the resources before they are ingested into Dynatrace 

----------------
153.1:


as you mentioned you are already pulling the step functions via the extension: https://www.dynatrace.com/support/help/setup-and-configuration/setup-on-cloud-platforms/amazon-web-s... If you are looking to get more like tracing I recommend putting in a RFE for extension enhancement. 

	-Chad


----------------
153.2:

We have the same usecase, We are very much waiting for support of Dynatrace supporting AWS step function ,already we are ingesting metrics but seeing end-to-end trace is our top priority.

----------------
154.1:

A colleague pointed out the isNull function to me. The syntax isfetch events| filter isNull(myItem.nonexisting) And this also works when the field does not exist.

----------------
155.1:


Hey Henk,
That's correct, at least for now they are only for Dynatrace. This as we require the extensions to be signed with the Dynatrace certificate due to security concerns of auto distributing python code which didn't go through an extensive security pipeline. If/when that changes we'll announce it with a blog post.
Mike

----------------
155.2:

Any updates on this? We have scripts we would like to deploy. We are kind of back against the wall at this point.

	HigherEd


----------------
155.3:

It is still planned, but we don’t have a timeline that we can communicate yet. The blog post is currently planned for the next quarter.

----------------
155.4:

Do we currently know what the timeline/perspective is to use the Python SDK for Extensions 2.0.?This topic was brought up by a customer of mine during a meeting today. Thanks in advance!

----------------
155.5:

More information will be shared in the next few months.

----------------
155.6:

I would also like this feature!

----------------
155.7:

Hi @Mike_L ! Any updates on this? Also, wouldnt the security be kept by using the signing process which is used on the other Extension 2.0 plugins?

----------------
155.8:

The messaging should go out in the next few weeks.
From a security point of view there is quite a large difference between using the Dynatrace infrastructure to distribute configuration, and using it to distribute any code.
FYI @michal_nalezin 

----------------
156.1:

  

----------------
156.2:

I am having the same issues.The MQ plugin stars as OK, and is fetching data, then it suddenly becomes uninitialized.Any suggestions?

----------------
156.3:

When is the Extension 2.0 MQ monitoring due?

----------------
157.1:


Hi,I am not sure if I understand you but can you execute this in data explorer?builtin:tech.jvm.memory.pool.used:splitBy("dt.entity.process_group_instance"):sort(value(auto,descending)):parentsIf you choose table visualization for example, you should see 3 columns:Hostname.Process.JVM heap memory pool used bytes.Best regards

	Consultant


----------------
157.2:

Hi @AntonPineiro ,Thank you so much for your response on this.  I've tried to execute the query in the Data Explorer and it works like a charm!. Thanks for helping out. I appreciate it!. By the way any idea how do i filter by hostname?.  was trying to use the :filter and eq("dt.entity.host","HOST-001") still not able to get the specific host to be filter. 

----------------
157.3:

Hi @Afrezal_Karim Here is an example for filter host. In this case you should also use parents transformation and filter together.builtin:tech.jvm.memory.pool.used:parents:filter(and(or(in("dt.entity.host",entitySelector("type(host),entityName(~"YOUR HOST NAME ~")"))))):splitBy("dt.entity.process_group_instance","dt.entity.host"):sort(value(auto,descending))Or you can use the dynamic filter on the dashboard as I mentioned before. I hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
157.4:


Hi @Afrezal_Karim @AntonPineiro  answer is perfect. If you would like to provide more extra, useful information about the jvm behaviour to the IT operation guys I reccomend these metrics: suspension time and garbage collection total time. You can also collect some extra jmx metrics at different types of jvms (jboss, tomcat, weblogic etc...) which ones could be useful for IT ops.Eg. at weblogic: hogging thread, pending requests or connection pool metrics waiting threads and failed db connects...   And it could be useful if you use the dynamic filter on dashboards:eg. I hope it helps to provide better service to your teams.Best regards,Mizső

	Certified Dynatrace Professional


----------------
157.5:

Hey @Mizső ,Thats a pretty cool Dashboard you've created. Looks awesome. Do you mind sharing the details of the builtin query keyword that i can use similar like yours ?.  Still learning and trying to understand which one is good to be put in the Dashboard.Again thanks for sharing and and also helping on this. Appreciate it. 

----------------
157.6:

Hi @Afrezal_Karim,These are the metric expressions: In bulilt basic metric:builtin:tech.jvm.memory.gc.suspensionTime:splitBy("dt.entity.process_group_instance"):max:sort(value(max,descending))builtin:tech.jvm.memory.gc.collectionTime:splitBy("dt.entity.process_group_instance"):max:sort(value(max,descending)) WL specific in built:builtin:tech.weblogic.connectionPool.WaitingForConnectionCurrentCount:splitBy("dt.entity.process_group_instance"):sum:sort(value(sum,descending))builtin:tech.weblogic.connectionPool.FailedReserveRequestCount:splitBy("dt.entity.process_group_instance"):sum:sort(value(sum,descending)) WL extra jmx metrics:ext:custom.jmx.HoggingThreadCount.metric_HoggingThreadCount_1601572768674:splitBy("dt.entity.process_group_instance"):max:sort(value(max,descending))ext:custom.jmx.PendingRequestCount_JMX.metric_PendingRequestCount_1601790848493:splitBy("dt.entity.process_group_instance"):max:sort(value(max,descending)) Oracle extension metric:builtin:tech.oracleDb.cd.sessions.active:splitBy("dt.entity.custom_device"):sum:sort(value(sum,descending)) I hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
158.1:

Szia Zoli!Igen. Várunk szeretettel. A helyszín változott, mindjárt lekövetem itt is: Helyszínváltozás: Paulaner Sörház H-1123 Budapest, Alkotás u. 53. (MOM Park I. em.) Web: paulanersorhaz.huÜdv:Mizső

	Certified Dynatrace Professional


----------------
158.2:

Ha valakinek megvan a csoportkép, én kíváncsi lennék majd rá. 

----------------
159.1:

Hello I think it's possible using Request Attributes More details here Request Attributes 

	Sharing Knowledge


----------------
159.2:

Hi @Malaik Question is about post-execution script in http monitor.How can we implement RA in http monitor?Yos  

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
159.3:


Hi Yosi, As the response body is a string, I'd say using a regex match would do the trick, with a capture group somewhat like this (adapt it to the format of your token of course):api.setValue("token", responseBody.match(new RegExp("token=\"([A-z0-9]+)\""))[1]) Regards,Álvaro

----------------
159.4:

Hi @alvaro_sanchez  Great , will give it a try next week at customer site and will update !Thanks a lotYos  

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
159.5:

Hi @Yosi_Neuman!
 
I'm curious how this issue has ended eventually, were you able to find a desired solution as promised last year? 
 
Best regards!

----------------
159.6:

Hi @Michal_Gebacki As far as I remember it works OK.I have accepted @alvaro_sanchez  answer as a solution  and sorry for the "slight" delay in doing that Yos 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
159.7:

I can confirm that you can use regex in the post-execution synthetic script. Here is who I did it for our application.   

----------------
159.8:

Hi,I'm trying to capture a specific value from the response of a HTTP (API) request.I have tried the approaches suggested by @alvaro_sanchez and @jkinner above, but with no success.I've attached an example of the response from the API request.I specifically need to capture the value returned for "policyNo" into a new variable, "policyNumber".Does anyone have any suggestions on how I can get this working?jmodeorain14

----------------
159.9:

I was able to extract the value of policyNo from the response body.In case anyone is interested or has a similar challenge in future, here is the post-execution script I used: jmodeorain14

----------------
159.10:

HiAnd where you put this code?

	Sharing Knowledge


----------------
160.1:

Looks like an incorrectly custom app with openkit. Most likely it's an extension reporting to the ActiveGate (and trying to send data locally). What extensions is the ActiveGate running?

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
160.2:

Your comment led me down the path of looking at our custom applications. I found that the app ID in the relative URL of the trace (see below), refers to a custom app for endpoints associated with AG extension SAP Application Server (ID: custom.remote.python.sap).I did find some custom apps associated with these endpoints configured to our internal vip that hits our ActiveGates, I changed the settings of each app to use the cluster AG. I believe the failures that are occurring now are associated with endpoints that have a custom app ID setup (in the endpoint settings) but no associated custom app actually created with that ID. Still doing some clean up. It is very likely that we removed some custom apps that have not had traffic in say 1 year, but did not remove the endpoint in the extension.   

----------------
161.1:

Hi @kostellod,Can you share the wrong result table? and the mentioned calculations?Best regards,Mizső

	Certified Dynatrace Professional


----------------
161.2:

This would be an example. I want 1 line, left column as "CPU %", 2nd as "Min", 3rd as "Avg", 4th as "Max". I'd like this for a couple of different metrics in the same table. 

----------------
161.3:

Since you are using the same metric, you should include all the tags in the filter for the same query. Example:builtin:host.cpu.usage:filter(and(or(in("dt.entity.host",entitySelector("type(host),tag(~"YOUR_FIRST_TAG:HERE~")")),in("dt.entity.host",entitySelector("type(host),tag(~"YOUR_SECOND_TAG:HERE~")")),in("dt.entity.host",entitySelector("type(host),tag(~"YOUR_TIRDH_TAG:HERE~")"))))):splitBy("dt.entity.host"):sort(value(auto,descending)):limit(100)EDIT:In your case, you should create the following queries, using the same formula, just replacing the aggregation you need. EDIT 2:I see the problem now. With no 'split by' condition, you still get the one line per query... So I think this can be an Idea candidate...

	Site Reliability Engineer @ Kyndryl


----------------
162.1:

you got this option to sort Sort byBy default, results are sorted in descending order based on the aggregation chosen.To set the sort orderIf Sort by is not already displayed in the query editor, select  and then select Sort by from the list.Set Sort by to the dimension by which you want to sort.Select the sort order: ASC (ascending) or DESC (descending). Documentation page https://www.dynatrace.com/support/help/observe-and-explore/explorer 

	Dynatrace Professional Certified


----------------
162.2:

I've got a sort added, but it's not working as I'd like. It's doing an alphabetic sort - I need numerical.

----------------
162.3:

Hello,Can you send a screenshot of your configurations? Thanks,Islam

	Dynatrace Certified Professional - Dynatrace Partner - Yourcompass.ca


----------------
162.4:


If it's a dimension, you cannot sort it numerically. Dimension is a string, not a number and is sorted lexicographically as stated here. The only way I can think of is to replace the data at the source and pad it with zeroes( 0 -> 00, 1 -> 01, 2 -> 02).

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
162.5:

Unfortunate. It would be nice to be able to do a transformation on data before it gets sent to the chart.

----------------
162.6:

yes, unfortunate. This probably won't happen with the classic data explorer and will be possible only with Grail.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
163.1:

this is awesome!!!

	Dynatrace Professional Certified


----------------
164.1:

Hi @yuesong_teh ,As far as I know, waterfall analysis is not exportable.Reported Values have a trick to read/query them but it doesn't work on Custom Applications (like SAP ABAP) unfortunately 

----------------
165.1:

Hi @KevThompson,Please double check it, but it will not meet your requirements exactly, because it gives back the all action count numbers from the affected sessions:SELECT DATETIME(startTime, 'HH:mm', '5m'), SUM (userActionCount) FROM usersession WHERE useraction.application='your appliacation name' AND useraction.name="your individual user action name" GROUP BY DATETIME(startTime, 'HH:mm', '5m')So it would be closer, because it gives back the session id count where the specific user action can be found. This is not deal with those cases where the specific action can be found more than one.SELECT DATETIME(startTime, 'HH:mm', '5m'), COUNT (userSessionId) FROM usersession WHERE useraction.application='your application name'AND useraction.name="your individual user action name" GROUP BY DATETIME(startTime, 'HH:mm', '5m')I hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
165.2:

Hi Mizső, Thanks for the feedback,  I've tried to use this one but I get the following error,  any ideas?   SELECT DATETIME(startTime, '2023-09-01 00:00', '5m'), COUNT (userSessionId) FROM usersession WHERE useraction.application='My3 App ' AND useraction.name="Screen change : app.dashboard" GROUP BY DATETIME(startTime, '2023-09-20 00:00', '5m')  ThanksKev

----------------
165.3:


Hi @KevThompson,Try this one, you should cahnge only the app and the user action name. In this case you will have graph and it can pin to dashboard:SELECT DATETIME(startTime, ''HH:mm', '5m'), COUNT (userSessionId) FROM usersession WHERE useraction.application='My3 App ' AND useraction.name="Screen change : app.dashboard" GROUP BY DATETIME(startTime, ''HH:mm', '5m').I have not tried it but check to create custom metric (for alerting) and change to graph to single value (maybe it would be better on dashboard with time filter). Best regards,Mizső

	Certified Dynatrace Professional


----------------
165.4:

Excellent thank you Mizső,  its working now,   the confusion point was I thought you had to put the required date ranges into the DateTime in the query, where as that comes form the timeframe selector.We have recently moved from another provider which also had its own QL so a few confusing cross over points.ThanksKev

----------------
165.5:

Your welcome! 

	Certified Dynatrace Professional


----------------
166.1:

Hi,You can send notifications via Webhooks.Best regards

	Consultant


----------------
166.2:

Hi,Is by webhooks will open a ticket automatically, and please provide me how to integrate.

----------------
166.3:

Hi,Dynatrace will send a payload to Ivanti. Do you have some API in Ivanti to receive information?Best regards

	Consultant


----------------
166.4:

Hello,You can use the webhook integration as @AntonPineiro mentioned. in case you need a tailored way for the integration, you can check Zigiwave integrations. they provide a connector between Dynatrace and Ivanti.https://zigiwave.com/dynatrace-integrations/ Thanks,Islam

	Dynatrace Certified Professional - Dynatrace Partner - Yourcompass.ca


----------------
167.1:

Perhaps dynatrace decided that this was planned behaviour. In general if shutdown was gracefull, better idea is configuring maintenance window to prevent falls positive alerting. Sebastian 

	Regards, Sebastian


----------------
167.2:

I needed that list of opened problems to remember the 100 hosts that I shutted down on Friday.Sure I could have done a Maintenance window but I didn't in order to pick every single problem tile today and start rebooting all hosts listed there.Can I avoid this automagic problem management system so I can keep my problem open even after 12h of shutted down hosts?

----------------
167.3:

No, but there is no issue with it. When you go to host list and pick filter that will list your offline hosts (by tags, by name etc) with timeframe 72 hours you will see all of them. Offline and online ones. In such case you see which of them still needs restarts or agent installation.Sebastian 

	Regards, Sebastian


----------------
167.4:

Thank you for your time Sebastian

----------------
167.5:


Yes that's by design, as documented here:https://www.dynatrace.com/support/help/shortlink/event-types-availabilityIn previous versions we kept the problems open for 7days but many customers were annoyed by the open problems and demanded a shorter timeout period of 12hours for closing the host unavailable problems. Alerts are sent out anyway, so it does not make much sense to keep those problems open forever if the host is not coming up again. Best greetings,Wolfgang

----------------
167.6:

As Ben also started, this is a big Process problem for us with ServiceNow Integration.  The PRoblem is closing the ServiceNow Incidents after 12 hours even if the server is still down.  This is unacceptable from our customers perspective who uses ServiceNow to rack the status and availability of their servers from ServiceNow. We need the ability to either change the configuration to a much longer time, like 7 days ;-), or never to close the Alert to ServiceNow unless the problem is corrected.

----------------
167.7:

Hi,It would be nice if this was configurable. In some scenarios it is nice that the problems time out and disappear, but in other scenarios that can be an issue

----------------
167.8:

One scenario where automatic closure after twelve hours causes problems is with the ServiceNow integration. The host going offline creates an incident in ServiceNow that is then closed after 12 hours. This in some cases prevents teams returning from the weekend from investigating these issues and hosts are then left in a offline state. 

----------------
167.9:

Sorry to revive this old thread, but today we also noticed issues with the hard 12 hour timeout. When a server goes down just after the end of a workday, the timeout prevents us from seeing the issue on our dashboards the following morning. It would be nice to have these timeouts be configurable.

----------------
167.10:

HI @RikvanEngelen At the moment, it is not possible to configure such a timeout. You can set up a Product Idea and describe your need in detail. 

	Have a nice day!


----------------
167.11:

It is correctly summarized that on the back end Dynatrace will close the problems after 12 hours, by designed, as asked for by a number of customers some time ago.  I think that may be fitting for some, but clearly not all. ANSWER (tactical) - You can request support to increase that time to several days as needed for your environment.ANSWER (strategic) - I did submit an enhancement idea for this configuration that Dynatrace Support has access to to be made available to us. 

----------------
167.12:

I've made a product idea for this functionality.Manually set timout for dynatrace problems - Dynatrace Community

----------------
168.1:

Love this!

----------------
168.2:

Cool!!!

----------------
168.3:

great monthly update  

----------------
168.4:

Thank you 

----------------
169.1:

Hi,Unfortunately this is not possible. You can only click on a particular tile on the dashboard and see the details on a separate tab (for eg. Data Explorer).Radek

	Have a nice day!


----------------
169.2:

Hi @Jamz,Surely an interesting idea, some dashboarding tools offer that indeed. I would suggest this to Dynatrace via the product ideas so that they can review it. GRAIL brings a lot more dashboarding options so maybe it would only be integrated there.   

	A Dynatrace Professional nerd working for Eviden


----------------
169.3:

thanks for this Marina i will do this now

----------------
169.4:

Product idea is here.

	Consultant


----------------
170.1:


Ansible / Ansible Tower is one that comes to mind. We have an integration with it that's discussed here:https://www.ansible.com/blog/enable-self-healing-applications-with-ansible-and-dynatrace https://www.dynatrace.com/news/blog/connect-dynatrace-with-ansible-tower-to-trigger-your-it-automati... https://www.dynatrace.com/news/blog/set-up-ansible-tower-with-dynatrace-to-enable-your-self-healing-... You can use it to kick of defined 'playbooks' in response to certain problems.

----------------
170.2:


James is Exactly right, Ansible tower can be used for auto remediation as well as deployments and can be very useful. I would recommend looking into leveraging the product. 

	-Chad


----------------
170.3:

Do we have a similar one for Terraform in AWS? 

----------------
170.4:

Hi @kvsudheerbabu,Could you please check these links:Docs overview | dynatrace-oss/dynatrace | Terraform | Terraform RegistryGitHub - dynatrace-oss/terraform-provider-dynatraceI hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
170.5:

Thanks for your quick response. How can we use these terraform modules to restart a specific process or host that were reported as part of metric event problem?  ThanksSudheer

----------------
170.6:

Hi @kvsudheerbabu,I have shared those links becasue you can find inofrmation about the DT and Terrafrom integration. I have never used Terrafroam.As in the previous answers in most cases I have met with Ansible Tower job template solution for autoremediation.This is an Azure example: Best regards,Mizső  

	Certified Dynatrace Professional


----------------
171.1:

Yes, is totatlly possible. Go to settings>monitoring> aplications and you will see the flag to delete this app   

	Dynatrace Professional Certified


----------------
171.2:

Sorry, but I was talking of a custom APPLICATION developoped and deployed in dyanatrace like this:npm run deploy You can see the duplication here.Thanks,Andrea

----------------
171.3:


oh, ok. I looked at the documentation page and found thisuninstallApp​appEngineRegistryAppsClient.uninstallApp(config): Promise<void>Uninstall an app.Required scope: app-engine:apps:delete Documentation Page:https://developer.dynatrace.com/reference/sdks/client-app-engine-registry/

	Dynatrace Professional Certified


----------------
171.4:


Hi @andreaCaria,
the simplest approach to uninstall an app is via Hub app. You can find the documentation at https://www.dynatrace.com/support/help/manage/hub#uninstall

----------------
172.1:


@natanael_mendes,I didn't try this before, but you can create a Request Attribute for client IPs. You could then eventually create a metric with that count, and IP as a dimension. You could then be able to dashboard it. But this approximation has a caveat: it would probably consume a lot of DDUs...

	Antonio Sousa


----------------
172.2:

yeah, i saw this. but i was trying to do without create any metric

	Dynatrace Professional Certified


----------------
172.3:


Check this out, and see if it helps: https://community.dynatrace.com/t5/Dashboarding/Multiple-access-attempts-from-one-IP/m-p/216668/high...

	Site Reliability Engineer @ Kyndryl


----------------
172.4:

So nice to see someone has done it 

	Antonio Sousa


----------------
173.1:

This is really good question. I too want to understand this. Appreciate is someone from Dynatrace product team can pick this up. 

----------------
173.2:

Hello @kwangxi,Can you share details about the endpoints corruption?We have similar issues since few months after the restart or some servers and the corruption of files like deployment.conf.Thanks for your help.

----------------
173.3:

Hello,
One thing you'd want to make sure you rule out is the part in the documentation shared about "alerting on graceful shutdown" and making sure that setting is turned off. 
 
 

----------------
173.4:


What I got from Doc on this: https://www.dynatrace.com/support/help/platform/davis-ai/anomaly-detection/adjust-sensitivity-anomal....By default, Dynatrace alerts only about unexpected outages.During a graceful shutdown, the host outage is expected and the operating system has sent a shutdown signal notifying OneAgent that an operator is intentionally shutting down the host.If OneAgent receives no shutdown signal, the shutdown is classified as unexpected.You can opt-in to receive notifications about graceful shutdowns as well.

	Dynatrace Certified Professional


----------------
174.1:


Yes, it expires after two years.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
174.2:

Yes, after two years.Take a look  

	Dynatrace Professional Certified


----------------
175.1:


I moved this to the Dynatrace Open Q&A because service detection is not related to or handled by extensions.Key requests have to be associated with a single service and service names are not guaranteed to be unique, so grouping them by a service name is not an option. You may need to look at some of the service detection options that are available to find a way of ensuring that new services are not detected in such scenarios where you would prefer to keep them the same.https://www.dynatrace.com/support/help/platform-modules/applications-and-microservices/services/serv... 

----------------
175.2:

Hi James,We have a service naming rule, which aggregates all the blue-green services to a single service. Hence, we were expecting that the key request feature will work, because the service name is unique. The filtering is important for us, because we need to opt-out irrelevant customer-related info.

----------------
176.1:

Hello,https://www.dynatrace.com/support/help/shortlink/user-action-metricsThis page details the different metrics around performance that are considered for various user actions. One possibility is looking at the metrics for the XHR action that appears to be taking longer than expected, and see if one of the other metrics seems to be a more accurate indicator of what you're looking for. For example, try looking at the "HTML Downloaded" or "Response End" metric.

----------------
176.2:

I know this, using other metrics is not an option. Need to know the root cause of the problem and fix it.Then use the required metrics with confidence as a source of truth.How are You supposed to make automated quality gates if metrics are broken? Workaround is not an option for high-quality products like Dynatrace.

----------------
177.1:

Hi @Maelam,It is not a Notebook but you can try it and use the created metric information on your Notebook.SSL Certificate Monitor | Dynatrace HubExample: Created metric with lot of dimension for splitting the cert information: You can check you this or other extensions health (eg. errors) with this:Extensions Health | Dynatrace HubI hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
177.2:

Hi @Maelam 
you can query it with such query
fetch `dt.entity.python:certificate_monitor_certificate`
| fieldsAdd lifetime, status = if(lifetime[end] -10d < now(), "", else:if(lifetime[end] -30d< now(), "🟡"))
and this would be the result
 
 
 
 
Best,Sini

----------------
178.1:

Thread id

----------------
178.2:

hi , could you explain more, please?I see in one transaction, calls are marked as asynchronous, but the thread ID and trace ID are the same for all these calls. As per my understanding, for an async call, a new thread is created. 

----------------
178.3:

I believe - it is by traces, you should see polling requests after the initial.if you have polling indeed.If this fire-and-forget async not sure.

----------------
179.1:

Ace certification?  Dynatrace Associate Certification?

	Dynatrace Certified Professional


----------------
179.2:

Service Delivery Certification

	Dynatrace Professional Certified


----------------
179.3:

ok, normally they have a practice test when you go to preparation but not sure on that cert as I don't have access to it.  You must be a partner.

	Dynatrace Certified Professional


----------------
179.4:

im a partner but the only material that i have are videos

	Dynatrace Professional Certified


----------------
179.5:

@natanael_mendes it's just the course - the videos + the mindmap (attached to the course). Be sure to check this existing thread.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
179.6:

Are you referring to the ACE Services Partner or Autonomous Cloud? 

----------------
179.7:

Services Delivery Certification

	Dynatrace Professional Certified


----------------
179.8:

Hi @natanael_mendes I passed this certificate. It is entirely sufficient for you to pass by carefully studying the videos you will find on University.Radek

	Have a nice day!


----------------
179.9:

@radek_jasinski Hi Radek, do you got any tips for the exam? where focus more or what its most important?

	Dynatrace Professional Certified


----------------
179.10:


What you should pay attention to is the best practice mentioned in the videos. There have been many questions where they have just asked about such details. They also asked what Dynatrace modules (One, Community, Support etc.) could be found on the Dynatrace website and in the DT console. There were certainly questions about the mind map.In general, if you watch the videos 2-3 times with understanding and take notes, you should pass without a problem:)Radek

	Have a nice day!


----------------
179.11:

thank you @radek_jasinski , you got linkedin?

	Dynatrace Professional Certified


----------------
179.12:

Yes I have Linkedin, but switched to private mode because I had terrible spam from recruiters . If you want to catch me directly it's best on FB or Instagram. You can find me as Radek Jasiński (city: Warsaw) 

	Have a nice day!


----------------
179.13:

i wasnt able to reach you, can you send some link or connect with me in linkedinhttps://www.linkedin.com/in/natanael-mendes-517111189/

	Dynatrace Professional Certified


----------------
180.1:

You can create Maintenance Window for this  Take a look on this documentation pagehttps://www.dynatrace.com/support/help/observe-and-explore/notifications-and-alerting/maintenance-wi... settings>preferences>maintenenace window. Any doubts feel free to ask 

	Dynatrace Professional Certified


----------------
180.2:

Thanks much. I've done this way.1. Tag process group instance for which alert suppression required via auto tagging2. Filter this created tag in the maintenance window.

----------------
180.3:

Hi @ssamraj ,If you are looking to turn off monitoring you can do so a couple of different ways. One of the ways is to explicitly state which group you want to monitor by turning it off environment-wide here: Another way, since you mentioned that you have declarative process grouping is to specify custom process monitoring rules here:https://www.dynatrace.com/support/help/shortlink/process-group-monitoring#rulesHope this helps!  

----------------
180.4:

@Taylor-Sanchez wrote:Hi @ssamraj ,If you are looking to turn off monitoring you can do so a couple of different ways. One of the ways is to explicitly state which group you want to monitor by turning it off environment-wide here: Another way, since you mentioned that you have declarative process grouping is to specify custom process monitoring rules here:https://www.dynatrace.com/support/help/shortlink/process-group-monitoring#rulesHope this helps!  Thanks for your response. My requirement is to turn of this specific process monitoring only for AIX systems and it should stay intact with Linux. Please note that exe name and path are same for both OS.

----------------
180.5:

This is where robust tagging comes into play. As you stated, you want to disable the monitoring for a given process name where the underlying OS is AIX. If you create an auto tag rule for the OS value, it can be populated from the host level and down into the PGs, PGIs, and Services. Once that is completed you can then create the Maintenance window to say suppress alert notifications for <PGName> where the tag is OS:AIX. 

	-Chad


----------------
180.6:

Thanks for the response.. Almost, I did the same.. Please see my reply to nataneal_mendes.

----------------
181.1:

You should be able to use this metric dsfm:server.notifications.problem_notifications. And then filter by alerting profile and select the one for SNOW. Let me know if that's what you were looking for  

	A Dynatrace Professional nerd working for Eviden


----------------
181.2:

Hi,So this i was able to pin the metric to Classic dashboards.How do i do the same for the new Dashboards? using Grails, i dont see these metrics in the docs.fetch events| filter dsfmlike that, doesnt work...

----------------
182.1:


You cannot change the property type without removing and readding the extension (which means you need to recreate all endpoints).
You can solve it by renaming the property in the plugin.json and the python code at the same time as changing the property type. That will just require you to re-add the password into the endpoints.

----------------
182.2:

Thanks for your reply Mike_L. Will try this and keep you posted.

----------------
182.3:

Thanks @Mike_L after removing the existing plugin and executed the plugin upload command, no errors encountered.Marked your reply as the solution. Thanks again!

----------------
183.1:


Hello,https://www.dynatrace.com/support/help/deploy-dyna...Perl isn't supported technology for deep monitoring by default. You can always use Dynatrace ADK to instrument it to see services and transactions. It is possible, I've done such things before. About additional perl metrics you need to prepare plugin for dynatrace  to see them. Sebastian 

	Regards, Sebastian


----------------
183.2:

Thanks, that's what I suspected. I was thrown off by Perl having its own page like that. To me it doesn't make sense to highlight a technology that's unsupported, it's a bit misleading to be honest.

----------------
183.3:

As you compare Perls page to others, generaly there is true. You see those processes with some bunch of basic metrics. But I understand with you that sometimes those pages are hard to understand. Sometimes clients tell me that he saw something there and I have to clarify his point of understanding. Sebastian 

	Regards, Sebastian


----------------
183.4:

Hi DynaMight Guru,Thank you for your Input.Which you have shared the link is not Working, throwing 404 Error msg. Could you please re share the Link where you can see as Perl isn't supported technology for deep monitoring .Thanks,Ameena.

----------------
183.5:

Hi @pb388 Check Extend AI-based root cause analysis with OneAgent SDK blog There you will see the follows explanation on how you can get code-level visibility also for Perl HTHYos  

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
184.1:

@chris_palmer,In a user action you have multiple TTFB, one for each request.There is a variable serverTime that gives you that information though.

	Antonio Sousa


----------------
184.2:

Thank you for the reply. I'm looking to run a query like this only with TTFB rather than LCP: I spoke to customer support regarding this and they suggested Response Time as an alternative but we didn't feel this was an accurate reflection of TTFB. They also suggested asking regarding TTFB here.

----------------
184.3:

select serverTime from useractionwill get you what you want. Just adapt it to your query.

	Antonio Sousa


----------------
184.4:

Thank you @AntonioSousa.

----------------
185.1:

@apasoquen1 metrics in Grail won't help you to solve this case. But this is already possible by defining your own calculated metric for the web application. Just use apdex as the metric, and add filters (user type, action type, ... ). Dynatrace will create a new metric and will only calculate the metric for the actions passing the filter.  

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
185.2:

I was thinking about doing this.  However, we have other synthetic monitoring tools running tests, that Dynatrace picks up as 'REAL USERS'.

----------------
185.3:

You can add Web crawler header to user agent for tests - they will be marked as ROBOTS

----------------
185.4:

Check your filters and compare results max 30 days (USQL limit).Use the same filters for USQL and Data ExplorerAlso, check if USQL is not limited by samplingResults should be similar.I don't recommend Apdex for low-level KPI (to abstract for developers)

----------------
185.5:

I don't think we have a "master plan" for all metrics yet. But we are actively working on moving them. For instance, I know about...: Application observability solution and the k8s teams are working on k8s metricsInfrastructure metrics are actively worked on but in your case the most relevant ones areDigital Experience and service metrics are also moved but the main missing piece is the possibility of having percentiles in Grail which is a bigger investment that is planned but not finished yet. @fcourbon, our metrics PM, can provide you with more details there. regardsThomas

----------------
186.1:

You can use deep object access if the method does not return a primitive. If there is no good way to access the value, you can add a simple getter to your application that returns the value you want, than instrument that with dynatrace.

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
186.2:

Hello PA, unfortunately we only have the return value available. Dynatrace does not allow deep object access for that option.

----------------
187.1:


Hi @CameronFW 
 
The reason why you're seeing this problem is, that the selection of too many permissions in the authorization settings of workflows can trigger such error. The short term workaround is to only select the permissions really needed ( Workflows > settings > authorization settings). The team is already working on a long-term solution. Unfortunately I can't provide you an ETA yet.
Best,Sini

----------------
188.1:

Hi @shubham1413,Which pod autoscaler do you use? I would check it at my clients in order to share with you the experience.Best regards,Mizső

	Certified Dynatrace Professional


----------------
189.1:

Hi @natanael_mendes ,This seems to be a general area in terms of the .NET space, meaning there could be a variety of reasons as to why you're getting this error. Doing a little bit of research here, I found this StackOverflow post that might be beneficial in your debugging process. https://stackoverflow.com/questions/16444981/the-controller-for-path-home-was-not-found-or-does-not-...In addition, since this could potentially be a .NET issue, you could have problems with the MVC framework. I suggest reviewing the code that you currently have with the exception errors to resolve the issue. Cheers,Taylor S. 

----------------
190.1:

Hi,I am not sure if you are asking about this, but you have top database statements in Dynatrace.Best regards

	Consultant


----------------
190.2:

but i cant see the "view" statement there

	Dynatrace Professional Certified


----------------
190.3:

Please review:https://www.dynatrace.com/support/help/shortlink/release-notes-saas-sprint-275#bind-variable-setting...Bind variable settings for DPS and Adaptive traffic management Version 3Application Observability | Distributed tracesBind variable capturing can be enabled by all accounts using a Dynatrace platform subscription and tenants that are using Adaptive Traffic Management V3. No additional support request is needed. 

	Dynatrace Certified Professional


----------------
190.4:

Hi @natanael_mendes ,What exactly do you mean by the 'view' statement, or what specific data are you trying to look for? As @AntonPineiro mentioned, most of the information that you're going to want to be able to analyze is going to be in the top database statements.Since Dynatrace captures the DB information from the perspective of the application, you'll be able to see specific queries and modifications as well in the 'Database' section of Dynatrace as well.   Drilling down into this might give you further insight into what you're trying to look for.Cheers,Taylor S.

----------------
191.1:


Hey Devinmarco,This is a very open ended request and I would highly recommend first narrowing it down.1. Without knowing what is important to you/your team this is difficult to answer. One team might care about network metrics, another about hardware, another about users. Also with over 100s of metrics to pick from relating to many different services (like 80+ supported) there is a lot. However, to get an idea of things that are important, Dynatrace has OOTB alerting available. This is only for a very small few services and metrics but it is there and can give you ideas. You can also look at other alerting options under the same settings to get an idea. Also, to see what metrics are available you can head over to the docs here: Amazon Web Services | Dynatrace Docs2. Try and focus on what someone would consider a problem. There are many different options, different conditions, models, etc so determining the best way to create alerts is very subjective. One alert may require completely different configurations to another. Also I would recommend starting small, ensuring what you have created works, makes sense, doesn't over alert, and then expand.3. Dynatrace supports Slack and Email notifications just fine. For SMS notifications it supports other services that can send via SMS or if your carrier supports it, there are options for sending custom messages to an API or email which can be configured to send via SMS.4. While setting up custom alerts you can see the last 7 days and whether or not those custom alerts would have alerted. This is incredibly helpful as well for setting up alerts just after a problem has occurred because you can tune the alert to not fire except during that problem scenario since you can visualize it right there in the UI. I would really recommend focusing on mission critical services and then expanding the alerts. Try not to look too far out just yet. Find something like Lambdas, or EC2 or something else and focus on just one service first.Hopefully this helps to move things in the right direction. If you have any specific questions follow up and hopefully people can help out!

----------------
192.1:


Hey Heramb,
You can use the new platform API for this. To get there you would go to https://Your.Tenant.Address.com/platform/swagger-ui/index.html?urls.primaryName=Document%20Service#/. Currently this is documented in our developer docs here https://developer.dynatrace.com/platform-services/#swagger-ui
Then from there you could follow the following steps to see how the document creation and editing process works as well as the format for requests:

GET /documents to find the ID of an example dashboard or notebook you want to use as a template.
GET /documents/{id}/content to get the layout that you would need to mimic.
POST /documents to then post an example document.

Once you have a template setup you would then in your script just do POST /documents to create a new document with your desired DQL OR do PUT /documents/{id}/content to update an already existing document with your DQL query.
Hope this helps!

----------------
192.2:

Hey thanks Fin for your help. This will definitely help to move forward.Regards,Heramb

----------------
192.3:

Hey ,I m trying to update my own dashboard( having id f3592b6d-XXXXXXXX411ae35) using  "updateDocumentContent" method but getting below exception Uncaught (in promise) 409: Share of type 'environment' with access 'read' already exists for document 'f3592b6d-XXXXXXXX411ae35'. errorRef: 282afd6c-2125-435b-8af5-f92fd10d670aWhat needs to be changed?? and What should be the value of optimisticLockingVersion???Regards,Heramb

----------------
192.4:

Hey ,Somebody please help me on this.Regards,Heramb

----------------
192.5:

Hey Heramb,Hopefully you've already come across the solution. I was unable to find anything regarding that exact error or reproduce it but as for the optimisticLockingVersion field, if you first GET the document you'll get a version returned. This is NOT the version in the document JSON but in it's metadata. The optimisticLockingVersion field needs to be this latest version. Every time a document is updated, this version will update and to update it through the API you'll need this latest version every time.   

----------------
193.1:


Hi @AntonioSousa ! Here are my tips for the "Log monitoring classic" that works with Managed :First you can rename your field if it contains "::" : Then you can to add your field in a custom log attribute :  https://www.dynatrace.com/support/help/observe-and-explore/logs/log-monitoring/analyze-log-data/log-...Finally you can search into it :  Hope it helps.  

	Observability Engineer at Phenisys - Dynatrace Professional


----------------
193.2:

@jegron,This is an exceptional tip!I hadn't had the time to try it out, but worked flawlessly!I believe you should post it in the Tips & Tricks zone, so other Community users might benefit.BTW, I was intrigued about the first step: it might be because "::" are not permitted as keys, or even caps letters being present. Do you have a confirmation why it is needed? Because if it is, I believe it is structural, and not even a Product Idea would be applicable here.

	Antonio Sousa


----------------
194.1:

i had the same problem. Take a look if the hosts that you selected have IIS on it

	Dynatrace Professional Certified


----------------
194.2:

That is what my second config has.  I have it based on a MZ that contains hosts with IIS installed.

----------------
194.3:

Open one of this logs and share with us please

	Dynatrace Professional Certified


----------------
194.4:

Here is a screenshot that chat support provided from the OneAgent Diagnostics that I've taken.

----------------
194.5:

To me seems like the IIS is not showing up on this host, can you certify that de IIS technology is on this host?

	Dynatrace Professional Certified


----------------
195.1:

what you can do is observe the action that directly you to this pdf pages, you can create a key user action to observe better like "If i click button A the pdf page will open for me"You can observe how many people clicked on this button. you can try create an request attribute to know with page was created.  Take a look on these documentation pageshttps://www.dynatrace.com/support/help/platform-modules/digital-experience/web-applications/addition...https://www.dynatrace.com/support/help/platform-modules/applications-and-microservices/services/requ... If you got any doubts feel free to ask 

	Dynatrace Professional Certified


----------------
196.1:


Hi @PrateekGupta,I would use API calls.First: Environment APIv2 Monitored entities:GET / entities provide a list of entities, you can filter only for hosts by type("HOST")Second:Configuration API  OneAgent on a host.POST  / hosts/{id}/autoupdate.Here is an example for disable with curl: I hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
197.1:

The best way is to create an Automatic TAG and assign it to a process and mark it so that it also covers hostshttps://www.dynatrace.com/support/help/manage/tags-and-metadata/setup/how-to-define-tags 

	Have a nice day!


----------------
198.1:


Hi @andreaCaria,
the AppLink component does not work for this case since the app dynatrace.classic.query.user.sessions does not support any intents.
For this particular page, you can use the ExternalLink like following:




import { getEnvironmentUrl } from '@dynatrace-sdk/app-environment';...<ExternalLink href={`${getEnvironmentUrl()}/ui/apps/dynatrace.classic.query.user.sessions/ui/user-sessions/query?gtf=-2h&gf=all&sessionquery=SELECT+*+FROM+usersession`}>A link to User Sessions</ExternalLink>


Please let me know if this works for you!



----------------
198.2:

It worked perfectly,thank you 

----------------
199.1:

I agree with you that documentation should be made available. For the moment, information about Copilot is only on the blog.

	Have a nice day!


----------------
200.1:

Hey @Lwl can you give us more details about?

	Dynatrace Professional Certified


----------------
200.2:

 That's it. Don't know what to do

----------------
200.3:

Hi @Lwl ,How's it going? Previously, was the data collection correct?Have you tried doing a restart of OA or AG? R.

	Have a nice day!


----------------
200.4:

Hi @radek_jasinskiIt's good to see you againNo attempt has been made to restart AG or OA 

----------------
200.5:

There seems to have been this situation before, but it has not been solved, and now I want to solve it.

----------------
200.6:

I had a similar situation when mcafee antivirus was running on the system. Have you checked the log entries?

	Have a nice day!


----------------
200.7:

Checked the logs, and there's not much difference between them and normal host nodes

----------------
200.8:


I believe you should report the case to support. You may have many variables as to why this data is not being collected correctly.

	Have a nice day!


----------------
200.9:

Yes, I will do that

----------------
201.1:


FYI,After my investiguation, the VmWare property "datacenter" is automatically collected by Dynatrace when VmWare monitoring is enabled :  I don't know yet why this property is sometimes not available for some Vmware clusters because it seems to be a mandatory property (version ? permissions ?...).If none applies, then there is the fallback to trying to resolve the IP address of the sender of the OsiInfo message to a geolocation (cf support). The workaround is to map IP to location manually on "Settings -> Web and Mobile Monitoring -> Geo Locations". Regards, Aurélien.    

	Observability consultant - Dynatrace Associate/Pro/Services certified


----------------
201.2:

Hello Aurelien,did you find a solution to deactivate this DC autoaffectation of a vsphere label  ?did you find a proper way to manage Datacenter in Dynatrace ? without "Geo Locations" method feature more dedicated of the customers api access  Thanks for your time

----------------
202.1:

i never heard about this but i dont think the Chrome agent is the cause. Dynatrace can identify real users and bot users. You can investigate de IP of this users. Tell me if i can help you in some way

	Dynatrace Professional Certified


----------------
202.2:

Hi @natanael_mendes, I see, however our user sessions are indeed real users and not bot users. It is just surprising to see so many android 10 users using chrome mobile, since android 10 is considered an old version and the last security patch was feb 2023. Hence we were not expecting to see much android 10. On the contrasting note, Chrome mentioned in the article that " Starting in Chrome 110 we are gradually introducing a fixed value for Android version and device model. Instead of seeing something like Android 13 on Pixel 7 the default value will always be Android 10 on a model K. " seems to match better with my suspicion because chrome 110 is a relevantly new version that rolled out this year.  

----------------
202.3:

Maybe some user start the session multiple times and this is causing the number of the android 10 sessions. Hope this help you. If you got any doubts feel free to ask

	Dynatrace Professional Certified


----------------
202.4:

Managed to do more analysis on the data, they seems to be different users. From my finding i realised that:This issue only affect users with browserFamily = Chrome browser.For browserMajorVersion before Chrome Mobile 110, i am about to capture the different osVersion e.g. Android 10, 11, 12, 13.However for browserMajorVersion from Chrome Mobile 110 onwards, osVersion are recorded mostly as Android 10. Though there are some outliers e.g, browserMajorVersion = Chrome Mobile 114 and osVersion = Android 11, however the ratio is like 1:100. As for device column they are null, maybe Dynatrace only capture device for mobile application. hence i am not able to verify if model K is being captured. Thanks.  

----------------
203.1:


Yes exist, the metric is literally CPU throttling haha"The CPU throttling metric tells you how long the application was throttled, so you can determine where more CPU time would have been needed for processing. This usually happens when the containers don't have enough CPU resources (limits) in the workload definition. This might affect the performance of the processes and applications running inside the containers." Take a look on this documentation pagehttps://www.dynatrace.com/support/help/platform-modules/infrastructure-monitoring/container-platform...You can also see the number of running pods versus desired pods for every cloud application.

	Dynatrace Professional Certified


----------------
203.2:


Hi @crabbylou,I usually use these ones at clinets:(  builtin:containers.cpu.throttledMilliCores:avg:parents:parents:splitBy("dt.entity.cloud_application_instance","dt.entity.cloud_application"):sum    / builtin:containers.cpu.usageMilliCores:avg:parents:parents:splitBy("dt.entity.cloud_application_instance","dt.entity.cloud_application"):sum    * 100):splitBy("dt.entity.cloud_application_instance","dt.entity.cloud_application"):setUnit(Percent):sort(value(avg,descending)):limit(5)  or builtin:containers.cpu.throttledMilliCores:filter(series(avg,gt,10)):parents:parents:splitBy("dt.entity.cloud_application_instance","dt.entity.cloud_application"):avg:auto:sort(value(avg,descending)):limit(5)  I hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
204.1:

Thanks for the tip @Akki 

----------------
205.1:


I believe the error is in the database, giving a timeout to process the request. Since the exception is in the database.The oneagent in the database is only for infra-only monitoring.The quality metrics are taken from the services that communicate with it. But if you look at the exception you can see that the request hit the database but took time to process 

	Dynatrace Professional Certified


----------------
205.2:

Thank you Natanael. So when you say "The exception is in the database" Are you saying that the exception listed was created from the SQL server and not the application server making the request? When I see the icon/image of the MS SQL database next to the entry [UserAssociations].[User_find] is this telling me that the data is from the SQL server? (And not from the application server?)In the case of a timeout, I guess it makes a difference as to who is reporting it. If the SQL server is the one reporting it, then we can safely say the message arrived. However, if the message is from the calling application server, then something may have happened on the way to the SQL server.  Knowing which server is providing that information helps immensely. Let me know which it is if you could and thanks! 

----------------
205.3:

Yes, I think the problem is in the sql server, with all the evidence you provide I come to that conclusion. You could try service backtrace or distributed trace to see if the component is taking longer to run. Feel free to ask if you got any doubts

	Dynatrace Professional Certified


----------------
206.1:


Hi,You can see here all technologies supported and versions.Best regards

	Consultant


----------------
206.2:

Hi Anton , Thanks for your answer. according to the documentation ONLY version 89 is supported , Is there a plan to add more versions soon ?

----------------
207.1:


Do you mean the only entities that have open problems? If so: you could you the normal problem api. These APIs give information about impacted entities / root causes etcetera. Using a small script you can easily get a result that provides exactly what you'll need.https://www.dynatrace.com/support/help/dynatrace-api/environment-api/problems-v2/problems/get-proble... Kind regards,Michiel 

	#Performance matter!


----------------
207.2:

Hello. I am trying similar thing: I want to list all open problems but only with some fields. I want problem title and hostname. Unfortunately I can't get the hostname into the resulting JSON. I tried name, hostname, but it doesn't put it there and I get result completely without hostnames or with hostnames but also with many other information which I don't want. The best thing would be to be able to get a CSV format result, but I guess this is not possible?

----------------
207.3:

Hi there, So basically the API gives you a LOT of field. You can't reduce this according to the documentation:A list of additional problem properties you can add to the response.The following properties are available (all other properties are always included and you can't remove them from the responseevidenceDetails: The details of the root cause.impactAnalysis: The impact analysis of the problem on other entities/users.recentComments: A list of the most recent comments to the problem.To add properties, specify them as a comma-separated list (for example, evidenceDetails,impactAnalysis).Second part is the question about HOST. What do you want to know exactly? The root cause?In the JSON response there will be something like this:rootCauseEntity": {        "entityId": {          "id": "PROCESS_GROUP-511F9ECC59F68DD4",          "type": "PROCESS_GROUP"
        },
        "name": "Oracle Database"
      } In case this is a HOST, you will have the host ID there.  If you want to customize something to XML, you'll probably need to write a simple custom script. by the way: adding field evidenceDetails can give you more infomation about the host. 

	#Performance matter!


----------------
208.1:

@AntonioSousa do you have any updates or insight on this integration that you can share with the community? 

	-Chad


----------------
208.2:

Yes, we have been developing an extension integration with Mirth. Are you a Mirth user?

	Antonio Sousa


----------------
208.3:

That is great news! Not that I am aware of.

	-Chad


----------------
208.4:

Hi, I am  working on project where mirth technology is implemented. Is the the solution to monitor mirth using DT available now?

----------------
208.5:

@SeemaP,Mirth data is available through an extension we have developed. It is not available in the Hub though. Please reach out directly with me if needed. 

	Antonio Sousa


----------------
208.6:

Hi @AntonioSousa , how is this project going? I would like to take a look on this extension you've created!!

	Site Reliability Engineer @ Kyndryl


----------------
209.1:


Hi,indeed, this is possible. See the following video: https://www.youtube.com/watch?v=LpH8IlUeBSU&list=P...Thorsten

----------------
209.2:

Thank you 

----------------
209.3:

The video is not available. could you please reupload the video?

----------------
209.4:

Hi @dynamic Try Dynatrace and PowerBI - Taming IT Change Risks through Automation

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
209.5:

Thank you for the informative webinar.  I think I have a better idea as to how to connect Dynatrace with Power BI.  I would like to know how to export/import user sessions from Dynatrace into Power BI.  We use both Power BI and Splunk here and I know our data analytics team and business teams would benefit greatly with at least the user session export into Power BI.

	Dynatrace Certified Professional


----------------
209.6:

Talk with your Dynatrace support team, we got a sample BI report/integration for problem reporting from our support team that really accelerated the process for us. 

----------------
209.7:

You can also take a look at this post.I've added a detailed description and guidelines.

----------------
210.1:

Hello, I see you said that you are getting an "extension crashed" error. Did you make sure that you had the correct permissions from the following list? Required scope: environment-api:extensions:read Required permission: environment:roles:manage-settings Thanks

----------------
210.2:

That is definitely the initial problem as I was able to capture the error, but I have added them to one of my group policies and it is still happening, so presumably I have not done that correctly.I have double checked my effective permissions and I have both of the required scope and permissions, so now I'm stuck.

----------------
210.3:

I verified everything was setup correctly, and contacted support. They had the same issue with the 'listExtensions' call that I did so they are escalating to the product team.I was able to do what I wanted using the Problems API, so I have working code now, just not with the API I want.I will report back here when there is a solution.

----------------
211.1:

You can select all certificates related to a host with an entity selector like:type("python:certificate_monitor_certificate"),fromRelationships.runsOn(type(HOST), entityId(HOST-xxxxxx))Apply this entity selector to an automatic tagging rule, you can get results like: Would that solve your use-case? 

----------------
212.1:

Hi @Iplinsky ,Aside from the documentation, which you can find in the following link, a good starting point would be to get familiar with DQL. This provides the most customization when it comes to creating these dashboards, considering you can import these data visualizations directly from the Notebook itself. There's an interactive tutorial that was recently created, I would suggest starting from there to get familiar with the functionality as you translate those skills to the newer dashboard capabilities. Dashboards: https://www.dynatrace.com/support/help/observe-and-explore/dashboards-newLearn DQL: https://www.dynatrace.com/hub/detail/learn-dql/Cheers,Taylor S.

----------------
212.2:

Hello
We are currently working on providing a solution to share workflow ideas with new users.
In the meantime, I recommend taking a look at the Observability Clinics or other video materials - they often feature templates for dashboards and notebooks which can be downloaded from Github:

Getting started: GitHub - dynatrace-perfclinics/dynatrace-getting-started: This repository contains supporting materi...
Open Observability: GitHub - dynatrace-perfclinics/OpenObservability-clinic

Christian

----------------
212.3:

I wonder if the BizOps Configurator will (can?) eventually contain new dashboards as well.https://dynatrace.github.io/BizOpsConfigurator 

	Kind regards, Frans Stekelenburg                 Certified Dynatrace Associate | measure.works, Dynatrace Partner


----------------
213.1:


@Martin K. This is currently not available in the product. Id recommend tossing in a RFE if your organization will need this functionality. Request a RFE:https://answers.dynatrace.com/questions/ask.html?space=482

	-Chad


----------------
213.2:

Are you a thrill seeker who thrives by being on the cutting edge and love using Chrome to access your Dynatrace dashboards?If you answered yes to both questions, I would suggest trying out this Chrome Plugin.https://chrome.google.com/webstore/detail/dynatrace-dashboard-power/dmpgdhbpdodhddciokonbahhbpaalmco

----------------
213.3:

Holy cow that is awesome, first time seen it. This is awesome. The math and Sankey is awesome!

----------------
213.4:

Yes, I just learned about in the last week or so, and had a great internal session about it this week at our virtual services conference.  The Sankey is really awesome, math is great, coloring based on thresholds...all very cool stuff.

----------------
213.5:


Something like this is now possible, see https://www.dynatrace.com/support/help/observe-and-explore/dashboards-classic/charts-and-tiles/visua... .

----------------
213.6:


Hi all,If you will use Single value or Table views you will find a switch called link background to thresholds that will answer @mkulov old request.  Just wonder why its shown up in different sections in each of this 2 options   HTHYos   

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
214.1:

Well deserved accolade! You have great vision and collaboration skills. Great work!

----------------
214.2:

Congrats @stefanie_pachne 

----------------
214.3:

Parent of “crazy” little kids here. Congrats, @stefanie_pachne !!Being a beach volleyball player, I bet you have heard of some Brazilian players in that area, right?

----------------
214.4:

Congratulations @stefanie_pachne. Beautiful Ski Center

----------------
214.5:

Congrats @stefanie_pachne . Very good work on thinking, creating, organizing and maintaining the Global CVE database. We use this database quite often and is of great value to to us and to our customers. 

----------------
214.6:

Congrats, @stefanie_pachne !!

----------------
214.7:

Hi @stefanie_pachne,First of all Congratulation!!!  cve-status.dynatrace.com is a very useful information source for me when I have to talk with clients IT sec teams. Keep going on!!!Best regards,Mizső

----------------
214.8:

Congratulations @stefanie_pachne.

----------------
215.1:


Regarding the Persmissions, You cannot specify which menu to hide or which page to access...At this time its very light. You can open a RFE for this. Have a good day.

	Sharing Knowledge


----------------
215.2:

Hi,Maybe creating a specific management zone for them where those entities are not included.I do not see a way to hide problem's menu.Best regards

	Consultant


----------------
215.3:

Hi AntonPineiro,Thank you for your suggestion, I already thought about it, but I am looking for a kind of matrix that manages both rights and the partitioning of data by "application/MZ"

----------------
216.1:

im right there with you on this @Julius_Loman. Have you made any headway with this?

	-Chad


----------------
216.2:

@ChadTurner no, there is no progress I'm aware of. In the current state is not useful for us, we are still using the legacy v1 smartscape API for process groups (mostly detecting processes requiring restarts).

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
216.3:

Yeah I tend to fall back on the Legacy methods even when they are "Deprecated" lol 

	-Chad


----------------
216.4:

Looks like some of my wishes sometimes make it to the product In 1.275 there is finally pagination supported as described in release notes. Still waiting for filtering on the monitoring states 

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
217.1:

Hi Heramb,
Unfortunately, none of the two commands is currently available for you. But the team is currently in the progress of deploying it. You can expect the command to be available within the next couple of days.
Best,
Sini

----------------
217.2:

Hi Sinisa,Any update on deployment. Those 2 commands ( fetch metric & timeseries) are still not available  and this is the  huddle for us to implement SRG for metric evaluation.Regards,Heramb Sawant

----------------
217.3:

Hi,Any update on this??Regards,Heramb Sawant

----------------
217.4:

Hi Heramb,
I'll email you so we can share and discuss more details around your specific tenant.
Take care,
Nick

----------------
217.5:

HI NIck,Even I am also searching for same thing. Please let me know once it is available. 

----------------
217.6:

Hi @ShyamPradhan,
This turned out to be a permissions issue. The required permission policy is called "Storage Default Monitoring Read". This should be added to the desired user groups in the account management page.
To do this, follow these steps:

Log in to your Dynatrace account as an account admin (https://account.dynatrace.com/my/accounts) and select your environment.
Go to "Identity Management" and select "Group Management."
Choose the user group that should have access to Grail monitoring data.
Scroll down to "Environment permissions" and click the expand button for the environment.
Change to the "Policies" tab and bind the "Storage Default Monitoring Read" policy.

The image below provides a visual representation of this process.
 
I hope this helps!
Take care,Nick

----------------
218.1:

Hi @ahmadjamali ,How are you currently monitoring the Azure applications (if you have them set up already)?If you're wondering about how to integrate the monitoring with the ActiveGates, you can do so via the documentation here:https://www.dynatrace.com/support/help/shortlink/azure-monitoring-guide#capable-activegateIn addition, I'm not sure what you mean by the URL of the AG, but you will need the AG to be accessible on the ports listed here(note that this is for a Linux server, but the idea generally remains uniform). By publicly accessible, it will need to accept incoming connections on port 9999 and make outgoing connections to port 443. Adjusting the necessary firewall configurations should allow these configurations to work as expected.https://www.dynatrace.com/support/help/shortlink/sgw-install-linux#allow-connections-through-firewal...Cheers,Taylor S.

----------------
218.2:

Hi Taylor,Thank you for your reply.Currently No azure monitoring is in the picture.I would like to only monitor azure app service (web app) and not the whole azure, which is mentioned in below article:Integrate on Azure App Service for Windows | Dynatrace DocsI am just wondering about the integration with the AG, as in azure it does ask for environment URL or AG URL,so simply typing the AG URL is enough (if the AG is publicly accessible on 9999) to route the traffic to AG or extra action needs to be taken as well. Please let me know if we can change the URL and port (AG URL and 9999) to our custom URL and port.Regards, 

----------------
219.1:

I don’t think so. Please go with a product idea. 

----------------
219.2:

hi, we have GTSL - Genesys PS product and it integrates in our environment with an API layer with PinDrop API. We use Dynatrace to monitor GTSL hosts and the API interfaces. 

----------------
220.1:


Yes, it is supported. Please see also this thread. For installation follow the documentation for Solaris. Since Solaris does have only the PaaS OneAgent version, you have to include the preloading of the OneAgent in the execution context as described here. Most likely you need to include it in the startup script, or in the Apache envvars file (not sure if OHS is using it) and also it seems OHS has also its own variable definition methods.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
221.1:

Hi @natanael_mendes ,I'm not too sure if you know of this website, but you can use it to test various cases of RegEx alongside Python if you're familiar with that as well. https://regex101.com/In addition, inputting your test case into the RegEx generator on that site, I was able to generate this. Hopefully it serves as a starting point:   Best Regards,Taylor Sanchez

----------------
221.2:

Also adding that you can use that RegEx generator to test out your specific String. I've noticed that the appending values are blotted out, so if it's sensitive information and the RegEx provided doesn't work, you can adjust as needed for your use case. 

----------------
222.1:

The error message you're seeing in the systemctl status output indicates that the Dynatrace Server service failed to start. Here are some steps you can follow to diagnose and potentially correct the issue:1. Check the logs: Look into the logs generated by Dynatrace Server for more detailed error messages. You can find these logs in the Dynatrace Server's log directory, which is typically located at `/var/log/dynatrace/`. Look for any specific error messages or stack traces that might help you pinpoint the issue.2. Review the systemd service unit file: Make sure that the systemd service unit file `/etc/systemd/system/dynatrace-server.service` is correctly configured for your Dynatrace Server installation. Check that the `ExecStart` line points to the correct `server.sh` script and that all required environment variables or configurations are set. You might need to update this file if paths or configurations have changed after your OS upgrade.3. Permissions and Ownership: Ensure that the `server.sh` script and all related files and directories have the correct permissions and ownership. The user account running the service should have appropriate access to all necessary files.4. Check for missing dependencies: After upgrading your operating system, some dependencies or libraries required by Dynatrace Server may have been updated or removed. Check if there are any new dependencies needed by Dynatrace Server, and make sure they are installed on your system.5. Systemd Service Reload: After making any changes to the systemd service unit file or other configurations, reload the systemd manager with the following command to ensure it recognizes the changes:```bashsudo systemctl daemon-reload```6. Try starting the service manually: You can attempt to start the Dynatrace Server manually to see if it provides more detailed error messages. Use the following command:```bashsudo /opt/dynatrace-managed/server/services/server.sh start```This might give you more immediate feedback on what's causing the issue.7. Check for resource constraints: Ensure that there are no resource constraints like low memory or disk space that might be preventing Dynatrace Server from starting properly.8. Check for configuration changes: Review any configuration files that Dynatrace Server relies on (e.g., `dynatraceserver.ini`) to ensure they are still valid and compatible with the upgraded OS.9. Check for SELinux or AppArmor: If you're using SELinux or AppArmor, ensure that the policies are correctly configured to allow Dynatrace Server to run.10. Contact Dynatrace Support: If you continue to face issues, consider reaching out to Dynatrace support for assistance. They may have specific troubleshooting steps or patches for compatibility with Red Hat 8.6.Remember to make backups of any configuration files or settings before making changes, and proceed with caution when troubleshooting system services.

	Dynatrace Professional Certified


----------------
222.2:


Hi @Vuceti ,I think this question could best be answered by the Dynatrace Support team by adding some additional files from the logs that are collected by Dyntrace to troubleshoot the issue. Link: https://support.dynatrace.com/In addition, this would allow for you to give context to Support Engineers by providing the Log Output. The most relevant logs in the Dynatrace files would be: Server Launcher LogsServer.0.0.loglaunc-logging.logYou can also download the SupportArchives as a Zip file and append it as a whole. 

----------------
223.1:


Hi @DAVID_JAUREGUI1 Have you already checked this?Istio Service Mesh | Dynatrace HubI hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
224.1:

Hi @natanael_mendes, assuming that name is a placeholder. You can use:/[[:upper:]]+[[:blank:]]+/gm 

	The true delight is in the finding out rather than in the knowing.


----------------
224.2:

 Im getting this

	Dynatrace Professional Certified


----------------
224.3:

Hi @natanael_mendes,you can also use the following for user tagging regex cleanup rule  

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
224.4:

i tried this too

	Dynatrace Professional Certified


----------------
224.5:

The sample that i have is this  \n \n <strong>e-CPF:</strong> LUIZ CLAUDIO GOMES DA SILVA - 27\n \n

	Dynatrace Professional Certified


----------------
224.6:


Hi @natanael_mendes,I've tested it and it works with the sample you've provided, you need to add "space" after ">"> (.*?)-    

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
224.7:

i used your code to do what i wanted, was not the solution for real but was very very helpful. thanks alot

	Dynatrace Professional Certified


----------------
224.8:

@DanielS thanks for providing the regex to complete this ask. @natanael_mendes - https://regex101.com/ is a great site to build and test your regex. I highly recommend it. using it, I was able to validate Daniels Solution:   

	-Chad


----------------
224.9:

I tried but the Dynatrace Regex is different from others

	Dynatrace Professional Certified


----------------
225.1:


@sbundi are you trying to install the Nagios integration extension? This one is a separately licensed extension developer by Alanata (Dynatrace Partner). Please reach out to dynatrace_integration@alanata.sk for a trial license if you are interested.You can find more about the extension here: https://alanata.atlassian.net/wiki/spaces/DTNAGIOS/overview

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
225.2:

Question out of curiosity... What does Nagios offer that would not be same as just placing the Dynatrace OneAgent on the hosts? Thanks!

----------------
225.3:

@larry_roberts Reasons for the extension vary, however typically customers do have some investment in their Nagios installation and want to use that data - such as custom integrations or hardware monitoring. It's also not uncommon for customers to have limited Dynatrace licenses (budget) and cannot cover the whole environment with OneAgents.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
225.4:

Makes sense. Thanks!!!!

----------------
226.1:


Why don't you subscribe a service method and set a threshold or adapt the baseline for that subscribed key request?

----------------
226.2:


There is no way to add threshold lines to charts in dynatrace yet.But automatic alerting based on key user action and key requests is possible. You can modify the baseline behavior or set static threholds for those.

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
226.3:

Wolfgang was a minute faster  The same is possible for key user actions and should do what you want.

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
226.4:

I have this same question. It makes sense to add this feature to the custom charting. This way while we look at the dashboards we would come to know if anything is crossing the thresholds. Plus one more point to make this request a requirement is the X & Y axes of the charts are not static, it is dynamic. Hence when we have a lot to monitor on a dashboard it becomes too hard to identify if the spike is really a spike or a normal transaction within the threshold. This becomes clear only when we look at the chart closely to understand what is the x/y axes of the chart pointing at.Alerts come under the problem tile and if there is a very sensitive application where there will be constant alerting, this gets missed out or it becomes over alerting.Please, this is a very needed requirement. Please do not ignore this feature request and provide workarounds. Kindly consider this. I hope you understand the concern.

----------------
226.5:

This is possible now, see https://www.dynatrace.com/support/help/shortlink/visualization-graph#thresholds .

----------------
227.1:


Hi @Vasil_Penev,I think this is not available, however, you can create a graph tile on the dashboard and select the last 7 days for instance then apply a baseline to the Graph tilealso, you can check Prediction-based anomaly detection that might help using the parameter predict=true to Dynatrace Metrics API v1 request, for more details check the following URLhttps://www.dynatrace.com/support/help/shortlink/anomaly-detection-prediction#application-load-predi...note that the prediction will be calculated for the next 30mins only as I remember.

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
227.2:

This is true, but you can't currently display the baseline on a dashboard - it's only visible in Data Explorer.

----------------
227.3:


Hi @Vasil_Penev There is a product idea for that which is currently under review, you can share your use case there for better reach.https://community.dynatrace.com/t5/Product-ideas/Option-to-apply-Seasonal-baseline-intelligence-to-A... BR,Islam

	Dynatrace Certified Professional - Dynatrace Partner - Yourcompass.ca


----------------
228.1:

Hi,Is it the same configuration log ? It seems you have a wrong entry in your configuration :Duplicated Host address / port (ip: 0.0.0.0, port: 161)Could you fix it ?

	Observability Engineer at Phenisys - Dynatrace Professional


----------------
228.2:

No Duplicate entry for device.  And no configuration gaps. 

----------------
228.3:

Hmm.Did you configure it through API or GUI ? Could you share your configuration payload (with anonymized IP of course) ?   

	Observability Engineer at Phenisys - Dynatrace Professional


----------------
228.4:

Using GUI for configuring the devices.  

----------------
228.5:

Regarding duplicate issue you should create a configuration with 1 host, then add gradually others to identify why it failed.Regarding timeout issue :Try to run snmpwalk from the AGIf it works well you can adapt SNMP settings in your configuration:Increase timeout if the device is far away from AG and you have lots of OiD to pollReduce Max repetitions to 50 if you have an MTU issue (reducing response payload)    

	Observability Engineer at Phenisys - Dynatrace Professional


----------------
228.6:

Could you please provide the right snmpwalk command to check connection establishment. We ran the below snmpwalk command from AG server but we received the timeout error.snmpwalk -v2 -c  public <IP Address>

----------------
229.1:


Hi @agylpradipta,I thnik you should try the combination of Monitored entities and Settings objects API. Enable/Disable by settings objects API: I hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
230.1:

Hey, you can use some rules to do this.Check this documentation if you use classic v2https://www.dynatrace.com/support/help/observe-and-explore/logs/log-monitoring/log-processing Check this documentation if you use Grailhttps://www.dynatrace.com/support/help/observe-and-explore/logs/log-management-and-analytics/lma-use... 

	Dynatrace Professional Certified


----------------
230.2:


Hi @olegus,Could you please check my pervious posts about log monitoring.Solved: List log files for a metric - Dynatrace CommunitySolved: Application Log monitoring - Dynatrace CommunityAs a first step is to set the log collection:1. At cutom log source configuration you add it manually the test file log  and then2. At log source configuration if DT recognized your text file log after ponit 1. It will be also usefull from other members: Solved: Logs Classic - Log storage configuration vs Custom log source - Dynatrace CommunityMaybe you can use them.I hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
230.3:

Thanks, Mizso,That looks promising, a question regarding switching to Log Monitoring v2 - what will we lose when we switch to v2? We dont monitor any logs yet , but if we do, would we need to redo all log metrics ?

----------------
230.4:

Hi @olegus,I think the answer yes. You will have to redo the log metrics. I was lucky because I switched to v2 quite early I did not have to much v1 configuration. You should do it as soon as possible because as you may read v1 support will end by 01.2024.Regarding the v1 vs v2. No questions, v2 has much more possibilities than v1. I perfer it.Best regards,Mizső

	Certified Dynatrace Professional


----------------
230.5:

Not  sure how this forum works, but the first post that was "accepted as a solution" (not by me btw) did not answer my questions   - it just contains links to general DT docs, which I already read before asking those questions.  I will re-read them and try solutions provided by Mizsco and report back.

----------------
230.6:

Hi @olegus,You can accept my answer also. Thanks in advance.Best regards,Mizső

	Certified Dynatrace Professional


----------------
230.7:

Mizso, 1. So far I created Custom Log Source configuration and I also created Log Storage configuration for the same log file - now i see my log in Logs&Events.2. I've added DQL rule to filter my log data to show only "exit code XXX" lines3. Looks like I'm good to go to create a Log event. 

----------------
231.1:

If you can see the grail pop up activation you are using log v2

	Dynatrace Professional Certified


----------------
231.2:


You can detect if you have v1 in Settings, but even if you don't have Settings, go to the Classic host page, on the bottom right you should see:  Click on one of them, and if you see something like the following, especially the "Download log files" button, you have the oldest Log  monitoring version...  

	Antonio Sousa


----------------
231.3:

Thanks for the response AntonioSousa, But, i actually don't see logs on hosts page (o logs) , logs are not directly ingested from the hosts but were forwarded using dynatrace-aws-s3-log-forwarder

----------------
231.4:

So, you should have v2 then v1 is only available in older tenants that didn't switch to v2, so they should be pretty rare these days...

	Antonio Sousa


----------------
232.1:

Yes, its totally possible. Take a look on this documentation pagehttps://www.dynatrace.com/support/help/platform-modules/applications-and-microservices/services/requ... In this screen you can set your filter based on request attribute and put there what you want like if i want a ip that begin with 192 the will retrieve if this value are on the filter  https://www.dynatrace.com/support/help/platform-modules/applications-and-microservices/services/requ...

	Dynatrace Professional Certified


----------------
232.2:

I read the documentation and I understand that we can filter requests using a complete Request Attribute value such as the provided example of "Booking = checkcreditcard" however I could not find where it mentions being able to filter using operators such as "contains" or "starts with" so that we can create a filter like "Booking contains credit".  

----------------
232.3:

You dont need use Contains, if you put Booking= creckThe querie will retrieve checkcreditcard, creckx and crecky

	Dynatrace Professional Certified


----------------
232.4:

I have walked through the example again and there is no way to modify the filter in the Multidimensional Analysis view, it simply uses whatever Request Attribute value that was selected in the Service details page.We are on Dynatrace Managed, could this ability to modify filters as you described be available on SaaS only?

----------------
232.5:

Can you send me a print screen?

	Dynatrace Professional Certified


----------------
232.6:

Sorry for my last post, it was wrong. im searching something that will help you

	Dynatrace Professional Certified


----------------
232.7:

The only way that you can do this is putting the whole IP for search. and insert more filtes based on the request attribute

	Dynatrace Professional Certified


----------------
232.8:

Could you elaborate as to how more filters could be applied?  Let's stay with the IP example where there is a Request Attribute called "SrcIP".  If we wanted to find all requests which contained "192" in "SrcIP" how would that be accomplished?

----------------
232.9:

this is what i was saying, i think thats not possible 

	Dynatrace Professional Certified


----------------
233.1:

Hello @Jamz You might have a license quota (host units) issue. Can you verify the license?Regards,Babar

----------------
233.2:


Another option may be to extract a support archive from the OneAgent and review the logs to see there are clues as to why the agents/hosts may be going offline.  The logs may show things like connectivity issues between the agent and the cluster or agent shutdowns, etc.https://www.dynatrace.com/support/help/setup-and-configuration/dynatrace-oneagent/oneagent-troublesh...

----------------
234.1:

You can ingest metrics into Dynatrace, here is a link on how to do it  https://www.dynatrace.com/support/help/dynatrace-api/environment-api/metric-v2/post-ingest-metrics 

	-Chad


----------------
234.2:

Hello glorywe have the prometheus dataSource for Extensions V2.0 that allows you to integrate those metrics directly.https://www.dynatrace.com/support/help/extend-dynatrace/extensions20/data-sources/prometheus-extensi...https://www.dynatrace.com/support/help/extend-dynatrace/extensions20/data-sources/prometheus-extensi...

----------------
235.1:

Hello @xtraspecialj under the Configuration API you have:  

	The true delight is in the finding out rather than in the knowing.


----------------
235.2:

Yeah, that's the API I mentioned in my original post, which is v1 API.   Based on your other post it sounds like you are saying there isn't an equivalent v2 API way to reach this?

----------------
235.3:

Right, as I add below, the future roadmap of APIv1 in particular and API in general is unclear, but in the latest Dynatrace there is at least a classic APIv1 and v2 environment.  

	The true delight is in the finding out rather than in the knowing.


----------------
235.4:

The future of the current API is not clear, even within V2 I have seen many modifications over time. I haven't seen end of life for API v1 yet. Your approach is valid, but today not everything has an equivalence. I think you have exhausted all the possibilities correctly.The only change that is likely to be implemented is to obtain Bearer tokens through an Oauth application.

	The true delight is in the finding out rather than in the knowing.


----------------
235.5:

You need to use the Monitoring entities API (Environment v2 API) and look for the APPLICATION_METHOD entities.Use the entitySelector with relation for looking up the key user actions for a particular application, for example:type(APPLICATION_METHOD),fromRelationships.isApplicationMethodOf(entityId(APPLICATION-C45712444213D6A1)) This will return the list of key user actions present in the searched timeframe. Then you can fetch the metrics using Metrics API for such actions. There is no schema in Settings API at this time which will allow you to configure or retrieve key user actions for an application.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
235.6:

No, as I stated in my original post, the Monitored Entities API will get you a list of all User Actions for an application.  There's no property that denotes whether any of those properties are Key User Actions.  At least not any that I could find.  I'm just using the v1 Configuration API for now.

----------------
235.7:

No, APPLICATION_METHOD is a key user action. You won't see non-key user actions in Monitored entities, only key user actions. Just be sure you are looking at the correct user action and application since key user actions can have the same name across different applications.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
235.8:

You can use terraform, which powered by v2 API https://registry.terraform.io/providers/dynatrace-oss/dynatrace/latest/docs/resources/web_applicatio...if TERRAFORM_EXPORT:    terraform_export = subprocess.Popen(        args=[os.environ['DYNATRACE_TERRAFORM_BIN'], "-export", "-id", MODULE],        cwd=PROJECT_FOLDER)    terraform_export.communicate()module "web_application" {  source = "./configuration/modules/web_application"}  

----------------
236.1:

Hi @Lwl ,To answer the best practice configuration, you can find additional information in our documentation here to configure Dynatrace with Kubernetes. Overall, there are different deployment options depending on what fits best for your observability purposes.https://www.dynatrace.com/support/help/shortlink/installation-k8s 

----------------
236.2:

Hi @Lwl ,You can connect to the public API or internal API endponit of Kubernetes. Kubernetes API Monitoring | Dynatrace DocsEvent monitoring configuration:Monitor Kubernetes/OpenShift events | Dynatrace DocsIn case of Internal API end point connection you need a containerized AG (FullStack) instrumentation. In case of AppOnly instrumentation you can also create a containerized AG as a StatefulSet set.Instrumentation types:Deployment options on Kubernetes/OpenShift | Dynatrace Docs Create manual containerized AG in case of AppOnly injection:Manually deploy ActiveGate as a StatefulSet | Dynatrace Docs For event configuration I always use this without filters (I prefer it, pvc consumes lot of DDU):  Then you can able to create nice dashboards and alerts (there are some perdefined in Settings / Anomaly detection): I hope it helps.Best regards,János

	Certified Dynatrace Professional


----------------
237.1:

I observe, when I add an extra rule in "Custom log source configuration" to tell Dynatrace /myFSLocation/var/log/tomcat/abcd2/abcd2-daily.log is a log, then it at last get's uploaded.But not associated to its PG nor itS PGI. Which is strange, because when I watch through the PG, the tabs "Logs" shows the log file alright. If I add a PG context in the "Custom log source configuration" rule then it's contextualised all-right with PG and PGI.Yet all this requires per log / per PGI définitions : quite some qork ! Ans not durable : if a PG-ID changes : all gone ! Any ideas.Regards.

----------------
238.1:

Hi @GregOReilly 
Current Azure log throughput characteristics are described in the documentation page mentioned by you in the section scaling guide . We have a backlog item to improve Azure throughput further. What would be the expected throughput in your environment?

----------------
238.2:

Hi. 
Just wanted to update this topic with information about the improvement to the throughput of Azure forwarder. It's now up to 138GB/h ​(3,3TB/day). Refer to the documentation for details and scaling guides: https://www.dynatrace.com/support/help/setup-and-configuration/setup-on-cloud-platforms/microsoft-az...

----------------
239.1:

@kadirhan,Have you checked the Dynatrace APIs? They should have the information you need...

	Antonio Sousa


----------------
239.2:

Hello ,Thanks for your answer , But I know that we can pull our own environment data using Api . Also, is there an API where we can pull the Dynatrace document page?I'm talking about the data on the Dynatrace Document page, not our own environment data.https://www.dynatrace.com/support/help/get-startedIs there a different way to pull the data from the Document page?Thanks.

----------------
239.3:

@kadirhan,OK, I get the idea If it's not for something like academia, you don't have to reinvent the wheel. Use Bing (quick example below):  

	Antonio Sousa


----------------
239.4:

Hi @kadirhan ,As @AntonioSousa mentioned, you are able to get information about your environment via the Dynatrace API as linked here:https://www.dynatrace.com/support/help/dynatrace-apiThe information that is returned is in JSON format as you mentioned.However, in terms of your question, I've noticed that you specify the Dynatrace documents. Do you mean the documentation page or the data collected in your environment? 

----------------
239.5:

Hello ,Thanks for your answer , But I know that we can pull our own environment data using Api . Also, is there an API where we can pull the Dynatrace document page?I'm talking about the data on the Dynatrace Document page, not our own environment data.https://www.dynatrace.com/support/help/get-startedIs there a different way to pull the data from the Document page?Thanks. 

----------------
239.6:

Hello Kadirhan, this is not possible. At least, not that I know of.
As far as I understood, please correct me if I am mistaken, you have a chat bot (a GPT-like) and you want to feed it our Dynatrace documentation so that it can answer you.
So, you are looking for an API to hand-deliver you our documentation in an easy format for the chat-bot to understand, unfortunately, we do not have this. So as previously mentioned, please raise a new feature request in Product ideas - Dynatrace Community.
The currently available solution for you is to scrap our documentation, in terms of staying up to date, you have feed.xml as previously provided.
Hope this helps.

----------------
239.7:

Hello Kadirhan,Can you please provide more details on what you want to achieve? And example JSON format that you are looking for? Is it that you want our HTML tags to be in JSON format?In terms of scrapping, you might want to just simply use https://www.dynatrace.com/support/help/feed.xml to only scrap for whats new, considering that this is in XML format, but it shouldn't be difficult to convert it to JSON on your end. If you want us to support JSON Feed, I'd suggest you to please raise a new feature request in Product ideas - Dynatrace Community.Hope this helps.Regards,Adham

----------------
239.8:

Hello ,Thanks for your answer, the link https://www.dynatrace.com/support/help/feed.xml seems to be enough for me. Is it possible to shoot all the contents of the titles in the document via this link?There is a project I want to do, I want to develop a chatbot with the help of a chatgpt using Dynatrace document data. For this, I need a structure to keep up-to-date document data and to classify all of these data as title - content.Thanks for support .

----------------
239.9:

Hello ,I see only a few titles and content from the RSS feed, I want to get all the content from the documentr page. is there an easier and different way to do this?Thanks

----------------
239.10:

No, you will have to scrap the documentation then rely on feed for whats new.

----------------
240.1:

Hi @pb388 Can you verify the agent log and see if there is a problem related to this process? There could be many causes, but let's check the agent log to start with.Radek

	Have a nice day!


----------------
240.2:

Hi Jasinski,Thanks for your response!We have checked the one-agent logs, but we didn't find any problem related to this process in the logs. could you please explain how this Perl bootstrap process will work in Dynatrace? Ameena 

----------------
240.3:

I can't answer you how this is implemented technically for Perl. I suggest you set up a ticket in support - you will get the most detailed answer there.

	Have a nice day!


----------------
241.1:

I would create a tag based off the entity selector and then supply the host name to the OS Service, which is a custom device and then use your Maintenance window to define out a set of tags for the entities you want to suppress.  The only down side is, I don't thin that the entity selector can do dynamic placeholders, but its worth a shot. I have an RFE out for added functionality on tags, please give it a like: https://community.dynatrace.com/t5/Product-ideas/Dynamic-Automatic-Tagging-Expansion/idi-p/210349https://community.dynatrace.com/t5/Product-ideas/Expand-Dynamic-Auto-Tag-constructs-for-Kubernetes/i...  

	-Chad


----------------
241.2:

We have thousands of hosts\custom devices. Hope not possible to create auto tag for each host and moreover not sure what is max limit for auto tags.I already created few tags on custom devices with referring the tag from Host, but those tags are keep missing and working intermediately. Already a case is open for this with Dynatrace. The ultimate solution is they need to include host name in the placeholders for custom devices or they need to revert back OS services are part of Host. This change is really irritating and impacting our business and not sure the reason behind this idea about separating OS services as custom devices from Host. How will OS services run without a HOST?We have a plan to decom Dynatrace and move to different monitoring tool if no solution from them as this change has been made in 1.265 and we are running 1.273 but still don't see any solution from them.

----------------
242.1:

Hi @Candy ,The documentation for configuring the Cluster ActiveGate SSL certificate can be found in this documentation:https://www.dynatrace.com/support/help/managed-cluster/installation/install-your-own-ssl-certificate...Cheers,Taylor S.

----------------
243.1:

Thank you for this awesome summary, @Ana_Kuzmenchuk!! 

----------------
243.2:

Great news, and very well documented.

----------------
243.3:

Thank you, @DanielS and @AntonPineiro, for your kind words, but also for giving us your feedback in the first place 

----------------
243.4:

thank you so much, i've been looking for this for a while

----------------
243.5:

The first step of introducing the personalized feed in the Community! 
We now have two additional sorting options that you can use to see only the content you're subscribed to.
Read more here.

----------------
243.6:

very exciting! 

----------------
244.1:


Hi @gurugogi ,Thank you for your question. The best approach really depends on your circumstances and what works for you, since each environment is different. Build time injection would simply be done once and less at deployment time, while the runtime injection involves automated download of agent files. In addition, build time injection is a less overhead intensive way to build the image, but the trade-off is the increase in size for application image and build time. The main two differences between the two are installation and set up related.

----------------
244.2:

Thanks @Taylor-Sanchez .what I understood is for "runtime injection" will have two containers, one is application container and another one is Oneagent container, oneAgent container will have required code modules based on the technology and inject it on to application container, injection will happen only time when these containers are run for first time, so oneagent container will run for onetime and inject code modules onto application container and then it will be in stopped status.Please let me know what I understood is correct or not.This is the path on oneAgent container which is available on volume mount where OneAgent code modules are stored ?Scroll to Environment, and in Environment variable, define LD_PRELOAD with the value /opt/dynatrace/oneagent/agent/lib64/liboneagentproc.so

----------------
244.3:

This is a very interesting topic. I've seen issues with monitoring Fargate. The main issue is that the Fargate node will not have access to download the Oneagent and do auto injection. Which then causes a gap in the monitoring stack. This is just one of the issues I've run into with Fargate. All the other K8 connections I've seen and work with were pretty seamless, Fargate is the one that gave us the most problems. 

	-Chad


----------------
245.1:


Hi, what do you mean by tenant version? Tenant is just an environment for agents that are versioned.

	Senior Product Manager, Dynatrace Managed expert


----------------
245.2:

By tenant I mean the version of my dynatrace environment - what version is running at my https://xxxx.live.dynatrace.com . 	I was about to try the Golang support, but I can't see the option in my environment. Blog post says it is from the cluster version 127. How can I see if my environment is at this level?Briefly looking at the HTML source code - it should be 127, since some URLs include this numbering, but I don't see the Golang support in our environment.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
245.3:

OK. I see. So in SaaS all clusters are already on 1.127. You can not bother that at all if you are SaaS user. We perform all cluster updates in time.It seems that this feature was not enabled yet for your tenant. Please give us some time, and we'll enable that shortly.

	Senior Product Manager, Dynatrace Managed expert


----------------
245.4:

Hey Julius, I've just received a confirmation this is going to be available on Friday. Thanks for your interest in willing to test that. Let us know your impressions and insights you discovered with that new functionality! 

	Senior Product Manager, Dynatrace Managed expert


----------------
245.5:


With recent sprints (probably from 146) the tenant version is visible in the bottom of the user menu. No need to look at the source code anymore.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
245.6:

I still cant see the SaaS version in the UI? Can you please help with the right navigation to see the same

----------------
245.7:


 SaaS Version

----------------
245.8:

Great, thank you

----------------
245.9:

Where we can see it with the new Dynatrace view?

----------------
245.10:

@Duran_Narbona it's not (yet) in the new platform UI but it will be available shortly in the next releases with additional improvements. You can switch to the old UI to get the version.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
245.11:


You can see the tenant version if you go to the Hub> Manage > any Classic App, e.g Data Explorer
 
 
 

----------------
246.1:

Awesome

----------------
247.1:

Hi Brian,With request naming rules you should be able to go service by service (using the UI) instead of request by request. You can create a cleanup rule that extracts the request name as is and converts it to lower case. Go to your Service > Edit > Web request naming rules > add Cleanup rule:If you have a need for this for more than a couple of services, the API is the alternative for creating these rules at a global level..../api/config/v1/service/requestNamingI hope this helps.Best regards,Radu

----------------
247.2:


Radu, this is not solution. It doesn`t work.  It transfer all URL to "/" - I have requested "/pDp/2222/dRd" and "/ppp/2222/ddd"   It can be done  by rule with additional placeholder:  Result:      Regards,Alexander 

----------------
247.3:

This is great, but by doing this it removes the clean up rule `Remove UUIDs, IP addresses and IBANs from URLs`Do you have a way how we can fix this ?

----------------
247.4:

You can apply the placeholder on the request name rather than the URL path to preserve [uuid] and similar replacements that Dynatrace already performed.In case of non-URL request names, I use a broader match of regex:  (\S+?)$

----------------
247.5:

I have this same issue and would really appreciate a global way to turn off case sensitivity on all requests. It has to be at least by service and I'd appreciate it if it was simply a check box at the global or service level. It's very much a pain to try and do this at a request or service level now.

----------------
248.1:

Is there not going to be an answer to this?  We're finding ourselves in the same position where we are unable to monitor these PaaS apps because we chose to deploy them to Linux.

----------------
248.2:

			
				
					
					
						Is Dynatrace going to find the solution for this or we have to tell our customers to use the Native tool instead of Dynatrace?
					
				
			
			
				
			
			
				
			
			
			
			
			
			
		
----------------
248.3:

https://www.dynatrace.com/support/help/technology-support/cloud-platforms/microsoft-azure/azure-serv...As I understand, you don't see available extension mentioned here for linux instances? Sebastian 

	Regards, Sebastian


----------------
248.4:

No, the extensions option is grayed out.  You also can't add extensions through Kudu.

----------------
248.5:

Extensions in general are not supported for App Services on Linux.  However, there is a workaround which isn't supported by Dynatrace.  It is based on the runtime OA script for Kubernetes and Docker.  The Azure App Service on Linux is essentially a Docker container.  The Java image used is a "musl" type.  I've created a basic script which will deploy OA under /home; this must be done in this directory as any changes outside of it will be lost when the container restarts.

	Dynatrace Certified Professional


----------------
248.6:

I tried doing something like this, more as a test, but it couldn't get access rights to the .Net dll so it wouldn't report on the process itself just the container.

----------------
248.7:

Is your app Java or .NET?  We are using Java in ours and was able to deploy OA successfully to our PROD and TEST environments.Also, In your application environment, you have to add "LD_PRELOAD=<*/agent/lib64/liboneagentproc.so> pathAnd then restart your application.Let me know if you need/want to talk about this offline.

	Dynatrace Certified Professional


----------------
248.8:

Our app is an ASP.NET Core app.  Thank you for your assistance thus far.  I'll continue to toy around with it and see if I can make any progress and if not I might just take you up on your offer.Again, thank you!

----------------
248.9:

Hi Josh - I have same requirement for ASP.NET Core app on Linux. Did yours work out?

----------------
248.10:

Hi Bill, it is possible to talk about Azure Linux WebApp OA deploy? We are facing with some issues with deploys, so I would be happy for some tips.Thanks!Ondrej

----------------
248.11:

Hello Bill,Can you share with me the script you deploy?Kofi

----------------
248.12:


This is what has been provided by Dynatrace support. I tried a few times and it works quite well. You would need to do the following steps: -) Set 3 environment variables via the Azure Portal -) Download and execute a script from us -) Set 1 environment variable via the Azure Portal -) Restart the WebAppFor this approach Dynatrace prepared a script which is comparable to our buildpacks: https://github.com/DTMad/azure_webapp_linux/blob/master/dynatrace_installer.sh In this script do the following steps:Download the agentInstall the agentSet the standalone.conf fileSteps to doThe customer needs to set the following environment variables through the Azure Portal:DT_TENANT - only the tenant ID (skj22538), not the entire URL (skj22538.live.dynatrace.com)DT_API_TOKEN – It needs to be a PaaS TokenDT_API_URL – needs to be the tenant URL followed by /api (ie skj22538.live.dynatrace.com/api) Then the customer needs to ssh to his container and execute the following command: wget https://raw.githubusercontent.com/DTMad/azure_webapp_linux/master/dynatrace_installer.sh && bash dynatrace_installer.shThis downloads the script mentioned above and runs it. After the agent installation is finished the customer then needs to set another environment variable via Azure Portal: 'LD_PRELOAD'The value for variable 'LD_PRELOAD' will be this path:NOTE: Let’s make sure the path in LD_PREDLOAD is correct, otherwise OneAgent will not load.I hope this helps !

----------------
248.13:

Thanks for share the solution. This is to install OneAgent after a container is built. In other words, if the appservices are swapped to another image, then we lost the OneAgent. Wonder if this can be included in the dockerfile to install during the container build time.

----------------
248.14:

Hi Juan, The GitHub link to the installer script doesn't seem to work - It has probably been removed. Do you know where I can find it? Francois

----------------
248.15:

Hi @bill_scheuernst . I'm not able to install it in non-containerized Linux AppServices solutions. It seems that for Linux AppServices, it is only possible for containers. --> https://www.dynatrace.com/support/help/technology-support/cloud-platforms/microsoft-azure-services/o...  I opened an idea the past 16th February -> https://community.dynatrace.com/t5/Dynatrace-product-ideas/App-Services-for-NON-CONTAINERIZED-Web-Ap... 

----------------
248.16:


https://www.dynatrace.com/support/help/setup-and-configuration/setup-on-cloud-platforms/microsoft-az...

----------------
248.17:

In the last year, i have had clients follow the documentation for linux in Azure and it worked perfectly for Azure app services.

----------------
249.1:


If you have followed to this configuration, you don't need to do anything else in runtime mode:https://www.dynatrace.com/support/help/shortlink/aws-fargate#runtime

	Have a nice day!


----------------
250.1:

The message you've provided indicates an issue related to the unload event in a web application being monitored by Dynatrace. Specifically, it mentions that the unload event does not reliably fire, and that listening for it can prevent browser optimizations like the Back-Forward Cache. To address this issue and potentially improve site performance, consider the following steps:1. Review the Usage of the Unload Event:- First, assess why you are using the unload event. Unload events are typically used to perform actions when a user navigates away from a web page, such as cleaning up resources or recording analytics data. Make sure you genuinely need this event for your specific use case.2. Replace Unload Event with Pagehide Event:- As recommended in the message, consider replacing the unload event with the pagehide event. The pagehide event is more reliable and can serve as an alternative for performing cleanup actions when a user leaves a page. Update your JavaScript code to use this event instead.Example:```javascriptwindow.addEventListener('pagehide', function(event) {// Your cleanup or tracking code here});```3. Test Impact on Site Performance:- After making the code changes, thoroughly test your web application to ensure that the replacement of the unload event with the pagehide event does not negatively impact site performance or functionality. Monitor performance metrics to confirm that any optimizations you've made are effective.4. Consider the Back-Forward Cache:- Understand the implications of the Back-Forward Cache in modern browsers. The Back-Forward Cache aims to improve navigation speed by keeping a cached version of a page when users use the browser's back or forward buttons. Listening for certain events, like unload, can prevent the browser from utilizing this cache effectively.5. Monitor with Dynatrace:- Continue to use Dynatrace to monitor your web application's performance. Dynatrace can provide insights into how your changes impact performance and help you identify any new issues that may arise.6. Optimize Other Aspects:- While addressing this specific issue, also consider other optimizations for your website, such as reducing page load times, minimizing the use of synchronous JavaScript, and optimizing server-side processes. These optimizations can have a significant impact on site performance.7. Stay Informed:- Keep up-to-date with best practices for web performance and browser optimization. Web technologies and best practices evolve over time, so staying informed will help you make informed decisions for your web application.By addressing the issue related to the unload event and optimizing your web application's performance, you can provide a better user experience while ensuring that Dynatrace monitoring continues to provide valuable insights.

	Dynatrace Professional Certified


----------------
250.2:

But as you can see in this report the issue points directly to ruxitagentjs file.Doesn't it come from dynatrace?  

----------------
251.1:

Hi,I don't remember there being an option to narrow down the permissions that much. What I would try is to create permissions (Manage monitoring settings)for a specific Management Zone. Then you would gain permissions to configure alert profiles, for example."Manage monitoring settings: Allows the changing of entity settings within a management zone, for example, the ability to record or edit synthetic monitors. It also grants access to some items in the global settings menu but only allows making modifications to assigned management zones. For example, alerting profiles can only be created and changed for a specific management zone."For the API, you have to use the settings.read and settings.write scopes to make the changes you want:https://www.dynatrace.com/support/help/dynatrace-api/environment-api/settings/schemas/builtin-alerti...You can narrow down the scope by specifying additional parameters like the name of the MZ, etc....Radek

	Have a nice day!


----------------
251.2:

The problem is that these permissions are only usable for users, not tokens/API .  the read and write API settings are way to broad for us.... Maybe something can be achieved with some scripting here.

	A Dynatrace Professional nerd working for Eviden


----------------
251.3:

In my opinion, this is currently the only method. You can submit a product idea for Dynatrace to allow more complex permission management on the settings tab. 

	Have a nice day!


----------------
252.1:


Maybe your user tag its not correctlyHere take a look on this documentation  https://www.dynatrace.com/support/help/platform-modules/digital-experience/web-applications/addition...

	Dynatrace Professional Certified


----------------
253.1:


If there is a metric for that (Check it in the menu Metrics in UI), then you are able to pull it easily. Is there any specific metric you need to query?

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
253.2:


This is a great list of the metrics and metric keys that are in Dynatrace: https://www.dynatrace.com/support/help/how-to-use-dynatrace/metrics/built-in-metrics/saas/

	-Chad


----------------
253.3:

So for example, I am trying to pull builtin:containers.cpu.usageMilliCores for an OpenShift entity. I can easily pull that with type(CONTAINER_GROUP_INSTANCE),entityName("my-app"). However I cannot seem to pull by tag that my-app belongs to.Lou 

----------------
253.4:

Same here would like to be able to see what each container is using as a total for millicores

----------------
253.5:

i am working on automating the pulling of metrics via the V2 API , could you please help if you have any resources or steps? thank you

----------------
253.6:

@dynamic  for pulling metrics, you need to use the Metrics API - Get metric data points. You need to supply parameters such as entitySelector and timeframe at least. Metric selector and entity selectors can be tricky for beginners, however for the new Unified Analysis Screens it's easy to show it in the data explorer: And then you can just copy the metric selector from there or also use the filter part as entitySelector. 

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
253.7:

I can pull metrics from API, however, I need to automate the next page key to pull data in real-time. and then create a report based on that data.  is there an efficient way to do it? the goal is to connect to powerBi

----------------
254.1:

Congrats @Viachaslau !

----------------
254.2:

Congrats @Viachaslau 

----------------
254.3:

Thank you) 

----------------
254.4:

Aha!! It seems that the season of music players has gone and now we are selecting athletes as member/employee of the month!Congrats, @Viachaslau !!!Now you need to set up a match with our Employee of the month. My bet is on you. Go, Members, go!!!

----------------
254.5:

Great Work @Viachaslau !!!! Another Asimov fan here.

----------------
254.6:

Super, keep it up!

----------------
254.7:

Congrats!Awesome post.Ayzek Asimov Pembroke Welsh Corgi  

----------------
254.8:

Congratulations @Viachaslau !!!

----------------
254.9:

Congrats @Viachaslau 

----------------
254.10:

congrats 

----------------
254.11:

Loved the eclectic path!I believe that such a diverse set of skills has been of great use throughout life, in so many wide-ranging use-cases!Congrats, @Viachaslau !!

----------------
255.1:

We have a 1 to 1 ratio - 1 query for 1 server as 1 Generic DB Extension Endpoint. We have not run into any issues.

	-Chad


----------------
255.2:

Yes i agree. Everything is stored in custom.db.query metric but so it's quite difficult to manage it (filtering to select data for many dashboards).

----------------
256.1:

Hi,If you have extensions that monitor your databases you can fetch them by using Metric API. With Grail you can currently fetch only built-in metrics. Best Regards,Mateusz

----------------
256.2:

Hi Mateusz,is there any plan to send extension metrics to Grail ? near future ?Thanks for your answer

----------------
257.1:

Hi Giles,Yes, to see the transactions go through the Datapower tier, you have to ensure that the X-dynaTrace header is not stripped and is passed through Datapower to the next tier. This is what I did to see my transactions go through Datapower.ThanksNJ

----------------
257.2:

Hello Ugochukwu;Do you know where I could apply the configuration in the datapower?Thanks for your answer.RGuerrero

----------------
257.3:

Hi NJ!Could you please share any details regarding the DataPower configuration? We are currently also facing this issue. Thank you in advance!RegardsArild

----------------
257.4:

Hi Ugo,Thanks for your answer.I'll check this.Gilles

----------------
257.5:

Hi,I come back to this issue. My customer confirmed that the x-dynaTrace header is stripped.But they did not find an easy way to configure the whole Datapower to copy the incoming request header to the outgoing request without having to set up a rule on each service (more than 200).Did anyone find a solution to apply that rule to the whole Datapower config?Thanks.Gilles

----------------
257.6:

hi All,i have same issu with dynatrace not allow x-dynatrace header after IBM DP, on proses MQ, there are solution how to allow x-dynatrace header on MQ, to show service flow end to end.need help for some documentation for allow Header on MQ Proses.Thnks

----------------
258.1:


Hi @AntonPineiro,The custom log storage which related to the logs that are not detected automatically by OneAgent, so you can specify the log source path. after adding the customized log source path you need to create another rule in the Log storage configuration to include/enable this custom log source and to be monitored.as for other log files that are automatically detected by OneAgent, you can create log monitoring configurations directly without creating any custom log source.so yes both are required to configure custom log path, the first step to configure the custom log path and the second step is to include/enable monitoring for this custom log.I hope this helps you and let me know if further clarifications are needed. 

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
258.2:


Hi @AntonPineiro , In response to your first question, there is no 'new' or 'legacy' in terms of log storage and the custom log source. Both are required in order for you to be able to detect a log that is not natively discovered by Dynatrace, as described by @Mohamed_Hamdy .  In addition, the documentations required for you to be able to do both can be found here, where it specifies that it must be done in two parts. Attaching the screenshot as well for visibility,https://www.dynatrace.com/support/help/shortlink/log-monitoring-custom-source  

----------------
258.3:

Hi,Thank you both. It is strange, I have just only created a log storage configuration (without log source configuration) and logs are being ingested.It is in relation to Windows Application Logs, maybe for Linux both rules are required.Best regards

	Consultant


----------------
258.4:


@AntonPineiro you definitely need log storage configuration (rules about what to ingest). If the log file is autodetected (windows event logs, standard linux log paths such as /var/log/syslog or any logs detected automatically (you can see them on the process group instance screen), then you don't need any custom log source rules.There is an exception - custom log source are still required for AIX for any logs. Autodetection is not working for AIX. Also if you still cannot see any entries, be sure to check loganalytics logs from the agent. It's not uncommon for the custom path to be blocked by security rules which can be overridden in the OneAgent configuration file.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
259.1:

It appears that you're facing a limitation with your current service level objective (SLO) configuration related to metrics and alerting. Here's a breakdown of the issue and some potential solutions:1. **Limitation on Stored Metric Expressions:** The error message you received suggests that you're using pseudo-metrics that cannot be used in Metric key configuration, and it's also stating that stored metric expressions are only supported in metric-selector-based query mode. This limitation is restricting your ability to configure SLOs for different user actions and APIs effectively.2. **Configuration Limits:** You mentioned that there are configuration limits for different types of SLO configurations, such as static thresholds, auto-adaptive thresholds, and seasonal baselines. These limits can further restrict your ability to set up SLOs for a large number of user actions and APIs.3. **Best Practices:** You've correctly noted that SLOs should ideally be associated with alerts. This is a standard best practice in monitoring and incident management, as it allows you to proactively detect and respond to issues that violate your SLOs.To address these challenges, consider the following steps:1. **Review Metric Configuration:** Check if there are any alternative metric configurations or query modes that allow you to use the stored metric expressions effectively. Consult your monitoring tool's documentation or support resources for guidance on this.2. **Evaluate SLO Priorities:** Prioritize the key user actions and APIs that are most critical to your application or service. You may not be able to set up SLOs for every possible action, so focus on those that have the most significant impact on user experience or business objectives.3. **Combine Metrics:** If possible, consolidate metrics to reduce the number of individual SLO configurations. For example, if multiple user actions share similar performance characteristics, you can group them together under a single SLO.4. **Custom Alerting:** If you cannot configure SLOs for all user actions and APIs within the limitations of your monitoring tool, consider setting up custom alerts using a different approach. While SLOs are a preferred method, custom alerts can still help you monitor and respond to issues effectively.5. **Advocate for Improvements:** If the limitations of your monitoring tool are hindering your ability to implement SLOs effectively, provide feedback to the tool's vendor or development team. They may consider expanding the capabilities of their SLO and alerting features in future updates.In summary, while the limitations you've encountered can be challenging, careful prioritization and creative solutions can help you establish effective SLOs and alerting mechanisms for your key user actions and APIs. Additionally, providing feedback to your monitoring tool's vendor can contribute to future improvements in this area.

	Dynatrace Professional Certified


----------------
259.2:

I had a conversation with the support: limit can be increased to 500 by request for environment.

----------------
260.1:


Workflow actions for integration typically require connecting to third-party systems and coming with their own settings schema. Those connections are then managed in Dynatrace settings 2.0. Ad-hoc scripts can leverage both settings and the credential vault via the SDKs.

	Michael


----------------
260.2:

For reference, you can access the Credential Vault by following the following API instructions.https://developer.dynatrace.com/reference/sdks/client-classic-environment-v2/#getcredentialsdetails import { credentialVaultClient } from "@dynatrace-sdk/client-classic-environment-v2";

const data = await credentialVaultClient.getCredentialsDetails({
  id: "...",
});

----------------
261.1:


Absolutely, let's explore various ways to extend Dynatrace Monaco beyond simple deployment templates to enhance your Dynatrace environment. Feel free to share your experiences or ask questions about these scenarios1. Custom Logic/Scripts with JSON and YAML:- Have you used Monaco to embed custom logic or scripts within your configuration templates? For instance, to perform advanced calculations, data transformations, or dynamic configuration adjustments based on certain conditions?2. Reporting to Fill UI Gap in Data Presentation:- Have you built custom reporting solutions using Monaco? This could involve extracting performance data from Dynatrace and presenting it in custom dashboards or reports tailored to your specific needs.3. Partial Data Sync within the Same Environment:- How have you managed partial data synchronization within a single Dynatrace environment? This could be useful for ensuring that specific configurations or settings are consistent while allowing for variations in other parts of the environment.4. Replacing Pure API Calls with Monaco Actions/Configs:- Share your experiences in transitioning from manual API calls to utilizing Monaco actions and configurations for more streamlined and automated management of Dynatrace settings.5. Creating Different Configurations Based on Product/MZ Difference:- Have you implemented Monaco to create and manage distinct configurations based on product-specific or microzone-specific requirements within your Dynatrace environment?6. User Management:- How have you leveraged Monaco for user management tasks, such as provisioning users, assigning roles, and configuring access controls within Dynatrace?7. Different Anomaly Detection Rules for Different Host Groups:- Share your strategies for setting up Monaco to apply unique anomaly detection rules to various host groups or services based on their specific performance profiles. If you have any questions or need further guidance on any of these topics, please don't hesitate to ask.

	Dynatrace Professional Certified


----------------
262.1:


Yes, its compatible.Look at the documentation.You can transform your message the way it fits into your workflow template https://www.dynatrace.com/support/help/observe-and-explore/notifications-and-alerting/problem-notifi...

	Dynatrace Professional Certified


----------------
263.1:


The Dynatrace Android Gradle plugin does not contain plugin marker artifacts and therefore the resolution via the Gradle plugin DSL does not work automatically. It is possible to manually set up the resolution step and use the Gradle plugin DSL.I can forward your feature request to our product manager. Or you post this topic via the Suggest an idea button. Then it will be automatically tracked by our product manager and he can provides updates to you and other interested customers.

----------------
263.2:

For those following along, the idea suggestion is here:https://community.dynatrace.com/t5/Product-ideas/Gradle-plugin-Add-support-for-Gradle-Plugin-DSL/idi... 

----------------
264.1:


you can try using log search

	Dynatrace Professional Certified


----------------
264.2:

Would log search associate the log entries by service? I did not see a way to do that.

----------------
264.3:


Sorry for the latest reply, i was searching about and i found what you looking  Search in multidimensional analysis and filter by Exception  And put the text of the exception like this  

	Dynatrace Professional Certified


----------------
265.1:

Currently, only problems are available on the mobile app. I suggest you add a Product Idea to the forum to be open to votes.

	The true delight is in the finding out rather than in the knowing.


----------------
265.2:


Hi,Product idea is here.Best regards

	Consultant


----------------
265.3:

Dear @nryan ,
The mobile app is dedicated to push notifications and quick summary information only. It is not planned to add enhanced dashboarding capability due to the restrictions of the native mobile platforms. Instead we do plan to elevate the new Dynatrace platform apps to be mobile consumable, which will then mean to simply open the Web app for dashboard within your mobile device to see the management dashboard. Same is planned for the upcoming platform problems app etc.
Best regards,
Wolfgang

----------------
266.1:

The error message "Hierarchy filter is not supported as filter" indicates that the filtering method you are trying to use in Dynatrace is not supported for creating the metric in the way you are attempting.To count the number of exceptions from a request to a specific service in Dynatrace, you can use other filtering options or alternative approaches:1. **Service Filter:**- Instead of using a hierarchy filter, try using a service filter. You can filter the requests by the specific service you're interested in, and then count the exceptions associated with that service.2. **Custom Metric:**- Create a custom metric for exceptions specific to the service. You can use Dynatrace's custom metric capabilities to instrument your code to capture exceptions and increment a counter metric whenever an exception occurs in the context of the service you're interested in.3. **Alerting Rules:**- You can create alerting rules in Dynatrace based on exceptions. Define alerting rules to trigger notifications or actions when exceptions exceed a certain threshold for the specific service.4. **Custom Scripting and API:**- If the built-in metric creation options do not meet your requirements, you can also consider using custom scripting and Dynatrace's API to extract and count exceptions from the service in a more customized way.5. **Dynatrace Support:**- If you're still facing difficulties or if your use case is complex, consider reaching out to Dynatrace support for specific guidance on how to achieve your metric counting goals.The exact approach you choose will depend on your specific use case and requirements. If you can provide more details about your setup and requirements, I can offer more specific guidance on which approach might be most suitable for your situation.

	Dynatrace Professional Certified


----------------
266.2:

@natanael_mendes thanks for the effort.Here is what i'm trying to do exactly :- I have a service (Proxy) - proxy is calling a lot of other services with the same request (let's call it proxy/request)When using exception count metric i can see all the exceptions generated on the proxy level.what i need is to see the exception that are generated only when calling a specific service (let's call it service X)i can do that using MDA using the filter "Called service"but now i need to display that on a Dashboard and i can't find a way because i can't create the metric with that filter.basically the filter is : any exception + on request (proxy/request) + called service (Service X)I hope this is clear

----------------
266.3:

Hi @SOBE I'll check back later to see if it's possible to pull what you need for the dashboard on my demo environment (unless someone writes back in the meantime). Alternatively, you can try to use Markdown Tile and make there a hyperlink to Multidimentional (without creating a metric) - yes I know it's a workaround, but I sometimes use it with clients.Radek

	Have a nice day!


----------------
266.4:

@radek_jasinski yes the markdown tile is my last solution if i can't find anything.Thanks for the effort and i hope to hear from you soon !

----------------
266.5:


Unfortunately, in my opinion, you are left with Markdown.DT doesn't allow you to configure metrics that way.

	Have a nice day!


----------------
266.6:

Hi,I think product idea has been raised about it.Best regards

	Consultant


----------------
266.7:

Yes but they said they'll only add this to grail and i'm a Managed user so i have to find some kind of workaround...

----------------
267.1:


You can still use the deprecated method, but the Alert Profile ID is also present in the URL when you select the alert profile form the UI. If that's not possible for you, you can leverage the new API via a 2 part call:  Basically you check the Alert Profiles, find the one you want and grab the Object ID, not the alert profile ID from the URL, then take that Object ID and supply it in the the settings API for that Object ID and you'll have the data you seek 

	-Chad


----------------
267.2:

Thx @ChadTurner for the reply,With the API I get value like you (objectID). But this value is différent to the id from the UI (alertingprofile).   I try to create "problem notifications" with the 2 value and I get the same result   Is it possible to define alertingProfile with his name ? Thx 

----------------
267.3:

Hi,If you are using Monaco, you can create an alerting profile, and create a problem notification linked to that alerting profile as a reference.Is this your use case?Best regards

	Consultant


----------------
267.4:

Hi @AntonPineiro ,Yes it is my use case. For profil notification is it possible to define reference without ID? With name of alerting profile?We have a CMDB with project and we want to use monaco to create SLO, alerting profile and problem notif automaticaly. Thx

----------------
267.5:


Hi,If you create all entities (alerting profile, problem notification, etc...) using Monaco, maybe it would be easier.Let me provide you an example. You can create an alerting profile and you choose ID for that alerting profile, a human name: configs:
- id: XXXXXXXX
  type:
    settings:
      schema: builtin:alerting.profile
      scope: environment
  config:
    name: XXXXXXXX
    template: XXXXXXXX.json And when you create a problem notification, you can reference that alerting profile ID: configs:
- id: XXXXXXXX
  type:
    settings:
      schema: builtin:problem.notifications
      scope: environment
  config:
    name: XXXXXXXX
    parameters:
      alerting_profile_id:
        project: alerting-profiles
        configId: XXXXXXXX
        configType: builtin:alerting.profile
        property: id
        type: reference
      recipients:
    template: XXXXXXXX.json   "configId" is a reference to id you had chosen defining alerting profile.If you create everything with Monaco, maybe it would be easier. You have more ways to reference entities in Monaco, checking this.  Best regards

	Consultant


----------------
268.1:


Hello @Pawel_Zalewski under role based auth you can monitor the "default" services without an ActiveGate: As you can see Amazon Cloudwatch Logs is non default so you must install and configure an Environment ActiveGate if you want to monitor either or both of the following:More than 2,000 AWS resources (AWS service instances)Non-default AWS Cloud servicesYou need an AG on your EC2 Account:Create a role for ActiveGate on the account that hosts ActiveGateDownload the YAML file with CloudFormation template.Create the stack in your Amazon Console: In your Amazon Console, go to CloudFormation.Go to Stacks and create a new stack with new resources.Select Template is ready, upload the template you created above, and then select Next.In Parameters, for Monitored Account ID, enter the ID of the account Dynatrace will monitor. Optionally, adapt other parameters as needed.Enter a name for your stack, and then select Next twice.Review your configuration, select I acknowledge that AWS CloudFormation might create IAM resources with custom names, and select Submit.3. Go to the Amazon EC2 console, right-click an instance hosting your Environment ActiveGate, and select Security > Modify IAM role.4. Select the role you created in step 1 and select Update IAM role. Part 2 Create a monitoring role for Dynatrace on your monitored account After the Dynatrace_ActiveGate_role is created on the account hosting the ActiveGate, create a role for the account to be monitored.Download a YAML file with CloudFormation template from github role_based_access_AG_account_template.yml.Create the stack in your Amazon Console: In your Amazon Console, go to CloudFormation.Go to Stacks and create a new stack with new resources.Select Template is ready, upload the template you created above, and select Next.In Parameters, enter External ID, ActiveGateRoleName and ActiveGateAccountID from the stack created in Step 2.3.2.1. Optionally, adapt other parameters if needed.Enter a name for your stack, and then select Next twice.Review your configuration, enable I acknowledge that AWS CloudFormation might create IAM resources with custom names, and select Submit.Hope it helps!!!!

	The true delight is in the finding out rather than in the knowing.


----------------
268.2:

Thanks a lot! I missed this steps:3. Go to the Amazon EC2 console, right-click an instance hosting your Environment ActiveGate, and select Security > Modify IAM role.4. Select the role you created in step 1 and select Update IAM role.Now it's working 

	"The lion does not ally with the coyote"


----------------
269.1:

What do you mean when you write "loop DataCenter information"? Do you want to place a tile regarding DataCenter and assign it to the correct MZ?

	Have a nice day!


----------------
269.2:

@radek_jasinski - correct, I want to add a tile to reflect DataCenter Information based on Management Zone.

----------------
269.3:


You need to create a rule in MZ that assigns the appropriate elements to the DataCenter. Then on the dashboard in the settings, select the appropriate MZ.Radek

	Have a nice day!


----------------
269.4:

Sure @radek_jasinski , will give a try . Thank you !.

----------------
269.5:

Super, if you need help, ask

	Have a nice day!


----------------
270.1:


The only small thing I can suggest is to check the Secret Key and other values are clean, so they do not cain any spaces, special or hidden characters.You could also check in the AD Logs of Azure and maybe the activity logs and see if there is any activity for your service principle - that might contain more information

----------------
270.2:


Hello,This is issue occurred mostly the secret key got expired, please create new secret key value for the appropriate service principal and update the same in Dynatrace azure service monitoring.Thanks 

----------------
271.1:

I think that what you want is a single value count, you can put two things to make this work"Count" and "where" like thisSELECT count(useraction.name) FROM usersession where useraction.name="AppStart (easyTravel)" This query will bring to me the count of the user action name AppStart (easyTravel)"

	Dynatrace Professional Certified


----------------
271.2:

Thanks for your feedback, but the number will not be accurate,I want for sur the count for the last step, but for whome that are followe the specific journey.Example:Journey: action A, action B, action Cwith your query, the count of (c) will be made even if the user wasnt make the action A and/or B whcih is not what I want.

	Sharing Knowledge


----------------
271.3:

oh okay, got it. You can do this with "and" expression like thisin this query you get what you want action A, Action B, Action C but only will show up the value of action C. SELECT COUNT(*) FROM usersession where useraction.name = "AppStart (easyTravel)" AND useraction.name = "searchJourney" AND useraction.name = "bookJourney" X SELECT FUNNEL (useraction.name = "AppStart (easyTravel)", useraction.name = "searchJourney", useraction.name = "bookJourney")FROM usersession  The result of the two queries above will be almost the same but when we use "and" expression we bring only the journey that passed thru Action A,B, C When we use funnel we see the Journey that passed the thru A, A And B and A,B,C  

	Dynatrace Professional Certified


----------------
271.4:

Thanks for your effort,But this is not 100% correct, the case is more complicated than that. The and, will count the journey A, B, C but also A, C, D and all other combinaisons.So the result with and will not be equal 100% to the FUNNEL

	Sharing Knowledge


----------------
272.1:


Hello @JB when you use AWS Fargate, only the applicationMonitoring deployment without the CSI driver is supported. I'm assuming they have a web server running inside this pods, my guess is that in this mode OneAgent is not injecting the JS tags on the pages of your webserver inside this container. So my recommendation is to create an Agentless Real User Monitoring and inject the JS tags in your web server pages to be able to monitor user experience. Please let me know how it goes.

	The true delight is in the finding out rather than in the knowing.


----------------
272.2:

Thank you very much for the explanation. This was the solution!!

----------------
272.3:

@JB  Hi,Please can you tell me Out of 3 deployment options which approach you have used, particularly out of Buildtime and runtime which approach is better and what advantages it has. Thanks

----------------
273.1:


Some things about this exist. But you can only compare them using the documentation of the other software, I will leave here some links that maybe will help you:
https://www.dynatrace.com/platform/comparison/dynatrace-vs-datadog/
dynatrace.com/platform/comparison/dynatrace-vs-appdynamics/
https://www.dynatrace.com/platform/comparison/dynatrace-vs-new-relic/

	Dynatrace Professional Certified


----------------
274.1:

Integrating a new JDBC driver for Google BigQuery into Dynatrace's "Generic DB Query Plugin" can be challenging, and it's important to ensure that every step of the integration process is correct. Since you're not receiving specific error messages, let's go through the integration process step by step to see if we can identify the issue:1. JDBC Driver and JAR Files:- Ensure that you have the correct and compatible version of the Simba JDBC driver for Google BigQuery (GoogleBigQueryJDBC42.jar) for your Dynatrace version.- Verify that you've placed the JAR files in the correct directory (`D:\dynatrace\remotepluginmodule\plugin_deployment\custom.remote.python.dbquery\jars`).2. Database URL and Credentials:- In your `dbquery_extension.py` file, double-check the configuration for the BigQuery database URL and the credentials used for authentication. Ensure that they are correctly set up.3. Plugin Configuration (`plugin.json`):- Make sure that you've updated the `plugin.json` file to define the endpoint for the new JDBC driver type accurately.- Check that the JSON structure is correct, and all required fields are properly configured.4. Testing the Connection:- Try to test the JDBC connection separately outside of Dynatrace to ensure that the driver and credentials are functioning correctly. You can use a simple Java program or a JDBC client tool for this purpose.5. Log Verbosity:- Increase the log verbosity in Dynatrace's plugin configuration. This can sometimes provide more detailed error messages that can help pinpoint the issue.6. Restart ActiveGate:- After making any changes, ensure that you restart the Dynatrace ActiveGate to apply the updates.7. Permissions and Firewalls:- Confirm that there are no firewall rules or network restrictions preventing the ActiveGate from connecting to Google BigQuery.- Check that the credentials you're using have the necessary permissions to access BigQuery.8. Dynatrace Community and Support:- Consider reaching out to the Dynatrace community or their support resources. Other Dynatrace users may have encountered similar issues and can provide guidance or solutions specific to Dynatrace's plugin framework.9. Review Documentation:- Carefully review the documentation provided by Dynatrace for plugin development and integration, as it may contain specific guidelines or best practices for integrating custom JDBC drivers.10. Debugging:- Implement thorough error handling and debugging in your plugin code to capture and log any potential errors during the execution of database queries. This can help you identify specific issues with the integration.11. Testing in a Controlled Environment:- Always test your changes in a controlled environment to avoid impacting your production setup.By following these steps and paying close attention to the configuration details, you should be able to identify and resolve the issue with integrating the Google BigQuery JDBC driver into Dynatrace. If you encounter specific error messages or face further difficulties, please provide more details for more precise assistance.

	Dynatrace Professional Certified


----------------
275.1:

The easiest by far is to use the Dynatrace extension addon for vscode. That one can generate both the dashboard and alert jsons. That is what my team uses for all of our extensions.

----------------
276.1:

I forgot to mention, I need to return the information for use in another workflow task.

----------------
276.2:

The "Action result is too large" error typically occurs when you're trying to return a very large object or a result that exceeds the allowed size limit for the response. To resolve this issue, you can take the following steps:1. Check the Size of `problem`: Since the error message mentions "Action result," it's likely that the `problem` object being returned is too large. You should inspect the size of the `problem` object and its nested properties.2. Reduce the Size of `problem`: If the `problem` object is indeed too large, consider whether you can reduce its size by excluding unnecessary data. You might only need specific properties of the problem rather than the entire object.3. Pagination: If the `problem` object contains a list of items or records (e.g., a list of comments or attachments), consider implementing pagination to fetch and return smaller subsets of data at a time.4. Compress Data: If the data cannot be reduced further, you can consider compressing it before sending it as a response. JavaScript provides libraries and functions for data compression, such as `zlib` or `pako`, depending on your environment.Here's an example of how you might apply compression to the response:```javascriptimport zlib from 'zlib';export default async function ({ execution_id }) {try {// ... (fetching and processing data)// Compress the problem dataconst compressedProblem = zlib.deflateSync(JSON.stringify(problem));return { compressedProblem };} catch (error) {console.error("An error occurred:", error);return { compressedProblem: null };}}```5. Consider Streamlining: If you're working with extremely large datasets, consider a different approach that doesn't involve returning the entire dataset in a single response. For instance, you might implement streaming or provide options for users to request specific parts of the data.Remember to adjust the client-side code that consumes this function to handle the compressed data appropriately.

	Dynatrace Professional Certified


----------------
277.1:

Events are only located on the entity pages and not tile-able from what I am aware of. A RFE would need to be submitted to get this functionality. 

	-Chad


----------------
277.2:

Where does one see the ingested events? We were hopeful that we could see all ingested events for a given time period. If we send in events under "Custom Info" where would we be able to see them?

----------------
277.3:

Hi @mathias_indermu Have You tried to use RELEASES dashboard? Usually what You want to achieve by pulling events on dashboard is global understanding of Your services and their status. RELEASES built-in dashboard show all relevant events for Your processes. It requires releases to be configured and implemented obviously.

----------------
277.4:

Hi All,Maybe this integration can be useful such cases. This solution pull the Events also via Events API and vizulaize in PowerBI in time order. https://www.youtube.com/watch?v=PNX0jCL8AHcI hope it helps.Best regards,Mizső

	Certified Dynatrace Professional


----------------
277.5:

We are considering just to send metrics instead of deployment events(They are designed pretty useless.)In this case it will be possible to correlate deployments in all charts.

----------------
277.6:


It's possible to put events on a dashboard (if you're on Grail) with the "fetch events" command (see example in https://www.dynatrace.com/support/help/platform/grail/dynatrace-query-language/commands#parse ).

----------------
277.7:

It's pretty disappointing that adding events to a Dashboard is Grail-dependent.  It seems like this will NOT be available to Dynatrace Managed customers.

----------------
278.1:

If you turn off monitoring via the Dynatrace UI that should solve your problem  

	-Chad


----------------
278.2:

possible to perform using command line? so the init services which are responsible for start doesnt do anything if we disable.

----------------
278.3:


@SachinJindal you can stop oneagent from being started by modifying the systemd unit file (Linux) / configuring the sysv (Linux) or using services (Windows).What is the use case here you are trying to solve? I'd not recommend disabling the startup of oneagent and prefer the UI or API method which @ChadTurner suggests.Agent disabled in Dynatrace does not perform any actions except for sending heartbeats to Dynatrace.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
278.4:

just wanted to stop the Dynatrace for quite some days  and it shouldnt startup if Servers are rebooted assuming we dont have DT UI access

----------------
278.5:

Then only way is to modify the startup of the agent itself. Not a great idea, since you can manage it from Dynatrace UI/API afterwards.Anyway, I don't recommend shutting down OneAgent unless there are really very good reasons. I recommend to either get access to the UI/API so you can manage it from there. Doing manual startup changes is discouraged in general.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
278.6:

You can also leverage the Services portal (Assuming you have SaaS access) which lives outside your Dynatrace UI to enable/disable the oneagent. 

	-Chad


----------------
278.7:

Hello, Assuming Linux OS -The doc page is here: Stop/restart OneAgent on Linux but this doesn't answer your specific question directly.OneAgent is installed as a system service, so you can use systemctl commands to disable or enable, example:   $ sudo systemctl disable oneagent.service   $ sudo systemctl enable oneagent.serviceYou'll need 'root' - with related complications. If you have root, then I'd anticipate you should be familiar with systemctl, hence please consider above advice to disable/enable from cluster side (which admittedly still lets OneAgent initiate at the OS service level).  

----------------
279.1:


Hi,There are a few ways to do that.Extensions and Scripting integrationExtensions SDK 1.0You can write your own script/simple app and use REST APISee also other ways to extend Dynatrace. Best regards,Mateusz

----------------
279.2:

The challenge is nit the Rest API but the fact that the endpoint called is providing ODATA 4.0 response that has to be parsed and converted into a metric. It does not seem there is any out-of-the-box solution that supports that within synthetic scripts. 

----------------
280.1:

Thank you for documenting this @DanielS 

	-Chad


----------------
280.2:

Your welcome @ChadTurner. The use of Oauth2 clients to obtain valid Bearer tokens is what is coming to Dynatrace API.

	The true delight is in the finding out rather than in the knowing.


----------------
280.3:

This is gold!

	Site Reliability Engineer @ Kyndryl


----------------
280.4:

Thanks @dannemca It took me a while to implement it in Postman, but it will surely be very useful for interacting with the API. I'm thinking improvements for future releases.

	The true delight is in the finding out rather than in the knowing.


----------------
280.5:

WOW!This is a very good and detailed guide! Thanks for sharing it @DanielS !

	Certified Dynatrace Professional


----------------
280.6:

Thanks @Mizső hope it helps.

	The true delight is in the finding out rather than in the knowing.


----------------
280.7:

GOLDEN!!!

	Dynatrace Certified Professional


----------------
280.8:

Thanks @Kenny_Gillette 

	The true delight is in the finding out rather than in the knowing.


----------------
280.9:

Awesome, Thanks to share.

	Sharing Knowledge


----------------
280.10:

As a Partner who often needs to manage several Accounts, this is so very very useful!! Thank you, @DanielS !!

	Best regards, Pedro Deodato


----------------
280.11:

Glad to help @PedroDeodato 

	The true delight is in the finding out rather than in the knowing.


----------------
281.1:

Learn more about DQL and workflows‌ Automations - helpful resources

 When passion meets people magic and innovation happen. 


----------------
281.2:

Thanks @AgataWlodarczyk for sharing this. We need more of this since it seems some if not most clients are still used and comfortable with the classic Dynatrace. Reason of this is that there is lack of knowledge transfer and skills translated to Partners and Customers in as much as we find the features exciting.I would suggest Dynatrace to schedule hands on sessions with Partners within specific regions  and locality because we have varying skills and expertise and knowledge and having a one size fits all approach to new features might leave some customers out due to lack of quick adaptation

	Dynatrace Certified Associate


----------------
282.1:

Hi @Hasan ,I am assuming both nodes are will send the same metric key.When both of them fail no metric data points will be sent into Dynatrace so data will be missing-> "alertOnNoData": true,Using a metric event like following would alert you if the metric is completely missing, i.e. primary and secondary both have failed. [{
    "schemaId": "builtin:anomaly-detection.metric-events",
    "schemaVersion": "1.0.15",
    "scope": "environment",
    "value": {
      "enabled": true,
      "summary": "Important Metric is missing",
      "queryDefinition": {
        "type": "METRIC_SELECTOR",
        "metricSelector": "very.important.metric.that.has.to.be.there",
        "managementZone": null,
        "queryOffset": null
      },
      "modelProperties": {
        "type": "STATIC_THRESHOLD",
        "threshold": -1,
        "alertOnNoData": true,
        "alertCondition": "BELOW",
        "violatingSamples": 3,
        "samples": 5,
        "dealertingSamples": 5
      },
      "eventTemplate": {
        "title": "Very important metric is missing",
        "description": "The {metricname} value was {alert_condition} normal behavior.",
        "eventType": "AVAILABILITY",
        "davisMerge": true,
        "metadata": []
      },
      "eventEntityDimensionKey": null,
      "legacyId": null
    }
  }
] 

----------------
282.2:

Hi Mark,Both nodes are sending separate metric key sharing the same below along with screenshots.Metric in Live servericardonline.prod.host119.FALCON.55382Metric in Fallback servericardonline.prodfb.host118.FALCON.55382 

----------------
282.3:

Hi @Hasan I cannot recommend using dimensions in the metric key, that is what metric dimensions are for.https://www.dynatrace.com/support/help/shortlink/metric-ingestion-protocolYou would send a metric line like this and both hosts would send this with different dimension values e.g.:icardonline,stage=prodfb,host=host118.FALCON.5538 <metric data>
icardonline,stage=prod,host=host119.FALCON.55382 <metric data> If you do not want or cannot use above's format, you still could use a metric query in the metric event adding up both metrics and alerting if data is missing, but again this is not recommended. BR,Mark 

----------------
283.1:

Hi @marina_pollehn We also cannot connect to the University and tried to get in touch with with support regarding that, with no answer till now Good luck with your practical exam !!! Yos 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
283.2:

Thanks for letting me know, I was already wondering if it was just me. I am trying via a support ticket at Dynatrace and at Examity now - I hope that I can still do the exam today 

	A Dynatrace Professional nerd working for Eviden


----------------
283.3:

University is reachable again !

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
283.4:

Hi @marina_pollehn Have you successfully passed the exam?

	Have a nice day!


----------------
283.5:

Unfortunately I couldn't get to it in time. Someone from Dynatrace One reached out tonight so I will try to schedule a new appointment for next weekend. 

	A Dynatrace Professional nerd working for Eviden


----------------
283.6:

Maybe you need some help or clarification on some topics before your exam:)? 

	Have a nice day!


----------------
283.7:

Hi,I remember to see a message banner, in University, during this week, for some scheduled maintenace during this weekend.Best regards

	Consultant


----------------
284.1:

@Larry R. were you able to get any additional insights on this? Anything you can share with the community on it? 

	-Chad


----------------
284.2:

Hi Chad! I am actually well on my way to building an ActiveGate plugin for this. You will be able select via the UI config exactly which of all the "Twilio Services" and / or "External Connectivity" services you want to monitoring the status for in Dynatrace using the Twilio status API.Due to the limitations of Dynatrace, I am having to go through route of custom devices once again to accomplish this. That in return allows for the tagging, etc. I am just putting the finishing touches on it. I would be happy to share via GitHub as soon as I am finished. We really need something else in Dynatrace that can be created as a custom entity that is not necessarily a custom device. There are custom services (which this is what I would consider Twilio to be), but in order to define those currently in Dynatrace, it requires a process group. In the case where you want to monitor something like Twilio through their status API, there would be no process group. 

----------------
284.3:

Hi Larry - can you please send me the link - or post it here. Thanks in advance. Manish

----------------
284.4:

YAY!! Would love to see anything you have. This would be a great help!!

----------------
284.5:

I have been swamped with other work, but plan to focus on this once again towards the end of this week. Should have it done soon.

----------------
284.6:

Hi Larry.  Wondering if you were able to complete the above and can share the plugin details?  

----------------
284.7:

Good afternoon, is there any news regarding this extension?

----------------
284.8:


    Dynatrace now has the ability to model any custom entity. So you can model a "status page" then create instances of each page. From there, you can attach metrics (and events) to each "status page" Once created, get to your entities via:  https://abc12345.live.dynatrace.com/ui/entity/list/entity:TYPE   then I used the Events v2 API to create a problem opening event:   curl -X POST "https://abc12345.live.dynatrace.com/api/v2/events/ingest"
-H "accept: */*"
-H "Authorization: Api-Token ***"
-H "Content-Type: application/json; charset=utf-8"
-d "{\"eventType\":\"ERROR_EVENT\",\"title\":\"An error has occurred\",\"timeout\":1,\"entitySelector\":\"type(entity:status_page),entityName.equals(twilio-gpkpyklzq55q)\",\"properties\":{\"foo\":\"bar\",\"foo22\":\"bar2\",\"foo3\":\"bar3\"}}"  

----------------
284.9:

How your experience has grown on this and what were you able to achieve?Regards

----------------
285.1:


Dynatrace metrics have the lowest granularity of 1 minute regardless of the ingestion type.  You can use the max / min aggregations as you have already mentioned.What is your source of the metric data? Maybe you can capture the relevant metrics using different means (tracing) and calculate the metrics based on captured trace data. 

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
286.1:

Hi Renata,I understand that you have correctly added variables to the registry on all servers in the cluster where you have MS SQL?https://www.dynatrace.com/support/help/shortlink/process-group-properties#variablesDon't you sometimes have a mechanism in the organization that verifies the configuration of servers and, if changes are detected, restores the original one.Radek

	Have a nice day!


----------------
286.2:

Hi RadekThere is any in-house script to restore the original values of the variables.This configuration of the variables might be at the Cluster Manager level (quorum), but I don't know where/how to setup them.Regards,Renata

----------------
286.3:

To set an environment variable using PowerShell and make it persistent (available even after a system reboot), you can use the following command:[Environment]::SetEnvironmentVariable("VARIABLE_NAME", "VARIABLE_VALUE",[System.EnvironmentVariableTarget]::Machine)Where:VARIABLE_NAME is the name of the environment variable you want to set.VARIABLE_VALUE is the value you want to assign to this variable.[System.EnvironmentVariableTarget]::Machine means that the variable will be set as a machine variable, which means it will be available to all users on that computer and will be persistent.https://shellgeek.com/set-environment-variable-using-powershell/See if this works:)Radek

	Have a nice day!


----------------
286.4:

Thanks for your inputs.I need to have the "tag" on Dynatrace only in the processes and Process Groups related to the MS SQL Server Service. That's why on Windows, it has to be set in the registry of Service and not as a System Variable. If I set the variable in the system, the server and all the processes will be tagged in Dynatrace with this variable - this is not the goal. The documentation Dynatrace (Define tags based on environment variables ) says : Applying tags to hosts (instead of thoughtfully setting up environment variables as explained here) isn't recommended. The same applies to applications and processes. For details on setting up the DT_CUSTOM_PROP environment variable for Tomcat or WebSphere application metadata, Kubernetes annotations for Kubernetes-based deployments, or AWS tagging, see Application metadata & tagging. 

----------------
286.5:

If you want to set a permanent variable for a specific process or group of processes in windows then you can do it this way:You can use PowerShell to create or modify environment variables in the Windows Registry. # Define permanent environment variables for different process groups$RegistryPath = "HKLM:\SYSTEM\CurrentControlSet\Control\Session Manager\Environment"# Group A Variables$GroupA_Variable1 = "ValueA1"$GroupA_Variable2 = "ValueA2"# Group B Variables$GroupB_Variable1 = "ValueB1"$GroupB_Variable2 = "ValueB2"# Set Group A VariablesSet-ItemProperty -Path $RegistryPath -Name "GroupA_Variable1" -Value $GroupA_Variable1Set-ItemProperty -Path $RegistryPath -Name "GroupA_Variable2" -Value $GroupA_Variable2# Set Group B VariablesSet-ItemProperty -Path $RegistryPath -Name "GroupB_Variable1" -Value $GroupB_Variable1Set-ItemProperty -Path $RegistryPath -Name "GroupB_Variable2" -Value $GroupB_Variable2In the above example, you set permanent environment variables for different process groups (GroupA_Variable1, GroupA_Variable2, GroupB_Variable1, and GroupB_Variable2) in the Windows Registry under HKLM:\SYSTEM\CurrentControlSet\Control\Session Manager\Environment. These variables will persist and be available to all processes system-wide.After setting permanent environment variables, you may need to restart or refresh processes (such as Explorer or PowerShell sessions) for them to recognize the new variables.Radek  

	Have a nice day!


----------------
287.1:


Was also having the same issue and seems to be resolved now. On 1.274.132.20230905-172015.

----------------
287.2:

Yeah, it's also working for us again. Microsoft Edge for Business version: 116.0.1938.76. Dynatrace version: 1.274.132.20230905-172015.

----------------
288.1:

HI @jose_araya As appears in Why don't I see my applications or monitoring data?Check the following to determine the cause of the problem:Confirm that the RUM JavaScript has been correctly injected into your application HTML.Confirm that the RUM JavaScript has downloaded correctly.Confirm that RUM data is being sent to Dynatrace. HTHYos 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
289.1:

@NavenduGupta this is possible via the configuration API:  If you are not a Dynatrace Admin you will need to have an admin supply a token for you to read those data points. 

	-Chad


----------------
289.2:

Thanks... These will only give me entityTypes/services... I want all the entities.

----------------
290.1:

Before COVID there was a lot of commuting to customers every week. Where possible with the train but witht he state of railway in germany, a lot was flying. But for the last ~2 years my daily commute has been the ~30 steps from my kitchen to the office, no cars involved   

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
290.2:

@pahofmann Are you planning to change your commute habits to those pre-covid? 

	Keep calm and build Community!


----------------
290.3:

If it where up to me no   But I don't think it will go back to nearly as much traveling as before. I'm not really sad as it saves a lot of time and is a lot more flexible remote, though a bit of traveling again would be nice.

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
290.4:

I use to take the Washington DC Metro to work, now I don't even have to go out of the house to get to the office! Cant say I miss the old commute! 

	-Chad


----------------
290.5:

Before the pandemic, many of us had to go to the customer's office. Now in the new normality, I had to create my own office (3rd room - guests only) and don't have to move to another place but every day I've to pick up my son from the school who is ~10 minutes away from the apartment. My mobility is obviously walking less than 30 minutes. 

	-César S. - LATAM Solutions Architect


----------------
290.6:

Same here, working from home since March 2020. Before pandemic, I used to take a bus to go to office (around 40km far from my home), and sometimes, my motorcycle.
Today , the only place I go daily is to my kids school, they are near, around 10 mins on feet (their pace).
But let's say I come back to office, weekly, I would definitely ride my Dyna, it is not so eco (a bit louder too), but that's how I like it.
 

	Site Reliability Engineer @ Kyndryl


----------------
290.7:

Fantastic! Around 80 kilometers of the trip to and back from work sounds like a perfect opportunity to enjoy the motorbike season as much as possible! 

----------------
290.8:

I commute by car. I do it almost all days with electrical power, so it's almost always eco friendly. 20 Km daily. Don't have a public transport option.Probably one of us that has worked less from home in the pandemic... Always secure and abiding by the law, but sometimes I would feel that I was like in a "The Walking Dead" episode...

	Antonio Sousa


----------------
290.9:

High five, @AntonioSousa!  I'm in the office 5 days a week, got back in June 2020 already when they opened the doors to Dynatrace labs for selected groups of employees - meaning those with no good conditions to work from home (be it equipment or kids ).
I rarely use car (don't have an electric one), so in 90% of the cases it's my bike, the other 10% is either train or car 

	Keep calm and build Community!


----------------
290.10:

Great to see Alex showing how it's done biking 
Some days I drive a car, some days I take my e-bike Ampler. It has completely changed my experience of urban biking and I recommend to take a ride with an e-bike for all ages and fitness levels.
 

----------------
290.11:

Not a big bike expert at all, but your machine looks fantastic - like a perfect for long trips around forests, rural areas, or city alleys!

----------------
290.12:

I commute by subway in Osaka. The Osaka subway is the second largest in Japan after the Tokyo subway.Not only the subway, but also Japanese railways operate according to the timetable, and there is not much delay.So, train delay of0min to 1min "Good" ,  1min to 3min"Tolerable",> 3 minutes "Frustrating".  

	T.Shirai IIM Corp. Osaka Japan


----------------
290.13:

Those are some nice punctuallity goals! In Germany everything below a 5:59min delay doesn't even count as not on time in the statistics. Often if a train has to much delay it will just cancel the last stops and change direction early, as cancled trains also don't count as "late" in the statistics... 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
290.14:

The punctuality is legendary. That's the way to go! Here in Portugal we don't know what that is... And I can just imagine OneAgents sourcing that data and feeding some nice dashboard/SLOs! 

	Antonio Sousa


----------------
290.15:

Lucky, here in India it will feel like ages to wait for local trains. Units are are displayed in nos from 00 to 10. 01 unit at time is 10 seconds or sometimes its 5 mins

	KG


----------------
290.16:

In India, when it comes to metropolitan areas, Metro trains will be right on time without any delays. In Bengaluru trains are very punctual and most of the people who travels to work via Metro itself. Local trains gets delayed due to some technical reasons that to when you are going for a long journey. When you are on a journey, it is okay to get delayed here and there sometimes... 

	Love more, hate less; Technology for all, together we grow.


----------------
290.17:

I have to have this badge!
 
On average I go to the office 4 times a week, by bike (~ 20km/day). Given the fact that the pandemic chained me for nearly two years to the home office and this exercise was missing .... correct, I still need to get rid of a few kg!!!!

	Director of Product Management @ DynatraceThat means I'm better at delegation than doing actual work!


----------------
290.18:

Just curious on what the altimetry profile is like for your 20 Kms?

	Antonio Sousa


----------------
290.19:

It's actually really flat along the Danube 

	Director of Product Management @ DynatraceThat means I'm better at delegation than doing actual work!


----------------
290.20:

Hey yes.. the initial pandemic time during complete lockdown, I experimented a lot of cooking and eventually eating it . Added a lot of weight all due to sugar sweet dishes. You can try cutting down sugar completely 

	KG


----------------
290.21:

I would love to share my commuting experience to office before the pandemic (10 Km per day) . I still use my bike for local travel and weekend touring. I use to ride this own custom bike of mine which was build using scrap materials form different  type of old bikes. I tweaked its engine by adjusting the fuel flow and  also reducing the diameter of gear teeth's to increase the RPM. It eventually cover more miles than any average low end bike and was very economic for me giving a range of 110 KM in a single liter of fuel.
Its still my passion to customize bike and I can spend my weekend building one again with some electric technology movement.

	KG


----------------
290.22:

Is this a Royal Enfield? I mean the engine and chassis, since the parts may be form others manufacturers 

	Site Reliability Engineer @ Kyndryl


----------------
290.23:

Thankyou its all different OEM

	KG


----------------
290.24:

Handle is Custom made aluminum after market similar to Harley, Chassis and engine  are Hero Honda passion plus its a 110  with a custom build carburetor

	KG


----------------
290.25:

Gear box battery box Chain cover set spoke wheels are Royal Enfield, Fuel tank is Yamaha RX100, Speedometer is Yamaha enticer, and many more of same brands above all got from 2nd hand market place.

	KG


----------------
290.26:

I rebuild each parts to stock new repair needed. Working on my next project on my weekends now. It have a Hero Honda Karizma R 228 cc 2007 rebuild as new powered engine with custom Fuel injector support and a scrambler look.

	KG


----------------
290.27:

Hello everyone,Personally, I much prefer public transport AND/OR electric scooter: for an hour, I have time to read the news, catch up with friends and family, reread articles or meet new people...But since my move, the city is not well served by public transport, which forces me to take my own car morning and evening.

	Sharing Knowledge


----------------
290.28:

Sometimes public transport is a perfect area to catch up with the stuff we don't have time to read at home! But as you say, sometimes it's simply not possible to use it as frequently as we'd like...

----------------
290.29:

Totally agree! Some 25 years ago, I had an hour commute, each direction... I would have a stack of magazines (anyone remembers Byte, for instance?) and read a lot! Although I'm an Internet user since 1991, magazines were still influential during about more 10 years.Today, it's even easier, and not only in public transportation. I normally hear podcasts on my car commute, things like "Pure Performance" 

	Antonio Sousa


----------------
290.30:

Personally, I still buy magazines sometimes. It's actually more convenient while being on the journey because you save your device's battery and have some rest from screens 

----------------
290.31:

Before the pandemic I had a 40 minute car ride to work and to be honest, I kind of miss it! it was a great time to relax, listen to some music, unwind and just prepare for the next day. It also helped keep that separation between work and home. Now, just like so many else I'm just a few steps away from work every morning. I mean thats not terrible either, you get to make your own office with your own hardware allowing you to put it together in a way the suites you!

----------------
290.32:

Pre-pandemic, I was either on-premise at clients or at the office. If at clients, it would mostly be by car to the nearest Gautrain station, then Gautrain to the closest station, and then either by foot or Gautrain bus to the client.If I had to grace my colleagues with my presence at the office (yeah, right hahaha!) I'd take my car since public transport is not the greatest in South Africa.I'd cycle to work if I could, but we do not have the fantastic facilities like those which Alexander Sommer has access to.Can't say I'm missing the commute, at all!! Love working from home and dreading the day things go back to normal, which will hopefully never happen completely 

----------------
290.33:

Haha!  I think many people fell in love with remote work during the pandemic 
 
Looks like you use many ways of commuting, Andre! Nice diversification!

	Keep calm and build Community!


----------------
290.34:

Hehehe .. I am missing working from office 

	KG


----------------
290.35:

I can relate my early days, when I dint had a bike to drive. Now bikes are easy to drive on streets and save a lot of time 

	KG


----------------
290.36:

I commute to work by train. The train takes only 20 minutes even though I live just outside the city, so including walking time it takes me around 40 minutes. I quite like the ride, and some times I even had more time for my audiobook or podcast episode Can't believe you plant a flower for every answer - what a nice idea!

----------------
290.37:

We'll do and we'll document it! 

	Keep calm and build Community!


----------------
290.38:

Wonderful! I'm also going to plant one 

	Antonio Sousa


----------------
290.39:

Thanks 

----------------
290.40:

I have planted one of my favorite flower plant today. This will be my Community Pelargonium:
 
I have been doing propagation with cuttings, and it seems that Pelargoniums are quite easy to propagate. Let's see if I didn't leave to many leafs... It's my second this year, because I already have a lot of them. This Community one is derived from my most beautiful Pelargonium, also because it has some nice Dynatrace color:
 

	Antonio Sousa


----------------
290.41:

Oh, wow!  I can't guarantee our plants will be as spectacular as the one above, but we'll do our best to take a good care of them 

	Keep calm and build Community!


----------------
290.42:

Oh wow, that is amazing @AntonioSousa  Love the colors!

----------------
290.43:

I love periwinkle in different colors, will be planting it soon 

	KG


----------------
290.44:

Trains are best way to commute here in India too 

	KG


----------------
290.45:

Another Harley guy here. 70km round-trip to downtown Toronto - averaging 7L/100km. Toronto allows free street parking for motorcycles and we're allowed to use the HOV lanes. 
 
I'm looking forward to our return to the office next month (% basis).
 
 

----------------
290.46:

That's the right (and brave) attitude! 

----------------
290.47:

We're not made of sugar, right? 
 
I wish you a smooth RTO! 

	Keep calm and build Community!


----------------
290.48:

You got to be in India , can't commute with this in the traffic to Office. Yes but definitely a loved one for long rides.

	KG


----------------
290.49:

My EDC commute equipment is:
 
 
Huge fan of Brompton Bikes.

	The true delight is in the finding out rather than in the knowing.


----------------
290.50:

Yes! Brompton bikes are actually the most comfortable for the city environment, here in Poland they're getting more and more popular 

----------------
290.51:

Being one of very less outsider and I am more of an insider. I go out rarely as my work is from home. However, I always like to go and travel to the neighbouring hill station. Here are some of those pics I took when I visited the view point, 
   

	Love more, hate less; Technology for all, together we grow.


----------------
290.52:

So stunning views, you're lucky to have such landscapes in your close neighborhood! 

----------------
290.53:

Indeed, Michal.It is so peaceful that sometimes I go there to relieve my stress from life. It is just so soothing to my eyes and mind. 

	Love more, hate less; Technology for all, together we grow.


----------------
290.54:

@pahofmann, @ChadTurner, @cesarsaravia, @dannemca, @AntonioSousa, @HansLougas, @Shirai, @kurt_aigner, @techean, @Malaik, @Fin_Ubels, @andre_vdveen, @robaxelsen, @richard_guerra, @DanielS, and @theharithsa 
 
As we promised, we've carefully seeded 16 plants in our office to celebrate all of your answers submitted to the Commuter Challenge. Take a look at how they proudly grow, it's never been so green in our room! 
 
 

----------------
290.55:

Awesome! How nice of you 

----------------
290.56:

So, so nice! 

	Antonio Sousa


----------------
290.57:

Ooooohhh, so cute!!! Which one is "mine"??? I would call it Nic.

	Site Reliability Engineer @ Kyndryl


----------------
290.58:

Awesome!!   Mine could have the name of my son? He is: Rasec. He is also planting a flowers at the school. 

	-César S. - LATAM Solutions Architect


----------------
290.59:

Thanks @Michal_Gebacki 

	The true delight is in the finding out rather than in the knowing.


----------------
290.60:

Oh thats awesome! Maybe I should start growing something on my baren wasteland of a desk. Whats on the post-it notes?

----------------
290.61:

The names of the challenge participants  Here are some pictures from the backstage 
 
  

	Keep calm and build Community!


----------------
290.62:

This is awesome!!

	Site Reliability Engineer @ Kyndryl


----------------
290.63:

Make sure you water it properly. I'll check on it, the next time in Gdansk 

	Director of Product Management @ DynatraceThat means I'm better at delegation than doing actual work!


----------------
290.64:

Hello @KarolinaL Where is mine in the photo? and how it's looks like after 1 year of groowing.

	Sharing Knowledge


----------------
290.65:

I still drive to the office, but this habit should soon change to a more eco-friendly option.

----------------
290.66:

Before COVID, I went to the office every day. Whenever possible, by bus or car, but since public transportation in Brazil is complicated until I bought my car, I had to use Uber. But after the pandemic I'm trying to get active again and do more sport

	Dynatrace Professional Certified


----------------
290.67:

I move inside my house. I use frequently my speakers for listen music, videos or webinars.Best regards,

	IT Master | dynatrace Certified professional | SRE Certified | Scrum Certified | Azure Certified | https://www.linkedin.com/in/rodrigocuevas/


----------------
290.68:

I usually prefer walking in warm days, but still the car option is the best during the summer 

	Dynatrace Certified Professional - Dynatrace Partner - Yourcompass.ca


----------------
290.69:

I mostly take the bus to the office and back, though sometimes I take the metro, mostly if it's raining or if I have to stop somewhere on the metro line on the way back!

----------------
291.1:

Hi @gmorreal,assuming that you are using email for problem notifications, to receive alerts only for this specific management zone, you need to create an alerting profile for this management zone, and in the problem notification choose this alerting profile, The following is a sample1- Create alerting profile:From the left side menu search for settings then Alerting-->Problem Alerting profileYou can leave the default alerting profile as it is and create a new one or duplicate the default and change the cloned one, change the name, choose the management zone, and click save if severity rules are fine (you can leave the default severity rules) 2- Create a problem notificationfrom the settings --> Integration --> Problem notifications--> Add notificationchoose notification type, Add Recipient, choose Alerting profile then save Note: Don't forget to remove your email account from the default notification if you want to receive notifications only for this management zone.Best Regard,Mohamed

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
291.2:

Thanks @Mohamed_Hamdy for the quick response. I'm using the mobile dynatrace app to receive push notifications and as I said I receive notifications for all the management zones, while I would like to receive that only for the MZ that I configured in the app. Is it possible?Thanks

----------------
291.3:


Hi @gmorreal ,I do not think it is currently available for the Dynatrace app to receive the notifications by Management Zone yet. You can post as a product idea to get more insight into when and if this might be available. 

----------------
292.1:

@DivyaP this is very interesting, can you tell us the cluster version you are on? I was going to ask if XHR monitoring was turned on, but as you said XHR works when the action prop isnt set. I'm curious if this is a bug in the cluster

	-Chad


----------------
292.2:

@DivyaP Can you share your code here? Maybe we'll see something you missed.

----------------
293.1:


Hello @strunzo we are following a similar question here.But Management Zones permissions are not enough, you need at least View environment under Environment permissions.

	The true delight is in the finding out rather than in the knowing.


----------------
293.2:

Not sure this resolves the issue.  I have View Environment as well as the management zones, yet the toggle is not accessible.  I'm trying to find out the least amount of privileges needed to enable this for new monitoring users.

----------------
293.3:

Hello @jmcgrath04 please check that View Environment is under tenant and not MZ. 

	The true delight is in the finding out rather than in the knowing.


----------------
293.4:

Correct, I currently have View Environment, in the environment permissions as well as the MZ permissions.

----------------
293.5:

Following up, it turns out it's more the policy for the environment controlling this.  I needed to turn on 'AppEngine - Admin' in the Environment Policies.  Thanks for assisting.

----------------
293.6:

Sorry, AppEngine - User would be more correct for the group I was working with.  My admin group has the admin policy. 

----------------
294.1:

Hi @natanael_mendes ,As far as I know, no documentation exists about integration of Dynatrace with Movidesk. To better answer your question, could you describe what information you're trying to get from Movidesk and what it does? In addition, any information provided on what you're trying to do by integrating it with Dynatrace would help too. Cheers,Taylor Sanchez

----------------
294.2:

Thanks for your answer Taylor. Movidesk is a itsm tool for open tickets

	Dynatrace Professional Certified


----------------
294.3:


What kind of integration are you looking for?If is to create tickets from Dynatrace problems, you may be able to, using the email as notification integration, since Movidesk allow you to create tickets based on emails: 

	Site Reliability Engineer @ Kyndryl


----------------
294.4:

Thanks for your Answer Danne, gon be helpful

	Dynatrace Professional Certified


----------------
295.1:


It seems like you're facing a challenge with tracking successful key requests in Dynatrace, particularly when your VMs are deployed as Immutable Cattle and the key requests are lost after each deployment. You're currently using a filter with a `keyRequest.successes.server.rate` metric, but this metric is tied to the service entity ID and doesn't carry over when a new VM is deployed. You're considering whether converting these key requests to metrics would provide a permanent solution.Here are a few considerations and potential solutions:1. **Using Custom Metrics:**Converting your key request tracking to custom metrics could be a solution, as you have control over the metric definition and how it's tracked. You could define custom metrics to track the success rate of the specific Java method. This approach might offer more flexibility in tracking success across deployments, as long as you ensure that the custom metric definitions persist across deployments.2. **Metric Separation:**When transitioning from key requests to custom metrics, make sure to carefully plan the metric names, dimensions, and definitions. You might need to update your monitoring configuration and any alerting or reporting mechanisms that rely on these metrics.3. **Custom Events:**Instead of relying solely on metrics, you could consider creating custom events that indicate the success of your specific Java method. Custom events can provide contextual information and might be easier to track across deployments.4. **Automation Integration:**If you're already using automation for your deployments, you might be able to integrate an automated step that triggers the "Mark as Key Request" action after a deployment. This way, the necessary key requests are automatically triggered after each deployment.5. **Communication Between Deployments:**Ensure that your deployment automation communicates with your monitoring system when a new deployment occurs. This communication could trigger actions such as marking key requests or updating custom metrics. This way, the monitoring system is aware of deployments and can adjust its tracking accordingly.6. **Consulting Dynatrace Support:**Since Dynatrace provides support for complex monitoring scenarios, it's a good idea to reach out to Dynatrace support to discuss your specific use case and get recommendations tailored to your environment.Ultimately, the solution you choose should align with your monitoring and operational requirements. Converting key requests to custom metrics might provide more control and resilience across deployments, but you'll need to carefully plan and implement this transition to ensure accurate monitoring and reporting.

	Dynatrace Professional Certified


----------------
295.2:

Thank You for the overview definitely food for thought leaning to converting to metric. Wondering if there is a how to to convert these. Questions like do I need to remove the key request before creating metric? thanks again

----------------
295.3:

If the Service Name/Request name is known, you can create a calculated metric from Multidimensional Analysis (https://www.dynatrace.com/support/help/platform-modules/applications-and-microservices/multidimensio...) using them as filter, and selecting the metric Successful request count, you should be able to get similar data.

	Site Reliability Engineer @ Kyndryl


----------------
296.1:

@swapnil , you can set log alert rules via the following:  Keep in mind if you are Using GRAIL you will need to leverage DQL. 1 & 2 can be completed using DQL, granted I'm new to DQL so I cant give you the query for it, but maybe some other community members that are more versed in DQL can. 

	-Chad


----------------
297.1:

Hi,What documentation exactly are you looking at?  The documentation here discusses event thresholds using 10 second intervals.  I believe 10 second intervals are used for infra alerting, and one minute intervals are used for graphing.  If you provide me the documentation where it says that, I can get clarification from product team and get updated appropriately.Regards,Bradley

----------------
297.2:


@bradley_danyo,The reference from documentation is here: https://www.dynatrace.com/support/help/platform/davis-ai/basics/events/event-types/resource-events 

	Antonio Sousa


----------------
297.3:

Thanks.  I've reached out to confirm and will let you know once I have more information. Regards,Bradley

----------------
297.4:

Hi Antonio,I've confirmed that the documentation you shared should be changed.  The CPU alerting now uses 10 second intervals.  Thank you for bringing this to our attention.Regards,Bradley

----------------
298.1:

Does this help? https://www.dynatrace.com/support/help/platform-modules/digital-experience/synthetic-monitoring/gene...
 

----------------
298.2:


To include Dynatrace Synthetic Monitors as part of your CI/CD pipeline for lower environment validations and executions, you can use the Dynatrace Synthetic Monitoring API to programmatically interact with Synthetic Monitors and retrieve their results. Here's an outline of the steps you can follow:1. **Enable Synthetic Monitor:**- Use the Dynatrace Synthetic Monitoring API to enable the Synthetic Monitor for your application.2. **Run Synthetic Monitor:**- Trigger the Synthetic Monitor execution via the API.3. **Validate Monitor Status:**- Monitor the status of the Synthetic Monitor execution to determine if it succeeded or failed.4. **Retrieve Metrics:**- If the monitor succeeds, use the API to retrieve important metrics such as failure rate, performance, availability, etc., from the Synthetic Monitor results.5. **Follow or Fail the Process:**- Based on the results and metrics obtained, you can proceed with the CI/CD pipeline if the monitor succeeds or fail the process if it fails.6. **Disable Synthetic Monitor:**- Optionally, use the API to disable the Synthetic Monitor when it's no longer needed.Here's more detail on steps 3 and 4:**3. Validate Monitor Status:**To determine if the Synthetic Monitor execution succeeded or failed, you can use the `/synthetic/monitors/{monitorId}/executions` endpoint of the Synthetic Monitoring API. When you trigger a monitor execution, it will return an execution ID. You can then query the status of that execution ID to check if it succeeded or failed.**4. Retrieve Metrics:**If the Synthetic Monitor execution is successful, you can use the `/synthetic/monitors/{monitorId}/executions/{executionId}/results` endpoint to retrieve metrics and results from that specific execution. You can extract metrics such as failure rate, performance, and availability from the response.Here's a high-level example in Python using the `requests` library to interact with the Synthetic Monitoring API:```pythonimport requests# Set your API token and URLapi_token = "YOUR_API_TOKEN"api_url = "https://YOUR_DYNATRACE_INSTANCE/api/v1"# Enable the Synthetic Monitor# Run the Synthetic Monitor# (Code for steps 1 and 2)# Check the status of the monitor executionexecution_id = "EXECUTION_ID"execution_status_response = requests.get(f"{api_url}/synthetic/monitors/{monitor_id}/executions/{execution_id}",headers={"Authorization": f"Api-Token {api_token}"})if execution_status_response.status_code == 200:execution_status = execution_status_response.json()["result"]["status"]if execution_status == "FINISHED":# Retrieve metrics if the execution is successfulexecution_metrics_response = requests.get(f"{api_url}/synthetic/monitors/{monitor_id}/executions/{execution_id}/results",headers={"Authorization": f"Api-Token {api_token}"})if execution_metrics_response.status_code == 200:metrics = execution_metrics_response.json()# Extract and use the desired metrics (e.g., failure rate, performance)else:# Handle the case where metrics retrieval failspasselse:# Handle the case where the monitor execution failedpasselse:# Handle the case where execution status retrieval failspass# Continue with your CI/CD pipeline based on the results```Make sure to replace placeholders like `YOUR_API_TOKEN`, `YOUR_DYNATRACE_INSTANCE`, `EXECUTION_ID`, and `monitor_id` with your actual values. This code provides a basic structure for interacting with the Dynatrace Synthetic Monitoring API to achieve your desired integration within your CI/CD pipeline.  See this Documentation page:https://www.dynatrace.com/support/help/platform-modules/digital-experience/synthetic-monitoring/gene...

	Dynatrace Professional Certified


----------------
298.3:

Wow this is great details. Are you able to provide more information on Steps 1 - 3? Thanks so much.1. **Enable Synthetic Monitor:**- Use the Dynatrace Synthetic Monitoring API to enable the Synthetic Monitor for your application.2. **Run Synthetic Monitor:**- Trigger the Synthetic Monitor execution via the API.3. **Validate Monitor Status:**- Monitor the status of the Synthetic Monitor execution to determine if it succeeded or failed.

----------------
298.4:

Good afternoon and thanks for the above. Wow this is great details you provided for step 4 - 6. Are you able to provide more information on Steps 1 - 3? Thanks so much.1. **Enable Synthetic Monitor:**- Use the Dynatrace Synthetic Monitoring API to enable the Synthetic Monitor for your application.2. **Run Synthetic Monitor:**- Trigger the Synthetic Monitor execution via the API.3. **Validate Monitor Status:**- Monitor the status of the Synthetic Monitor execution to determine if it succeeded or failed.

----------------
298.5:


1. **Enable Synthetic Monitor:**- Use the Dynatrace Synthetic Monitoring API to enable the Synthetic Monitor for your application.https://www.dynatrace.com/support/help/dynatrace-api/environment-api/synthetic/synthetic-monitors/pu...
2. **Run Synthetic Monitor:**- Trigger the Synthetic Monitor execution via the API.https://www.dynatrace.com/support/help/dynatrace-api/environment-api/synthetic-v2/synthetic-monitor-...
3. **Validate Monitor Status:**- Monitor the status of the Synthetic Monitor execution to determine if it succeeded or failed.
https://www.dynatrace.com/support/help/dynatrace-api/environment-api/synthetic-v2/synthetic-monitor-...

----------------
299.1:


Hello,In general, an instance means a configuration. For example, having one configuration added in the extension, one datasource instance is created. In addition, if a configuration has a very large number of endpoints added, then more instances are created. This is because the configuration is divided into smaller parts to not overhelm one process. In this case the config id does not change and all instances have the same config id. Best Regards,Mateusz

----------------
299.2:

Thanks Mateusz - that all makes sense. Any chance we could get the documentation to say something similar?

----------------
299.3:

I will reach out to the team to document it. Thanks for the feedback!

----------------
300.1:


Hi,I think there are a few ways currently. AFAIK, CyberArk shares Prometheus metrics, so you can write your own custom Dynatrace Extension to monitor itYou can use Dynatrace Synthetic If your CyberArk is Self-Hosted you can also install Dynatrace OneAgentI recommend you to contact with your local sales office in order to get the actual offer and possible options. Best Regards,Mateusz

----------------
301.1:

HiIn that case, it is recommended to create a support ticket.Thanks,Mateusz

----------------
302.1:


Hi @AsafAx, it should be possible to do this with an extension, either OneAgent or ActiveGate.@leon_vanzyl created an ActiveGate SSL/TLS certificate monitoring plugin that does exactly that: it checks the expiration date of the certificate and gets the current time, then alerts when the expiry date is within the defined threshold.I'm sure there could be other ways of doing this, but this popped into my mind when I read your post - hope it helps!

----------------
302.2:


You might also be able to integrate it with synthetic monitors which you probably have already. There it will directly state how many days you have left before the certificate expires and a problem will be raised and remain open until the certificate issue has been solved. You can also specify how long in advance alerting should start.You can find that in your settings of the synthetic monitor if you go to HTTP requests and select visual mode. 

	A Dynatrace Professional nerd working for Eviden


----------------
302.3:


Hi,The question is what licenses you want to monitor. If it is about SSL certificates then you can monitor as colleagues described above.In my opinion you should create a simple script/plugin that verifies the licenses and returns the values to DT. It can return all values and create thresholds in DT based on that, or it can return only those that need intervention.https://www.dynatrace.com/support/help/extend-dynatrace/extend-metricsRadek

	Have a nice day!


----------------
303.1:

Hi @KeanBoon ,This question might best be served as a Chat question on D1 or Support so that you can provide the entire relevant output, logs, and specific steps taken for installation. Cheers,Taylor S.

----------------
303.2:


This specific line tells the Server process is running, however it hasn't complete the startup:

Sep 08 03:06:17 server.sh[272397]: Starting Server ... failed, it's running but not listening

In order to find out, you have to look into the server.log. Usually such situations occur when where's a connectivity issue with other nodes or a misconfigured operating system. As suggested, the fastest way to solve it - get in touch with us via Zendesk - visit Support Center - https://support.dynatrace.com/

	Senior Product Manager, Dynatrace Managed expert


----------------
304.1:

Although the help document, found some relevant information, but still a little bit not understand.Configure monitoring for namespaces and pods | Dynatrace Docs 

----------------
304.2:

Hi @Lwl ,you can go with the same way mentioned in the link you've shared or before the implementation for monitoring K8s, You can create the needed rules as per the following screenshot from the UI settings, I do recommend using do not monitor as this works for me to exclude some namespaces  

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
304.3:

Thank you for your reply.

----------------
304.4:


The solution depends on the Dynatrace deployment model you use in k8s see https://www.dynatrace.com/support/help/shortlink/how-it-works-k8sIf you use classic full stack (still the default if you deploying it using the guided UI approach), then the container rules mentioned by @Mohamed_Hamdy  apply. If you use the cloudNativeFullStack or application only, it's described on the page mentioned by @Lwl - you define monitoring rules in your kubernetes deployment by labeling the namespaces and setting the annotiations at pods to exclude a particular pod from being monitored (if required).

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
305.1:


Hi @Duran_Narbona 
There is a similar example in our help: https://www.dynatrace.com/support/help/shortlink/dashboard-component-variable#resolution-in-dql-comm...
Just add 2 variables to dashboard, one for resolution and one for unit.
Then the query can look like this:
fetch events
| filter event.kind == "DAVIS_PROBLEM"
| fieldsAdd toDuration(multiplier)
| summarize {count = count(),event.status_transition = takeLast(event.status)}, by: {status = event.status_transition,`interval` = bin(timestamp, duration($resolution, unit:$unit))}
 
Best,Sini
 

----------------
306.1:

If Dynatrace's official instrumentation for Go Kafka isn't supported in your environment, you can consider alternative approaches to instrumenting your Go Kafka microservices for distributed tracing. While Dynatrace provides OneAgent and SDKs for certain languages like Java, Go might not have native support yet. Here's a general approach you can consider:1. **OpenTelemetry (OTel) for Go:**OpenTelemetry is a set of APIs, libraries, agents, and instrumentation to provide observability for applications. You can use the OpenTelemetry Go library to manually instrument your Go Kafka microservices.- You would need to import the OpenTelemetry Go library into your Go Kafka application.- Use OpenTelemetry to create and propagate traces as messages flow through your Kafka producers and consumers.- Ensure that you follow the OpenTelemetry guidelines to set up span contexts and propagate them in Kafka messages.2. **Custom Instrumentation:**If OpenTelemetry is too heavy or doesn't fit your needs, you can implement custom instrumentation for your Go Kafka microservices.- Create custom functions or wrappers around Kafka producer and consumer libraries to record trace data.- Manually create and propagate trace context in your messages.- Send trace information as custom headers or metadata within Kafka messages.3. **Third-party Libraries:**Some third-party Go libraries and frameworks may offer built-in support for distributed tracing. Check if any of these libraries align with your technology stack and can help with tracing Kafka messages.4. **Integration with Existing Dynatrace Instrumentation:**Since you are already using Dynatrace OneAgent for Java, consider ways to integrate Go-based tracing into your existing Dynatrace environment. This may involve custom scripts or integrations to bridge the gap between Go-based tracing and the Dynatrace ecosystem.5. **Collaboration with Dynatrace Support:**Reach out to Dynatrace support or your Dynatrace account manager to inquire about any updates or upcoming support for Go Kafka. Dynatrace may have future plans for Go instrumentation, and they can provide guidance or beta solutions.In any case, regardless of the approach you choose, the goal is to ensure that trace context is correctly propagated within your Kafka messages so that Dynatrace can correlate requests across different microservices, regardless of the language they are implemented in. Be prepared for some development effort to instrument your Go Kafka applications and ensure that trace information is correctly captured and reported to your observability platform.

	Dynatrace Professional Certified


----------------
306.2:

Thank you, One more question around this, if we have the OneAgent on the Go service with deep monitoring. Can we instrument the Go kafka tracing through the OneAgent detection and transmission or do we have to leverage the Dynatrace OTEL Metrix Exporter method? Since there is a cost in metric units for us to leverage exporters but when using the OneAgent OpenT* Sensor method, there is no cost since the OneAgent is handling the transmission and protocols within the trace. 

----------------
307.1:

Great Tip! thanks @AntonioSousa 

	-Chad


----------------
307.2:

Hello Antonio. So does that mean that these codes can be removed without problem for Apdex issues?

----------------
307.3:

As always, I also got this exotic. Does anyone know some undocumented JS agent flags like cux = 0 that could help in this case and remove this status codes from application\affecting application?Customer faced with problem that these JS codes impact on customer "best frontend code ever".Regards,Alex Romanenkov

	DT_NGINX_ALL_WHITELISTED=1


----------------
307.4:

@Romanenkov_Al3x Did you remove them from the error detection rules for the web application?

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
307.5:

Hi Julius.I have already removed this rule, but it didn't help. Customers code works only without JS agent loaded on page. Problem related to file uploading when agent is injected and customer code look like works without "No response" http codes.Dynatrace documentation:For applications created with Dynatrace version 1.238+, the RUM JavaScript reports some request errors using custom status codes 970–979 when the real HTTP status code can't be captured. Note that these custom status codes are not real HTTP status codes; they just mean that the RUM JavaScript detected an error fired by the framework you use. Customer wan't change his "very good code" because it's insanely expensive.I have already checked behavior with extended log of JS agent loaded on page. Already checked all information from support archive and HAR sessions of problematic behavior.Also - I have tried to exclude this page with injection rule. It also didn't help Regards,Alex 

	DT_NGINX_ALL_WHITELISTED=1


----------------
307.6:

So the issue is the web application does not work properly when RUM JS code is injected? Or do they complain about seeing the 97x errors in the waterfall?

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
307.7:

Yes, the issue is that the web application does not work properly when RUM JS code is injected.I see 97x errors in problematic sessions. 

	DT_NGINX_ALL_WHITELISTED=1


----------------
307.8:

Then you should open support ticket for that. Most likely the application is written in a way that including the RUM breaks it. The 97x errors are just the effect of the application itself not working.I'd not recommend turning off the capture of 97x errors.

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
307.9:

Thanks. I will.

	DT_NGINX_ALL_WHITELISTED=1


----------------
307.10:

What was the outcome of the support ticket?  I'm seeing the same issue. Thanks!

----------------
308.1:


Create a Threshold Alert: Once you have the custom log metric, you can set up an alerting profile in Dynatrace to trigger an alert when the metric exceeds 100,000 logs in a 24-hour period. Here's a general outline of the steps:a. Navigate to the alerting configuration section in your Dynatrace account.b. Create a new alerting profile or use an existing one.c. Configure a new alert condition. Choose the custom log metric you created in step 2 and set the threshold to 100,000 logs.d. Define the alerting criteria, such as the evaluation interval (e.g., every 5 minutes) and the number of consecutive violations required to trigger an alert.e. Configure alert notifications to be sent to the appropriate teams or individuals when the condition is met.

	Dynatrace Professional Certified


----------------
309.1:

I dont see it in the built in, but would be a great RFE 

	-Chad


----------------
310.1:


Hi,Yes, you can configure service failure detection.Best regards

	Consultant


----------------
310.2:

Excellent thank you   

----------------
311.1:

We have the same need to be able to export a subset of logs to our SIEM solution or even Cloud storage for archiving or data analytics. 

----------------
311.2:


Hi, You should try this Envirnment v2 API. It is early adopter... I have never used it but looks promising.   I guess this is the most important part of the GET log export. Log Monitoring API - GET export logs | Dynatrace Docs  Log viewer | Dynatrace Docs I hope you can use it such purposes. Best regards,Mizső 

	Certified Dynatrace Professional


----------------
311.3:

Hi,I am trying this api call, but i struggle on how to send the query in the body. i tried with a json body like this:{"status":"ERROR"}as a response i get also log entries with status "INFO".The manual somehow doesn't explain how to setup the query

----------------
311.4:

ok, just found out that i need to add it to the paramaters of the API call 

----------------
312.1:

interesting method. You could cut out the gateway and just leverage the Dynatrace alerting via email and supply the carrier @ address and phone number to get SMS Messages on users phones. 

	-Chad


----------------
312.2:

We have fixed this using vendor's provided Rest API and custom payload. API:https://xservices.rich.sa/RiCHClientServiceREST.svc/SendSmsToList Payload:{"username": "******","password": "******","Sender": "***","Text": "{{ProblemID}} - {State} - {{ProblemTitle}}","Array": ["****","****","****"],"MsgBodyType": 0} 

----------------
313.1:

easy fix, your token dosnt have the needed read access. Go back in t your Dynatrace UI and make a new tokens with the access as defined in the error message. Existing tokens you cant add permissions to, so tokens and permissions will always be net new FYI. 

	-Chad


----------------
314.1:

Thanks for sharing this @Nick-Montana 

	-Chad


----------------
315.1:

Thanks for sharing this! 

----------------
316.1:

Thanks for sharing this, It would be nice if the system did reference which rule was being triggered for denial of deep monitoring, otherwise you have to kind of comb through them all. 

----------------
317.1:

Hi,1. Make sure you restart the processes.2. I think the rule may be case sensitive.Regards,Bradley

----------------
317.2:

@McVitas,I would say in this case that you open a Support case, if you haven't done already. Looking at the logs will be essential here, and they should be able to help you.

	Antonio Sousa


----------------
317.3:

I agree with Antonio

	Have a nice day!


----------------
318.1:

Hi,Maybe this other thread is useful.Best regards

	Consultant


----------------
319.1:


This means basically means OneAgent was unable to capture all the information. First, check if you are running a supported version of NGINX and then you can reach out to Dynatrace One to provide you with more detailed information on why this is happening. 

	Certified Dynatrace Master | Alanata a.s., Slovakia, Dynatrace Master Partner


----------------
320.1:


By default the sql statements are im miliseconds.but when a trace is saved to either a file or a database table, the Duration column value is written in microseconds

	Dynatrace Professional Certified


----------------
320.2:

Hello @natanael_mendes Thank you for your comments. Are you referring to the MDA or log viewer elapsed time? Is the screenshot I shared will be considered as milliseconds?Regards,Babar

----------------
321.1:


Hi Ellery,I do not think that there is a way currently to format the 'Single Value' to not append the 'k'; however, if you look at the value under the 'Table' tab, it should show you the detailed number that was collected from the count() call. I will also add that in Grail Notebooks, you are able to add more Formatting options as oppose to the Advanced Views in logs. The output there should show you the value as a single number without the appending 'k' if you deselect 'View value formatter'. Cheers, Taylor

----------------
322.1:


This is not possible, both the driver class name and the connection string are built for MySQL. So we don't support MariaDB at this time.You do have the option to edit the extension code and add this driver and connection string (making the extension unsupported), or get in touch with us (extensions team) for a paid engagement where we can add that support for you. You can get in touch with us via your account manager

----------------
322.2:

Thanks @david_lopes 

	The true delight is in the finding out rather than in the knowing.


----------------
322.3:

Hi @DanielS, I know of one case where they successfully connected to MariaDB using the standard MySQL option. Instead of using jdbc:mariadb://localhost:3306/mydatabase for the connection string (which failed, by the way), they tried jdbc:mysql://localhost:3306/mydatabase and it worked.It's worth a shot, but if it fails, pick an option that David suggested 

----------------
323.1:

Hi, I think it may be best to open a ticket with Dynatrace support team.https://support.dynatrace.comRegards,Bradley

----------------
324.1:


Setting up routing for problem alert notifications in Dynatrace to the appropriate Platform or Application Support team is essential for efficient incident management. Here are some best practices for doing this:1. **Understand Your Teams and Escalation Paths:**- Before setting up routing, ensure you have a clear understanding of your organization's support teams, their responsibilities, and the escalation paths for different types of issues. This will help you determine which team should receive which alerts.2. **Custom Alerting Profiles:**- Create custom alerting profiles within Dynatrace based on your teams or applications. For example, you might have an "Application A Support" alerting profile and an "Infrastructure Team" alerting profile.3. **Alerting Rules:**- Configure alerting rules within each alerting profile to define the conditions under which alerts should be triggered. These rules should be specific to the needs of each team or application.4. **Notification Channels:**- Set up notification channels within each alerting profile. Notification channels define how and where alerts are sent. Common notification channels include email, SMS, Slack, and custom webhooks.5. **Integration with Incident Management Tools:**- If your organization uses incident management tools like ServiceNow, JIRA, or PagerDuty, integrate Dynatrace with these tools to automate incident creation and assignment. This ensures that alerts are routed directly to the appropriate support teams.6. **Define Escalation Policies:**- Define escalation policies within your incident management tools or within Dynatrace itself. These policies should outline the steps to take if an alert isn't acknowledged or resolved within a certain timeframe. Escalation may involve notifying higher-level teams or personnel.7. **Team and Role-Based Access Control:**- Implement role-based access control in Dynatrace to restrict access to specific environments, applications, or alerting profiles. This ensures that only the relevant teams have access to the alerts that concern them.8. **Regular Review and Testing:**- Periodically review and test your alerting configurations and routing. Make sure alerts are reaching the right teams and that your escalation policies are effective.9. **Documentation:**- Maintain documentation that clearly outlines the alerting and routing procedures. This documentation should be easily accessible to all team members involved in incident management.10. **Training and Onboarding:**- Ensure that team members are properly trained and onboarded regarding the alerting and incident management processes. This includes understanding how to respond to alerts and follow escalation procedures.By following these best practices, you can effectively route problem alert notifications to the appropriate Platform or Application Support teams, improving incident response and resolution times in Dynatrace.

	Dynatrace Professional Certified


----------------
325.1:

Thank you for sharing this @Dyna_Patrick 

----------------
326.1:

Hello @Mat-Moo you can use entity selector to tags your services running on AWS, in my case type(SERVICE),fromRelationships.runsOn(type(AWS_LAMBDA_FUNCTION),fromRelationships.isAccessibleBy(type(AWS_CREDENTIALS),awsAccountId("XXxxXxxxxXXXX")))  

	The true delight is in the finding out rather than in the knowing.


----------------
326.2:

Thanks, it kinda makes sense, but I'm still not there. I'm using ECS Fargate on AWS, [API requests] if I get the ECS service entityId, I can see a link to the Host, and the host should give me the ability to check AWS accountID? Could I use the activegatewayId as the MZ definer? Be nice to have an easier way to explore relationships etc. except via api post request 

----------------
326.3:

If you are using Fargate, I wrote the following article. It would be easy to separate in host groups and later assign host and services to MZ. I'm doing that. AFAIK you can't use AG id.

	The true delight is in the finding out rather than in the knowing.


----------------
326.4:

We deploy the same container over all the AWS estates, do adding to the container doesn't make sense to me?Your original reply makes sense, I'm just struggling with the syntax - If I understand this, I need to follow the tree, Service -> Host -> account id, I don't use lambda but I can see that the fromRelationships connects to a HOST, so I thought i could do something liketype(SERVICE),fromRelationships.runsOn(type(HOST),fromRelationships.isAccessibleBy(type(AWS_CREDENTIALS),awsAccountId("XXxxXxxxxXXXX")))

----------------
326.5:

@Mat-Mooyou need to query the entities API to have all valid relationships but based on what you say:type(SERVICE),fromRelationships.runsOnHost(type(HOST),fromRelationships.runsOn(type(EC2_INSTANCE),fromRelationships.isAccessibleBy(type(AWS_CREDENTIALS),awsAccountId("XXxxXxxxxXXXX")))) Hope it helps!!!

	The true delight is in the finding out rather than in the knowing.


----------------
326.6:

All starting to click, but so close but so far. When I use the above and do preview I get no matching entities. Looking at my API responses, runsonHost is good, but then runsOn(type(EC2_INSTANCE) - nothing I can see in the api responses. In fact the fromRelationships only contains a single item. which is a RELATIONAL_DATABASE_SERVICE.The service is linked to a PROCESS_GROUP which has the AWS_CLUSTER name, I'm wondering if I can use that property metadata to link instead? but this is where my entity selector syntax lets me down - type(SERVICE)->fromRelationship(PROCESS_GROUP)->isAccessableBy(typeAWS_Credentials),awsAccountID("XXX"))Thanks for help so far btw

----------------
326.7:

Hi @Mat-Moo under {{baseUrl}}/entityTypes?pageSize=500 you can see the relations. But may be this approach is better. type(SERVICE),fromRelationships.runsOn(type(PROCESS_GROUP),metadata("AWS_ECS_CLUSTER:arnecs:us-west-2:XXXXXXXxxxXXXXXxxXX"))  

	The true delight is in the finding out rather than in the knowing.


----------------
326.8:

I've just realised the ARN includes the AWS account id, so it could be as simple as type(SERVICE),fromRelationships.runsOn(type(PROCESS_GROUP),metadata("AWS_ECS_CLUSTER:*XXX*")) - but now I can't figure out the wildcard selection (Not sure it's possible) - or even metadata.startsWith("AWS_ECS_CLUSTER:xxxx"))

----------------
326.9:

Unluckily it isn't possible to use Wildcards at that level.

	The true delight is in the finding out rather than in the knowing.


----------------
326.10:

BTW your last answer is almost perfect, but with 20+ clusternames, would be hard to maintain, hence the wildcard

----------------
326.11:

type(SERVICE),fromRelationships.runsOnHost(type(HOST),fromRelationships.isNetworkClientOfHost(type(RELATIONAL_DATABASE_SERVICE),fromRelationships.isAccessibleBy(type(AWS_CREDENTIALS),awsAccountId("XXXXX"))))Bit messy but works - I have some services that use non-relational DB's though so need to look at those now as well. In the meantime, looking at the one-agent see if I can inject a tag to make life easier

----------------
327.1:

When you are creating a custom integration with webhook you have a few options, one of which is not to alert if the problem occurs again, which is probably what is happening in your environment. I recommend disabling it to avoid this barrage of notifications  

	Dynatrace Professional Certified


----------------
327.2:

Hi @natanael_mendes ,Thanks for replay and proposal.Actually this is how we set it up:... "webHookNotification": {      "acceptAnyCertificate": true,      "notifyEventMergesEnabled": false,      "notifyClosedProblems": false,  ...Still not working   

----------------
327.3:


I got an advice from DT Support to open RFE for it as "it works as designed". Hence: Ability todisable WEbhook activation in case of reopening of the Problem - Dynatrace Community

----------------
328.1:


Hi,Action means how many actions of a certain type you have per minute on your application. (For example, there are 1.63 shares of /Journey per minute.)Errors means how many JS errors you have per minute for that action per minute.You can find more details here: https://www.dynatrace.com/support/help/platform-modules/digital-experience/rum-concepts/user-actionsRadek

	Have a nice day!


----------------
328.2:


Totally with @radek_jasinski but I think the number of errors is referring to all types of errors, so that would be request, JavaScript and custom errors for user actions. Good example is this one: In the list it has 1.87 errors per minute. If I go to the user action overview, it gives me the same amount of error per minutes but the graph shows that these errors are almost exclusively request errors. And this means the number is also equal to the number of CDN errors, 3rd party errors and 1st party errors combined    

	A Dynatrace Professional nerd working for Eviden


----------------
328.3:

@marina_pollehn thank you for expanding my answer 

	Have a nice day!


----------------
329.1:

Hi @Saharnir,I'm trying to understand the scenario, but I think you can go to the application's advanced setup and specify the source path for loading the JS. also, you can Specify the path where the JavaScript tag should send monitoring data, such as adding the activegate as endpoint

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
329.2:

Site 1: amazon.com - OA is installed, and JavaScript downloads are working perfectly. You can observe the URLs like https://amazon.com/ruxitagent......js However, after a few seconds, the site redirects you to the login site, mylogin.amazon.com, which doesn't have OA installed as it's an IDM service. Due to this automatic redirection, you can notice that the URL for downloading the JavaScript has changed. It now appears as mylogin.amazon.com/ruxitagent......js, and this change is a result of using relative URLs.After completing the login process, the customer is redirected back to the initial site, amazon.com. I hope this explanation clarifies the situation.  

----------------
330.1:

@jmmatia1 I don't quite understand what you would like to achieve:) Maybe describe your issue in more detail?Radek

	Have a nice day!


----------------
330.2:

Just as there are metrics that exclude maintenance windows:Availability rate - excl. maintenance windows (by location) [browser monitor].I would like to be able to configure a VM to exclude response time (performance) metrics from maintenance windows when there are server reboots

----------------
330.3:

Unfortunately, there is no option in the Maintenance Windows settings that you are looking for. This can be set at the host (or group host) or process (or group process) level. Alternatively, try to narrow the area with tags, but only to the level of a single process.

	Have a nice day!


----------------
330.4:

I believe you can achieve that by using tags, please check the below document for that.https://www.dynatrace.com/support/help/shortlink/maintenance-window-define#scope 

	Dynatrace Certified Professional - Dynatrace Partner - Yourcompass.ca


----------------
330.5:

Yes, but he will not narrow down to a specific metric (Response Time) - as I wrote

	Have a nice day!


----------------
331.1:

Hi,I cannot find any specific entry in Dynatrace Hub.I would say you are right.Best regards

	Consultant


----------------
331.2:

Hi,If you find that one of the technologies used in this application is JavaScript, you can try using the Dynatrace RUM API. However, I do not give any guarantee that it will work.Radek

	Have a nice day!


----------------
332.1:


Not yet possible but there is a workaround – Quick workaround: Deploy the app with a different id / in a different DT environment, so you can test the production build there.

----------------
332.2:

Its been a year since the last update, is there an API sandbox avaialble yet?

----------------
332.3:

hi @netfreq 
What do you mean with "API sandbox"? can you please elaborate?
There is an environment called "Discover Dynatrace" to which everyone has access to and can explore it: https://wkf10640.apps.dynatrace.com/ . But you are not allowed to deploy or install new apps.
Best,Sini

----------------
333.1:

Hello,
 
Here is the documentation for the Custom DB Query extension.
 
Custom Database Queries | Dynatrace Hub
 
I just wanted to confirm that those were the steps you were following, you have the active gate set up and can communicate with it / have downloaded the extension to it, but you're getting errors on being able to connect to the database within the dynatrace extension? 
Thanks

----------------
333.2:

Hello,Yes, I have followed the same steps mentioned in the documentation, still getting the error. Can you please check once.Thanks,Bhargav

----------------
333.3:

I have the same issue

----------------
333.4:

The error message you're encountering suggests that there is a problem with the communication between your Dynatrace Generic DB Query Plugin and the MySQL database. This issue can be caused by various factors, and here are some steps to troubleshoot and resolve it:1. **Network Connectivity and Firewall Issues:**- Ensure that your Dynatrace server and the MySQL database server can communicate over the network. Check for any firewall rules that might be blocking the connection.- Verify that the port you specified in the plugin configuration (typically 3306 for MySQL) is open and accessible from the Dynatrace server.- If your MySQL database is hosted on a remote server, make sure that it allows external connections and that the host and port settings are correct.2. **MySQL Server Status:**- Confirm that the MySQL server is running and accepting connections. You can do this by logging into the MySQL server directly or using a MySQL client tool.- Check the MySQL server logs for any errors or issues related to connections. Look for log files in the MySQL data directory or wherever your MySQL server is configured to store logs.3. **MySQL User Privileges:**- Ensure that the MySQL user specified in your Dynatrace plugin configuration has the necessary privileges to connect to the database and perform the required queries. You can check and grant privileges using the MySQL `GRANT` statement.4. **MySQL JDBC Driver:**- Verify that you are using the correct JDBC driver for MySQL. In your case, you are using the `com.mysql.cj.jdbc.Driver`, which is appropriate for MySQL 5.7. Ensure that the JDBC driver JAR file is included in your Dynatrace environment and that it's compatible with the Dynatrace version you are using.5. **Connection String Configuration:**- Check the connection string in your plugin configuration. It should include the correct hostname or IP address of the MySQL server, port number, database name, username, and password.6. **Dynatrace Plugin Configuration:**- Review your plugin configuration in Dynatrace and double-check that all required fields are filled in correctly. Ensure that there are no extra spaces or special characters causing issues in the configuration.7. **Test Connection:**- Some plugin configurations provide a "Test Connection" or "Test" button. Try using this feature to validate the database connection from within Dynatrace. It can help identify specific issues with the configuration.8. **MySQL Server Version Compatibility:**- Make sure that the MySQL server version you are connecting to is compatible with the JDBC driver you are using. The `com.mysql.cj.jdbc.Driver` is suitable for MySQL 5.7, but if you upgrade to a newer version of MySQL, you may need to update the JDBC driver.By systematically checking these points, you should be able to identify and resolve the issue that is preventing your Dynatrace Generic DB Query Plugin from connecting to your MySQL 5.7 database. You can see the documentation page herehttps://www.dynatrace.com/support/help/setup-and-configuration/technology-support/dynatrace-extensio...

	Dynatrace Professional Certified


----------------
334.1:

Hi @Gerbert Did you assign your AG to my-group? If you filter your Active Gates by groups  under deployment status do you see your AG? Yos

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
334.2:

Hi @Yosi_Neuman,Thanks for the response. Yes, I can confirm that I was able to assign the AG to the group. I only have one AG and group as of the moment.

----------------
334.3:

And your active gate shows under modules extension 1 & 2 enabled?  

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
334.4:

Yes, they are enabled. I attached the screenshot.

----------------
334.5:

Ammmm .... contact support via in product chat or open a ticket Yos 

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
334.6:

Just an update. After talking to support, I reinstalled the ActiveGate and it worked.

----------------
335.1:

This month's challenge is an easy one! But difficult because there are so many places left where I would love to go! As I got one off my list this year, here are my Top 10:Rio de JaneiroIcelandPragueCanadian Rocky MountainsMaldivesSantoriniMachu PicchuHawaiiIbizaBudapest

	Antonio Sousa


----------------
335.2:

Prague and Budapest are perfect city break locations - and not so distant, highly recommend them!

----------------
335.3:

Hooo Love it. I want to visit in the next coming years:1- Seychelles.2- New Zealand: Auckland, Queenstown, etcss.3- Pérou: Machu Picchu.4- Scotland: a big trip in much places.5- Ireland. 

	Sharing Knowledge


----------------
335.4:

Ireland rocks! They really call it a "green island" for a reason, it's so relaxing to travel around rural areas there 

----------------
335.5:

 I don't have a lot of places on my list but the following cities and countries are always in my mind and I hope to travel to someday:1- Osaka, Kyoto, Tokyo - Japan2- Seychelles3- Napoli - Italy

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
335.6:

My very first place is not a place in fact, but the reason why. I just want to see the northern lights... just that.Anywhere where I can see the northern lights.Then I would visit some places with a beautiful beach view.FijiHawaiiPhilippinesAnd then, some place with snow.SwitzerlandNorwayFinlandSo, if Norway was also a beach place, I would list only that country to my list 

	Site Reliability Engineer @ Kyndryl


----------------
335.7:

Huuummm, beach and snow at the same time??? This is not an easy one.But one of the most interesting places where I've been is Marakesh, in Morocco. You've got the Atlas mountains very near, with Oukaïmeden being the highest ski resort in Africa. And golden sandy beaches are not far away! So, it might meet your requirements, with additional things too!Additionally, it's where I had the most surreal temperature experience: 46ºC, very low humidity and windy. Got in the pool, it was OK, but when I got out, I started shivering with cold! It lasted about 30 seconds. I couldn't believe it, so I got in the pool again  I had to think a little bit what was going on, so I shivered several times, in and out of the pool  To understand what was going on, my previous experiences with zeers helped a little bit 

	Antonio Sousa


----------------
335.8:

LOL, I am imagining you getting in, getting out the pool and taking notes on a notebook for experience purposes.I remember when I went to Chile, San Pedro de Atacama, in the geysers, outside around -9ºC, inside pool (thermal waters from underground) around 40ºC. It was a pain to get out and put clothes on. And I have it on tape, https://youtu.be/JSgd2vM2_jc?t=96 

	Site Reliability Engineer @ Kyndryl


----------------
335.9:

Let's kick the temperature difference a little bit higher? How about entering the 300 Club? https://en.wikipedia.org/wiki/300_Club

	Antonio Sousa


----------------
335.10:

Iceland should tick three boxes off your list: snow , beaches (black sand!)  and northern lights!  

	The only constant is change. Finding ways for great things to happen!


----------------
335.11:

Hi,Difficult answer but:  Tokio, Japan.  Pekin, China.  Paris, France.  Tenerife, Spain.  New York, USA.Best regards

	Consultant


----------------
335.12:

I'd go with the following:
1. New Zeeland, preferably with a helicopter to the places where they shot Lord of the Rings.
2. Iceland during a northern light. Even though I'm from Sweden I never saw a really clear one. Iceland seems like a great place to see it first
3. Hawaii, the relaxed island vibe seems great
4. One of the Caribbean islands, perfect beaches and crystal clear water sounds like a nice vacation

----------------
335.13:

Last month there were northern lights visible across half of Poland, sadly the sky was rather cloudy. Seems like I'll need to travel somewhere above the Polar Circle to see this phenomenon after all 

----------------
335.14:

This is a good one ! Still waiting for the opportunity to visit Lapland and ride a dog sled And definitely will want to visit again:The Rocky Mountains with RVNorthern India on a motor bike Hạ Long Bay with a cruise ship Drive slowly all The Pacific Coast Highway Road Trip Track by foot from the old city of Jerusalem to the deepest place on earth the Dead Sea Now I really need a vacation  

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
335.15:

I love to travel, and out of many places I want to go, I chose three places.1. Montreal, CanadaMy daughter was studying abroad in 2019 at McGill University in Montreal. She often told me about the charm of Montreal, which is called the "Paris of North America."2. New York Yankees StadiumI like baseball, so it's a place I'd like to visit once.3. Grand CanyonIt happened in 1996 when I visited the United States on my honeymoon. My wife and I flew from Las Vegas to the Grand Canyon on a small plane. However, due to bad weather, we were unable to land at the airport and the plane turned back, which was very disappointing. It's been a long time since then, but I hope to visit the Grand Canyon one day.

	T.Shirai IIM Corp. Osaka Japan


----------------
335.16:

In a nutshell...I would love to go everywhere and see everything! 

 When passion meets people magic and innovation happen. 


----------------
335.17:

My personal top 5 places  :1. Tahiti2. New Zealand 3. Hawaii4. Canada5. Antarctica 

	Observability consultant - Dynatrace Associate/Pro/Services certified


----------------
335.18:

My list in no particular order: - Maldives- Greece- Austria- Hawaii- ParisWe are going back to Slovakia in about a month and will be flying into Austria. Maybe we will have some time to visit the beauty of Austria  

	-Chad


----------------
335.19:

Seems like you're having a outstanding passion for Europe, Chad!

----------------
335.20:

How about visiting any of the Dynatrace offices in Austria? Vienna, Linz, Graz, or Innsbruck, for example? 

	Keep calm and build Community!


----------------
335.21:

Oh boy, so many great options listed above! So many destinations I'd like to see one day 
 
But if I had to come up with a list:
1. Norway - the last country in Scandinavia I'm yet to visit. I'm so fond of Sweden and Denmark, no doubt that I will love Norway too!2. Iceland. Seems like such a magical place, with black sands, blue ice and northern lights 
3. USA: would love to have an opportunity to go on a road trip all over the states one day, to hike in as many national parks as possible, and see some locations from the movies as well.
4. Japan. From stories and videos I've seen, it's another world! Such a different culture that I'd love to dive in!
5. Madagascar. For the name itself (and the cartoon ), but I'm sure there will be lots of amazing stuff to see and experience as well.
 

	The only constant is change. Finding ways for great things to happen!


----------------
335.22:

My bucket list:Alaskan cruiseWrigley Field (Chicago Cubs game)RomeIsrael as an adult (I went as a kid)Australia

	Dynatrace Certified Professional


----------------
335.23:

I have been a traveler since I was of legal age, but my pending places are:JapanEgyptGreeceNorwayGermany

	The true delight is in the finding out rather than in the knowing.


----------------
335.24:

Some of the favorite places I already visited are Thailand and Scotland.Still on the bucket list:Sout KoreaJapanNetherlands IcelandSo many more for the latter list, can't mention them all 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
335.25:

Don't you live around the corner from the Netherlands?  If you ever decide to come you can drop me a message and I can point out some things to see.

----------------
335.26:

Yes, it's ~7h by train so not really sure why I haven't made it yetThanks will pick you up on that when I finally make it 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
335.27:

It's tricky to choose, but here are the places I'd love to see:Tierra del Fuego & Patagonia, ArgentinaLofoten Islands & Northern Lights, NorwayReykjavik & volcanoes, IcelandTokyo & Mount Fuji, JapanPotala Palace, TibetQuébéc, CanadaAtlas Mountains, MoroccoThe coast of Oman, by motorcycleShipwreck Lodge on the Skeleton Coast, Namibia

----------------
335.28:

Such a solid selection, I can add all of these positions to my list as well!

----------------
335.29:

Hi @derick_hewetson this is a lovely trekking at the end of the world .

	The true delight is in the finding out rather than in the knowing.


----------------
335.30:

When heading from Tokyo to Nagoya on the Tokaido Shinkansen, you can see Mt. Fuji on the right side of the direction of travel, and on the left side when heading from Nagoya to Tokyo. But only when the weather is fine.

	T.Shirai IIM Corp. Osaka Japan


----------------
335.31:

Very difficult to choose only five: 1.  See the Stromboli volcano again but in this case at night,2.  Island of Madeira3.  Iceland4.  Route665.  Dubai Aura Skypool

	Certified Dynatrace Professional


----------------
335.32:

Regarding Skypools, I personally would love to see one day Marina Bay in Singapore, even more exiting views guaranteed!

----------------
335.33:

EasyJapon (Osaka, Tokio)  Norway (northen lights)  Iceland (black beach)  Argentina (The land of Fire)  

----------------
335.34:

1.  French Polynesia (cocorico!)2.  Japan3.  Egypt 

	Observability Engineer at Phenisys - Dynatrace Professional


----------------
335.35:

Places I want to visit1. Italy 2. Greece 3. Thailand4. Japan5. Egypt6. Hawaii (been there already but want to keep going back)

----------------
335.36:

Well, this one's hard... because when you live in a place as beautiful as Palmela, you don't even dream of going out  Whenever we go out and then return, there's no words to describe the feeling of seeing our amazing Castle appearing on the horizon... that's when you know you're home  However, I do have some places I would like to visit (even knowing I will be homesick for the duration of the trip  ).Some of them I see already here on the list, but here goes:Positano, Italy  Santorini, Greece  Route 66, USA  Bali, Indonesia  Kakslauttanen, Finland  

	Best regards, Pedro Deodato


----------------
335.37:

Hi,You hit it right with the topic of the thread in my person's case I just returned from a month-long motorcycle trip through southern Europe with my fiancée. We rode without having a plan for the whole trip and how much time we would spend in a particular place. If we liked it we would stop for a longer period of time, and otherwise we would escape further even on the same day (as we did in Ksiamil (Albania)). We tried local cuisines, slept in strange places, helped with Parma ham production and in the olive grove. We didn't think about anything related to work and everyday life. Back to the days of school vacations and carefree days.Below is the route of our trip:Warsaw - Znojmo (Czech Republic)Znojmo - Belgrade (Serbia)Belgrade - Sarajevo - Mostar (Bosnia and Herzegovina).Mostar - Korcula - Dubrovnik (Croatia).Dubrovnik - Kotor - Budva - Vlora (Albania).Vlora - Corfu (Greece)Corfu - Thessaloniki (Greece)Thessaloniki - Istanbul (Thrace)(Ferry) Istanbul - Athens (Greece)4 days in southern GreeceZakinthos (2 days)Kefalonia (2 days)(Ferry) Patras to Brindisi (Italy)Sicily (4 days) (Italy)Messina - Naples (Italy)Naples - Roma (Italy)Northern Italy (Bologna, Pisa, Milan, Garda)A few days back in the Polish Jura Krakowsko-Czestochowska.Next year we are planning the same one-month trip only in India. And this year still a mass of shorter and longer trips combined with remote work - eh too bad we already have a lack of available vacation PS: For the trip I packed as a spare Dynatrace socks (it turned out that I didn’t do laundry beforehand xD). Special motorcycle socks didn't make it and were terribly uncomfortable. My everyday choice was just DT socks. Send me more of them because they are awesome for a motorcycle - I don't know how this is possible, but it is xD      

	Have a nice day!


----------------
335.38:

That's an amazing experience! I'm dreaming about a similar road trip to explore Balkans, in my case in the meantime I want to include Romania, Bulgaria, Northern Macedonia, Albania, and Montenegro. I have a prepared map for that journey, waiting for a proper time 

----------------
335.39:

I recommend it - you can get an amazing break from work, etc. If you would like I can share a more detailed route 

	Have a nice day!


----------------
335.40:

Bike photo, I need to see your bike photo!!!

	Site Reliability Engineer @ Kyndryl


----------------
335.41:

Hehehe no problem! Catch them    

	Have a nice day!


----------------
335.42:

That's not a bike. That's a spaceship!!! My wife is pushing me to replace my current uncomfortable hard choper for a big trail, as we had in past (Tiger 800 xRX). Let's see, one day... 

	Site Reliability Engineer @ Kyndryl


----------------
335.43:

You can always have two  thank you - problem solved The new Triumphs are great!

	Have a nice day!


----------------
335.44:

Love the pics (and the socks :D)! 

	The only constant is change. Finding ways for great things to happen!


----------------
335.45:

I want to visit in the next coming years:1. Norway2. Sweden3. Germany

----------------
335.46:

My travel list will be as follows:1- Maldives2- Japan3- Iceland4- Rio de Janeiro5- Hawaii

	Dynatrace Certified Professional - Dynatrace Partner - Yourcompass.ca


----------------
335.47:

1.  Seoul, South Korea2. Grenoble, France3. Mdina, Malta4. Kyoto, Japan5. Cartagena, Spain

----------------
335.48:

I Love Travelling, My Dream Rides are  Ladakh  Kedarnath  Regards,Venkat

----------------
335.49:

1. Melbourne2. Tokyo3. Hong Kong4. Tallinn5. Oslo

----------------
335.50:

1-Paris2-Las Vegas3-Tokio (Japan at all)4-Santiago5-Ibiza

	Dynatrace Professional Certified


----------------
335.51:

AustraliaJapanMaldivesFranceSingapore

	IT Master | dynatrace Certified professional | SRE Certified | Scrum Certified | Azure Certified | https://www.linkedin.com/in/rodrigocuevas/


----------------
336.1:

You can create custom services for thislook at the documentation pagehttps://www.dynatrace.com/support/help/platform-modules/applications-and-microservices/services/serv...

	Dynatrace Professional Certified


----------------
336.2:

This is what we do today, but it's a manual task via the Dynatrace UI correct?  We need something that is baked into code, so that when our app deploys it has the proper entry points instrumented.

----------------
336.3:

Hi,You can check Monaco, custom services is supported.Best regards

	Consultant


----------------
337.1:

It sounds like you are encountering an issue with the naming of endpoints in Dynatrace when using OpenTelemetry to instrument Java applications running on Websphere Application Server. The problem appears to be related to the generic `http.route` attribute being used for the span name, which results in less informative endpoint names.To achieve more specific and informative endpoint names in Dynatrace, you can consider the following approaches:1. **Custom Instrumentation**:- One approach is to perform custom instrumentation of your Java applications using OpenTelemetry. This will allow you to define how the span names are generated. You can extract the actual endpoint information from the `http.target` attribute and set it as the span name. This way, you can have more specific endpoint names in Dynatrace.2. **Attribute Extraction and Transformation**:- You can configure OpenTelemetry to extract the relevant information from the `http.target` attribute and transform it into a more meaningful span name before it's reported to Dynatrace. This can be done using OpenTelemetry's attributes processor or a similar mechanism depending on your OpenTelemetry configuration.3. **Dynatrace Service Naming Rules**:- Dynatrace provides the ability to create custom service naming rules. You can define rules that use the extracted information from `http.target` to create more specific service names in Dynatrace. This can help in better grouping and visualization of your traces.4. **Dynatrace Custom Attributes**:- You can also use custom attributes in Dynatrace to store additional information related to the service or endpoint. This can be used to add more context to your traces and help differentiate between different endpoints.5. **OpenTelemetry Instrumentation Configuration**:- Check your OpenTelemetry instrumentation configuration for any settings related to span naming. Some instrumentation libraries allow you to customize how span names are generated. You might find an option to use a specific attribute as the span name.6. **OpenTelemetry Updates**:- Ensure that you are using the latest version of the OpenTelemetry instrumentation for Java. Newer versions may provide enhanced capabilities for customizing span names or extracting attributes.7. **Collaborate with Dynatrace Support**:- If you are still facing difficulties after trying the above steps, consider reaching out to Dynatrace support. They may have specific recommendations or updates related to their integration with OpenTelemetry.By combining these approaches, you should be able to improve the specificity and accuracy of endpoint naming in Dynatrace, allowing for better trace grouping and analysis. Remember to thoroughly test any changes in a non-production environment before applying them to your production setup.

	Dynatrace Professional Certified


----------------
337.2:

Thanks for your tips!So as far as current Dynatrace capabilities, we cannot change the naming for these endpoints?We have worked with Service Naming Rules and Service Request naming rules but in this case for Unified Services ingested with OpenTelemetry, the naming section doesn't show up inside those services. And we don't have the option right now to customize the OpenTelemetry instrumentation, we can only work with auto-instrumentation.Strange thing is, some services DO have the correct endpoint names, and others do not.

----------------
338.1:


its possible but not for all the tools, oneagents need instrument the technologies that are monitored, and other tools do the same thing.When you got a agent coflict you can see in the deployment status the agent that are in conflict See this pagehttps://community.dynatrace.com/t5/Open-Q-A/Conflicting-monitoring-agents-temporarily-deactivated/td...

	Dynatrace Professional Certified


----------------
339.1:

pas acces au formulaire....

----------------
339.2:

Salut Nicolas. Je te ferais signe quand c'est ouvert vue que tu'es intéressé

----------------
340.1:


i think that dynatrace can but in the documentation i cant see nothing about this, but you can see all technologies that dynatrace support https://www.dynatrace.com/support/help/setup-and-configuration/technology-support

	Dynatrace Professional Certified


----------------
341.1:


Hey Abnerlusung i sugest you to read this page of documentationhttps://www.dynatrace.com/support/help/observe-and-explore/logs/log-monitoring/analyze-log-data/mana... Management zones are an information-partitioning mechanism that allow you to focus on specific parts of your topology. You can customize a management zone to include a specific set of monitored entities via management-zone rules. Use one of these two methods to analyze logs generated by a management-zone entity.

	Dynatrace Professional Certified


----------------
342.1:

There is no standard OOTB dashboard that contains all of that information AFAIK; however, this is available under the Overview of the Process that has the JVM's in question. (All of the tabs below the Process selected should show you the JVM metrics.)In terms of creating a dashboard, it is possible for you to create something that contains metrics that Dynatrace natively collects. That information can be found here: https://www.dynatrace.com/support/help/shortlink/built-in-metrics#jvmYou can simply configure those metrics in the Data Explorer, then pin them to a dashboard. Links below are for Data Explorer & Dashboarding:Data Explorer: https://www.dynatrace.com/support/help/observe-and-explore/explorerDashboard: https://www.dynatrace.com/support/help/observe-and-explore/dashboards-classic/dashboards/create-dash...

----------------
343.1:

So many to choose from, so little space!
Favorite childhood game: The Legend of Zelda, Ocarina of Time.I'm currently listening to an album with a more epic take on Zelda songs: https://open.spotify.com/album/5VgztJRvkD0xFqFfMZcxDW?si=ik6WBUd-SV-FDcNFS_jOig
  
 
Most hours spent in one game: I guess an MMO, probably World of Warcraft or The Lord of the Rings Online 
Currently playing: Diablo 4 and Factorio. Diablo 4 is great in couch co-op. Factorio makes me feel like I'm an engineer in my spare time as well.
 
 

----------------
343.2:

Hard to choose but,The first one: Countles hours/days/weeks... in Diablo 2, not the new Resurected version, but the classic one, i think i replaced my mouse like 2 times because of this game. The second one: maybe the Half Life (the full series), the story is just amazing, with amazing gameplay. (and Counter Strike, because it was a mod for this game at the beginning.)        The third one: World of Warcraft, i think, this game took quite a few hours of my life... The grind was real  Now Legend of Zelda Tears of the Kingdom, and Diablo 4 ofc.

----------------
343.3:

Ooo Diablo! I completed many times each of the four parts! I love this game:)

	Have a nice day!


----------------
343.4:

This challenge topic sent me down the nostalgic rabbit hole, beware 
As a late-late millennial, my childhood still happened in the pre-PC games era. Instead, I had Sega console!  
Hours were lost to these games:
 Sonic The Hedgehog
 Jurassic Park’s Raptor Mode
Then a neighbour of mine got the first PS, and we got obsessed with:
 Mortal Kombat
And in my teens, of course:
 Need for speed: Underground
 Sims 1 (and 2 for a moment)

	The only constant is change. Finding ways for great things to happen!


----------------
343.5:

Remembered another one 
 Neighbour from hell

	The only constant is change. Finding ways for great things to happen!


----------------
343.6:

My gaming skills (and availability) has gone long time ago...These are the ones that still present in my mind from when I was a kid, playing in a small tube TV at my parents room;The Fantastic Adventures of Dizzy: https://www.deadpark.com/30-minute-reviews/the-fantastic-adventures-of-dizzy-nes/I started to learn english with this one. In order to complete the tasks, you should pay attention to the instructions, so to avoid being lost or enclosed somewhere in the game, I had to use a dictionary. I have a lot to thank for from this game for this. When I got my hands in a computer, these were the ones that I spent more time on.Carmageddonhttps://en.wikipedia.org/wiki/Carmageddon Believe me or not, I have learned to drive with this game. Doing exactly the opposite I was supposed to do when playing. The Incredible Machinehttps://en.wikipedia.org/wiki/The_Incredible_Machine That' another one that I remember part of my (young) life was spent out. I loved the challenges by each level.You know what.. I think I will find this one out and start playing it again... That's your fault, @Michal_Gebacki 

	Site Reliability Engineer @ Kyndryl


----------------
343.7:

I'm facing it regularly, don't blame the timeless perfection of this game! 

----------------
343.8:

@dannemca Carmageddon is awesome game @dannemca Carmagedon is awesome game. I even played it last year 

	Have a nice day!


----------------
343.9:

Not really a gamer. But I played this a lot: I recently discovered that Tetris was taken to new levels in the last decade. With hypertappers, Tetris seems to have started a whole new era, and the values obtained since then were absolutely unimaginable when I was playing it: https://tetrisinterest.com/tetris-champion/Some years ago, I was also much into chess: Nowadays, I don't play a lot...

	Antonio Sousa


----------------
343.10:

I have just watched the Tetris film yesterday. Great movie, btw.

	Site Reliability Engineer @ Kyndryl


----------------
343.11:

@dannemca,Nice coincidence!

	Antonio Sousa


----------------
343.12:

Hi, these should be in my list:Championship Manager: Season 01/02  Age of Empires II: The Conquerors  Commandos: Behind Enemy Lines  Best regards

	Consultant


----------------
343.13:

Time to make me feel old.  My favorite games are story games.  Originally they were by Sierra: King's Quest, Space Quest and Police Quest. King's Quest Space Quest Police QuestThen Links 386  I started playing games again a few years ago on PS4.  Favorites: Uncharted IV (why I got back into gaming), Star Wars Battlefront II, Spider-Man, and Red Dead Redemption II (Hope they remaster the first one). Uncharted IV Star Wars BattleFront II SpiderMan Red Dead Redemption II (I think my favorite game of all time.  Finishing my 3rd play through right now). Notable mentions:Nintendo games: Super Mario Bros., Contra, Punch-Out, etc. https://www.denofgeek.com/games/best-nes-games-all-time-ever/PS4: God of War, Horizon Zero Dawn, Last of Us, Assassin's Creed series, Tomb Raider series. Guess I have played a few games   

	Dynatrace Certified Professional


----------------
343.14:

Tetris Zybex  Montezuma Quake III Arena Need for speed underground   

	IT Master | dynatrace Certified professional | SRE Certified | Scrum Certified | Azure Certified | https://www.linkedin.com/in/rodrigocuevas/


----------------
343.15:

Great challange! Another one where the list could go on and on For competitive I really enjoy(ed) Starcraft 2 and World of Warcraft, those probably have the most time invest as well     Favorite childhood game I agree with @Mike_L, Ocarina of Time was amazing. That also led to my triforce.   Also Knights and Merchants was really fun for an early RTS:   Currently I'm playing Diablo 4 and Factorio always comes back for me, the factory must grow!     

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
343.16:

Oh, I forgot Starcraft 2. The number of hours I spent in there with ladder, direct strike and co op must be quite substantial as well. I'm looking forward to Stormgate as it's created by many of the same people. It's been quite some time since I've been excited by a new RTS.

----------------
343.17:

Yes, excited for Stormgate as well. The dev talks for it sounded pretty good as well 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
343.18:

Getting a dose of stormgate sooner than anticipated   

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
343.19:

Nice! Congratulations 

----------------
343.20:

 Starcraft 2 

	DT_NGINX_ALL_WHITELISTED=1


----------------
343.21:

Such a great game! Not sure if I played it more or watched more games 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
343.22:

I usually fall asleep when I watch GSL\ESL\Katowice games. But this is not because the games are not interesting, only because I want to sleep 

	DT_NGINX_ALL_WHITELISTED=1


----------------
343.23:

What a lovely challenge . for me as an old Gamer (Ps3, Ps4, Ps5, Xbox and for sure PC) i have some great figures to mention: God of War, Red dead redemption and Max Payne    

	Dynatrace Certified Professional - Dynatrace Partner - Yourcompass.ca


----------------
343.24:

Currently these two ofc    And for some reason, even though it was waaaay before my time, PacMan remained a favorite.   

	A Dynatrace Professional nerd working for Eviden


----------------
343.25:

PacMan is a favorite too!

	Dynatrace Certified Professional


----------------
343.26:

What better to promote Community gamification, than games themselves, huh?  Happy to see that some of my all time favorites are already on the list!I've played World of Warcraft for SEVERAL years: my main was a very happy Tauren Warrior (tank).Met very nice people through the game, and also brought a lot of my IRL friends to play! Lots of fun!  I even got an Horde T-Shirt when I got my Mists of Pandaria expansion pack, back in 2013! For the Horde!   However, my heart will always go to the best WoW expansion ever: Wrath of the Lich King!What a blast!  Being a World of Warcraft gamer, naturally I also delved into the realms of League of Legends (back when LoL was just an excuse to have a break from WoW, while we waited for instance queues).In WoW, I was a tank and helped protect others... in LoL I've always played support: not much of a damage person, here! But I loved being a part of a team, and supporting my team (literally) throughout every match!Played LoL since Season 1, and kept playing also for several years.  In the meantime, I also played some CS:GO, but my all-time favorite FPS is, definitely, Crysis!Wonderful graphics, but - most important - very thrilling and exciting, keeps you hooked from the first minute!  Saved the best for last, the game that introduced me to what gaming is all about: living a story!Do not be fooled by my first two choices, which are online and focused on competing!Even in those, you are always either a caracter in some story or - better yet - part of a team: a team member (in every team, in every context, really) is always a sort of a character in some story (most of the times, a story much bigger than the character itself).The first game that led me to this crazy storytelling/storyliving world was a very simple, friendly but albeit wonderful game: Sly Cooper.I first got it when I was something like 7 or 8 years old, and played it at least once a year since: to revive those cheerful childhood moments, and to remind myself of what a warm feeling it is to go through with a great story!  

	Best regards, Pedro Deodato


----------------
343.27:

Finally, I've found one that plays League Of Legends! I'm a main Jungler and secondary supporter  I hope we meet sometime at the Summoner's Rift! 

	Senior Product Manager, Dynatrace Managed expert


----------------
343.28:

okay here we go1. House of the Dead (1&2)2. DX-Ball3. Need for Speed4. GTA5. Roadrash6. Lots of mobile game (Candy Crush, Subway Surfers, Temple Run)7. Bloons Tower Defense 8. Skyrim9. Dota 10. League of Legends
 
 
 
 
 
 
 

----------------
343.29:

 to League of Legends!

	Senior Product Manager, Dynatrace Managed expert


----------------
343.30:

Super Mario 

----------------
343.31:

The original Super Mario was only 40kb, and it's a classic that can't be topped

----------------
343.32:

Classic!

	Dynatrace Certified Professional


----------------
343.33:

Hi,There are three games in my memory from my school days:- Turok - Worms Armagedon - Serious Sam II Turok is one of the first games I had on my computer - I remember the guy who sold us the computer saying that if I go back and forth on the map my computer will crash xDWorks Armageddon and Serious Sam II, on the other hand, meant many hours of playing with friends from the estate.Who among you also carried the whole computer in a suitcase to play arm in arm with a friend in one room?Radek

	Have a nice day!


----------------
343.34:

Hey, how about playing some online game together? If we already have such a topic then maybe we can make a DT Community team  Any suggestions?

	Have a nice day!


----------------
343.35:

I'd be more than happy to play together Among Us!

	Senior Product Manager, Dynatrace Managed expert


----------------
343.36:

I'm in!  Anyone else? 

	Have a nice day!


----------------
343.37:

The Community is already on the topic of organizing a global Community event  That would be sooooo cool!

	Keep calm and build Community!


----------------
343.38:

Great thread already So my absolute favorite at the moment is Disco Elysium - I always loved RPGs, but this was the first one, that I really felt that I can roleplay not just from the class point of view (mage, warrior, etc.), but as a real character. If someone played Planescape Torment or the classic point-and-click adventure games in the past, they will feel at home with this one. Besides that, here is a list of my other favorites:-Elden Ring-Witcher 3 (mandatory position for everyone from Poland I guess  )-The Legend of Zelda - Wind Walker-Quake-Doom Eternal-Binding of Issac-League of Legends (more as an esport viewer at the moment)-Halo
-Hollow Knight

	If you have any questions about the Community, you can contact me at maciej.neumann@dynatrace.com


----------------
343.39:

Currently playing a lot of Diablo IV and Fall Guys, which are the complete opposite of each other :

 
 
 


Games I've played a LOT of and mean a lot to me include the Halo, Destiny, and Overwatch games:

 
 
 
 


And one of the best, unknown party games out there (which is still playable via Backwards Compatibility on the Xbox One today) is Fuzion Frenzy! 

 
 



----------------
343.40:

YESSSSS! Fuzion Frenzy was such a great game. I remember a lot of laughs, anger, and joy at the same time with this game. LOL!

----------------
343.41:

 So many great moments online with friends or at home. Also Monkey Island, Starcraft, Tetris, Duke Nukem and Zelda Series. Love to see that Factorio is on the list of many.Scoop, Someone at Dynatrace recently showed me game ports that run as an application on the latest Dynatrace. PacMan, Doom. 

	The true delight is in the finding out rather than in the knowing.


----------------
343.42:

We're also gamers at Dynatrace!
 
 
 
I'm looking forward to your games deployed at Dynatrace AppEngine!

	Senior Product Manager, Dynatrace Managed expert


----------------
343.43:

aaaaa and immortal Doom!
 
 

	Senior Product Manager, Dynatrace Managed expert


----------------
343.44:

Starcraft II  The peak of my gaming career was the solo murder of a raid boss in a very famous online MMORPG when all my teammates died. I hit him solo for 3 hours. Heroes of Might & Magic IIII don’t play anymore, HoMM3 - just watch twitch streams and fall asleep Alex

	DT_NGINX_ALL_WHITELISTED=1


----------------
343.45:

the following are my favorite games - Metal Gear Solid 3  - Resident Evil 3 & 4 - Dino Crisis 2- FIFA All Versions- Medal of Honor online 

	Certified Dynatrace Professional | Certified Dynatrace Services Delivery - Observability & CloudOps | Dynatrace Partner - yourcompass.ca


----------------
343.46:

Well, I've been playing Civilization Series since 2007. But in my early days I was addicted to Diablo, Warcraft, SimCity and Transport Tycoon.
 Transport Tycoon Civilization

----------------
343.47:

Transport Tycoon, of course! 
I had such fond memories of that game that when I decided what to do with some spare time I created my own 3d engine to make an online multiplayer spin on it.
Just found an old video I made with some updates: https://www.youtube.com/watch?v=RDW2FpxPpOw&ab_channel=StateofFortune

----------------
343.48:

I loooove Transport Tycoon, the game is still alive and well with OpenTTD, such a delightfully relaxing game.

----------------
343.49:

If anyone here plays Chess at Chess.com please add me there https://www.chess.com/member/andrelcsilva 

----------------
343.50:

Regret you haven't seen my face while scrolling through all these posts - like a child in the toy shop! So many memories and adventures, starting with Tetris and Perestroika -> Soviet Mind games   through Civilization, Heroes of Might and Magic I, II, III, and IV, and many, many more games. 
 
Currently, I'm a big fan of Riot Games - including League Of Legends, Teamfight Tactics, Legends of Runeterra, and Valorant! I'm also an e-sport fan!
 
So screenshots of two games that were not mentioned yet and that are close to my heart - Among Us - which helped to survive socializing during the pandemic and Team Fight Tactics:
 
 
 
 
 
 
 


	Senior Product Manager, Dynatrace Managed expert


----------------
343.51:

Ammm nostalgia  Prince Of Persia , Tetris & Minesweeper

	dynatrace certificated professional - dynatrace master partner - Matrix Soft Ware Division - Israel


----------------
343.52:

Tetris of course!  Minesweeper - forgot about that.  Man I played that a lot too

	Dynatrace Certified Professional


----------------
343.53:

I don't consider myself a gamer, but please let me share some electronic and computer games I have enjoyed over the years -We got an Atari 2600 as a Christmas present (1979?) - and spent many hours on Space Invaders. Sadly I disposed of this 2600 system and carts when I moved in 2003. Another hit, in the 80's this time - Coleco Electronic Quarterback. I don't know what happened to this unit.  Late 90's MS-DOS game Scorched Earth Late 90's Windows 3.1 game 'Ski Free' (or something like that).   Dopewars - late 90's early 2000's Palm Pilot era 

----------------
343.54:

Ohhh, great games, Scorched Earth was great, recently I've found Forts, a new game that reminds me of it.

	The true delight is in the finding out rather than in the knowing.


----------------
343.55:

How could I forget Scorched Earth in my list! And Worms.

----------------
343.56:

MS3

----------------
343.57:

The first of then will always be Gta SA and Gta V. But i really like to play the classic like Bomber Man 2. with this 3 games, i can say that takes 90% of my entire life gameplays.   there is also a game that looks like Gta but a brazilian version, the name is 171 and its disponible at steam in a beta version:    

	Dynatrace Certified


----------------
343.58:

thinking about this i found a duality in my classic games list, in one hand i played resident evil which for me was one of the best and scariest games at that time. on the other hand i had Crash Bandicoot, that for me was one of the funniest in my chilhood, a complete classics.   

----------------
343.59:

Oh my god, Crash Bandicoot!! Thanks for bringing back all the memories 

	The only constant is change. Finding ways for great things to happen!


----------------
343.60:

Oh....UNREAL TOURNAMENT  (1999)Amaaaazing storyline and MUSIC Probably it was the time when I fell in love with electronic sounds...UNREAL TOURNAMENT SOUNDTRACK 

 When passion meets people magic and innovation happen. 


----------------
343.61:

And my first game ever...LOTUS Lotus Esprit Turbo Challenge (1990)My first "speeding" in a red car with a joystick in my hand, driving through long tunnels...It also was the time when I fell in love, with.... cars and speed And I've just realized that maybe because of that I have a red car  with a manual gear   

 When passion meets people magic and innovation happen. 


----------------
343.62:

So many good memories!
I am a old blizzard fanatic myself so all the Diablo 2, World of Warcraft and Starcraft brings a lot of memories!
But my favorites all time are from the Final Fantasy franchise specially this master piece https://en.wikipedia.org/wiki/Final_Fantasy_VII
I spent my whole childhood playing that game. And of course:
 
 
 
A honorable mention to:
 
 
 

----------------
343.63:

I played Games on Amiga 500, PS1, PS2 and the PC - With my Brother and sister. We loved the below:
 
 
 

----------------
343.64:

Reading all of the comments....SO MANY GREAT GAMES AND MEMORIES!!! Between PC and consoles, my gaming library is around 500+ games and it keeps growing. I'd add Contra on Nintendo and Shinobi on Sega. From current gen console, I enjoyed Assassin's Creed games, Cyberpunk2077 - with all of its flaws -  and God of War games so much I opted for the collector's edition.
Yup, that's Mjolnir aka Thor's hammer .
 God of War Ragnarök
 Cyberpunk 2077

----------------
343.65:

Great success for this challenge Dofus was my first (and last) MMORPG ! So many hours on it : My first video game ever :  My first Zelda in 2001, and it still my favorite licence today:  

	Observability Engineer at Phenisys - Dynatrace Professional


----------------
343.66:

I used to play "Die Siedler" A LOT 
 
Couple of years ago I learned there is sort of a community remake, free and open source called Widelands( https://www.widelands.org/ or https://en.wikipedia.org/wiki/Widelands). It works very well already and there is versus mode. If you like games like this I highly recommend it
 
If you own a VR Headset and like CoOp games I highly recommend https://vrgiants.com/ 
 
The Person wearing the Headset plays a giant, that is chained to the ground and the other player plays a dwarf. Together you have to solve puzzles. It is done by a guy (Wolfgang Tschauko) whos Master Thesis was about bodily presence in virtual reality. I also quite like it for Teambuilding and communications training (Keep Talking and nobody explodes is also perfect for the latter but too stressful for many people).

----------------
343.67:

My favourite games of all time are 2, 

NFS Most Wanted (2005 Edition) 
FIFA (Now EA Sports FC)
 
 


I played these games for over 1000 hours, and still, it feels fresh and wanna play more and more. They bring that kid in me. 

	Love more, hate less; Technology for all, together we grow.


----------------
343.68:

What a great Challenge! So many of these submissions have brought me back to my childhood. But there were few big ones that were missing for me: Stronghold Crusader - "Not enough wood my lord", Why is there never enough wood!?  Lemmings:  Flight Simulator:  Train Simulator:  Tremulous:  

	-Chad


----------------
343.69:

Oh No! More Lemmings.    Great Great Game.

	The true delight is in the finding out rather than in the knowing.


----------------
344.1:


Hi,
We're gradually working on migrating metrics to Grail and we're at the moment working on the first Synthetic metrics. We don't have a timeline for when all of the Synthetic metrics will be available in Grail but you'll gradually see more and more of them available in Grail as we progress with the migration.

----------------
344.2:

We have slightly changed the strategy of synthetic metrics rollout.
First set of metrics will be available as a preview with Dynatrace version 269. It will cover huge majority of HTTP and 3rd monitors metrics plus basic set of Browser monitor metrics.
I will be happy to discuss reasons details of your use case, what are the main goals you would like to achieve with synthetic metrics in Grail. I would like all community participants to consider my comment as an invitation to such discussion and participation in preview. Please, leave comment under that message if you're interested in. 
 
Best Regards,
 
Jacek

----------------
344.3:

Hi Jacek !Unfortunately, I missed your response  in May ...but if you need any feedback about synthetic metrics, I'll be happy to discuss. Christophe

----------------
345.1:

I remember this can happen if you did not perform the latest Windows update - some of them are needed to run applications. So you could try updating Windows. Does running in admin mode help?There are many more options but these are the easier ones to try I guess...Otherwise you could still consider changing the timeout settings in the registry editor.

	A Dynatrace Professional nerd working for Eviden


----------------
345.2:

Hi @marina_pollehn  Thanks for the feedback, I can certainly review those items and see if we can implement them.  Thanks,Steven

----------------
345.3:

@marina_pollehn Do you know what type of changes must be made in registry for timeouts? I can certainly have the team look into that. 

----------------
345.4:

I definitely can't recall it from the top of my head anymore but I found  a small manual online which should explain the method a bit  (Personal note: You might want to do a Registry Backup before as playing with the Registry Editor can also go wrong if there is any typo or the wrong button pressed) Changing the Service startup timeout (ServicesPipeTimeout) in Windows (citrix.com)To increase the service startup time yourself, create the following registry entry:Subkey:HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\ControlName: ServicesPipeTimeoutType: REG_DWORDData: The number of milliseconds that you want to give the services to start in.To create this registry entry, follow these steps:Click Start, click Run, type regedit, and then click OK.Locate and then click the following registry subkey:HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\ControlRight-click Control, point to New, and then click DWORD Value.In the New Value #1 box, type ServicesPipeTimeout, and then press ENTER.Right-click ServicesPipeTimeout, and then click Modify.Click Decimal, type the number of milliseconds that you want to wait until the service times out, and then click OK.For example, to wait 60 seconds before the service times out, type 60000.Quit Registry Editor, and then restart the computer. Then again, no guarantee that this will solve your problem, just one of the many scenarios that could be the problem. If you managed to solve it either with this method or with the DT support pls let me know - interested in what the root cause was in the end 

	A Dynatrace Professional nerd working for Eviden


----------------
345.5:

Thanks! Will have to keep you posted.

----------------
346.1:

Hi,Unfortunately, you don't have the option to add an IP address as a placeholder in Tag Value. For DB, you have 3 options that you provided.Have you tried DatabaseHostName? Radek

	Have a nice day!


----------------
346.2:

You can also try using {Host:ipAddress}.

	Have a nice day!


----------------
346.3:

If you ingest the custom IP as custom metadata on the host or even the process/service level, you can infact dynamically tag that entity via Auto tags rules. For example:  Granted this isn't IP, but its the same principal. Now was that Metadata value may change form host to host, it will reflect in the tag. Giving us 1 Auto tag rule for every dynamic value.

	-Chad


----------------
346.4:

oooo I didn't know that option  Thanks Chad!

	Have a nice day!


----------------
346.5:

That's not being sent a custom meta data but they are in built meta data & i wanted to use them in automated tagging.

	Sai Venkatesh Nichenametla


----------------
347.1:

Hi,Can you check deep monitoring rules?Best regards

	Consultant


----------------
347.2:

Hi, I checked couldn't identify any items that disables deep monitoring in that case

----------------
347.3:


OneAgent does not inject into database processes, so what you're seeing is expected. The DB calls are instead detected from Java or .NET services calling the database. The reason why you don't see any services yet could be:1. You don't have deep monitoring enabled for the calling services2. During the timeframe there has been no activity like that (sometimes possible in test environments with low load)In your screenshot it shows 10 processes calling the database process. You can click that box to list those processes, and then drill down from there. Check the deep monitoring status of those processes, maybe they're still pending a restart for example?

----------------
347.4:

Have you verified the entries in the OA logs? Perhaps you have a problem with supporting some version of the application process that communicates with the database. Check or submit the logs.

	Have a nice day!


----------------
348.1:


Basically any entity in which you see the availability metric. SO Hosts, Processes, synthetics etc..  You'll use the API Metrics query selector to grab the values of the availability over your defined time intervals.     

	-Chad


----------------
348.2:

Thank you so much Chad , can you please provide me with some sample queries for % availability for monitors 

----------------
348.3:

Queries will be unique to your use case. My recommendation is to try it out and use the data explorer for the metric values.  Than you'll add in further filtering criteria per your use case. 

	-Chad


----------------
348.4:

Hi @ChadTurner ,In the same subject if you please can help for a specific case, I am looking for PROCESS AVAILABILITY % , and not PROCESS GROUP AVAILABILITY % I did not found it on the data explorer , is there any thing that I am missing ? thanks in advance  Mahdi

----------------
348.5:

@Mahdi24322  from the Data Explorer you'll want to search for 'Availability' and select the one that is for the Process Instances. (Cluster Version: 1.274.121.20230901-111004). Notice entity type is in fact the 'Process_Group_Instance'. Once selected you can filter and sort via the instance desired.  This can also be extended to the API via metrics. I hope this helps, let me know if you need anything additional.

	-Chad


----------------
349.1:

Hi @SOBE In this situation, I would suggest two operations to make DT more sensitive to requests with less traffic or which are more important to you:1. setting the request as Key Request.2. you can also split large services into smaller ones using custom services.Radek

	Have a nice day!


----------------
349.2:

the request was already a key request, that's whats bothering me 

----------------
349.3:

Have you tried changing the percentage threshold or time span? Perhaps you have too little deviation from normal traffic

	Have a nice day!


----------------
350.1:

Hi @sureshvasudevan,looks like the endpoint you passed to the integration is not valid.It should have a format like this e.g. /rest/api/2/issueMore Info hereIf you want to create the issue under a specific Epic you would need to pass that information in the payloadBR,Mark

----------------
351.1:

Hi If you are looking to e.g. find the process group instances (PGI) for a specific host you can use the relationships.e.g. to get the PGIs of host(s) tagged with "CF Tag" you can use following entititySelectortype(process_group_instance),fromRelationships.isProcessOf(type(host),tag("CF Tag")) Or directly from a specific host using it's own IDtype(process_group_instance),fromRelationships.isProcessOf(type(host),entityId(HOST-EA50C80CC9354652))Atm it is not possible to query multiple entity types in one call.Hope it helps.Best,Mark

----------------
352.1:

 1990 - Brasilia 2017 - California 2023 - Linz

----------------
352.2:

Love that your smile is with you through all those years!! Thanks for sharing 

	The only constant is change. Finding ways for great things to happen!


----------------
352.3:

Me Then:  Me Now: The years sure have flown!  

	-Chad


----------------
352.4:

Huge character development! 

----------------
352.5:

Time travelling. What a wonderful challenge! Since it's a holiday here in Lisbon, Portugal, I had some time to check my photos.I was bon in Canada. As a little kid, I didn't know I would be traveling so much  Some 20 years ago, I was much into geocaching... It's (or was for me) the world's most entertaining treasure hunt where you use satellites to plant/find tupperwares in the woods    This is from one of the most memorable, a geocache placed more than 20 years ago, https://www.geocaching.com/geocache/GC4B0D_the-bear-treasure, revisiting it in 2004: Still loving adventurous places. Recently, this year, at one of my dream locations: 

	Antonio Sousa


----------------
352.6:

Nice travel throughout the years, Antonio!  Now, then, and in-between 

	Keep calm and build Community!


----------------
352.7:

I don't have old enough photos of me on the phone to make it a time traveling experience. I do however have a 10 week old Samwise Greybeard, a.k.a Sammy, compared to how he looks now at 6 years old.
 
 
 
He's an Australian Labradoodle and his favorite things to do are sleeping, eating, going outside and chasing balls.

----------------
352.8:

The sound I just made at the first photo definitely wan't human 
What a cutie patootie!  And what an awesome name too!

	The only constant is change. Finding ways for great things to happen!


----------------
352.9:

No real old photos of myself. But you can see the 7 years (and 7kgs ) on Mr. Furglton and Arch: Younf Old(er)  We had named them Fedora and Arch, but Fedora turned out to be a boy  

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
352.10:

Lovely couple, the more cats the better!

----------------
352.11:

Patrick, you're not alone  I used to have a rabbit that had a female name, but it also turned out to be a boy  Now my son has a small turtle and we'll learn its actual gender in 8-10 years  My son claims the turtle is a boy and calls him as such  

	Keep calm and build Community!


----------------
352.12:

I actually had the same issue there as well! My  is 10 now, so I know it's a boy. But the name just stuck with "Kröt" (Turtle = Schildkröte in German) because I didn't want to pick a name while not knowing the gender 

	Dynatrace Certified Master, AppMon Certified Master - Dynatrace Partner - 360Performance.net


----------------
352.13:



	Keep calm and build Community!


----------------
352.14:

Two things make me notice the passage of time  more than others:

my baby sister (who's not a baby anymore)

  

and my cat Axel (who's not a little bean we brought home five years ago either)

  

	The only constant is change. Finding ways for great things to happen!


----------------
352.15:

I love my family, so here it goes, then (2002) and now (2023). still dating 2002 21 years laterWe first met in 2002, married in 2010, first kid in 2016, second (and last) in 2019.

	Site Reliability Engineer @ Kyndryl


----------------
352.16:

It's amazing to see how far I've come in my career since joining Compuware as a software engineer in 2010. I've worked hard and achieved so much, now holding the impressive title of product manager and building the content for our Perform confs!
2010 vs 2022
       

	Senior Product Manager, Dynatrace Managed expert


----------------
352.17:

Hi,Many things are changing in my life.... career, cars, bikes, girls , etc. However, my dog friend has been with me for 14 years now and is not going anywhere.PS: Well okay now there are two of them  2009       2023

	Have a nice day!


----------------
352.18:

That's really impressive age, true dog veteran!

----------------
352.19:

 
 
It's me! (2000 vs 2022)
 

----------------
352.20:

Last month I had a time travel... I'd like to dedicate this post to my elder son. He became 18 and now he is legally an adult (Hungarian legistlation). I have created him a short 30 mins ppt about his frist 18 years for his birthday party (with Yiruma piano music The Best Of YIRUMA Yiruma's Greatest Hits ~ Best Piano (HD/HQ) - YouTube).  Some pics from the slide show: First day - 2005 First keyboard - 2006 First laptop - 2008 My favourite - 2012 Little 18 - 2023

	Certified Dynatrace Professional


----------------
352.21:

Great setup for the 18th bithday, the quantity of "18s" doesn't let forget how important anniversary it is 

----------------
352.22:

 Circa 1861  Now It's been a wild ride so far...

	The true delight is in the finding out rather than in the knowing.


----------------
352.23:

A wild ride, but seems like a smile-worth one too 

	The only constant is change. Finding ways for great things to happen!


----------------
352.24:

Dynatrace - up and running over the yearsas I can only attach 5 images this is just a quick selection that shows how Dynatrace grew and the branding changed you should be able to spot me in every picture 
2007
 
 
2013
 
 
2015
 
 
2016
 
 
2022 
 
 
     

	iOS help: https://www.dynatrace.com/support/help/shortlink/ios-hub


----------------
352.25:

Even better approach towards the challenge - evolution year by year! 

----------------
352.26:

oh nooo ... there's a running pic without me 

----------------
352.27:

Only one photo, but my friend's 1990 Softail Custom next-to my 2014 Heritage Softail.  

----------------
352.28:

That 90's is awesome... it is like a Dyna without the hard tail.Great bikes!!!

	Site Reliability Engineer @ Kyndryl


----------------
352.29:

   Some people comes and goes but basketball is always with me 

	"The lion does not ally with the coyote"


----------------
352.30:

I see the sport awards are growing with you 

	Have a nice day!


----------------
353.1:


How to define service from Requests to unmonitored hosts - Dynatrace CommunitySlightly older community post but I think this is what you meant? 

	A Dynatrace Professional nerd working for Eviden


----------------
353.2:

its not this but is something similar, thanks for your answer

	Dynatrace Professional Certified


----------------
353.3:

Maybe you are looking for a Custom Device creation:  When you create a custom device informing the Unmonitored host and port (called by monitored hosts), Dynatrace will create services over this custom device and you will be able to see them in the service flow/traces.You can see this option only after you select one of the requests as filter.Is this what are you looking for?

	Site Reliability Engineer @ Kyndryl


----------------
354.1:

This is my query to see all OPEN and CLOSED events. But it doesn't work, because it's duplicating events.fetch events
| filter event.kind == "DAVIS_PROBLEM"
| filter event.status_transition =="CREATED" or event.status_transition=="RESOLVED" or event.status_transition=="CLOSED"
| sort timestamp desc 

----------------
354.2:

hi @Duran_Narbona In general Davis problems and events stored in grail are just status updates. For a further explanation please have a look here: https://community.dynatrace.com/t5/DQL/Notebook-query/m-p/211195/highlight/true#M53This query should work for youfetch events
| filter event.kind == "DAVIS_PROBLEM"
| sort timestamp, direction:"ascending"
| summarize {event.status = takeLast(event.status)}, by:{ event.id }
| summarize count=count(), by:{event.status}You can try it out hereFor further examples regarding Davis problems & events in grail, please have a look at helpBest,Sini

----------------
355.1:


Hi Simon,
With version 236 we introduced a new placeholder that allows you to include individual tags in your payload: {Tags[key]}
 
 
 
If there are multiple values with the same key it would result in a comma-separated list of the values.
 
Hope this helps,
Cheers,
Dirk

----------------
355.2:

Thanks, I will test it !

----------------
355.3:

Thanks much for sharing the news.It's a feature I have been waiting for some time -- one step forward in having a reasonable ability to customize alert messages. Thanks. Tibebe

----------------
355.4:

How can we use this feature if we have a context for a tag.[AWS]Name, [AWS] key

	Sai Venkatesh Nichenametla


----------------
355.5:

Hey, did you find any solution to this? I am facing the same issue.

----------------
355.6:

Hi Agsta,{Tags[[AWS]Name]}I passed this way in email body & it worked.

	Sai Venkatesh Nichenametla


----------------
356.1:


Dynatrace Remote Plugin Module responsible for running ActiveGate plugin moduleThe Extension Execution Controller (EEC) is the Dynatrace component running your extensions. EEC can query your local data sources when run on OneAgent, or remote data sources when run from an ActiveGate. EEC doesn't need your attention at all; it's automatically installed and managed with each OneAgent and ActiveGate instance. EEC takes care of translating all the ingested data so that Dynatrace can leverage it for our Davis AI causation analysis.  Here some Links that will help you understand more ECChttps://www.dynatrace.com/support/help/extend-dynatrace/extensions20/extensions-concepts Remote Pluginhttps://www.dynatrace.com/support/help/extend-dynatrace/extensions/development/extension-how-tos/act...

	Dynatrace Professional Certified


----------------
356.2:

Thanks for links to the documentation. I already read them just before to ask my question and still didn't understood how Remote plugin interact with Extensions.I didn't figure both functionalityRemote plugin seems embbeded in Extensions from doc point of view but appears at same level than Extension 1 and Extension 2 in ActiveGate status menu.Most valuable document i found is: activegate-extensions/introduction-to-activegate-plugins 

----------------
356.3:

With ActiveGate extensions, you can extend Dynatrace monitoring to any remote technology that exposes an interface, where OneAgent installation isn't an option. For example, PaaS technologies, network devices, or cloud technologies. ActiveGate extensions (aka Remote Plugins) are executed on ActiveGate and can acquire metrics and topology from remote sources, fully integrating new-technology monitoring into Dynatrace Smartscape and problem detection. You need some Python expertise to develop ActiveGate extensions. The Extension Execution Controller (EEC) is the Dynatrace component running your extensions. EEC can query your local data sources when run on OneAgent, or remote data sources when run from an ActiveGate. EEC doesn't need your attention at all; it's automatically installed and managed with each OneAgent and ActiveGate instance. EEC takes care of translating all the ingested data so that Dynatrace can leverage it for our Davis AI causation analysis

	Dynatrace Professional Certified


----------------
356.4:

Thanks Natanael,As far as i understand from following configure-activegate#extn1_mod , RPM (Remote Plugin Module) is the old name for Extension 1 and now there is also Extension 2rpm_enabled: Enables the Remote plugin module, which is used to run ActiveGate extensions.extension_controller_enabled: Enables the Extensions 2.0 module. Possible values: true or false.

----------------
357.1:

You can see the host group in the new page view, look. Click on properties and tags in the host page and you gon see  

----------------
358.1:

Hello @Mikhail A.I guess for the time being there is no custom category to plot something processes related including the availability.Regards,Babar

----------------
358.2:

it is strange

----------------
358.3:


At the moment, availability metrics aren't supported to be charted or alerted on, but we're working on that. Nevertheless, a number of general process metrics can be found under the metric registry Path Technology > Generic

----------------
358.4:

@Roman W. Is there update on process availability metrics? This is critical metric for any operation. I know this is available through API but why it is restricted for custom chart?

----------------
358.5:

Has there been any updates regarding Process Availability charting? I have some key processes that do not run services but the application owners would like to see when those processes stop from a dashboard perspective. I know we can turn on the alerts for graceful shutdowns but we would like a dashboarding ability for this same metric. Any info on this enhancement? 

----------------
358.6:

Chiming in here, we also would like to get process availability into a custom chart

----------------
358.7:

Is there a metric yet, for process availability? = we have the option for Process Availability Alerts at the group level.

----------------
358.8:

Is there process availability yet?  I need to create report montly for this

----------------
358.9:

Need the process availibility % as metric to use for dashboards or metrics thanks in advance

----------------
